=== TEXT EXTRACTION REPORT ===
Source: C:\Users\dhyan\Projects_All\Personal\UC-Berkley-GovernanceAI\trial3\data\The EU AI Act (1).pdf
Extraction Date: 2025-07-12 19:52:42
Content Type: pdf
Detected Language: en
Confidence Score: 0.95
Processing Time: 369.96 seconds
Metadata: {
  "pages": 204,
  "tables": [],
  "images": 1
}
==================================================

=== EXTRACTED TEXT ===
--- Page 1 ---
OfficialJournal
oftheEuropeanUnionEN
Lseries
2024/1689 12.7.2024
REGULATION(EU)2024/1689OFTHEEUROPEANPARLIAMENT
ANDOFTHECOUNCIL
of13June2024
layingdownharmonisedrulesonartificialintelligenceandamending
Regulations(EC)No300/2008,(EU)No167/2013,(EU)No168/2013,
(EU)2018/858,(EU)2018/1139and(EU)2019/2144andDirectives
2014/90/EU,(EU)2016/797and(EU)2020/1828(ArtificialIntelligence
Act)
(TextwithEEArelevance)
THEEUROPEANPARLIAMENTANDTHECOUNCILOFTHE
EUROPEANUNION,
HavingregardtotheTreatyontheFunctioningoftheEuropeanUnion,and
inparticularArticles16and114thereof,
HavingregardtotheproposalfromtheEuropeanCommission,
Aftertransmissionofthedraftlegislativeacttothenationalparliaments,
HavingregardtotheopinionoftheEuropeanEconomicandSocial
Committee(1),
HavingregardtotheopinionoftheEuropeanCentralBank(2),
HavingregardtotheopinionoftheCommitteeoftheRegions(3),
Actinginaccordancewiththeordinarylegislativeprocedure(4),
Whereas:
(1)ThepurposeofthisRegulationistoimprovethefunctioningoftheinternalmarket
bylayingdownauniformlegalframeworkinparticularforthedevelopment,the

--- Page 2 ---
placingonthemarket,theputtingintoserviceandtheuseofartificialintelligence
systems(AIsystems)intheUnion,inaccordancewithUnionvalues,topromote
theuptakeofhumancentricandtrustworthyartificialintelligence(AI)while
ensuringahighlevelofprotectionofhealth,safety,fundamentalrightsas
enshrinedintheCharterofFundamentalRightsoftheEuropeanUnion(the
‘Charter’),includingdemocracy,theruleoflawandenvironmentalprotection,to
protectagainsttheharmfuleffectsofAIsystemsintheUnion,andtosupport
innovation.ThisRegulationensuresthefreemovement,cross-border,ofAI-based
goodsandservices,thuspreventingMemberStatesfromimposingrestrictionson
thedevelopment,marketinganduseofAIsystems,unlessexplicitlyauthorisedby
thisRegulation.
(2)ThisRegulationshouldbeappliedinaccordancewiththevaluesoftheUnion
enshrinedasintheCharter,facilitatingtheprotectionofnaturalpersons,
undertakings,democracy,theruleoflawandenvironmentalprotection,while
boostinginnovationandemploymentandmakingtheUnionaleaderintheuptake
oftrustworthyAI.
(3)AIsystemscanbeeasilydeployedinalargevarietyofsectorsoftheeconomyand
manypartsofsociety,includingacrossborders,andcaneasilycirculatethroughout
theUnion.CertainMemberStateshavealreadyexploredtheadoptionofnational
rulestoensurethatAIistrustworthyandsafeandisdevelopedandusedin
accordancewithfundamentalrightsobligations.Divergingnationalrulesmaylead
tothefragmentationoftheinternalmarketandmaydecreaselegalcertaintyfor
operatorsthatdevelop,importoruseAIsystems.Aconsistentandhighlevelof
protectionthroughouttheUnionshouldthereforebeensuredinordertoachieve
trustworthyAI,whiledivergenceshamperingthefreecirculation,innovation,
deploymentandtheuptakeofAIsystemsandrelatedproductsandserviceswithin
theinternalmarketshouldbepreventedbylayingdownuniformobligationsfor
operatorsandguaranteeingtheuniformprotectionofoverridingreasonsofpublic
interestandofrightsofpersonsthroughouttheinternalmarketonthebasisof
Article114oftheTreatyontheFunctioningoftheEuropeanUnion(TFEU).To
theextentthatthisRegulationcontainsspecificrulesontheprotectionof
individualswithregardtotheprocessingofpersonaldataconcerningrestrictionsof
theuseofAIsystemsforremotebiometricidentificationforthepurposeoflaw
enforcement,oftheuseofAIsystemsforriskassessmentsofnaturalpersonsfor
thepurposeoflawenforcementandoftheuseofAIsystemsofbiometric
categorisationforthepurposeoflawenforcement,itisappropriatetobasethis
Regulation,insofarasthosespecificrulesareconcerned,onArticle16TFEU.In
lightofthosespecificrulesandtherecoursetoArticle16TFEU,itisappropriate
toconsulttheEuropeanDataProtectionBoard.
(4)AIisafastevolvingfamilyoftechnologiesthatcontributestoawidearrayof
economic,environmentalandsocietalbenefitsacrosstheentirespectrumof
industriesandsocialactivities.Byimprovingprediction,optimisingoperationsand
resourceallocation,andpersonalisingdigitalsolutionsavailableforindividualsand
organisations,theuseofAIcanprovidekeycompetitiveadvantagesto
undertakingsandsupportsociallyandenvironmentallybeneficialoutcomes,for
exampleinhealthcare,agriculture,foodsafety,educationandtraining,media,
sports,culture,infrastructuremanagement,energy,transportandlogistics,public
services,security,justice,resourceandenergyefficiency,environmental

--- Page 3 ---
monitoring,theconservationandrestorationofbiodiversityandecosystemsand
climatechangemitigationandadaptation.
(5)Atthesametime,dependingonthecircumstancesregardingitsspecific
application,use,andleveloftechnologicaldevelopment,AImaygeneraterisks
andcauseharmtopublicinterestsandfundamentalrightsthatareprotectedby
Unionlaw.Suchharmmightbematerialorimmaterial,includingphysical,
psychological,societaloreconomicharm.
(6)GiventhemajorimpactthatAIcanhaveonsocietyandtheneedtobuildtrust,itis
vitalforAIanditsregulatoryframeworktobedevelopedinaccordancewith
UnionvaluesasenshrinedinArticle2oftheTreatyonEuropeanUnion(TEU),the
fundamentalrightsandfreedomsenshrinedintheTreatiesand,pursuantto
Article6TEU,theCharter.Asaprerequisite,AIshouldbeahuman-centric
technology.Itshouldserveasatoolforpeople,withtheultimateaimofincreasing
humanwell-being.
(7)Inordertoensureaconsistentandhighlevelofprotectionofpublicinterestsas
regardshealth,safetyandfundamentalrights,commonrulesforhigh-riskAI
systemsshouldbeestablished.ThoserulesshouldbeconsistentwiththeCharter,
non-discriminatoryandinlinewiththeUnion’sinternationaltradecommitments.
TheyshouldalsotakeintoaccounttheEuropeanDeclarationonDigitalRightsand
PrinciplesfortheDigitalDecadeandtheEthicsguidelinesfortrustworthyAIof
theHigh-LevelExpertGrouponArtificialIntelligence(AIHLEG).
(8)AUnionlegalframeworklayingdownharmonisedrulesonAIisthereforeneeded
tofosterthedevelopment,useanduptakeofAIintheinternalmarketthatatthe
sametimemeetsahighlevelofprotectionofpublicinterests,suchashealthand
safetyandtheprotectionoffundamentalrights,includingdemocracy,theruleof
lawandenvironmentalprotectionasrecognisedandprotectedbyUnionlaw.To
achievethatobjective,rulesregulatingtheplacingonthemarket,theputtinginto
serviceandtheuseofcertainAIsystemsshouldbelaiddown,thusensuringthe
smoothfunctioningoftheinternalmarketandallowingthosesystemstobenefit
fromtheprincipleoffreemovementofgoodsandservices.Thoserulesshouldbe
clearandrobustinprotectingfundamentalrights,supportiveofnewinnovative
solutions,enablingaEuropeanecosystemofpublicandprivateactorscreatingAI
systemsinlinewithUnionvaluesandunlockingthepotentialofthedigital
transformationacrossallregionsoftheUnion.Bylayingdownthoserulesaswell
asmeasuresinsupportofinnovationwithaparticularfocusonsmallandmedium
enterprises(SMEs),includingstartups,thisRegulationsupportstheobjectiveof
promotingtheEuropeanhuman-centricapproachtoAIandbeingagloballeaderin
thedevelopmentofsecure,trustworthyandethicalAIasstatedbytheEuropean
Council(5),anditensurestheprotectionofethicalprinciples,asspecifically
requestedbytheEuropeanParliament(6).
(9)Harmonisedrulesapplicabletotheplacingonthemarket,theputtingintoservice
andtheuseofhigh-riskAIsystemsshouldbelaiddownconsistentlywith
Regulation(EC)No765/2008oftheEuropeanParliamentandoftheCouncil(7),
DecisionNo768/2008/ECoftheEuropeanParliamentandoftheCouncil(8)and
Regulation(EU)2019/1020oftheEuropeanParliamentandofthe
Council(9)(NewLegislativeFramework).Theharmonisedruleslaiddowninthis
Regulationshouldapplyacrosssectorsand,inlinewiththeNewLegislative

--- Page 4 ---
Framework,shouldbewithoutprejudicetoexistingUnionlaw,inparticularon
dataprotection,consumerprotection,fundamentalrights,employment,and
protectionofworkers,andproductsafety,towhichthisRegulationis
complementary.Asaconsequence,allrightsandremediesprovidedforbysuch
Unionlawtoconsumers,andotherpersonsonwhomAIsystemsmayhave
anegativeimpact,includingasregardsthecompensationofpossibledamages
pursuanttoCouncilDirective85/374/EEC(10)remainunaffectedandfully
applicable.Furthermore,inthecontextofemploymentandprotectionofworkers,
thisRegulationshouldthereforenotaffectUnionlawonsocialpolicyandnational
labourlaw,incompliancewithUnionlaw,concerningemploymentandworking
conditions,includinghealthandsafetyatworkandtherelationshipbetween
employersandworkers.ThisRegulationshouldalsonotaffecttheexerciseof
fundamentalrightsasrecognisedintheMemberStatesandatUnionlevel,
includingtherightorfreedomtostrikeortotakeotheractioncoveredbythe
specificindustrialrelationssystemsinMemberStatesaswellastherightto
negotiate,toconcludeandenforcecollectiveagreementsortotakecollective
actioninaccordancewithnationallaw.ThisRegulationshouldnotaffectthe
provisionsaimingtoimproveworkingconditionsinplatformworklaiddownin
aDirectiveoftheEuropeanParliamentandoftheCouncilonimprovingworking
conditionsinplatformwork.Moreover,thisRegulationaimstostrengthenthe
effectivenessofsuchexistingrightsandremediesbyestablishingspecific
requirementsandobligations,includinginrespectofthetransparency,technical
documentationandrecord-keepingofAIsystems.Furthermore,theobligations
placedonvariousoperatorsinvolvedintheAIvaluechainunderthisRegulation
shouldapplywithoutprejudicetonationallaw,incompliancewithUnionlaw,
havingtheeffectoflimitingtheuseofcertainAIsystemswheresuchlawfalls
outsidethescopeofthisRegulationorpursueslegitimatepublicinterestobjectives
otherthanthosepursuedbythisRegulation.Forexample,nationallabourlawand
lawontheprotectionofminors,namelypersonsbelowtheageof18,takinginto
accounttheUNCRCGeneralCommentNo25(2021)onchildren’srightsin
relationtothedigitalenvironment,insofarastheyarenotspecifictoAIsystems
andpursueotherlegitimatepublicinterestobjectives,shouldnotbeaffectedby
thisRegulation.
(10)Thefundamentalrighttotheprotectionofpersonaldataissafeguardedin
particularbyRegulations(EU)2016/679(11)and(EU)2018/1725(12)ofthe
EuropeanParliamentandoftheCouncilandDirective(EU)2016/680ofthe
EuropeanParliamentandoftheCouncil(13).Directive2002/58/ECofthe
EuropeanParliamentandoftheCouncil(14)additionallyprotectsprivatelifeand
theconfidentialityofcommunications,includingbywayofprovidingconditions
foranystoringofpersonalandnon-personaldatain,andaccessfrom,terminal
equipment.ThoseUnionlegalactsprovidethebasisforsustainableand
responsibledataprocessing,includingwheredatasetsincludeamixofpersonal
andnon-personaldata.ThisRegulationdoesnotseektoaffecttheapplicationof
existingUnionlawgoverningtheprocessingofpersonaldata,includingthetasks
andpowersoftheindependentsupervisoryauthoritiescompetenttomonitor
compliancewiththoseinstruments.Italsodoesnotaffecttheobligationsof
providersanddeployersofAIsystemsintheirroleasdatacontrollersor
processorsstemmingfromUnionornationallawontheprotectionofpersonal
datainsofarasthedesign,thedevelopmentortheuseofAIsystemsinvolvesthe

--- Page 5 ---
processingofpersonaldata.Itisalsoappropriatetoclarifythatdatasubjects
continuetoenjoyalltherightsandguaranteesawardedtothembysuchUnion
law,includingtherightsrelatedtosolelyautomatedindividualdecision-making,
includingprofiling.Harmonisedrulesfortheplacingonthemarket,theputting
intoserviceandtheuseofAIsystemsestablishedunderthisRegulationshould
facilitatetheeffectiveimplementationandenabletheexerciseofthedata
subjects’rightsandotherremediesguaranteedunderUnionlawontheprotection
ofpersonaldataandofotherfundamentalrights.
(11)ThisRegulationshouldbewithoutprejudicetotheprovisionsregardingthe
liabilityofprovidersofintermediaryservicesassetoutinRegulation(EU)
2022/2065oftheEuropeanParliamentandoftheCouncil(15).
(12)Thenotionof‘AIsystem’inthisRegulationshouldbeclearlydefinedandshould
becloselyalignedwiththeworkofinternationalorganisationsworkingonAIto
ensurelegalcertainty,facilitateinternationalconvergenceandwideacceptance,
whileprovidingtheflexibilitytoaccommodatetherapidtechnological
developmentsinthisfield.Moreover,thedefinitionshouldbebasedonkey
characteristicsofAIsystemsthatdistinguishitfromsimplertraditionalsoftware
systemsorprogrammingapproachesandshouldnotcoversystemsthatarebased
ontherulesdefinedsolelybynaturalpersonstoautomaticallyexecuteoperations.
AkeycharacteristicofAIsystemsistheircapabilitytoinfer.Thiscapabilityto
inferreferstotheprocessofobtainingtheoutputs,suchaspredictions,content,
recommendations,ordecisions,whichcaninfluencephysicalandvirtual
environments,andtoacapabilityofAIsystemstoderivemodelsoralgorithms,
orboth,frominputsordata.Thetechniquesthatenableinferencewhilebuilding
anAIsystemincludemachinelearningapproachesthatlearnfromdatahowto
achievecertainobjectives,andlogic-andknowledge-basedapproachesthatinfer
fromencodedknowledgeorsymbolicrepresentationofthetasktobesolved.The
capacityofanAIsystemtoinfertranscendsbasicdataprocessingbyenabling
learning,reasoningormodelling.Theterm‘machine-based’referstothefactthat
AIsystemsrunonmachines.Thereferencetoexplicitorimplicitobjectives
underscoresthatAIsystemscanoperateaccordingtoexplicitdefinedobjectives
ortoimplicitobjectives.TheobjectivesoftheAIsystemmaybedifferentfrom
theintendedpurposeoftheAIsysteminaspecificcontext.Forthepurposesof
thisRegulation,environmentsshouldbeunderstoodtobethecontextsinwhich
theAIsystemsoperate,whereasoutputsgeneratedbytheAIsystemreflect
differentfunctionsperformedbyAIsystemsandincludepredictions,content,
recommendationsordecisions.AIsystemsaredesignedtooperatewithvarying
levelsofautonomy,meaningthattheyhavesomedegreeofindependenceof
actionsfromhumaninvolvementandofcapabilitiestooperatewithouthuman
intervention.TheadaptivenessthatanAIsystemcouldexhibitafterdeployment,
referstoself-learningcapabilities,allowingthesystemtochangewhileinuse.AI
systemscanbeusedonastand-alonebasisorasacomponentofaproduct,
irrespectiveofwhetherthesystemisphysicallyintegratedintotheproduct
(embedded)orservesthefunctionalityoftheproductwithoutbeingintegrated
therein(non-embedded).
(13)Thenotionof‘deployer’referredtointhisRegulationshouldbeinterpretedas
anynaturalorlegalperson,includingapublicauthority,agencyorotherbody,
usinganAIsystemunderitsauthority,exceptwheretheAIsystemisusedinthe

--- Page 6 ---
courseofapersonalnon-professionalactivity.DependingonthetypeofAI
system,theuseofthesystemmayaffectpersonsotherthanthedeployer.
(14)Thenotionof‘biometricdata’usedinthisRegulationshouldbeinterpretedin
lightofthenotionofbiometricdataasdefinedinArticle4,point(14)of
Regulation(EU)2016/679,Article3,point(18)ofRegulation(EU)2018/1725
andArticle3,point(13)ofDirective(EU)2016/680.Biometricdatacanallow
fortheauthentication,identificationorcategorisationofnaturalpersonsandfor
therecognitionofemotionsofnaturalpersons.
(15)Thenotionof‘biometricidentification’referredtointhisRegulationshouldbe
definedastheautomatedrecognitionofphysical,physiologicalandbehavioural
humanfeaturessuchastheface,eyemovement,bodyshape,voice,prosody,gait,
posture,heartrate,bloodpressure,odour,keystrokescharacteristics,forthe
purposeofestablishinganindividual’sidentitybycomparingbiometricdataof
thatindividualtostoredbiometricdataofindividualsinareferencedatabase,
irrespectiveofwhethertheindividualhasgivenitsconsentornot.Thisexcludes
AIsystemsintendedtobeusedforbiometricverification,whichincludes
authentication,whosesolepurposeistoconfirmthataspecificnaturalpersonis
thepersonheorsheclaimstobeandtoconfirmtheidentityofanaturalperson
forthesolepurposeofhavingaccesstoaservice,unlockingadeviceorhaving
securityaccesstopremises.
(16)Thenotionof‘biometriccategorisation’referredtointhisRegulationshouldbe
definedasassigningnaturalpersonstospecificcategoriesonthebasisoftheir
biometricdata.Suchspecificcategoriescanrelatetoaspectssuchassex,age,hair
colour,eyecolour,tattoos,behaviouralorpersonalitytraits,language,religion,
membershipofanationalminority,sexualorpoliticalorientation.Thisdoesnot
includebiometriccategorisationsystemsthatareapurelyancillaryfeature
intrinsicallylinkedtoanothercommercialservice,meaningthatthefeature
cannot,forobjectivetechnicalreasons,beusedwithouttheprincipalservice,and
theintegrationofthatfeatureorfunctionalityisnotameanstocircumventthe
applicabilityoftherulesofthisRegulation.Forexample,filterscategorising
facialorbodyfeaturesusedononlinemarketplacescouldconstitutesuchan
ancillaryfeatureastheycanbeusedonlyinrelationtotheprincipalservicewhich
consistsinsellingaproductbyallowingtheconsumertopreviewthedisplayof
theproductonhimorherselfandhelptheconsumertomakeapurchasedecision.
Filtersusedononlinesocialnetworkserviceswhichcategorisefacialorbody
featurestoallowuserstoaddormodifypicturesorvideoscouldalsobe
consideredtobeancillaryfeatureassuchfiltercannotbeusedwithoutthe
principalserviceofthesocialnetworkservicesconsistinginthesharingof
contentonline.
(17)Thenotionof‘remotebiometricidentificationsystem’referredtointhis
Regulationshouldbedefinedfunctionally,asanAIsystemintendedforthe
identificationofnaturalpersonswithouttheiractiveinvolvement,typicallyat
adistance,throughthecomparisonofaperson’sbiometricdatawiththe
biometricdatacontainedinareferencedatabase,irrespectivelyoftheparticular
technology,processesortypesofbiometricdataused.Suchremotebiometric
identificationsystemsaretypicallyusedtoperceivemultiplepersonsortheir
behavioursimultaneouslyinordertofacilitatesignificantlytheidentificationof
naturalpersonswithouttheiractiveinvolvement.ThisexcludesAIsystems

--- Page 7 ---
intendedtobeusedforbiometricverification,whichincludesauthentication,the
solepurposeofwhichistoconfirmthataspecificnaturalpersonisthepersonhe
orsheclaimstobeandtoconfirmtheidentityofanaturalpersonforthesole
purposeofhavingaccesstoaservice,unlockingadeviceorhavingsecurity
accesstopremises.Thatexclusionisjustifiedbythefactthatsuchsystemsare
likelytohaveaminorimpactonfundamentalrightsofnaturalpersonscompared
totheremotebiometricidentificationsystemswhichmaybeusedforthe
processingofthebiometricdataofalargenumberofpersonswithouttheiractive
involvement.Inthecaseof‘real-time’systems,thecapturingofthebiometric
data,thecomparisonandtheidentificationoccurallinstantaneously,near-
instantaneouslyorinanyeventwithoutasignificantdelay.Inthisregard,there
shouldbenoscopeforcircumventingtherulesofthisRegulationonthe‘real-
time’useoftheAIsystemsconcernedbyprovidingforminordelays.‘Real-time’
systemsinvolvetheuseof‘live’or‘near-live’material,suchasvideofootage,
generatedbyacameraorotherdevicewithsimilarfunctionality.Inthecaseof
‘post’systems,incontrast,thebiometricdatahasalreadybeencapturedandthe
comparisonandidentificationoccuronlyafterasignificantdelay.Thisinvolves
material,suchaspicturesorvideofootagegeneratedbyclosedcircuittelevision
camerasorprivatedevices,whichhasbeengeneratedbeforetheuseofthesystem
inrespectofthenaturalpersonsconcerned.
(18)Thenotionof‘emotionrecognitionsystem’referredtointhisRegulationshould
bedefinedasanAIsystemforthepurposeofidentifyingorinferringemotionsor
intentionsofnaturalpersonsonthebasisoftheirbiometricdata.Thenotionrefers
toemotionsorintentionssuchashappiness,sadness,anger,surprise,disgust,
embarrassment,excitement,shame,contempt,satisfactionandamusement.It
doesnotincludephysicalstates,suchaspainorfatigue,including,forexample,
systemsusedindetectingthestateoffatigueofprofessionalpilotsordriversfor
thepurposeofpreventingaccidents.Thisdoesalsonotincludethemeredetection
ofreadilyapparentexpressions,gesturesormovements,unlesstheyareusedfor
identifyingorinferringemotions.Thoseexpressionscanbebasicfacial
expressions,suchasafrownorasmile,orgesturessuchasthemovementof
hands,armsorhead,orcharacteristicsofaperson’svoice,suchasaraisedvoice
orwhispering.
(19)ForthepurposesofthisRegulationthenotionof‘publiclyaccessiblespace’
shouldbeunderstoodasreferringtoanyphysicalspacethatisaccessibletoan
undeterminednumberofnaturalpersons,andirrespectiveofwhetherthespacein
questionisprivatelyorpubliclyowned,irrespectiveoftheactivityforwhichthe
spacemaybeused,suchasforcommerce,forexample,shops,restaurants,cafés;
forservices,forexample,banks,professionalactivities,hospitality;forsport,for
example,swimmingpools,gyms,stadiums;fortransport,forexample,bus,metro
andrailwaystations,airports,meansoftransport;forentertainment,forexample,
cinemas,theatres,museums,concertandconferencehalls;orforleisureor
otherwise,forexample,publicroadsandsquares,parks,forests,playgrounds.
Aspaceshouldalsobeclassifiedasbeingpubliclyaccessibleif,regardlessof
potentialcapacityorsecurityrestrictions,accessissubjecttocertain
predeterminedconditionswhichcanbefulfilledbyanundeterminednumberof
persons,suchasthepurchaseofaticketortitleoftransport,priorregistrationor
havingacertainage.Incontrast,aspaceshouldnotbeconsideredtobepublicly
accessibleifaccessislimitedtospecificanddefinednaturalpersonsthrough

--- Page 8 ---
eitherUnionornationallawdirectlyrelatedtopublicsafetyorsecurityorthrough
theclearmanifestationofwillbythepersonhavingtherelevantauthorityoverthe
space.Thefactualpossibilityofaccessalone,suchasanunlockeddoororan
opengateinafence,doesnotimplythatthespaceispubliclyaccessibleinthe
presenceofindicationsorcircumstancessuggestingthecontrary,suchas.signs
prohibitingorrestrictingaccess.Companyandfactorypremises,aswellas
officesandworkplacesthatareintendedtobeaccessedonlybyrelevant
employeesandserviceproviders,arespacesthatarenotpubliclyaccessible.
Publiclyaccessiblespacesshouldnotincludeprisonsorbordercontrol.Some
otherspacesmaycomprisebothpubliclyaccessibleandnon-publiclyaccessible
spaces,suchasthehallwayofaprivateresidentialbuildingnecessarytoaccess
adoctor’sofficeoranairport.Onlinespacesarenotcovered,astheyarenot
physicalspaces.Whetheragivenspaceisaccessibletothepublicshouldhowever
bedeterminedonacase-by-casebasis,havingregardtothespecificitiesofthe
individualsituationathand.
(20)InordertoobtainthegreatestbenefitsfromAIsystemswhileprotecting
fundamentalrights,healthandsafetyandtoenabledemocraticcontrol,AI
literacyshouldequipproviders,deployersandaffectedpersonswiththenecessary
notionstomakeinformeddecisionsregardingAIsystems.Thosenotionsmay
varywithregardtotherelevantcontextandcanincludeunderstandingthecorrect
applicationoftechnicalelementsduringtheAIsystem’sdevelopmentphase,the
measurestobeappliedduringitsuse,thesuitablewaysinwhichtointerpretthe
AIsystem’soutput,and,inthecaseofaffectedpersons,theknowledgenecessary
tounderstandhowdecisionstakenwiththeassistanceofAIwillhaveanimpact
onthem.InthecontextoftheapplicationthisRegulation,AIliteracyshould
provideallrelevantactorsintheAIvaluechainwiththeinsightsrequiredto
ensuretheappropriatecomplianceanditscorrectenforcement.Furthermore,the
wideimplementationofAIliteracymeasuresandtheintroductionofappropriate
follow-upactionscouldcontributetoimprovingworkingconditionsand
ultimatelysustaintheconsolidation,andinnovationpathoftrustworthyAIinthe
Union.TheEuropeanArtificialIntelligenceBoard(the‘Board’)shouldsupport
theCommission,topromoteAIliteracytools,publicawarenessand
understandingofthebenefits,risks,safeguards,rightsandobligationsinrelation
totheuseofAIsystems.Incooperationwiththerelevantstakeholders,the
CommissionandtheMemberStatesshouldfacilitatethedrawingupofvoluntary
codesofconducttoadvanceAIliteracyamongpersonsdealingwiththe
development,operationanduseofAI.
(21)Inordertoensurealevelplayingfieldandaneffectiveprotectionofrightsand
freedomsofindividualsacrosstheUnion,therulesestablishedbythisRegulation
shouldapplytoprovidersofAIsystemsinanon-discriminatorymanner,
irrespectiveofwhethertheyareestablishedwithintheUnionorinathirdcountry,
andtodeployersofAIsystemsestablishedwithintheUnion.
(22)Inlightoftheirdigitalnature,certainAIsystemsshouldfallwithinthescopeof
thisRegulationevenwhentheyarenotplacedonthemarket,putintoservice,or
usedintheUnion.Thisisthecase,forexample,whereanoperatorestablishedin
theUnioncontractscertainservicestoanoperatorestablishedinathirdcountry
inrelationtoanactivitytobeperformedbyanAIsystemthatwouldqualifyas
high-risk.Inthosecircumstances,theAIsystemusedinathirdcountrybythe

--- Page 9 ---
operatorcouldprocessdatalawfullycollectedinandtransferredfromtheUnion,
andprovidetothecontractingoperatorintheUniontheoutputofthatAIsystem
resultingfromthatprocessing,withoutthatAIsystembeingplacedonthemarket,
putintoserviceorusedintheUnion.Topreventthecircumventionofthis
Regulationandtoensureaneffectiveprotectionofnaturalpersonslocatedinthe
Union,thisRegulationshouldalsoapplytoprovidersanddeployersofAI
systemsthatareestablishedinathirdcountry,totheextenttheoutputproduced
bythosesystemsisintendedtobeusedintheUnion.Nonetheless,totakeinto
accountexistingarrangementsandspecialneedsforfuturecooperationwith
foreignpartnerswithwhominformationandevidenceisexchanged,this
Regulationshouldnotapplytopublicauthoritiesofathirdcountryand
internationalorganisationswhenactingintheframeworkofcooperationor
internationalagreementsconcludedatUnionornationallevelforlaw
enforcementandjudicialcooperationwiththeUnionortheMemberStates,
providedthattherelevantthirdcountryorinternationalorganisationprovides
adequatesafeguardswithrespecttotheprotectionoffundamentalrightsand
freedomsofindividuals.Whererelevant,thismaycoveractivitiesofentities
entrustedbythethirdcountriestocarryoutspecifictasksinsupportofsuchlaw
enforcementandjudicialcooperation.Suchframeworkforcooperationor
agreementshavebeenestablishedbilaterallybetweenMemberStatesandthird
countriesorbetweentheEuropeanUnion,EuropolandotherUnionagenciesand
thirdcountriesandinternationalorganisations.Theauthoritiescompetentfor
supervisionofthelawenforcementandjudicialauthoritiesunderthisRegulation
shouldassesswhetherthoseframeworksforcooperationorinternational
agreementsincludeadequatesafeguardswithrespecttotheprotectionof
fundamentalrightsandfreedomsofindividuals.Recipientnationalauthoritiesand
Unioninstitutions,bodies,officesandagenciesmakinguseofsuchoutputsinthe
UnionremainaccountabletoensuretheirusecomplieswithUnionlaw.When
thoseinternationalagreementsarerevisedornewonesareconcludedinthe
future,thecontractingpartiesshouldmakeutmosteffortstoalignthose
agreementswiththerequirementsofthisRegulation.
(23)ThisRegulationshouldalsoapplytoUnioninstitutions,bodies,officesand
agencieswhenactingasaproviderordeployerofanAIsystem.
(24)If,andinsofaras,AIsystemsareplacedonthemarket,putintoservice,orused
withorwithoutmodificationofsuchsystemsformilitary,defenceornational
securitypurposes,thoseshouldbeexcludedfromthescopeofthisRegulation
regardlessofwhichtypeofentityiscarryingoutthoseactivities,suchaswhether
itisapublicorprivateentity.Asregardsmilitaryanddefencepurposes,such
exclusionisjustifiedbothbyArticle4(2)TEUandbythespecificitiesofthe
MemberStates’andthecommonUniondefencepolicycoveredbyChapter2of
TitleVTEUthataresubjecttopublicinternationallaw,whichisthereforethe
moreappropriatelegalframeworkfortheregulationofAIsystemsinthecontext
oftheuseoflethalforceandotherAIsystemsinthecontextofmilitaryand
defenceactivities.Asregardsnationalsecuritypurposes,theexclusionisjustified
bothbythefactthatnationalsecurityremainsthesoleresponsibilityofMember
StatesinaccordancewithArticle4(2)TEUandbythespecificnatureand
operationalneedsofnationalsecurityactivitiesandspecificnationalrules
applicabletothoseactivities.Nonetheless,ifanAIsystemdeveloped,placedon
themarket,putintoserviceorusedformilitary,defenceornationalsecurity

--- Page 10 ---
purposesisusedoutsidethosetemporarilyorpermanentlyforotherpurposes,for
example,civilianorhumanitarianpurposes,lawenforcementorpublicsecurity
purposes,suchasystemwouldfallwithinthescopeofthisRegulation.Inthat
case,theentityusingtheAIsystemforotherthanmilitary,defenceornational
securitypurposesshouldensurethecomplianceoftheAIsystemwiththis
Regulation,unlessthesystemisalreadycompliantwiththisRegulation.AI
systemsplacedonthemarketorputintoserviceforanexcludedpurpose,namely
military,defenceornationalsecurity,andoneormorenon-excludedpurposes,
suchascivilianpurposesorlawenforcement,fallwithinthescopeofthis
Regulationandprovidersofthosesystemsshouldensurecompliancewiththis
Regulation.Inthosecases,thefactthatanAIsystemmayfallwithinthescopeof
thisRegulationshouldnotaffectthepossibilityofentitiescarryingoutnational
security,defenceandmilitaryactivities,regardlessofthetypeofentitycarrying
outthoseactivities,touseAIsystemsfornationalsecurity,militaryanddefence
purposes,theuseofwhichisexcludedfromthescopeofthisRegulation.AnAI
systemplacedonthemarketforcivilianorlawenforcementpurposeswhichis
usedwithorwithoutmodificationformilitary,defenceornationalsecurity
purposesshouldnotfallwithinthescopeofthisRegulation,regardlessofthetype
ofentitycarryingoutthoseactivities.
(25)ThisRegulationshouldsupportinnovation,shouldrespectfreedomofscience,
andshouldnotundermineresearchanddevelopmentactivity.Itistherefore
necessarytoexcludefromitsscopeAIsystemsandmodelsspecifically
developedandputintoserviceforthesolepurposeofscientificresearchand
development.Moreover,itisnecessarytoensurethatthisRegulationdoesnot
otherwiseaffectscientificresearchanddevelopmentactivityonAIsystemsor
modelspriortobeingplacedonthemarketorputintoservice.Asregards
product-orientedresearch,testinganddevelopmentactivityregardingAIsystems
ormodels,theprovisionsofthisRegulationshouldalsonotapplypriortothose
systemsandmodelsbeingputintoserviceorplacedonthemarket.That
exclusioniswithoutprejudicetotheobligationtocomplywiththisRegulation
whereanAIsystemfallingintothescopeofthisRegulationisplacedonthe
marketorputintoserviceasaresultofsuchresearchanddevelopmentactivity
andtotheapplicationofprovisionsonAIregulatorysandboxesandtestinginreal
worldconditions.Furthermore,withoutprejudicetotheexclusionofAIsystems
specificallydevelopedandputintoserviceforthesolepurposeofscientific
researchanddevelopment,anyotherAIsystemthatmaybeusedfortheconduct
ofanyresearchanddevelopmentactivityshouldremainsubjecttotheprovisions
ofthisRegulation.Inanyevent,anyresearchanddevelopmentactivityshouldbe
carriedoutinaccordancewithrecognisedethicalandprofessionalstandardsfor
scientificresearchandshouldbeconductedinaccordancewithapplicableUnion
law.
(26)InordertointroduceaproportionateandeffectivesetofbindingrulesforAI
systems,aclearlydefinedrisk-basedapproachshouldbefollowed.Thatapproach
shouldtailorthetypeandcontentofsuchrulestotheintensityandscopeofthe
risksthatAIsystemscangenerate.Itisthereforenecessarytoprohibitcertain
unacceptableAIpractices,tolaydownrequirementsforhigh-riskAIsystemsand
obligationsfortherelevantoperators,andtolaydowntransparencyobligations
forcertainAIsystems.

--- Page 11 ---
(27)Whiletherisk-basedapproachisthebasisforaproportionateandeffectivesetof
bindingrules,itisimportanttorecallthe2019Ethicsguidelinesfortrustworthy
AIdevelopedbytheindependentAIHLEGappointedbytheCommission.In
thoseguidelines,theAIHLEGdevelopedsevennon-bindingethicalprinciples
forAIwhichareintendedtohelpensurethatAIistrustworthyandethically
sound.Thesevenprinciplesincludehumanagencyandoversight;technical
robustnessandsafety;privacyanddatagovernance;transparency;diversity,non-
discriminationandfairness;societalandenvironmentalwell-beingand
accountability.Withoutprejudicetothelegallybindingrequirementsofthis
RegulationandanyotherapplicableUnionlaw,thoseguidelinescontributetothe
designofcoherent,trustworthyandhuman-centricAI,inlinewiththeCharter
andwiththevaluesonwhichtheUnionisfounded.Accordingtotheguidelines
oftheAIHLEG,humanagencyandoversightmeansthatAIsystemsare
developedandusedasatoolthatservespeople,respectshumandignityand
personalautonomy,andthatisfunctioninginawaythatcanbeappropriately
controlledandoverseenbyhumans.Technicalrobustnessandsafetymeansthat
AIsystemsaredevelopedandusedinawaythatallowsrobustnessinthecaseof
problemsandresilienceagainstattemptstoaltertheuseorperformanceoftheAI
systemsoastoallowunlawfulusebythirdparties,andminimiseunintended
harm.PrivacyanddatagovernancemeansthatAIsystemsaredevelopedand
usedinaccordancewithprivacyanddataprotectionrules,whileprocessingdata
thatmeetshighstandardsintermsofqualityandintegrity.Transparencymeans
thatAIsystemsaredevelopedandusedinawaythatallowsappropriate
traceabilityandexplainability,whilemakinghumansawarethatthey
communicateorinteractwithanAIsystem,aswellasdulyinformingdeployers
ofthecapabilitiesandlimitationsofthatAIsystemandaffectedpersonsabout
theirrights.Diversity,non-discriminationandfairnessmeansthatAIsystemsare
developedandusedinawaythatincludesdiverseactorsandpromotesequal
access,genderequalityandculturaldiversity,whileavoidingdiscriminatory
impactsandunfairbiasesthatareprohibitedbyUnionornationallaw.Socialand
environmentalwell-beingmeansthatAIsystemsaredevelopedandusedin
asustainableandenvironmentallyfriendlymanneraswellasinawaytobenefit
allhumanbeings,whilemonitoringandassessingthelong-termimpactsonthe
individual,societyanddemocracy.Theapplicationofthoseprinciplesshouldbe
translated,whenpossible,inthedesignanduseofAImodels.Theyshouldinany
caseserveasabasisforthedraftingofcodesofconductunderthisRegulation.
Allstakeholders,includingindustry,academia,civilsocietyandstandardisation
organisations,areencouragedtotakeintoaccount,asappropriate,theethical
principlesforthedevelopmentofvoluntarybestpracticesandstandards.
(28)AsidefromthemanybeneficialusesofAI,itcanalsobemisusedandprovide
novelandpowerfultoolsformanipulative,exploitativeandsocialcontrol
practices.Suchpracticesareparticularlyharmfulandabusiveandshouldbe
prohibitedbecausetheycontradictUnionvaluesofrespectforhumandignity,
freedom,equality,democracyandtheruleoflawandfundamentalrights
enshrinedintheCharter,includingtherighttonon-discrimination,todata
protectionandtoprivacyandtherightsofthechild.
(29)AI-enabledmanipulativetechniquescanbeusedtopersuadepersonstoengagein
unwantedbehaviours,ortodeceivethembynudgingthemintodecisionsinaway

--- Page 12 ---
thatsubvertsandimpairstheirautonomy,decision-makingandfreechoices.The
placingonthemarket,theputtingintoserviceortheuseofcertainAIsystems
withtheobjectivetoortheeffectofmateriallydistortinghumanbehaviour,
wherebysignificantharms,inparticularhavingsufficientlyimportantadverse
impactsonphysical,psychologicalhealthorfinancialinterestsarelikelytooccur,
areparticularlydangerousandshouldthereforebeprohibited.SuchAIsystems
deploysubliminalcomponentssuchasaudio,image,videostimulithatpersons
cannotperceive,asthosestimuliarebeyondhumanperception,orother
manipulativeordeceptivetechniquesthatsubvertorimpairperson’sautonomy,
decision-makingorfreechoiceinwaysthatpeoplearenotconsciouslyawareof
thosetechniquesor,wheretheyareawareofthem,canstillbedeceivedorarenot
abletocontrolorresistthem.Thiscouldbefacilitated,forexample,bymachine-
braininterfacesorvirtualrealityastheyallowforahigherdegreeofcontrolof
whatstimuliarepresentedtopersons,insofarastheymaymateriallydistorttheir
behaviourinasignificantlyharmfulmanner.Inaddition,AIsystemsmayalso
otherwiseexploitthevulnerabilitiesofapersonoraspecificgroupofpersonsdue
totheirage,disabilitywithinthemeaningofDirective(EU)2019/882ofthe
EuropeanParliamentandoftheCouncil(16),oraspecificsocialoreconomic
situationthatislikelytomakethosepersonsmorevulnerabletoexploitationsuch
aspersonslivinginextremepoverty,ethnicorreligiousminorities.SuchAI
systemscanbeplacedonthemarket,putintoserviceorusedwiththeobjectiveto
ortheeffectofmateriallydistortingthebehaviourofapersonandinamanner
thatcausesorisreasonablylikelytocausesignificantharmtothatoranother
personorgroupsofpersons,includingharmsthatmaybeaccumulatedovertime
andshouldthereforebeprohibited.Itmaynotbepossibletoassumethatthereis
anintentiontodistortbehaviourwherethedistortionresultsfromfactorsexternal
totheAIsystemwhichareoutsidethecontroloftheproviderorthedeployer,
namelyfactorsthatmaynotbereasonablyforeseeableandthereforenotpossible
fortheproviderorthedeployeroftheAIsystemtomitigate.Inanycase,itisnot
necessaryfortheproviderorthedeployertohavetheintentiontocause
significantharm,providedthatsuchharmresultsfromthemanipulativeor
exploitativeAI-enabledpractices.TheprohibitionsforsuchAIpracticesare
complementarytotheprovisionscontainedinDirective2005/29/ECofthe
EuropeanParliamentandoftheCouncil(17),inparticularunfaircommercial
practicesleadingtoeconomicorfinancialharmstoconsumersareprohibited
underallcircumstances,irrespectiveofwhethertheyareputinplacethroughAI
systemsorotherwise.Theprohibitionsofmanipulativeandexploitativepractices
inthisRegulationshouldnotaffectlawfulpracticesinthecontextofmedical
treatmentsuchaspsychologicaltreatmentofamentaldiseaseorphysical
rehabilitation,whenthosepracticesarecarriedoutinaccordancewiththe
applicablelawandmedicalstandards,forexampleexplicitconsentofthe
individualsortheirlegalrepresentatives.Inaddition,commonandlegitimate
commercialpractices,forexampleinthefieldofadvertising,thatcomplywiththe
applicablelawshouldnot,inthemselves,beregardedasconstitutingharmful
manipulativeAI-enabledpractices.
(30)Biometriccategorisationsystemsthatarebasedonnaturalpersons’biometric
data,suchasanindividualperson’sfaceorfingerprint,todeduceorinferan
individuals’politicalopinions,tradeunionmembership,religiousorphilosophical
beliefs,race,sexlifeorsexualorientationshouldbeprohibited.Thatprohibition
shouldnotcoverthelawfullabelling,filteringorcategorisationofbiometricdata

--- Page 13 ---
setsacquiredinlinewithUnionornationallawaccordingtobiometricdata,such
asthesortingofimagesaccordingtohaircolouroreyecolour,whichcanfor
examplebeusedintheareaoflawenforcement.
(31)AIsystemsprovidingsocialscoringofnaturalpersonsbypublicorprivateactors
mayleadtodiscriminatoryoutcomesandtheexclusionofcertaingroups.They
mayviolatetherighttodignityandnon-discriminationandthevaluesofequality
andjustice.SuchAIsystemsevaluateorclassifynaturalpersonsorgroups
thereofonthebasisofmultipledatapointsrelatedtotheirsocialbehaviourin
multiplecontextsorknown,inferredorpredictedpersonalorpersonality
characteristicsovercertainperiodsoftime.Thesocialscoreobtainedfromsuch
AIsystemsmayleadtothedetrimentalorunfavourabletreatmentofnatural
personsorwholegroupsthereofinsocialcontexts,whichareunrelatedtothe
contextinwhichthedatawasoriginallygeneratedorcollectedortoadetrimental
treatmentthatisdisproportionateorunjustifiedtothegravityoftheirsocial
behaviour.AIsystemsentailingsuchunacceptablescoringpracticesandleading
tosuchdetrimentalorunfavourableoutcomesshouldthereforebeprohibited.
Thatprohibitionshouldnotaffectlawfulevaluationpracticesofnaturalpersons
thatarecarriedoutforaspecificpurposeinaccordancewithUnionandnational
law.
(32)TheuseofAIsystemsfor‘real-time’remotebiometricidentificationofnatural
personsinpubliclyaccessiblespacesforthepurposeoflawenforcementis
particularlyintrusivetotherightsandfreedomsoftheconcernedpersons,tothe
extentthatitmayaffecttheprivatelifeofalargepartofthepopulation,evoke
afeelingofconstantsurveillanceandindirectlydissuadetheexerciseofthe
freedomofassemblyandotherfundamentalrights.TechnicalinaccuraciesofAI
systemsintendedfortheremotebiometricidentificationofnaturalpersonscan
leadtobiasedresultsandentaildiscriminatoryeffects.Suchpossiblebiased
resultsanddiscriminatoryeffectsareparticularlyrelevantwithregardtoage,
ethnicity,race,sexordisabilities.Inaddition,theimmediacyoftheimpactand
thelimitedopportunitiesforfurtherchecksorcorrectionsinrelationtotheuseof
suchsystemsoperatinginreal-timecarryheightenedrisksfortherightsand
freedomsofthepersonsconcernedinthecontextof,orimpactedby,law
enforcementactivities.
(33)Theuseofthosesystemsforthepurposeoflawenforcementshouldthereforebe
prohibited,exceptinexhaustivelylistedandnarrowlydefinedsituations,where
theuseisstrictlynecessarytoachieveasubstantialpublicinterest,theimportance
ofwhichoutweighstherisks.Thosesituationsinvolvethesearchforcertain
victimsofcrimeincludingmissingpersons;certainthreatstothelifeortothe
physicalsafetyofnaturalpersonsorofaterroristattack;andthelocalisationor
identificationofperpetratorsorsuspectsofthecriminaloffenceslistedinan
annextothisRegulation,wherethosecriminaloffencesarepunishableinthe
MemberStateconcernedbyacustodialsentenceoradetentionorderfor
amaximumperiodofatleastfouryearsandastheyaredefinedinthelawofthat
MemberState.Suchathresholdforthecustodialsentenceordetentionorderin
accordancewithnationallawcontributestoensuringthattheoffenceshouldbe
seriousenoughtopotentiallyjustifytheuseof‘real-time’remotebiometric
identificationsystems.Moreover,thelistofcriminaloffencesprovidedinan
annextothisRegulationisbasedonthe32criminaloffenceslistedintheCouncil

--- Page 14 ---
FrameworkDecision2002/584/JHA(18),takingintoaccountthatsomeofthose
offencesare,inpractice,likelytobemorerelevantthanothers,inthatthe
recourseto‘real-time’remotebiometricidentificationcould,foreseeably,be
necessaryandproportionatetohighlyvaryingdegreesforthepracticalpursuitof
thelocalisationoridentificationofaperpetratororsuspectofthedifferent
criminaloffenceslistedandhavingregardtothelikelydifferencesinthe
seriousness,probabilityandscaleoftheharmorpossiblenegativeconsequences.
Animminentthreattolifeorthephysicalsafetyofnaturalpersonscouldalso
resultfromaseriousdisruptionofcriticalinfrastructure,asdefinedinArticle2,
point(4)ofDirective(EU)2022/2557oftheEuropeanParliamentandofthe
Council(19),wherethedisruptionordestructionofsuchcriticalinfrastructure
wouldresultinanimminentthreattolifeorthephysicalsafetyofaperson,
includingthroughseriousharmtotheprovisionofbasicsuppliestothe
populationortotheexerciseofthecorefunctionoftheState.Inaddition,this
Regulationshouldpreservetheabilityforlawenforcement,bordercontrol,
immigrationorasylumauthoritiestocarryoutidentitychecksinthepresenceof
thepersonconcernedinaccordancewiththeconditionssetoutinUnionand
nationallawforsuchchecks.Inparticular,lawenforcement,bordercontrol,
immigrationorasylumauthoritiesshouldbeabletouseinformationsystems,in
accordancewithUnionornationallaw,toidentifypersonswho,duringan
identitycheck,eitherrefusetobeidentifiedorareunabletostateorprovetheir
identity,withoutbeingrequiredbythisRegulationtoobtainpriorauthorisation.
Thiscouldbe,forexample,apersoninvolvedinacrime,beingunwilling,or
unableduetoanaccidentoramedicalcondition,todisclosetheiridentitytolaw
enforcementauthorities.
(34)Inordertoensurethatthosesystemsareusedinaresponsibleandproportionate
manner,itisalsoimportanttoestablishthat,ineachofthoseexhaustivelylisted
andnarrowlydefinedsituations,certainelementsshouldbetakenintoaccount,in
particularasregardsthenatureofthesituationgivingrisetotherequestandthe
consequencesoftheusefortherightsandfreedomsofallpersonsconcernedand
thesafeguardsandconditionsprovidedforwiththeuse.Inaddition,theuseof
‘real-time’remotebiometricidentificationsystemsinpubliclyaccessiblespaces
forthepurposeoflawenforcementshouldbedeployedonlytoconfirmthe
specificallytargetedindividual’sidentityandshouldbelimitedtowhatisstrictly
necessaryconcerningtheperiodoftime,aswellasthegeographicandpersonal
scope,havingregardinparticulartotheevidenceorindicationsregardingthe
threats,thevictimsorperpetrator.Theuseofthereal-timeremotebiometric
identificationsysteminpubliclyaccessiblespacesshouldbeauthorisedonlyif
therelevantlawenforcementauthorityhascompletedafundamentalrightsimpact
assessmentand,unlessprovidedotherwiseinthisRegulation,hasregisteredthe
systeminthedatabaseassetoutinthisRegulation.Thereferencedatabaseof
personsshouldbeappropriateforeachusecaseineachofthesituations
mentionedabove.
(35)Eachuseofa‘real-time’remotebiometricidentificationsysteminpublicly
accessiblespacesforthepurposeoflawenforcementshouldbesubjecttoan
expressandspecificauthorisationbyajudicialauthorityorbyanindependent
administrativeauthorityofaMemberStatewhosedecisionisbinding.Such
authorisationshould,inprinciple,beobtainedpriortotheuseoftheAIsystem
withaviewtoidentifyingapersonorpersons.Exceptionstothatruleshouldbe

--- Page 15 ---
allowedindulyjustifiedsituationsongroundsofurgency,namelyinsituations
wheretheneedtousethesystemsconcernedissuchastomakeiteffectivelyand
objectivelyimpossibletoobtainanauthorisationbeforecommencingtheuseof
theAIsystem.Insuchsituationsofurgency,theuseoftheAIsystemshouldbe
restrictedtotheabsoluteminimumnecessaryandshouldbesubjecttoappropriate
safeguardsandconditions,asdeterminedinnationallawandspecifiedinthe
contextofeachindividualurgentusecasebythelawenforcementauthorityitself.
Inaddition,thelawenforcementauthorityshouldinsuchsituationsrequestsuch
authorisationwhileprovidingthereasonsfornothavingbeenabletorequestit
earlier,withoutunduedelayandatthelatestwithin24hours.Ifsuchan
authorisationisrejected,theuseofreal-timebiometricidentificationsystems
linkedtothatauthorisationshouldceasewithimmediateeffectandallthedata
relatedtosuchuseshouldbediscardedanddeleted.Suchdataincludesinputdata
directlyacquiredbyanAIsysteminthecourseoftheuseofsuchsystemaswell
astheresultsandoutputsoftheuselinkedtothatauthorisation.Itshouldnot
includeinputthatislegallyacquiredinaccordancewithanotherUnionornational
law.Inanycase,nodecisionproducinganadverselegaleffectonapersonshould
betakenbasedsolelyontheoutputoftheremotebiometricidentificationsystem.
(36)Inordertocarryouttheirtasksinaccordancewiththerequirementssetoutinthis
Regulationaswellasinnationalrules,therelevantmarketsurveillanceauthority
andthenationaldataprotectionauthorityshouldbenotifiedofeachuseofthe
real-timebiometricidentificationsystem.Marketsurveillanceauthoritiesandthe
nationaldataprotectionauthoritiesthathavebeennotifiedshouldsubmittothe
Commissionanannualreportontheuseofreal-timebiometricidentification
systems.
(37)Furthermore,itisappropriatetoprovide,withintheexhaustiveframeworksetby
thisRegulationthatsuchuseintheterritoryofaMemberStateinaccordance
withthisRegulationshouldonlybepossiblewhereandinasfarastheMember
Stateconcernedhasdecidedtoexpresslyprovideforthepossibilitytoauthorise
suchuseinitsdetailedrulesofnationallaw.Consequently,MemberStates
remainfreeunderthisRegulationnottoprovideforsuchapossibilityatallorto
onlyprovideforsuchapossibilityinrespectofsomeoftheobjectivescapableof
justifyingauthoriseduseidentifiedinthisRegulation.Suchnationalrulesshould
benotifiedtotheCommissionwithin30daysoftheiradoption.
(38)TheuseofAIsystemsforreal-timeremotebiometricidentificationofnatural
personsinpubliclyaccessiblespacesforthepurposeoflawenforcement
necessarilyinvolvestheprocessingofbiometricdata.TherulesofthisRegulation
thatprohibit,subjecttocertainexceptions,suchuse,whicharebasedon
Article16TFEU,shouldapplyaslexspecialisinrespectoftherulesonthe
processingofbiometricdatacontainedinArticle10ofDirective(EU)2016/680,
thusregulatingsuchuseandtheprocessingofbiometricdatainvolvedinan
exhaustivemanner.Therefore,suchuseandprocessingshouldbepossibleonlyin
asfarasitiscompatiblewiththeframeworksetbythisRegulation,withoutthere
beingscope,outsidethatframework,forthecompetentauthorities,wheretheyact
forpurposeoflawenforcement,tousesuchsystemsandprocesssuchdatain
connectiontheretoonthegroundslistedinArticle10ofDirective(EU)2016/680.
Inthatcontext,thisRegulationisnotintendedtoprovidethelegalbasisforthe
processingofpersonaldataunderArticle8ofDirective(EU)2016/680.

--- Page 16 ---
However,theuseofreal-timeremotebiometricidentificationsystemsinpublicly
accessiblespacesforpurposesotherthanlawenforcement,includingby
competentauthorities,shouldnotbecoveredbythespecificframeworkregarding
suchuseforthepurposeoflawenforcementsetbythisRegulation.Suchusefor
purposesotherthanlawenforcementshouldthereforenotbesubjecttothe
requirementofanauthorisationunderthisRegulationandtheapplicabledetailed
rulesofnationallawthatmaygiveeffecttothatauthorisation.
(39)Anyprocessingofbiometricdataandotherpersonaldatainvolvedintheuseof
AIsystemsforbiometricidentification,otherthaninconnectiontotheuseof
real-timeremotebiometricidentificationsystemsinpubliclyaccessiblespacesfor
thepurposeoflawenforcementasregulatedbythisRegulation,shouldcontinue
tocomplywithallrequirementsresultingfromArticle10ofDirective(EU)
2016/680.Forpurposesotherthanlawenforcement,Article9(1)ofRegulation
(EU)2016/679andArticle10(1)ofRegulation(EU)2018/1725prohibitthe
processingofbiometricdatasubjecttolimitedexceptionsasprovidedinthose
Articles.IntheapplicationofArticle9(1)ofRegulation(EU)2016/679,theuse
ofremotebiometricidentificationforpurposesotherthanlawenforcementhas
alreadybeensubjecttoprohibitiondecisionsbynationaldataprotection
authorities.
(40)InaccordancewithArticle6aofProtocolNo21onthepositionoftheUnited
KingdomandIrelandinrespectoftheareaoffreedom,securityandjustice,as
annexedtotheTEUandtotheTFEU,Irelandisnotboundbytheruleslaiddown
inArticle5(1),firstsubparagraph,point(g),totheextentitappliestotheuseof
biometriccategorisationsystemsforactivitiesinthefieldofpolicecooperation
andjudicialcooperationincriminalmatters,Article5(1),firstsubparagraph,
point(d),totheextentitappliestotheuseofAIsystemscoveredbythat
provision,Article5(1),firstsubparagraph,point(h),Article5(2)to(6)and
Article26(10)ofthisRegulationadoptedonthebasisofArticle16TFEUwhich
relatetotheprocessingofpersonaldatabytheMemberStateswhencarryingout
activitiesfallingwithinthescopeofChapter4orChapter5ofTitleVofPart
ThreeoftheTFEU,whereIrelandisnotboundbytherulesgoverningtheforms
ofjudicialcooperationincriminalmattersorpolicecooperationwhichrequire
compliancewiththeprovisionslaiddownonthebasisofArticle16TFEU.
(41)InaccordancewithArticles2and2aofProtocolNo22onthepositionof
Denmark,annexedtotheTEUandtotheTFEU,Denmarkisnotboundbyrules
laiddowninArticle5(1),firstsubparagraph,point(g),totheextentitappliesto
theuseofbiometriccategorisationsystemsforactivitiesinthefieldofpolice
cooperationandjudicialcooperationincriminalmatters,Article5(1),first
subparagraph,point(d),totheextentitappliestotheuseofAIsystemscovered
bythatprovision,Article5(1),firstsubparagraph,point(h),(2)to(6)and
Article26(10)ofthisRegulationadoptedonthebasisofArticle16TFEU,or
subjecttotheirapplication,whichrelatetotheprocessingofpersonaldatabythe
MemberStateswhencarryingoutactivitiesfallingwithinthescopeofChapter4
orChapter5ofTitleVofPartThreeoftheTFEU.
(42)Inlinewiththepresumptionofinnocence,naturalpersonsintheUnionshould
alwaysbejudgedontheiractualbehaviour.Naturalpersonsshouldneverbe
judgedonAI-predictedbehaviourbasedsolelyontheirprofiling,personality
traitsorcharacteristics,suchasnationality,placeofbirth,placeofresidence,

--- Page 17 ---
numberofchildren,levelofdebtortypeofcar,withoutareasonablesuspicionof
thatpersonbeinginvolvedinacriminalactivitybasedonobjectiveverifiable
factsandwithouthumanassessmentthereof.Therefore,riskassessmentscarried
outwithregardtonaturalpersonsinordertoassessthelikelihoodoftheir
offendingortopredicttheoccurrenceofanactualorpotentialcriminaloffence
basedsolelyonprofilingthemoronassessingtheirpersonalitytraitsand
characteristicsshouldbeprohibited.Inanycase,thatprohibitiondoesnotreferto
ortouchuponriskanalyticsthatarenotbasedontheprofilingofindividualsor
onthepersonalitytraitsandcharacteristicsofindividuals,suchasAIsystems
usingriskanalyticstoassessthelikelihoodoffinancialfraudbyundertakingson
thebasisofsuspicioustransactionsorriskanalytictoolstopredictthelikelihood
ofthelocalisationofnarcoticsorillicitgoodsbycustomsauthorities,forexample
onthebasisofknowntraffickingroutes.
(43)Theplacingonthemarket,theputtingintoserviceforthatspecificpurpose,orthe
useofAIsystemsthatcreateorexpandfacialrecognitiondatabasesthroughthe
untargetedscrapingoffacialimagesfromtheinternetorCCTVfootage,should
beprohibitedbecausethatpracticeaddstothefeelingofmasssurveillanceand
canleadtogrossviolationsoffundamentalrights,includingtherighttoprivacy.
(44)ThereareseriousconcernsaboutthescientificbasisofAIsystemsaimingto
identifyorinferemotions,particularlyasexpressionofemotionsvary
considerablyacrossculturesandsituations,andevenwithinasingleindividual.
Amongthekeyshortcomingsofsuchsystemsarethelimitedreliability,thelack
ofspecificityandthelimitedgeneralisability.Therefore,AIsystemsidentifying
orinferringemotionsorintentionsofnaturalpersonsonthebasisoftheir
biometricdatamayleadtodiscriminatoryoutcomesandcanbeintrusivetothe
rightsandfreedomsoftheconcernedpersons.Consideringtheimbalanceof
powerinthecontextofworkoreducation,combinedwiththeintrusivenatureof
thesesystems,suchsystemscouldleadtodetrimentalorunfavourabletreatment
ofcertainnaturalpersonsorwholegroupsthereof.Therefore,theplacingonthe
market,theputtingintoservice,ortheuseofAIsystemsintendedtobeusedto
detecttheemotionalstateofindividualsinsituationsrelatedtotheworkplaceand
educationshouldbeprohibited.ThatprohibitionshouldnotcoverAIsystems
placedonthemarketstrictlyformedicalorsafetyreasons,suchassystems
intendedfortherapeuticaluse.
(45)PracticesthatareprohibitedbyUnionlaw,includingdataprotectionlaw,non-
discriminationlaw,consumerprotectionlaw,andcompetitionlaw,shouldnotbe
affectedbythisRegulation.
(46)High-riskAIsystemsshouldonlybeplacedontheUnionmarket,putintoservice
orusediftheycomplywithcertainmandatoryrequirements.Thoserequirements
shouldensurethathigh-riskAIsystemsavailableintheUnionorwhoseoutputis
otherwiseusedintheUniondonotposeunacceptableriskstoimportantUnion
publicinterestsasrecognisedandprotectedbyUnionlaw.Onthebasisofthe
NewLegislativeFramework,asclarifiedintheCommissionnotice‘The“Blue
Guide”ontheimplementationofEUproductrules2022’(20),thegeneralruleis
thatmorethanonelegalactofUnionharmonisationlegislation,suchas
Regulations(EU)2017/745(21)and(EU)2017/746(22)oftheEuropeanParliament
andoftheCouncilorDirective2006/42/ECoftheEuropeanParliamentandof
theCouncil(23),maybeapplicabletooneproduct,sincethemakingavailableor

--- Page 18 ---
puttingintoservicecantakeplaceonlywhentheproductcomplieswithall
applicableUnionharmonisationlegislation.Toensureconsistencyandavoid
unnecessaryadministrativeburdensorcosts,providersofaproductthatcontains
oneormorehigh-riskAIsystems,towhichtherequirementsofthisRegulation
andoftheUnionharmonisationlegislationlistedinanannextothisRegulation
apply,shouldhaveflexibilitywithregardtooperationaldecisionsonhowto
ensurecomplianceofaproductthatcontainsoneormoreAIsystemswithall
applicablerequirementsoftheUnionharmonisationlegislationinanoptimal
manner.AIsystemsidentifiedashigh-riskshouldbelimitedtothosethathave
asignificantharmfulimpactonthehealth,safetyandfundamentalrightsof
personsintheUnionandsuchlimitationshouldminimiseanypotentialrestriction
tointernationaltrade.
(47)AIsystemscouldhaveanadverseimpactonthehealthandsafetyofpersons,in
particularwhensuchsystemsoperateassafetycomponentsofproducts.
ConsistentwiththeobjectivesofUnionharmonisationlegislationtofacilitatethe
freemovementofproductsintheinternalmarketandtoensurethatonlysafeand
otherwisecompliantproductsfindtheirwayintothemarket,itisimportantthat
thesafetyrisksthatmaybegeneratedbyaproductasawholeduetoitsdigital
components,includingAIsystems,aredulypreventedandmitigated.For
instance,increasinglyautonomousrobots,whetherinthecontextof
manufacturingorpersonalassistanceandcareshouldbeabletosafelyoperate
andperformstheirfunctionsincomplexenvironments.Similarly,inthehealth
sectorwherethestakesforlifeandhealthareparticularlyhigh,increasingly
sophisticateddiagnosticssystemsandsystemssupportinghumandecisionsshould
bereliableandaccurate.
(48)TheextentoftheadverseimpactcausedbytheAIsystemonthefundamental
rightsprotectedbytheCharterisofparticularrelevancewhenclassifyinganAI
systemashighrisk.Thoserightsincludetherighttohumandignity,respectfor
privateandfamilylife,protectionofpersonaldata,freedomofexpressionand
information,freedomofassemblyandofassociation,therighttonon-
discrimination,therighttoeducation,consumerprotection,workers’rights,the
rightsofpersonswithdisabilities,genderequality,intellectualpropertyrights,the
righttoaneffectiveremedyandtoafairtrial,therightofdefenceandthe
presumptionofinnocence,andtherighttogoodadministration.Inadditionto
thoserights,itisimportanttohighlightthefactthatchildrenhavespecificrights
asenshrinedinArticle24oftheCharterandintheUnitedNationsConventionon
theRightsoftheChild,furtherdevelopedintheUNCRCGeneralComment
No25asregardsthedigitalenvironment,bothofwhichrequireconsiderationof
thechildren’svulnerabilitiesandprovisionofsuchprotectionandcareas
necessaryfortheirwell-being.Thefundamentalrighttoahighlevelof
environmentalprotectionenshrinedintheCharterandimplementedinUnion
policiesshouldalsobeconsideredwhenassessingtheseverityoftheharmthatan
AIsystemcancause,includinginrelationtothehealthandsafetyofpersons.
(49)Asregardshigh-riskAIsystemsthataresafetycomponentsofproductsor
systems,orwhicharethemselvesproductsorsystemsfallingwithinthescopeof
Regulation(EC)No300/2008oftheEuropeanParliamentandoftheCouncil(24),
Regulation(EU)No167/2013oftheEuropeanParliamentandoftheCouncil(25),
Regulation(EU)No168/2013oftheEuropeanParliamentandoftheCouncil(26),

--- Page 19 ---
Directive2014/90/EUoftheEuropeanParliamentandoftheCouncil(27),
Directive(EU)2016/797oftheEuropeanParliamentandoftheCouncil(28),
Regulation(EU)2018/858oftheEuropeanParliamentandoftheCouncil(29),
Regulation(EU)2018/1139oftheEuropeanParliamentandoftheCouncil(30),
andRegulation(EU)2019/2144oftheEuropeanParliamentandofthe
Council(31),itisappropriatetoamendthoseactstoensurethattheCommission
takesintoaccount,onthebasisofthetechnicalandregulatoryspecificitiesof
eachsector,andwithoutinterferingwithexistinggovernance,conformity
assessmentandenforcementmechanismsandauthoritiesestablishedtherein,the
mandatoryrequirementsforhigh-riskAIsystemslaiddowninthisRegulation
whenadoptinganyrelevantdelegatedorimplementingactsonthebasisofthose
acts.
(50)AsregardsAIsystemsthataresafetycomponentsofproducts,orwhichare
themselvesproducts,fallingwithinthescopeofcertainUnionharmonisation
legislationlistedinanannextothisRegulation,itisappropriatetoclassifythem
ashigh-riskunderthisRegulationiftheproductconcernedundergoesthe
conformityassessmentprocedurewithathird-partyconformityassessmentbody
pursuanttothatrelevantUnionharmonisationlegislation.Inparticular,such
productsaremachinery,toys,lifts,equipmentandprotectivesystemsintendedfor
useinpotentiallyexplosiveatmospheres,radioequipment,pressureequipment,
recreationalcraftequipment,cablewayinstallations,appliancesburninggaseous
fuels,medicaldevices,invitrodiagnosticmedicaldevices,automotiveand
aviation.
(51)TheclassificationofanAIsystemashigh-riskpursuanttothisRegulationshould
notnecessarilymeanthattheproductwhosesafetycomponentistheAIsystem,
ortheAIsystemitselfasaproduct,isconsideredtobehigh-riskunderthecriteria
establishedintherelevantUnionharmonisationlegislationthatappliestothe
product.Thisis,inparticular,thecaseforRegulations(EU)2017/745and(EU)
2017/746,whereathird-partyconformityassessmentisprovidedformedium-risk
andhigh-riskproducts.
(52)Asregardsstand-aloneAIsystems,namelyhigh-riskAIsystemsotherthanthose
thataresafetycomponentsofproducts,orthatarethemselvesproducts,itis
appropriatetoclassifythemashigh-riskif,inlightoftheirintendedpurpose,they
poseahighriskofharmtothehealthandsafetyorthefundamentalrightsof
persons,takingintoaccountboththeseverityofthepossibleharmandits
probabilityofoccurrenceandtheyareusedinanumberofspecificallypre-
definedareasspecifiedinthisRegulation.Theidentificationofthosesystemsis
basedonthesamemethodologyandcriteriaenvisagedalsoforanyfuture
amendmentsofthelistofhigh-riskAIsystemsthattheCommissionshouldbe
empoweredtoadopt,viadelegatedacts,totakeintoaccounttherapidpaceof
technologicaldevelopment,aswellasthepotentialchangesintheuseofAI
systems.
(53)ItisalsoimportanttoclarifythattheremaybespecificcasesinwhichAIsystems
referredtoinpre-definedareasspecifiedinthisRegulationdonotleadto
asignificantriskofharmtothelegalinterestsprotectedunderthoseareasbecause
theydonotmateriallyinfluencethedecision-makingordonotharmthose
interestssubstantially.ForthepurposesofthisRegulation,anAIsystemthatdoes
notmateriallyinfluencetheoutcomeofdecision-makingshouldbeunderstoodto

--- Page 20 ---
beanAIsystemthatdoesnothaveanimpactonthesubstance,andtherebythe
outcome,ofdecision-making,whetherhumanorautomated.AnAIsystemthat
doesnotmateriallyinfluencetheoutcomeofdecision-makingcouldinclude
situationsinwhichoneormoreofthefollowingconditionsarefulfilled.Thefirst
suchconditionshouldbethattheAIsystemisintendedtoperformanarrow
proceduraltask,suchasanAIsystemthattransformsunstructureddatainto
structureddata,anAIsystemthatclassifiesincomingdocumentsintocategories
oranAIsystemthatisusedtodetectduplicatesamongalargenumberof
applications.Thosetasksareofsuchnarrowandlimitednaturethattheypose
onlylimitedriskswhicharenotincreasedthroughtheuseofanAIsystemin
acontextthatislistedasahigh-riskuseinanannextothisRegulation.The
secondconditionshouldbethatthetaskperformedbytheAIsystemisintended
toimprovetheresultofapreviouslycompletedhumanactivitythatmaybe
relevantforthepurposesofthehigh-riskuseslistedinanannextothis
Regulation.Consideringthosecharacteristics,theAIsystemprovidesonlyan
additionallayertoahumanactivitywithconsequentlyloweredrisk.That
conditionwould,forexample,applytoAIsystemsthatareintendedtoimprove
thelanguageusedinpreviouslydrafteddocuments,forexampleinrelationto
professionaltone,academicstyleoflanguageorbyaligningtexttoacertain
brandmessaging.ThethirdconditionshouldbethattheAIsystemisintendedto
detectdecision-makingpatternsordeviationsfrompriordecision-making
patterns.TheriskwouldbeloweredbecausetheuseoftheAIsystemfollows
apreviouslycompletedhumanassessmentwhichitisnotmeanttoreplaceor
influence,withoutproperhumanreview.SuchAIsystemsincludeforinstance
thosethat,givenacertaingradingpatternofateacher,canbeusedtocheckex
postwhethertheteachermayhavedeviatedfromthegradingpatternsoastoflag
potentialinconsistenciesoranomalies.ThefourthconditionshouldbethattheAI
systemisintendedtoperformataskthatisonlypreparatorytoanassessment
relevantforthepurposesoftheAIsystemslistedinanannextothisRegulation,
thusmakingthepossibleimpactoftheoutputofthesystemverylowintermsof
representingariskfortheassessmenttofollow.Thatconditioncovers,interalia,
smartsolutionsforfilehandling,whichincludevariousfunctionsfromindexing,
searching,textandspeechprocessingorlinkingdatatootherdatasources,orAI
systemsusedfortranslationofinitialdocuments.Inanycase,AIsystemsusedin
high-riskuse-caseslistedinanannextothisRegulationshouldbeconsideredto
posesignificantrisksofharmtothehealth,safetyorfundamentalrightsiftheAI
systemimpliesprofilingwithinthemeaningofArticle4,point(4)ofRegulation
(EU)2016/679orArticle3,point(4)ofDirective(EU)2016/680orArticle3,
point(5)ofRegulation(EU)2018/1725.Toensuretraceabilityandtransparency,
aproviderwhoconsidersthatanAIsystemisnothigh-riskonthebasisofthe
conditionsreferredtoaboveshoulddrawupdocumentationoftheassessment
beforethatsystemisplacedonthemarketorputintoserviceandshouldprovide
thatdocumentationtonationalcompetentauthoritiesuponrequest.Such
aprovidershouldbeobligedtoregistertheAIsystemintheEUdatabase
establishedunderthisRegulation.Withaviewtoprovidingfurtherguidancefor
thepracticalimplementationoftheconditionsunderwhichtheAIsystemslisted
inanannextothisRegulationare,onanexceptionalbasis,non-high-risk,the
Commissionshould,afterconsultingtheBoard,provideguidelinesspecifying
thatpracticalimplementation,completedbyacomprehensivelistofpractical
examplesofusecasesofAIsystemsthatarehigh-riskandusecasesthatarenot.

--- Page 21 ---
(54)Asbiometricdataconstitutesaspecialcategoryofpersonaldata,itisappropriate
toclassifyashigh-riskseveralcritical-usecasesofbiometricsystems,insofaras
theiruseispermittedunderrelevantUnionandnationallaw.Technical
inaccuraciesofAIsystemsintendedfortheremotebiometricidentificationof
naturalpersonscanleadtobiasedresultsandentaildiscriminatoryeffects.The
riskofsuchbiasedresultsanddiscriminatoryeffectsisparticularlyrelevantwith
regardtoage,ethnicity,race,sexordisabilities.Remotebiometricidentification
systemsshouldthereforebeclassifiedashigh-riskinviewoftherisksthatthey
pose.SuchaclassificationexcludesAIsystemsintendedtobeusedforbiometric
verification,includingauthentication,thesolepurposeofwhichistoconfirmthat
aspecificnaturalpersoniswhothatpersonclaimstobeandtoconfirmthe
identityofanaturalpersonforthesolepurposeofhavingaccesstoaservice,
unlockingadeviceorhavingsecureaccesstopremises.Inaddition,AIsystems
intendedtobeusedforbiometriccategorisationaccordingtosensitiveattributes
orcharacteristicsprotectedunderArticle9(1)ofRegulation(EU)2016/679on
thebasisofbiometricdata,insofarasthesearenotprohibitedunderthis
Regulation,andemotionrecognitionsystemsthatarenotprohibitedunderthis
Regulation,shouldbeclassifiedashigh-risk.Biometricsystemswhichare
intendedtobeusedsolelyforthepurposeofenablingcybersecurityandpersonal
dataprotectionmeasuresshouldnotbeconsideredtobehigh-riskAIsystems.
(55)Asregardsthemanagementandoperationofcriticalinfrastructure,itis
appropriatetoclassifyashigh-risktheAIsystemsintendedtobeusedassafety
componentsinthemanagementandoperationofcriticaldigitalinfrastructureas
listedinpoint(8)oftheAnnextoDirective(EU)2022/2557,roadtrafficandthe
supplyofwater,gas,heatingandelectricity,sincetheirfailureormalfunctioning
mayputatriskthelifeandhealthofpersonsatlargescaleandleadtoappreciable
disruptionsintheordinaryconductofsocialandeconomicactivities.Safety
componentsofcriticalinfrastructure,includingcriticaldigitalinfrastructure,are
systemsusedtodirectlyprotectthephysicalintegrityofcriticalinfrastructureor
thehealthandsafetyofpersonsandpropertybutwhicharenotnecessaryinorder
forthesystemtofunction.Thefailureormalfunctioningofsuchcomponents
mightdirectlyleadtoriskstothephysicalintegrityofcriticalinfrastructureand
thustoriskstohealthandsafetyofpersonsandproperty.Componentsintendedto
beusedsolelyforcybersecuritypurposesshouldnotqualifyassafety
components.Examplesofsafetycomponentsofsuchcriticalinfrastructuremay
includesystemsformonitoringwaterpressureorfirealarmcontrollingsystemsin
cloudcomputingcentres.
(56)ThedeploymentofAIsystemsineducationisimportanttopromotehigh-quality
digitaleducationandtrainingandtoallowalllearnersandteacherstoacquireand
sharethenecessarydigitalskillsandcompetences,includingmedialiteracy,and
criticalthinking,totakeanactivepartintheeconomy,society,andindemocratic
processes.However,AIsystemsusedineducationorvocationaltraining,in
particularfordeterminingaccessoradmission,forassigningpersonsto
educationalandvocationaltraininginstitutionsorprogrammesatalllevels,for
evaluatinglearningoutcomesofpersons,forassessingtheappropriatelevelof
educationforanindividualandmateriallyinfluencingthelevelofeducationand
trainingthatindividualswillreceiveorwillbeabletoaccessorformonitoring
anddetectingprohibitedbehaviourofstudentsduringtestsshouldbeclassifiedas

--- Page 22 ---
high-riskAIsystems,sincetheymaydeterminetheeducationalandprofessional
courseofaperson’slifeandthereforemayaffectthatperson’sabilitytosecure
alivelihood.Whenimproperlydesignedandused,suchsystemsmaybe
particularlyintrusiveandmayviolatetherighttoeducationandtrainingaswell
astherightnottobediscriminatedagainstandperpetuatehistoricalpatternsof
discrimination,forexampleagainstwomen,certainagegroups,personswith
disabilities,orpersonsofcertainracialorethnicoriginsorsexualorientation.
(57)AIsystemsusedinemployment,workersmanagementandaccesstoself-
employment,inparticularfortherecruitmentandselectionofpersons,formaking
decisionsaffectingtermsofthework-relatedrelationship,promotionand
terminationofwork-relatedcontractualrelationships,forallocatingtasksonthe
basisofindividualbehaviour,personaltraitsorcharacteristicsandformonitoring
orevaluationofpersonsinwork-relatedcontractualrelationships,shouldalsobe
classifiedashigh-risk,sincethosesystemsmayhaveanappreciableimpacton
futurecareerprospects,livelihoodsofthosepersonsandworkers’rights.Relevant
work-relatedcontractualrelationshipsshould,inameaningfulmanner,involve
employeesandpersonsprovidingservicesthroughplatformsasreferredtointhe
CommissionWorkProgramme2021.Throughouttherecruitmentprocessandin
theevaluation,promotion,orretentionofpersonsinwork-relatedcontractual
relationships,suchsystemsmayperpetuatehistoricalpatternsofdiscrimination,
forexampleagainstwomen,certainagegroups,personswithdisabilities,or
personsofcertainracialorethnicoriginsorsexualorientation.AIsystemsusedto
monitortheperformanceandbehaviourofsuchpersonsmayalsounderminetheir
fundamentalrightstodataprotectionandprivacy.
(58)AnotherareainwhichtheuseofAIsystemsdeservesspecialconsiderationisthe
accesstoandenjoymentofcertainessentialprivateandpublicservicesand
benefitsnecessaryforpeopletofullyparticipateinsocietyortoimproveone’s
standardofliving.Inparticular,naturalpersonsapplyingfororreceiving
essentialpublicassistancebenefitsandservicesfrompublicauthoritiesnamely
healthcareservices,socialsecuritybenefits,socialservicesprovidingprotection
incasessuchasmaternity,illness,industrialaccidents,dependencyoroldageand
lossofemploymentandsocialandhousingassistance,aretypicallydependenton
thosebenefitsandservicesandinavulnerablepositioninrelationtothe
responsibleauthorities.IfAIsystemsareusedfordeterminingwhethersuch
benefitsandservicesshouldbegranted,denied,reduced,revokedorreclaimedby
authorities,includingwhetherbeneficiariesarelegitimatelyentitledtosuch
benefitsorservices,thosesystemsmayhaveasignificantimpactonpersons’
livelihoodandmayinfringetheirfundamentalrights,suchastherighttosocial
protection,non-discrimination,humandignityoraneffectiveremedyandshould
thereforebeclassifiedashigh-risk.Nonetheless,thisRegulationshouldnot
hamperthedevelopmentanduseofinnovativeapproachesinthepublic
administration,whichwouldstandtobenefitfromawideruseofcompliantand
safeAIsystems,providedthatthosesystemsdonotentailahighrisktolegaland
naturalpersons.Inaddition,AIsystemsusedtoevaluatethecreditscoreor
creditworthinessofnaturalpersonsshouldbeclassifiedashigh-riskAIsystems,
sincetheydeterminethosepersons’accesstofinancialresourcesoressential
servicessuchashousing,electricity,andtelecommunicationservices.AIsystems
usedforthosepurposesmayleadtodiscriminationbetweenpersonsorgroups
andmayperpetuatehistoricalpatternsofdiscrimination,suchasthatbasedon

--- Page 23 ---
racialorethnicorigins,gender,disabilities,ageorsexualorientation,ormay
createnewformsofdiscriminatoryimpacts.However,AIsystemsprovidedfor
byUnionlawforthepurposeofdetectingfraudintheofferingoffinancial
servicesandforprudentialpurposestocalculatecreditinstitutions’andinsurance
undertakings’capitalrequirementsshouldnotbeconsideredtobehigh-riskunder
thisRegulation.Moreover,AIsystemsintendedtobeusedforriskassessment
andpricinginrelationtonaturalpersonsforhealthandlifeinsurancecanalso
haveasignificantimpactonpersons’livelihoodandifnotdulydesigned,
developedandused,caninfringetheirfundamentalrightsandcanleadtoserious
consequencesforpeople’slifeandhealth,includingfinancialexclusionand
discrimination.Finally,AIsystemsusedtoevaluateandclassifyemergencycalls
bynaturalpersonsortodispatchorestablishpriorityinthedispatchingof
emergencyfirstresponseservices,includingbypolice,firefightersandmedical
aid,aswellasofemergencyhealthcarepatienttriagesystems,shouldalsobe
classifiedashigh-risksincetheymakedecisionsinverycriticalsituationsforthe
lifeandhealthofpersonsandtheirproperty.
(59)Giventheirroleandresponsibility,actionsbylawenforcementauthorities
involvingcertainusesofAIsystemsarecharacterisedbyasignificantdegreeof
powerimbalanceandmayleadtosurveillance,arrestordeprivationofanatural
person’slibertyaswellasotheradverseimpactsonfundamentalrights
guaranteedintheCharter.Inparticular,iftheAIsystemisnottrainedwithhigh-
qualitydata,doesnotmeetadequaterequirementsintermsofitsperformance,its
accuracyorrobustness,orisnotproperlydesignedandtestedbeforebeingputon
themarketorotherwiseputintoservice,itmaysingleoutpeoplein
adiscriminatoryorotherwiseincorrectorunjustmanner.Furthermore,the
exerciseofimportantproceduralfundamentalrights,suchastherighttoan
effectiveremedyandtoafairtrialaswellastherightofdefenceandthe
presumptionofinnocence,couldbehampered,inparticular,wheresuchAI
systemsarenotsufficientlytransparent,explainableanddocumented.Itis
thereforeappropriatetoclassifyashigh-risk,insofarastheiruseispermitted
underrelevantUnionandnationallaw,anumberofAIsystemsintendedtobe
usedinthelawenforcementcontextwhereaccuracy,reliabilityandtransparency
isparticularlyimportanttoavoidadverseimpacts,retainpublictrustandensure
accountabilityandeffectiveredress.Inviewofthenatureoftheactivitiesandthe
risksrelatingthereto,thosehigh-riskAIsystemsshouldincludeinparticularAI
systemsintendedtobeusedbyoronbehalfoflawenforcementauthoritiesorby
Unioninstitutions,bodies,offices,oragenciesinsupportoflawenforcement
authoritiesforassessingtheriskofanaturalpersontobecomeavictimof
criminaloffences,aspolygraphsandsimilartools,fortheevaluationofthe
reliabilityofevidenceininthecourseofinvestigationorprosecutionofcriminal
offences,and,insofarasnotprohibitedunderthisRegulation,forassessingthe
riskofanaturalpersonoffendingorreoffendingnotsolelyonthebasisofthe
profilingofnaturalpersonsortheassessmentofpersonalitytraitsand
characteristicsorthepastcriminalbehaviourofnaturalpersonsorgroups,for
profilinginthecourseofdetection,investigationorprosecutionofcriminal
offences.AIsystemsspecificallyintendedtobeusedforadministrative
proceedingsbytaxandcustomsauthoritiesaswellasbyfinancialintelligence
unitscarryingoutadministrativetasksanalysinginformationpursuanttoUnion
anti-moneylaunderinglawshouldnotbeclassifiedashigh-riskAIsystemsused

--- Page 24 ---
bylawenforcementauthoritiesforthepurposeofprevention,detection,
investigationandprosecutionofcriminaloffences.TheuseofAItoolsbylaw
enforcementandotherrelevantauthoritiesshouldnotbecomeafactorof
inequality,orexclusion.TheimpactoftheuseofAItoolsonthedefencerightsof
suspectsshouldnotbeignored,inparticularthedifficultyinobtainingmeaningful
informationonthefunctioningofthosesystemsandtheresultingdifficultyin
challengingtheirresultsincourt,inparticularbynaturalpersonsunder
investigation.
(60)AIsystemsusedinmigration,asylumandbordercontrolmanagementaffect
personswhoareofteninparticularlyvulnerablepositionandwhoaredependent
ontheoutcomeoftheactionsofthecompetentpublicauthorities.Theaccuracy,
non-discriminatorynatureandtransparencyoftheAIsystemsusedinthose
contextsarethereforeparticularlyimportanttoguaranteerespectforthe
fundamentalrightsoftheaffectedpersons,inparticulartheirrightstofree
movement,non-discrimination,protectionofprivatelifeandpersonaldata,
internationalprotectionandgoodadministration.Itisthereforeappropriateto
classifyashigh-risk,insofarastheiruseispermittedunderrelevantUnionand
nationallaw,AIsystemsintendedtobeusedbyoronbehalfofcompetentpublic
authoritiesorbyUnioninstitutions,bodies,officesoragencieschargedwithtasks
inthefieldsofmigration,asylumandbordercontrolmanagementaspolygraphs
andsimilartools,forassessingcertainrisksposedbynaturalpersonsenteringthe
territoryofaMemberStateorapplyingforvisaorasylum,forassisting
competentpublicauthoritiesfortheexamination,includingrelatedassessmentof
thereliabilityofevidence,ofapplicationsforasylum,visaandresidencepermits
andassociatedcomplaintswithregardtotheobjectivetoestablishtheeligibility
ofthenaturalpersonsapplyingforastatus,forthepurposeofdetecting,
recognisingoridentifyingnaturalpersonsinthecontextofmigration,asylumand
bordercontrolmanagement,withtheexceptionofverificationoftravel
documents.AIsystemsintheareaofmigration,asylumandbordercontrol
managementcoveredbythisRegulationshouldcomplywiththerelevant
proceduralrequirementssetbytheRegulation(EC)No810/2009oftheEuropean
ParliamentandoftheCouncil(32),theDirective2013/32/EUoftheEuropean
ParliamentandoftheCouncil(33),andotherrelevantUnionlaw.TheuseofAI
systemsinmigration,asylumandbordercontrolmanagementshould,inno
circumstances,beusedbyMemberStatesorUnioninstitutions,bodies,officesor
agenciesasameanstocircumventtheirinternationalobligationsundertheUN
ConventionrelatingtotheStatusofRefugeesdoneatGenevaon28July1951as
amendedbytheProtocolof31January1967.Norshouldtheybeusedtoinany
wayinfringeontheprincipleofnon-refoulement,ortodenysafeandeffective
legalavenuesintotheterritoryoftheUnion,includingtherighttointernational
protection.
(61)CertainAIsystemsintendedfortheadministrationofjusticeanddemocratic
processesshouldbeclassifiedashigh-risk,consideringtheirpotentially
significantimpactondemocracy,theruleoflaw,individualfreedomsaswellas
therighttoaneffectiveremedyandtoafairtrial.Inparticular,toaddressthe
risksofpotentialbiases,errorsandopacity,itisappropriatetoqualifyashigh-
riskAIsystemsintendedtobeusedbyajudicialauthorityoronitsbehalfto
assistjudicialauthoritiesinresearchingandinterpretingfactsandthelawandin
applyingthelawtoaconcretesetoffacts.AIsystemsintendedtobeusedby

--- Page 25 ---
alternativedisputeresolutionbodiesforthosepurposesshouldalsobeconsidered
tobehigh-riskwhentheoutcomesofthealternativedisputeresolution
proceedingsproducelegaleffectsfortheparties.TheuseofAItoolscansupport
thedecision-makingpowerofjudgesorjudicialindependence,butshouldnot
replaceit:thefinaldecision-makingmustremainahuman-drivenactivity.The
classificationofAIsystemsashigh-riskshouldnot,however,extendtoAI
systemsintendedforpurelyancillaryadministrativeactivitiesthatdonotaffect
theactualadministrationofjusticeinindividualcases,suchasanonymisationor
pseudonymisationofjudicialdecisions,documentsordata,communication
betweenpersonnel,administrativetasks.
(62)WithoutprejudicetotherulesprovidedforinRegulation(EU)2024/900ofthe
EuropeanParliamentandoftheCouncil(34),andinordertoaddresstherisksof
undueexternalinterferencewiththerighttovoteenshrinedinArticle39ofthe
Charter,andofadverseeffectsondemocracyandtheruleoflaw,AIsystems
intendedtobeusedtoinfluencetheoutcomeofanelectionorreferendumorthe
votingbehaviourofnaturalpersonsintheexerciseoftheirvoteinelectionsor
referendashouldbeclassifiedashigh-riskAIsystemswiththeexceptionofAI
systemswhoseoutputnaturalpersonsarenotdirectlyexposedto,suchastools
usedtoorganise,optimiseandstructurepoliticalcampaignsfroman
administrativeandlogisticalpointofview.
(63)ThefactthatanAIsystemisclassifiedasahigh-riskAIsystemunderthis
Regulationshouldnotbeinterpretedasindicatingthattheuseofthesystemis
lawfulunderotheractsofUnionlaworundernationallawcompatiblewith
Unionlaw,suchasontheprotectionofpersonaldata,ontheuseofpolygraphs
andsimilartoolsorothersystemstodetecttheemotionalstateofnaturalpersons.
Anysuchuseshouldcontinuetooccursolelyinaccordancewiththeapplicable
requirementsresultingfromtheCharterandfromtheapplicableactsofsecondary
Unionlawandnationallaw.ThisRegulationshouldnotbeunderstoodas
providingforthelegalgroundforprocessingofpersonaldata,includingspecial
categoriesofpersonaldata,whererelevant,unlessitisspecificallyotherwise
providedforinthisRegulation.
(64)Tomitigatetherisksfromhigh-riskAIsystemsplacedonthemarketorputinto
serviceandtoensureahighleveloftrustworthiness,certainmandatory
requirementsshouldapplytohigh-riskAIsystems,takingintoaccountthe
intendedpurposeandthecontextofuseoftheAIsystemandaccordingtothe
risk-managementsystemtobeestablishedbytheprovider.Themeasuresadopted
bytheproviderstocomplywiththemandatoryrequirementsofthisRegulation
shouldtakeintoaccountthegenerallyacknowledgedstateoftheartonAI,be
proportionateandeffectivetomeettheobjectivesofthisRegulation.Basedonthe
NewLegislativeFramework,asclarifiedinCommissionnotice‘The“Blue
Guide”ontheimplementationofEUproductrules2022’,thegeneralruleisthat
morethanonelegalactofUnionharmonisationlegislationmaybeapplicableto
oneproduct,sincethemakingavailableorputtingintoservicecantakeplaceonly
whentheproductcomplieswithallapplicableUnionharmonisationlegislation.
ThehazardsofAIsystemscoveredbytherequirementsofthisRegulation
concerndifferentaspectsthantheexistingUnionharmonisationlegislationand
thereforetherequirementsofthisRegulationwouldcomplementtheexisting
bodyoftheUnionharmonisationlegislation.Forexample,machineryormedical

--- Page 26 ---
devicesproductsincorporatinganAIsystemmightpresentrisksnotaddressedby
theessentialhealthandsafetyrequirementssetoutintherelevantUnion
harmonisedlegislation,asthatsectorallawdoesnotdealwithrisksspecifictoAI
systems.Thiscallsforasimultaneousandcomplementaryapplicationofthe
variouslegislativeacts.Toensureconsistencyandtoavoidanunnecessary
administrativeburdenandunnecessarycosts,providersofaproductthatcontains
oneormorehigh-riskAIsystem,towhichtherequirementsofthisRegulation
andoftheUnionharmonisationlegislationbasedontheNewLegislative
FrameworkandlistedinanannextothisRegulationapply,shouldhaveflexibility
withregardtooperationaldecisionsonhowtoensurecomplianceofaproduct
thatcontainsoneormoreAIsystemswithalltheapplicablerequirementsofthat
Unionharmonisedlegislationinanoptimalmanner.Thatflexibilitycouldmean,
forexampleadecisionbytheprovidertointegrateapartofthenecessarytesting
andreportingprocesses,informationanddocumentationrequiredunderthis
Regulationintoalreadyexistingdocumentationandproceduresrequiredunder
existingUnionharmonisationlegislationbasedontheNewLegislative
FrameworkandlistedinanannextothisRegulation.Thisshouldnot,inanyway,
underminetheobligationoftheprovidertocomplywithalltheapplicable
requirements.
(65)Therisk-managementsystemshouldconsistofacontinuous,iterativeprocessthat
isplannedandrunthroughouttheentirelifecycleofahigh-riskAIsystem.That
processshouldbeaimedatidentifyingandmitigatingtherelevantrisksofAI
systemsonhealth,safetyandfundamentalrights.Therisk-managementsystem
shouldberegularlyreviewedandupdatedtoensureitscontinuingeffectiveness,
aswellasjustificationanddocumentationofanysignificantdecisionsandactions
takensubjecttothisRegulation.Thisprocessshouldensurethattheprovider
identifiesrisksoradverseimpactsandimplementsmitigationmeasuresforthe
knownandreasonablyforeseeablerisksofAIsystemstothehealth,safetyand
fundamentalrightsinlightoftheirintendedpurposeandreasonablyforeseeable
misuse,includingthepossiblerisksarisingfromtheinteractionbetweentheAI
systemandtheenvironmentwithinwhichitoperates.Therisk-management
systemshouldadoptthemostappropriaterisk-managementmeasuresinlightof
thestateoftheartinAI.Whenidentifyingthemostappropriaterisk-management
measures,theprovidershoulddocumentandexplainthechoicesmadeand,when
relevant,involveexpertsandexternalstakeholders.Inidentifyingthereasonably
foreseeablemisuseofhigh-riskAIsystems,theprovidershouldcoverusesofAI
systemswhich,whilenotdirectlycoveredbytheintendedpurposeandprovided
forintheinstructionforusemayneverthelessbereasonablyexpectedtoresult
fromreadilypredictablehumanbehaviourinthecontextofthespecific
characteristicsanduseofaparticularAIsystem.Anyknownorforeseeable
circumstancesrelatedtotheuseofthehigh-riskAIsysteminaccordancewithits
intendedpurposeorunderconditionsofreasonablyforeseeablemisuse,which
mayleadtoriskstothehealthandsafetyorfundamentalrightsshouldbe
includedintheinstructionsforusethatareprovidedbytheprovider.Thisisto
ensurethatthedeployerisawareandtakesthemintoaccountwhenusingthe
high-riskAIsystem.Identifyingandimplementingriskmitigationmeasuresfor
foreseeablemisuseunderthisRegulationshouldnotrequirespecificadditional
trainingforthehigh-riskAIsystembytheprovidertoaddressforeseeablemisuse.
Theprovidershoweverareencouragedtoconsidersuchadditionaltraining

--- Page 27 ---
measurestomitigatereasonableforeseeablemisusesasnecessaryand
appropriate.
(66)Requirementsshouldapplytohigh-riskAIsystemsasregardsriskmanagement,
thequalityandrelevanceofdatasetsused,technicaldocumentationandrecord-
keeping,transparencyandtheprovisionofinformationtodeployers,human
oversight,androbustness,accuracyandcybersecurity.Thoserequirementsare
necessarytoeffectivelymitigatetherisksforhealth,safetyandfundamental
rights.Asnootherlesstraderestrictivemeasuresarereasonablyavailablethose
requirementsarenotunjustifiedrestrictionstotrade.
(67)High-qualitydataandaccesstohigh-qualitydataplaysavitalroleinproviding
structureandinensuringtheperformanceofmanyAIsystems,especiallywhen
techniquesinvolvingthetrainingofmodelsareused,withaviewtoensurethat
thehigh-riskAIsystemperformsasintendedandsafelyanditdoesnotbecome
asourceofdiscriminationprohibitedbyUnionlaw.High-qualitydatasetsfor
training,validationandtestingrequiretheimplementationofappropriatedata
governanceandmanagementpractices.Datasetsfortraining,validationand
testing,includingthelabels,shouldberelevant,sufficientlyrepresentative,andto
thebestextentpossiblefreeoferrorsandcompleteinviewoftheintended
purposeofthesystem.InordertofacilitatecompliancewithUniondata
protectionlaw,suchasRegulation(EU)2016/679,datagovernanceand
managementpracticesshouldinclude,inthecaseofpersonaldata,transparency
abouttheoriginalpurposeofthedatacollection.Thedatasetsshouldalsohave
theappropriatestatisticalproperties,includingasregardsthepersonsorgroupsof
personsinrelationtowhomthehigh-riskAIsystemisintendedtobeused,with
specificattentiontothemitigationofpossiblebiasesinthedatasets,thatare
likelytoaffectthehealthandsafetyofpersons,haveanegativeimpacton
fundamentalrightsorleadtodiscriminationprohibitedunderUnionlaw,
especiallywheredataoutputsinfluenceinputsforfutureoperations(feedback
loops).Biasescanforexamplebeinherentinunderlyingdatasets,especially
whenhistoricaldataisbeingused,orgeneratedwhenthesystemsare
implementedinrealworldsettings.ResultsprovidedbyAIsystemscouldbe
influencedbysuchinherentbiasesthatareinclinedtograduallyincreaseand
therebyperpetuateandamplifyexistingdiscrimination,inparticularforpersons
belongingtocertainvulnerablegroups,includingracialorethnicgroups.The
requirementforthedatasetstobetothebestextentpossiblecompleteandfreeof
errorsshouldnotaffecttheuseofprivacy-preservingtechniquesinthecontextof
thedevelopmentandtestingofAIsystems.Inparticular,datasetsshouldtake
intoaccount,totheextentrequiredbytheirintendedpurpose,thefeatures,
characteristicsorelementsthatareparticulartothespecificgeographical,
contextual,behaviouralorfunctionalsettingwhichtheAIsystemisintendedto
beused.Therequirementsrelatedtodatagovernancecanbecompliedwithby
havingrecoursetothirdpartiesthatoffercertifiedcomplianceservicesincluding
verificationofdatagovernance,datasetintegrity,anddatatraining,validation
andtestingpractices,asfarascompliancewiththedatarequirementsofthis
Regulationareensured.
(68)Forthedevelopmentandassessmentofhigh-riskAIsystems,certainactors,such
asproviders,notifiedbodiesandotherrelevantentities,suchasEuropeanDigital
InnovationHubs,testingexperimentationfacilitiesandresearchers,shouldbe

--- Page 28 ---
abletoaccessandusehigh-qualitydatasetswithinthefieldsofactivitiesofthose
actorswhicharerelatedtothisRegulation.Europeancommondataspaces
establishedbytheCommissionandthefacilitationofdatasharingbetween
businessesandwithgovernmentinthepublicinterestwillbeinstrumentalto
providetrustful,accountableandnon-discriminatoryaccesstohigh-qualitydata
forthetraining,validationandtestingofAIsystems.Forexample,inhealth,the
Europeanhealthdataspacewillfacilitatenon-discriminatoryaccesstohealthdata
andthetrainingofAIalgorithmsonthosedatasets,inaprivacy-preserving,
secure,timely,transparentandtrustworthymanner,andwithanappropriate
institutionalgovernance.Relevantcompetentauthorities,includingsectoralones,
providingorsupportingtheaccesstodatamayalsosupporttheprovisionofhigh-
qualitydataforthetraining,validationandtestingofAIsystems.
(69)Therighttoprivacyandtoprotectionofpersonaldatamustbeguaranteed
throughouttheentirelifecycleoftheAIsystem.Inthisregard,theprinciplesof
dataminimisationanddataprotectionbydesignandbydefault,assetoutin
Uniondataprotectionlaw,areapplicablewhenpersonaldataareprocessed.
Measurestakenbyproviderstoensurecompliancewiththoseprinciplesmay
includenotonlyanonymisationandencryption,butalsotheuseoftechnology
thatpermitsalgorithmstobebroughttothedataandallowstrainingofAI
systemswithoutthetransmissionbetweenpartiesorcopyingoftherawor
structureddatathemselves,withoutprejudicetotherequirementsondata
governanceprovidedforinthisRegulation.
(70)Inordertoprotecttherightofothersfromthediscriminationthatmightresult
fromthebiasinAIsystems,theprovidersshould,exceptionally,totheextentthat
itisstrictlynecessaryforthepurposeofensuringbiasdetectionandcorrectionin
relationtothehigh-riskAIsystems,subjecttoappropriatesafeguardsforthe
fundamentalrightsandfreedomsofnaturalpersonsandfollowingtheapplication
ofallapplicableconditionslaiddownunderthisRegulationinadditiontothe
conditionslaiddowninRegulations(EU)2016/679and(EU)2018/1725and
Directive(EU)2016/680,beabletoprocessalsospecialcategoriesofpersonal
data,asamatterofsubstantialpublicinterestwithinthemeaningofArticle9(2),
point(g)ofRegulation(EU)2016/679andArticle10(2),point(g)ofRegulation
(EU)2018/1725.
(71)Havingcomprehensibleinformationonhowhigh-riskAIsystemshavebeen
developedandhowtheyperformthroughouttheirlifetimeisessentialtoenable
traceabilityofthosesystems,verifycompliancewiththerequirementsunderthis
Regulation,aswellasmonitoringoftheiroperationsandpostmarketmonitoring.
Thisrequireskeepingrecordsandtheavailabilityoftechnicaldocumentation,
containinginformationwhichisnecessarytoassessthecomplianceoftheAI
systemwiththerelevantrequirementsandfacilitatepostmarketmonitoring.Such
informationshouldincludethegeneralcharacteristics,capabilitiesandlimitations
ofthesystem,algorithms,data,training,testingandvalidationprocessesusedas
wellasdocumentationontherelevantrisk-managementsystemanddrawnin
aclearandcomprehensiveform.Thetechnicaldocumentationshouldbekeptup
todate,appropriatelythroughoutthelifetimeoftheAIsystem.Furthermore,
high-riskAIsystemsshouldtechnicallyallowfortheautomaticrecordingof
events,bymeansoflogs,overthedurationofthelifetimeofthesystem.
(72)ToaddressconcernsrelatedtoopacityandcomplexityofcertainAIsystemsand

--- Page 29 ---
helpdeployerstofulfiltheirobligationsunderthisRegulation,transparency
shouldberequiredforhigh-riskAIsystemsbeforetheyareplacedonthemarket
orputitintoservice.High-riskAIsystemsshouldbedesignedinamannerto
enabledeployerstounderstandhowtheAIsystemworks,evaluateits
functionality,andcomprehenditsstrengthsandlimitations.High-riskAIsystems
shouldbeaccompaniedbyappropriateinformationintheformofinstructionsof
use.Suchinformationshouldincludethecharacteristics,capabilitiesand
limitationsofperformanceoftheAIsystem.Thosewouldcoverinformationon
possibleknownandforeseeablecircumstancesrelatedtotheuseofthehigh-risk
AIsystem,includingdeployeractionthatmayinfluencesystembehaviourand
performance,underwhichtheAIsystemcanleadtoriskstohealth,safety,and
fundamentalrights,onthechangesthathavebeenpre-determinedandassessed
forconformitybytheproviderandontherelevanthumanoversightmeasures,
includingthemeasurestofacilitatetheinterpretationoftheoutputsoftheAI
systembythedeployers.Transparency,includingtheaccompanyinginstructions
foruse,shouldassistdeployersintheuseofthesystemandsupportinformed
decisionmakingbythem.Deployersshould,interalia,beinabetterpositionto
makethecorrectchoiceofthesystemthattheyintendtouseinlightofthe
obligationsapplicabletothem,beeducatedabouttheintendedandprecluded
uses,andusetheAIsystemcorrectlyandasappropriate.Inordertoenhance
legibilityandaccessibilityoftheinformationincludedintheinstructionsofuse,
whereappropriate,illustrativeexamples,forinstanceonthelimitationsandonthe
intendedandprecludedusesoftheAIsystem,shouldbeincluded.Providers
shouldensurethatalldocumentation,includingtheinstructionsforuse,contains
meaningful,comprehensive,accessibleandunderstandableinformation,taking
intoaccounttheneedsandforeseeableknowledgeofthetargetdeployers.
Instructionsforuseshouldbemadeavailableinalanguagewhichcanbeeasily
understoodbytargetdeployers,asdeterminedbytheMemberStateconcerned.
(73)High-riskAIsystemsshouldbedesignedanddevelopedinsuchawaythat
naturalpersonscanoverseetheirfunctioning,ensurethattheyareusedas
intendedandthattheirimpactsareaddressedoverthesystem’slifecycle.Tothat
end,appropriatehumanoversightmeasuresshouldbeidentifiedbytheprovider
ofthesystembeforeitsplacingonthemarketorputtingintoservice.In
particular,whereappropriate,suchmeasuresshouldguaranteethatthesystemis
subjecttoin-builtoperationalconstraintsthatcannotbeoverriddenbythesystem
itselfandisresponsivetothehumanoperator,andthatthenaturalpersonsto
whomhumanoversighthasbeenassignedhavethenecessarycompetence,
trainingandauthoritytocarryoutthatrole.Itisalsoessential,asappropriate,to
ensurethathigh-riskAIsystemsincludemechanismstoguideandinform
anaturalpersontowhomhumanoversighthasbeenassignedtomakeinformed
decisionsif,whenandhowtointerveneinordertoavoidnegativeconsequences
orrisks,orstopthesystemifitdoesnotperformasintended.Consideringthe
significantconsequencesforpersonsinthecaseofanincorrectmatchbycertain
biometricidentificationsystems,itisappropriatetoprovideforanenhanced
humanoversightrequirementforthosesystemssothatnoactionordecisionmay
betakenbythedeployeronthebasisoftheidentificationresultingfromthe
systemunlessthishasbeenseparatelyverifiedandconfirmedbyatleasttwo
naturalpersons.Thosepersonscouldbefromoneormoreentitiesandincludethe
personoperatingorusingthesystem.Thisrequirementshouldnotpose

--- Page 30 ---
unnecessaryburdenordelaysanditcouldbesufficientthattheseparate
verificationsbythedifferentpersonsareautomaticallyrecordedinthelogs
generatedbythesystem.Giventhespecificitiesoftheareasoflawenforcement,
migration,bordercontrolandasylum,thisrequirementshouldnotapplywhere
Unionornationallawconsiderstheapplicationofthatrequirementtobe
disproportionate.
(74)High-riskAIsystemsshouldperformconsistentlythroughouttheirlifecycleand
meetanappropriatelevelofaccuracy,robustnessandcybersecurity,inlightof
theirintendedpurposeandinaccordancewiththegenerallyacknowledgedstate
oftheart.TheCommissionandrelevantorganisationsandstakeholdersare
encouragedtotakedueconsiderationofthemitigationofrisksandthenegative
impactsoftheAIsystem.Theexpectedlevelofperformancemetricsshouldbe
declaredintheaccompanyinginstructionsofuse.Providersareurgedto
communicatethatinformationtodeployersinaclearandeasilyunderstandable
way,freeofmisunderstandingsormisleadingstatements.Unionlawonlegal
metrology,includingDirectives2014/31/EU(35)and2014/32/EU(36)ofthe
EuropeanParliamentandoftheCouncil,aimstoensuretheaccuracyof
measurementsandtohelpthetransparencyandfairnessofcommercial
transactions.Inthatcontext,incooperationwithrelevantstakeholdersand
organisation,suchasmetrologyandbenchmarkingauthorities,theCommission
shouldencourage,asappropriate,thedevelopmentofbenchmarksand
measurementmethodologiesforAIsystems.Indoingso,theCommissionshould
takenoteandcollaboratewithinternationalpartnersworkingonmetrologyand
relevantmeasurementindicatorsrelatingtoAI.
(75)Technicalrobustnessisakeyrequirementforhigh-riskAIsystems.Theyshould
beresilientinrelationtoharmfulorotherwiseundesirablebehaviourthatmay
resultfromlimitationswithinthesystemsortheenvironmentinwhichthe
systemsoperate(e.g.errors,faults,inconsistencies,unexpectedsituations).
Therefore,technicalandorganisationalmeasuresshouldbetakentoensure
robustnessofhigh-riskAIsystems,forexamplebydesigninganddeveloping
appropriatetechnicalsolutionstopreventorminimiseharmfulorotherwise
undesirablebehaviour.Thosetechnicalsolutionmayincludeforinstance
mechanismsenablingthesystemtosafelyinterruptitsoperation(fail-safeplans)
inthepresenceofcertainanomaliesorwhenoperationtakesplaceoutsidecertain
predeterminedboundaries.Failuretoprotectagainsttheseriskscouldleadto
safetyimpactsornegativelyaffectthefundamentalrights,forexampledueto
erroneousdecisionsorwrongorbiasedoutputsgeneratedbytheAIsystem.
(76)CybersecurityplaysacrucialroleinensuringthatAIsystemsareresilientagainst
attemptstoaltertheiruse,behaviour,performanceorcompromisetheirsecurity
propertiesbymaliciousthirdpartiesexploitingthesystem’svulnerabilities.
CyberattacksagainstAIsystemscanleverageAIspecificassets,suchastraining
datasets(e.g.datapoisoning)ortrainedmodels(e.g.adversarialattacksor
membershipinference),orexploitvulnerabilitiesintheAIsystem’sdigitalassets
ortheunderlyingICTinfrastructure.Toensurealevelofcybersecurity
appropriatetotherisks,suitablemeasures,suchassecuritycontrols,should
thereforebetakenbytheprovidersofhigh-riskAIsystems,alsotakinginto
accountasappropriatetheunderlyingICTinfrastructure.
(77)Withoutprejudicetotherequirementsrelatedtorobustnessandaccuracysetout

--- Page 31 ---
inthisRegulation,high-riskAIsystemswhichfallwithinthescopeof
aregulationoftheEuropeanParliamentandoftheCouncilonhorizontal
cybersecurityrequirementsforproductswithdigitalelements,inaccordancewith
thatregulationmaydemonstratecompliancewiththecybersecurityrequirements
ofthisRegulationbyfulfillingtheessentialcybersecurityrequirementssetoutin
thatregulation.Whenhigh-riskAIsystemsfulfiltheessentialrequirementsof
aregulationoftheEuropeanParliamentandoftheCouncilonhorizontal
cybersecurityrequirementsforproductswithdigitalelements,theyshouldbe
deemedcompliantwiththecybersecurityrequirementssetoutinthisRegulation
insofarastheachievementofthoserequirementsisdemonstratedintheEU
declarationofconformityorpartsthereofissuedunderthatregulation.Tothat
end,theassessmentofthecybersecurityrisks,associatedtoaproductwithdigital
elementsclassifiedashigh-riskAIsystemaccordingtothisRegulation,carried
outunderaregulationoftheEuropeanParliamentandoftheCouncilon
horizontalcybersecurityrequirementsforproductswithdigitalelements,should
considerriskstothecyberresilienceofanAIsystemasregardsattemptsby
unauthorisedthirdpartiestoalteritsuse,behaviourorperformance,includingAI
specificvulnerabilitiessuchasdatapoisoningoradversarialattacks,aswellas,as
relevant,riskstofundamentalrightsasrequiredbythisRegulation.
(78)TheconformityassessmentprocedureprovidedbythisRegulationshouldapply
inrelationtotheessentialcybersecurityrequirementsofaproductwithdigital
elementscoveredbyaregulationoftheEuropeanParliamentandoftheCouncil
onhorizontalcybersecurityrequirementsforproductswithdigitalelementsand
classifiedasahigh-riskAIsystemunderthisRegulation.However,thisrule
shouldnotresultinreducingthenecessarylevelofassuranceforcriticalproducts
withdigitalelementscoveredbyaregulationoftheEuropeanParliamentandof
theCouncilonhorizontalcybersecurityrequirementsforproductswithdigital
elements.Therefore,bywayofderogationfromthisrule,high-riskAIsystems
thatfallwithinthescopeofthisRegulationandarealsoqualifiedasimportant
andcriticalproductswithdigitalelementspursuanttoaregulationofthe
EuropeanParliamentandoftheCouncilonhorizontalcybersecurityrequirements
forproductswithdigitalelementsandtowhichtheconformityassessment
procedurebasedoninternalcontrolsetoutinanannextothisRegulationapplies,
aresubjecttotheconformityassessmentprovisionsofaregulationofthe
EuropeanParliamentandoftheCouncilonhorizontalcybersecurityrequirements
forproductswithdigitalelementsinsofarastheessentialcybersecurity
requirementsofthatregulationareconcerned.Inthiscase,foralltheother
aspectscoveredbythisRegulationtherespectiveprovisionsonconformity
assessmentbasedoninternalcontrolsetoutinanannextothisRegulationshould
apply.BuildingontheknowledgeandexpertiseofENISAonthecybersecurity
policyandtasksassignedtoENISAundertheRegulation(EU)2019/881ofthe
EuropeanParliamentandoftheCouncil(37),theCommissionshouldcooperate
withENISAonissuesrelatedtocybersecurityofAIsystems.
(79)Itisappropriatethataspecificnaturalorlegalperson,definedastheprovider,
takesresponsibilityfortheplacingonthemarketortheputtingintoserviceof
ahigh-riskAIsystem,regardlessofwhetherthatnaturalorlegalpersonisthe
personwhodesignedordevelopedthesystem.
(80)AssignatoriestotheUnitedNationsConventionontheRightsofPersonswith

--- Page 32 ---
Disabilities,theUnionandtheMemberStatesarelegallyobligedtoprotect
personswithdisabilitiesfromdiscriminationandpromotetheirequality,toensure
thatpersonswithdisabilitieshaveaccess,onanequalbasiswithothers,to
informationandcommunicationstechnologiesandsystems,andtoensurerespect
forprivacyforpersonswithdisabilities.Giventhegrowingimportanceanduseof
AIsystems,theapplicationofuniversaldesignprinciplestoallnewtechnologies
andservicesshouldensurefullandequalaccessforeveryonepotentiallyaffected
byorusingAItechnologies,includingpersonswithdisabilities,inawaythat
takesfullaccountoftheirinherentdignityanddiversity.Itisthereforeessential
thatprovidersensurefullcompliancewithaccessibilityrequirements,including
Directive(EU)2016/2102oftheEuropeanParliamentandoftheCouncil(38)and
Directive(EU)2019/882.Providersshouldensurecompliancewiththese
requirementsbydesign.Therefore,thenecessarymeasuresshouldbeintegrated
asmuchaspossibleintothedesignofthehigh-riskAIsystem.
(81)Theprovidershouldestablishasoundqualitymanagementsystem,ensurethe
accomplishmentoftherequiredconformityassessmentprocedure,drawupthe
relevantdocumentationandestablisharobustpost-marketmonitoringsystem.
Providersofhigh-riskAIsystemsthataresubjecttoobligationsregardingquality
managementsystemsunderrelevantsectoralUnionlawshouldhavethe
possibilitytoincludetheelementsofthequalitymanagementsystemprovidedfor
inthisRegulationaspartoftheexistingqualitymanagementsystemprovidedfor
inthatothersectoralUnionlaw.ThecomplementaritybetweenthisRegulation
andexistingsectoralUnionlawshouldalsobetakenintoaccountinfuture
standardisationactivitiesorguidanceadoptedbytheCommission.Public
authoritieswhichputintoservicehigh-riskAIsystemsfortheirownusemay
adoptandimplementtherulesforthequalitymanagementsystemaspartofthe
qualitymanagementsystemadoptedatanationalorregionallevel,asappropriate,
takingintoaccountthespecificitiesofthesectorandthecompetencesand
organisationofthepublicauthorityconcerned.
(82)ToenableenforcementofthisRegulationandcreatealevelplayingfieldfor
operators,and,takingintoaccountthedifferentformsofmakingavailableof
digitalproducts,itisimportanttoensurethat,underallcircumstances,aperson
establishedintheUnioncanprovideauthoritieswithallthenecessary
informationonthecomplianceofanAIsystem.Therefore,priortomakingtheir
AIsystemsavailableintheUnion,providersestablishedinthirdcountriesshould,
bywrittenmandate,appointanauthorisedrepresentativeestablishedintheUnion.
Thisauthorisedrepresentativeplaysapivotalroleinensuringthecomplianceof
thehigh-riskAIsystemsplacedonthemarketorputintoserviceintheUnionby
thoseproviderswhoarenotestablishedintheUnionandinservingastheir
contactpersonestablishedintheUnion.
(83)InlightofthenatureandcomplexityofthevaluechainforAIsystemsandinline
withtheNewLegislativeFramework,itisessentialtoensurelegalcertaintyand
facilitatethecompliancewiththisRegulation.Therefore,itisnecessarytoclarify
theroleandthespecificobligationsofrelevantoperatorsalongthatvaluechain,
suchasimportersanddistributorswhomaycontributetothedevelopmentofAI
systems.Incertainsituationsthoseoperatorscouldactinmorethanoneroleat
thesametimeandshouldthereforefulfilcumulativelyallrelevantobligations
associatedwiththoseroles.Forexample,anoperatorcouldactasadistributor

--- Page 33 ---
andanimporteratthesametime.
(84)Toensurelegalcertainty,itisnecessarytoclarifythat,undercertainspecific
conditions,anydistributor,importer,deployerorotherthird-partyshouldbe
consideredtobeaproviderofahigh-riskAIsystemandthereforeassumeallthe
relevantobligations.Thiswouldbethecaseifthatpartyputsitsnameor
trademarkonahigh-riskAIsystemalreadyplacedonthemarketorputinto
service,withoutprejudicetocontractualarrangementsstipulatingthatthe
obligationsareallocatedotherwise.Thiswouldalsobethecaseifthatparty
makesasubstantialmodificationtoahigh-riskAIsystemthathasalreadybeen
placedonthemarketorhasalreadybeenputintoserviceinawaythatitremains
ahigh-riskAIsysteminaccordancewiththisRegulation,orifitmodifiesthe
intendedpurposeofanAIsystem,includingageneral-purposeAIsystem,which
hasnotbeenclassifiedashigh-riskandhasalreadybeenplacedonthemarketor
putintoservice,inawaythattheAIsystembecomesahigh-riskAIsystemin
accordancewiththisRegulation.Thoseprovisionsshouldapplywithoutprejudice
tomorespecificprovisionsestablishedincertainUnionharmonisationlegislation
basedontheNewLegislativeFramework,togetherwithwhichthisRegulation
shouldapply.Forexample,Article16(2)ofRegulation(EU)2017/745,
establishingthatcertainchangesshouldnotbeconsideredtobemodificationsof
adevicethatcouldaffectitscompliancewiththeapplicablerequirements,should
continuetoapplytohigh-riskAIsystemsthataremedicaldeviceswithinthe
meaningofthatRegulation.
(85)General-purposeAIsystemsmaybeusedashigh-riskAIsystemsbythemselves
orbecomponentsofotherhigh-riskAIsystems.Therefore,duetotheirparticular
natureandinordertoensureafairsharingofresponsibilitiesalongtheAIvalue
chain,theprovidersofsuchsystemsshould,irrespectiveofwhethertheymaybe
usedashigh-riskAIsystemsassuchbyotherprovidersorascomponentsofhigh-
riskAIsystemsandunlessprovidedotherwiseunderthisRegulation,closely
cooperatewiththeprovidersoftherelevanthigh-riskAIsystemstoenabletheir
compliancewiththerelevantobligationsunderthisRegulationandwiththe
competentauthoritiesestablishedunderthisRegulation.
(86)Where,undertheconditionslaiddowninthisRegulation,theproviderthat
initiallyplacedtheAIsystemonthemarketorputitintoserviceshouldnolonger
beconsideredtobetheproviderforthepurposesofthisRegulation,andwhen
thatproviderhasnotexpresslyexcludedthechangeoftheAIsystemintoahigh-
riskAIsystem,theformerprovidershouldnonethelesscloselycooperateand
makeavailablethenecessaryinformationandprovidethereasonablyexpected
technicalaccessandotherassistancethatarerequiredforthefulfilmentofthe
obligationssetoutinthisRegulation,inparticularregardingthecompliancewith
theconformityassessmentofhigh-riskAIsystems.
(87)Inaddition,whereahigh-riskAIsystemthatisasafetycomponentofaproduct
whichfallswithinthescopeofUnionharmonisationlegislationbasedontheNew
LegislativeFrameworkisnotplacedonthemarketorputintoservice
independentlyfromtheproduct,theproductmanufacturerdefinedinthat
legislationshouldcomplywiththeobligationsoftheproviderestablishedinthis
Regulationandshould,inparticular,ensurethattheAIsystemembeddedinthe
finalproductcomplieswiththerequirementsofthisRegulation.

--- Page 34 ---
(88)AlongtheAIvaluechainmultiplepartiesoftensupplyAIsystems,toolsand
servicesbutalsocomponentsorprocessesthatareincorporatedbytheprovider
intotheAIsystemwithvariousobjectives,includingthemodeltraining,model
retraining,modeltestingandevaluation,integrationintosoftware,orother
aspectsofmodeldevelopment.Thosepartieshaveanimportantroletoplayinthe
valuechaintowardstheproviderofthehigh-riskAIsystemintowhichtheirAI
systems,tools,services,componentsorprocessesareintegrated,andshould
providebywrittenagreementthisproviderwiththenecessaryinformation,
capabilities,technicalaccessandotherassistancebasedonthegenerally
acknowledgedstateoftheart,inordertoenabletheprovidertofullycomplywith
theobligationssetoutinthisRegulation,withoutcompromisingtheirown
intellectualpropertyrightsortradesecrets.
(89)Thirdpartiesmakingaccessibletothepublictools,services,processes,orAI
componentsotherthangeneral-purposeAImodels,shouldnotbemandatedto
complywithrequirementstargetingtheresponsibilitiesalongtheAIvaluechain,
inparticulartowardstheproviderthathasusedorintegratedthem,whenthose
tools,services,processes,orAIcomponentsaremadeaccessibleunderafreeand
open-sourcelicence.Developersoffreeandopen-sourcetools,services,
processes,orAIcomponentsotherthangeneral-purposeAImodelsshouldbe
encouragedtoimplementwidelyadopteddocumentationpractices,suchasmodel
cardsanddatasheets,asawaytoaccelerateinformationsharingalongtheAI
valuechain,allowingthepromotionoftrustworthyAIsystemsintheUnion.
(90)TheCommissioncoulddevelopandrecommendvoluntarymodelcontractual
termsbetweenprovidersofhigh-riskAIsystemsandthirdpartiesthatsupply
tools,services,componentsorprocessesthatareusedorintegratedinhigh-risk
AIsystems,tofacilitatethecooperationalongthevaluechain.Whendeveloping
voluntarymodelcontractualterms,theCommissionshouldalsotakeintoaccount
possiblecontractualrequirementsapplicableinspecificsectorsorbusinesscases.
(91)GiventhenatureofAIsystemsandtheriskstosafetyandfundamentalrights
possiblyassociatedwiththeiruse,includingasregardstheneedtoensureproper
monitoringoftheperformanceofanAIsysteminareal-lifesetting,itis
appropriatetosetspecificresponsibilitiesfordeployers.Deployersshouldin
particulartakeappropriatetechnicalandorganisationalmeasurestoensurethey
usehigh-riskAIsystemsinaccordancewiththeinstructionsofuseandcertain
otherobligationsshouldbeprovidedforwithregardtomonitoringofthe
functioningoftheAIsystemsandwithregardtorecord-keeping,asappropriate.
Furthermore,deployersshouldensurethatthepersonsassignedtoimplementthe
instructionsforuseandhumanoversightassetoutinthisRegulationhavethe
necessarycompetence,inparticularanadequatelevelofAIliteracy,trainingand
authoritytoproperlyfulfilthosetasks.Thoseobligationsshouldbewithout
prejudicetootherdeployerobligationsinrelationtohigh-riskAIsystemsunder
Unionornationallaw.
(92)ThisRegulationiswithoutprejudicetoobligationsforemployerstoinformorto
informandconsultworkersortheirrepresentativesunderUnionornationallaw
andpractice,includingDirective2002/14/ECoftheEuropeanParliamentandof
theCouncil(39),ondecisionstoputintoserviceoruseAIsystems.Itremains
necessarytoensureinformationofworkersandtheirrepresentativesonthe

--- Page 35 ---
planneddeploymentofhigh-riskAIsystemsattheworkplacewherethe
conditionsforthoseinformationorinformationandconsultationobligationsin
otherlegalinstrumentsarenotfulfilled.Moreover,suchinformationrightis
ancillaryandnecessarytotheobjectiveofprotectingfundamentalrightsthat
underliesthisRegulation.Therefore,aninformationrequirementtothateffect
shouldbelaiddowninthisRegulation,withoutaffectinganyexistingrightsof
workers.
(93)WhilstrisksrelatedtoAIsystemscanresultfromthewaysuchsystemsare
designed,riskscanaswellstemfromhowsuchAIsystemsareused.Deployers
ofhigh-riskAIsystemthereforeplayacriticalroleinensuringthatfundamental
rightsareprotected,complementingtheobligationsoftheproviderwhen
developingtheAIsystem.Deployersarebestplacedtounderstandhowthehigh-
riskAIsystemwillbeusedconcretelyandcanthereforeidentifypotential
significantrisksthatwerenotforeseeninthedevelopmentphase,duetoamore
preciseknowledgeofthecontextofuse,thepersonsorgroupsofpersonslikelyto
beaffected,includingvulnerablegroups.Deployersofhigh-riskAIsystemslisted
inanannextothisRegulationalsoplayacriticalroleininformingnaturalpersons
andshould,whentheymakedecisionsorassistinmakingdecisionsrelatedto
naturalpersons,whereapplicable,informthenaturalpersonsthattheyaresubject
totheuseofthehigh-riskAIsystem.Thisinformationshouldincludethe
intendedpurposeandthetypeofdecisionsitmakes.Thedeployershouldalso
informthenaturalpersonsabouttheirrighttoanexplanationprovidedunderthis
Regulation.Withregardtohigh-riskAIsystemsusedforlawenforcement
purposes,thatobligationshouldbeimplementedinaccordancewithArticle13of
Directive(EU)2016/680.
(94)AnyprocessingofbiometricdatainvolvedintheuseofAIsystemsforbiometric
identificationforthepurposeoflawenforcementneedstocomplywithArticle10
ofDirective(EU)2016/680,thatallowssuchprocessingonlywherestrictly
necessary,subjecttoappropriatesafeguardsfortherightsandfreedomsofthe
datasubject,andwhereauthorisedbyUnionorMemberStatelaw.Suchuse,
whenauthorised,alsoneedstorespecttheprincipleslaiddowninArticle4(1)of
Directive(EU)2016/680includinglawfulness,fairnessandtransparency,purpose
limitation,accuracyandstoragelimitation.
(95)WithoutprejudicetoapplicableUnionlaw,inparticularRegulation(EU)
2016/679andDirective(EU)2016/680,consideringtheintrusivenatureofpost-
remotebiometricidentificationsystems,theuseofpost-remotebiometric
identificationsystemsshouldbesubjecttosafeguards.Post-remotebiometric
identificationsystemsshouldalwaysbeusedinawaythatisproportionate,
legitimateandstrictlynecessary,andthustargeted,intermsoftheindividualsto
beidentified,thelocation,temporalscopeandbasedonacloseddatasetof
legallyacquiredvideofootage.Inanycase,post-remotebiometricidentification
systemsshouldnotbeusedintheframeworkoflawenforcementtoleadto
indiscriminatesurveillance.Theconditionsforpost-remotebiometric
identificationshouldinanycasenotprovideabasistocircumventtheconditions
oftheprohibitionandstrictexceptionsforrealtimeremotebiometric
identification.
(96)Inordertoefficientlyensurethatfundamentalrightsareprotected,deployersof
high-riskAIsystemsthatarebodiesgovernedbypubliclaw,orprivateentities

--- Page 36 ---
providingpublicservicesanddeployersofcertainhigh-riskAIsystemslistedin
anannextothisRegulation,suchasbankingorinsuranceentities,shouldcarry
outafundamentalrightsimpactassessmentpriortoputtingitintouse.Services
importantforindividualsthatareofpublicnaturemayalsobeprovidedbyprivate
entities.Privateentitiesprovidingsuchpublicservicesarelinkedtotasksinthe
publicinterestsuchasintheareasofeducation,healthcare,socialservices,
housing,administrationofjustice.Theaimofthefundamentalrightsimpact
assessmentisforthedeployertoidentifythespecificriskstotherightsof
individualsorgroupsofindividualslikelytobeaffected,identifymeasurestobe
takeninthecaseofamaterialisationofthoserisks.Theimpactassessmentshould
beperformedpriortodeployingthehigh-riskAIsystem,andshouldbeupdated
whenthedeployerconsidersthatanyoftherelevantfactorshavechanged.The
impactassessmentshouldidentifythedeployer’srelevantprocessesinwhichthe
high-riskAIsystemwillbeusedinlinewithitsintendedpurpose,andshould
includeadescriptionoftheperiodoftimeandfrequencyinwhichthesystemis
intendedtobeusedaswellasofspecificcategoriesofnaturalpersonsandgroups
whoarelikelytobeaffectedinthespecificcontextofuse.Theassessmentshould
alsoincludetheidentificationofspecificrisksofharmlikelytohaveanimpacton
thefundamentalrightsofthosepersonsorgroups.Whileperformingthis
assessment,thedeployershouldtakeintoaccountinformationrelevanttoaproper
assessmentoftheimpact,includingbutnotlimitedtotheinformationgivenby
theproviderofthehigh-riskAIsystemintheinstructionsforuse.Inlightofthe
risksidentified,deployersshoulddeterminemeasurestobetakeninthecaseof
amaterialisationofthoserisks,includingforexamplegovernancearrangements
inthatspecificcontextofuse,suchasarrangementsforhumanoversight
accordingtotheinstructionsofuseor,complainthandlingandredress
procedures,astheycouldbeinstrumentalinmitigatingriskstofundamentalrights
inconcreteuse-cases.Afterperformingthatimpactassessment,thedeployer
shouldnotifytherelevantmarketsurveillanceauthority.Whereappropriate,to
collectrelevantinformationnecessarytoperformtheimpactassessment,
deployersofhigh-riskAIsystem,inparticularwhenAIsystemsareusedinthe
publicsector,couldinvolverelevantstakeholders,includingtherepresentativesof
groupsofpersonslikelytobeaffectedbytheAIsystem,independentexperts,and
civilsocietyorganisationsinconductingsuchimpactassessmentsanddesigning
measurestobetakeninthecaseofmaterialisationoftherisks.TheEuropean
ArtificialIntelligenceOffice(AIOffice)shoulddevelopatemplatefor
aquestionnaireinordertofacilitatecomplianceandreducetheadministrative
burdenfordeployers.
(97)Thenotionofgeneral-purposeAImodelsshouldbeclearlydefinedandsetapart
fromthenotionofAIsystemstoenablelegalcertainty.Thedefinitionshouldbe
basedonthekeyfunctionalcharacteristicsofageneral-purposeAImodel,in
particularthegeneralityandthecapabilitytocompetentlyperformawiderange
ofdistincttasks.Thesemodelsaretypicallytrainedonlargeamountsofdata,
throughvariousmethods,suchasself-supervised,unsupervisedorreinforcement
learning.General-purposeAImodelsmaybeplacedonthemarketinvarious
ways,includingthroughlibraries,applicationprogramminginterfaces(APIs),as
directdownload,orasphysicalcopy.Thesemodelsmaybefurthermodifiedor
fine-tunedintonewmodels.AlthoughAImodelsareessentialcomponentsofAI
systems,theydonotconstituteAIsystemsontheirown.AImodelsrequirethe

--- Page 37 ---
additionoffurthercomponents,suchasforexampleauserinterface,tobecome
AIsystems.AImodelsaretypicallyintegratedintoandformpartofAIsystems.
ThisRegulationprovidesspecificrulesforgeneral-purposeAImodelsandfor
general-purposeAImodelsthatposesystemicrisks,whichshouldapplyalso
whenthesemodelsareintegratedorformpartofanAIsystem.Itshouldbe
understoodthattheobligationsfortheprovidersofgeneral-purposeAImodels
shouldapplyoncethegeneral-purposeAImodelsareplacedonthemarket.When
theproviderofageneral-purposeAImodelintegratesanownmodelintoitsown
AIsystemthatismadeavailableonthemarketorputintoservice,thatmodel
shouldbeconsideredtobeplacedonthemarketand,therefore,theobligationsin
thisRegulationformodelsshouldcontinuetoapplyinadditiontothoseforAI
systems.Theobligationslaiddownformodelsshouldinanycasenotapplywhen
anownmodelisusedforpurelyinternalprocessesthatarenotessentialfor
providingaproductoraservicetothirdpartiesandtherightsofnaturalpersons
arenotaffected.Consideringtheirpotentialsignificantlynegativeeffects,the
general-purposeAImodelswithsystemicriskshouldalwaysbesubjecttothe
relevantobligationsunderthisRegulation.ThedefinitionshouldnotcoverAI
modelsusedbeforetheirplacingonthemarketforthesolepurposeofresearch,
developmentandprototypingactivities.Thisiswithoutprejudicetotheobligation
tocomplywiththisRegulationwhen,followingsuchactivities,amodelisplaced
onthemarket.
(98)Whereasthegeneralityofamodelcould,interalia,alsobedeterminedby
anumberofparameters,modelswithatleastabillionofparametersandtrained
withalargeamountofdatausingself-supervisionatscaleshouldbeconsidered
todisplaysignificantgeneralityandtocompetentlyperformawiderangeof
distinctivetasks.
(99)LargegenerativeAImodelsareatypicalexampleforageneral-purposeAI
model,giventhattheyallowforflexiblegenerationofcontent,suchasinthe
formoftext,audio,imagesorvideo,thatcanreadilyaccommodateawiderange
ofdistinctivetasks.
(100)Whenageneral-purposeAImodelisintegratedintoorformspartofanAI
system,thissystemshouldbeconsideredtobegeneral-purposeAIsystemwhen,
duetothisintegration,thissystemhasthecapabilitytoserveavarietyof
purposes.Ageneral-purposeAIsystemcanbeuseddirectly,oritmaybe
integratedintootherAIsystems.
(101)Providersofgeneral-purposeAImodelshaveaparticularroleandresponsibility
alongtheAIvaluechain,asthemodelstheyprovidemayformthebasisfor
arangeofdownstreamsystems,oftenprovidedbydownstreamprovidersthat
necessitateagoodunderstandingofthemodelsandtheircapabilities,bothto
enabletheintegrationofsuchmodelsintotheirproducts,andtofulfiltheir
obligationsunderthisorotherregulations.Therefore,proportionatetransparency
measuresshouldbelaiddown,includingthedrawingupandkeepinguptodate
ofdocumentation,andtheprovisionofinformationonthegeneral-purposeAI
modelforitsusagebythedownstreamproviders.Technicaldocumentation
shouldbepreparedandkeptuptodatebythegeneral-purposeAImodel
providerforthepurposeofmakingitavailable,uponrequest,totheAIOffice
andthenationalcompetentauthorities.Theminimalsetofelementstobe
includedinsuchdocumentationshouldbesetoutinspecificannexestothis

--- Page 38 ---
Regulation.TheCommissionshouldbeempoweredtoamendthoseannexesby
meansofdelegatedactsinlightofevolvingtechnologicaldevelopments.
(102)Softwareanddata,includingmodels,releasedunderafreeandopen-source
licencethatallowsthemtobeopenlysharedandwhereuserscanfreelyaccess,
use,modifyandredistributethemormodifiedversionsthereof,cancontributeto
researchandinnovationinthemarketandcanprovidesignificantgrowth
opportunitiesfortheUnioneconomy.General-purposeAImodelsreleased
underfreeandopen-sourcelicencesshouldbeconsideredtoensurehighlevels
oftransparencyandopennessiftheirparameters,includingtheweights,the
informationonthemodelarchitecture,andtheinformationonmodelusageare
madepubliclyavailable.Thelicenceshouldbeconsideredtobefreeandopen-
sourcealsowhenitallowsuserstorun,copy,distribute,study,changeand
improvesoftwareanddata,includingmodelsundertheconditionthatthe
originalproviderofthemodeliscredited,theidenticalorcomparabletermsof
distributionarerespected.
(103)Freeandopen-sourceAIcomponentscoversthesoftwareanddata,including
modelsandgeneral-purposeAImodels,tools,servicesorprocessesofanAI
system.Freeandopen-sourceAIcomponentscanbeprovidedthroughdifferent
channels,includingtheirdevelopmentonopenrepositories.Forthepurposesof
thisRegulation,AIcomponentsthatareprovidedagainstapriceorotherwise
monetised,includingthroughtheprovisionoftechnicalsupportorother
services,includingthroughasoftwareplatform,relatedtotheAIcomponent,or
theuseofpersonaldataforreasonsotherthanexclusivelyforimprovingthe
security,compatibilityorinteroperabilityofthesoftware,withtheexceptionof
transactionsbetweenmicroenterprises,shouldnotbenefitfromtheexceptions
providedtofreeandopen-sourceAIcomponents.ThefactofmakingAI
componentsavailablethroughopenrepositoriesshouldnot,initself,constitute
amonetisation.
(104)Theprovidersofgeneral-purposeAImodelsthatarereleasedunderafreeand
open-sourcelicence,andwhoseparameters,includingtheweights,the
informationonthemodelarchitecture,andtheinformationonmodelusage,are
madepubliclyavailableshouldbesubjecttoexceptionsasregardsthe
transparency-relatedrequirementsimposedongeneral-purposeAImodels,
unlesstheycanbeconsideredtopresentasystemicrisk,inwhichcasethe
circumstancethatthemodelistransparentandaccompaniedbyanopen-source
licenseshouldnotbeconsideredtobeasufficientreasontoexcludecompliance
withtheobligationsunderthisRegulation.Inanycase,giventhatthereleaseof
general-purposeAImodelsunderfreeandopen-sourcelicencedoesnot
necessarilyrevealsubstantialinformationonthedatasetusedforthetrainingor
fine-tuningofthemodelandonhowcomplianceofcopyrightlawwasthereby
ensured,theexceptionprovidedforgeneral-purposeAImodelsfromcompliance
withthetransparency-relatedrequirementsshouldnotconcerntheobligationto
produceasummaryaboutthecontentusedformodeltrainingandtheobligation
toputinplaceapolicytocomplywithUnioncopyrightlaw,inparticularto
identifyandcomplywiththereservationofrightspursuanttoArticle4(3)of
Directive(EU)2019/790oftheEuropeanParliamentandoftheCouncil(40).
(105)General-purposeAImodels,inparticularlargegenerativeAImodels,capableof
generatingtext,images,andothercontent,presentuniqueinnovation

--- Page 39 ---
opportunitiesbutalsochallengestoartists,authors,andothercreatorsandthe
waytheircreativecontentiscreated,distributed,usedandconsumed.The
developmentandtrainingofsuchmodelsrequireaccesstovastamountsoftext,
images,videosandotherdata.Textanddataminingtechniquesmaybeused
extensivelyinthiscontextfortheretrievalandanalysisofsuchcontent,which
maybeprotectedbycopyrightandrelatedrights.Anyuseofcopyrightprotected
contentrequirestheauthorisationoftherightsholderconcernedunlessrelevant
copyrightexceptionsandlimitationsapply.Directive(EU)2019/790introduced
exceptionsandlimitationsallowingreproductionsandextractionsofworksor
othersubjectmatter,forthepurposeoftextanddatamining,undercertain
conditions.Undertheserules,rightsholdersmaychoosetoreservetheirrights
overtheirworksorothersubjectmattertopreventtextanddatamining,unless
thisisdoneforthepurposesofscientificresearch.Wheretherightstooptout
hasbeenexpresslyreservedinanappropriatemanner,providersofgeneral-
purposeAImodelsneedtoobtainanauthorisationfromrightsholdersifthey
wanttocarryouttextanddataminingoversuchworks.
(106)Providersthatplacegeneral-purposeAImodelsontheUnionmarketshould
ensurecompliancewiththerelevantobligationsinthisRegulation.Tothatend,
providersofgeneral-purposeAImodelsshouldputinplaceapolicytocomply
withUnionlawoncopyrightandrelatedrights,inparticulartoidentifyand
complywiththereservationofrightsexpressedbyrightsholderspursuantto
Article4(3)ofDirective(EU)2019/790.Anyproviderplacingageneral-
purposeAImodelontheUnionmarketshouldcomplywiththisobligation,
regardlessofthejurisdictioninwhichthecopyright-relevantactsunderpinning
thetrainingofthosegeneral-purposeAImodelstakeplace.Thisisnecessaryto
ensurealevelplayingfieldamongprovidersofgeneral-purposeAImodels
wherenoprovidershouldbeabletogainacompetitiveadvantageintheUnion
marketbyapplyinglowercopyrightstandardsthanthoseprovidedintheUnion.
(107)Inordertoincreasetransparencyonthedatathatisusedinthepre-trainingand
trainingofgeneral-purposeAImodels,includingtextanddataprotectedby
copyrightlaw,itisadequatethatprovidersofsuchmodelsdrawupandmake
publiclyavailableasufficientlydetailedsummaryofthecontentusedfor
trainingthegeneral-purposeAImodel.Whiletakingintodueaccounttheneed
toprotecttradesecretsandconfidentialbusinessinformation,thissummary
shouldbegenerallycomprehensiveinitsscopeinsteadoftechnicallydetailedto
facilitatepartieswithlegitimateinterests,includingcopyrightholders,to
exerciseandenforcetheirrightsunderUnionlaw,forexamplebylistingthe
maindatacollectionsorsetsthatwentintotrainingthemodel,suchaslarge
privateorpublicdatabasesordataarchives,andbyprovidinganarrative
explanationaboutotherdatasourcesused.ItisappropriatefortheAIOfficeto
provideatemplateforthesummary,whichshouldbesimple,effective,and
allowtheprovidertoprovidetherequiredsummaryinnarrativeform.
(108)Withregardtotheobligationsimposedonprovidersofgeneral-purposeAI
modelstoputinplaceapolicytocomplywithUnioncopyrightlawandmake
publiclyavailableasummaryofthecontentusedforthetraining,theAIOffice
shouldmonitorwhethertheproviderhasfulfilledthoseobligationswithout
verifyingorproceedingtoawork-by-workassessmentofthetrainingdatain
termsofcopyrightcompliance.ThisRegulationdoesnotaffecttheenforcement

--- Page 40 ---
ofcopyrightrulesasprovidedforunderUnionlaw.
(109)Compliancewiththeobligationsapplicabletotheprovidersofgeneral-purpose
AImodelsshouldbecommensurateandproportionatetothetypeofmodel
provider,excludingtheneedforcomplianceforpersonswhodeveloporuse
modelsfornon-professionalorscientificresearchpurposes,whoshould
neverthelessbeencouragedtovoluntarilycomplywiththeserequirements.
WithoutprejudicetoUnioncopyrightlaw,compliancewiththoseobligations
shouldtakedueaccountofthesizeoftheproviderandallowsimplifiedwaysof
complianceforSMEs,includingstart-ups,thatshouldnotrepresentanexcessive
costandnotdiscouragetheuseofsuchmodels.Inthecaseofamodificationor
fine-tuningofamodel,theobligationsforprovidersofgeneral-purposeAI
modelsshouldbelimitedtothatmodificationorfine-tuning,forexampleby
complementingthealreadyexistingtechnicaldocumentationwithinformation
onthemodifications,includingnewtrainingdatasources,asameanstocomply
withthevaluechainobligationsprovidedinthisRegulation.
(110)General-purposeAImodelscouldposesystemicriskswhichinclude,butarenot
limitedto,anyactualorreasonablyforeseeablenegativeeffectsinrelationto
majoraccidents,disruptionsofcriticalsectorsandseriousconsequencesto
publichealthandsafety;anyactualorreasonablyforeseeablenegativeeffectson
democraticprocesses,publicandeconomicsecurity;thedisseminationofillegal,
false,ordiscriminatorycontent.Systemicrisksshouldbeunderstoodtoincrease
withmodelcapabilitiesandmodelreach,canarisealongtheentirelifecycleof
themodel,andareinfluencedbyconditionsofmisuse,modelreliability,model
fairnessandmodelsecurity,thelevelofautonomyofthemodel,itsaccessto
tools,novelorcombinedmodalities,releaseanddistributionstrategies,the
potentialtoremoveguardrailsandotherfactors.Inparticular,international
approacheshavesofaridentifiedtheneedtopayattentiontorisksfrompotential
intentionalmisuseorunintendedissuesofcontrolrelatingtoalignmentwith
humanintent;chemical,biological,radiological,andnuclearrisks,suchasthe
waysinwhichbarrierstoentrycanbelowered,includingforweapons
development,designacquisition,oruse;offensivecybercapabilities,suchasthe
waysinvulnerabilitydiscovery,exploitation,oroperationalusecanbeenabled;
theeffectsofinteractionandtooluse,includingforexamplethecapacityto
controlphysicalsystemsandinterferewithcriticalinfrastructure;risksfrom
modelsofmakingcopiesofthemselvesor‘self-replicating’ortrainingother
models;thewaysinwhichmodelscangiverisetoharmfulbiasand
discriminationwithriskstoindividuals,communitiesorsocieties;thefacilitation
ofdisinformationorharmingprivacywiththreatstodemocraticvaluesand
humanrights;riskthataparticulareventcouldleadtoachainreactionwith
considerablenegativeeffectsthatcouldaffectuptoanentirecity,anentire
domainactivityoranentirecommunity.
(111)Itisappropriatetoestablishamethodologyfortheclassificationofgeneral-
purposeAImodelsasgeneral-purposeAImodelwithsystemicrisks.Since
systemicrisksresultfromparticularlyhighcapabilities,ageneral-purposeAI
modelshouldbeconsideredtopresentsystemicrisksifithashigh-impact
capabilities,evaluatedonthebasisofappropriatetechnicaltoolsand
methodologies,orsignificantimpactontheinternalmarketduetoitsreach.
High-impactcapabilitiesingeneral-purposeAImodelsmeanscapabilitiesthat

--- Page 41 ---
matchorexceedthecapabilitiesrecordedinthemostadvancedgeneral-purpose
AImodels.Thefullrangeofcapabilitiesinamodelcouldbebetterunderstood
afteritsplacingonthemarketorwhendeployersinteractwiththemodel.
AccordingtothestateoftheartatthetimeofentryintoforceofthisRegulation,
thecumulativeamountofcomputationusedforthetrainingofthegeneral-
purposeAImodelmeasuredinfloatingpointoperationsisoneoftherelevant
approximationsformodelcapabilities.Thecumulativeamountofcomputation
usedfortrainingincludesthecomputationusedacrosstheactivitiesandmethods
thatareintendedtoenhancethecapabilitiesofthemodelpriortodeployment,
suchaspre-training,syntheticdatagenerationandfine-tuning.Therefore,an
initialthresholdoffloatingpointoperationsshouldbeset,which,ifmetby
ageneral-purposeAImodel,leadstoapresumptionthatthemodelisageneral-
purposeAImodelwithsystemicrisks.Thisthresholdshouldbeadjustedover
timetoreflecttechnologicalandindustrialchanges,suchasalgorithmic
improvementsorincreasedhardwareefficiency,andshouldbesupplemented
withbenchmarksandindicatorsformodelcapability.Toinformthis,theAI
Officeshouldengagewiththescientificcommunity,industry,civilsocietyand
otherexperts.Thresholds,aswellastoolsandbenchmarksfortheassessmentof
high-impactcapabilities,shouldbestrongpredictorsofgenerality,its
capabilitiesandassociatedsystemicriskofgeneral-purposeAImodels,and
couldtakeintoaccountthewaythemodelwillbeplacedonthemarketorthe
numberofusersitmayaffect.Tocomplementthissystem,thereshouldbe
apossibilityfortheCommissiontotakeindividualdecisionsdesignating
ageneral-purposeAImodelasageneral-purposeAImodelwithsystemicriskif
itisfoundthatsuchmodelhascapabilitiesoranimpactequivalenttothose
capturedbythesetthreshold.Thatdecisionshouldbetakenonthebasisofan
overallassessmentofthecriteriaforthedesignationofageneral-purposeAI
modelwithsystemicrisksetoutinanannextothisRegulation,suchasquality
orsizeofthetrainingdataset,numberofbusinessandendusers,itsinputand
outputmodalities,itslevelofautonomyandscalability,orthetoolsithasaccess
to.Uponareasonedrequestofaproviderwhosemodelhasbeendesignatedas
ageneral-purposeAImodelwithsystemicrisk,theCommissionshouldtakethe
requestintoaccountandmaydecidetoreassesswhetherthegeneral-purposeAI
modelcanstillbeconsideredtopresentsystemicrisks.
(112)Itisalsonecessarytoclarifyaprocedurefortheclassificationofageneral-
purposeAImodelwithsystemicrisks.Ageneral-purposeAImodelthatmeets
theapplicablethresholdforhigh-impactcapabilitiesshouldbepresumedtobe
ageneral-purposeAImodelswithsystemicrisk.Theprovidershouldnotifythe
AIOfficeatthelatesttwoweeksaftertherequirementsaremetoritbecomes
knownthatageneral-purposeAImodelwillmeettherequirementsthatleadto
thepresumption.Thisisespeciallyrelevantinrelationtothethresholdof
floatingpointoperationsbecausetrainingofgeneral-purposeAImodelstakes
considerableplanningwhichincludestheupfrontallocationofcompute
resourcesand,therefore,providersofgeneral-purposeAImodelsareableto
knowiftheirmodelwouldmeetthethresholdbeforethetrainingiscompleted.
Inthecontextofthatnotification,theprovidershouldbeabletodemonstrate
that,becauseofitsspecificcharacteristics,ageneral-purposeAImodel
exceptionallydoesnotpresentsystemicrisks,andthatitthusshouldnotbe
classifiedasageneral-purposeAImodelwithsystemicrisks.Thatinformationis

--- Page 42 ---
valuablefortheAIOfficetoanticipatetheplacingonthemarketofgeneral-
purposeAImodelswithsystemicrisksandtheproviderscanstarttoengage
withtheAIOfficeearlyon.Thatinformationisespeciallyimportantwithregard
togeneral-purposeAImodelsthatareplannedtobereleasedasopen-source,
giventhat,aftertheopen-sourcemodelrelease,necessarymeasurestoensure
compliancewiththeobligationsunderthisRegulationmaybemoredifficultto
implement.
(113)IftheCommissionbecomesawareofthefactthatageneral-purposeAImodel
meetstherequirementstoclassifyasageneral-purposeAImodelwithsystemic
risk,whichpreviouslyhadeithernotbeenknownorofwhichtherelevant
providerhasfailedtonotifytheCommission,theCommissionshouldbe
empoweredtodesignateitso.Asystemofqualifiedalertsshouldensurethatthe
AIOfficeismadeawarebythescientificpanelofgeneral-purposeAImodels
thatshouldpossiblybeclassifiedasgeneral-purposeAImodelswithsystemic
risk,inadditiontothemonitoringactivitiesoftheAIOffice.
(114)Theprovidersofgeneral-purposeAImodelspresentingsystemicrisksshouldbe
subject,inadditiontotheobligationsprovidedforprovidersofgeneral-purpose
AImodels,toobligationsaimedatidentifyingandmitigatingthoserisksand
ensuringanadequatelevelofcybersecurityprotection,regardlessofwhetherit
isprovidedasastandalonemodelorembeddedinanAIsystemoraproduct.To
achievethoseobjectives,thisRegulationshouldrequireproviderstoperformthe
necessarymodelevaluations,inparticularpriortoitsfirstplacingonthemarket,
includingconductinganddocumentingadversarialtestingofmodels,also,as
appropriate,throughinternalorindependentexternaltesting.Inaddition,
providersofgeneral-purposeAImodelswithsystemicrisksshouldcontinuously
assessandmitigatesystemicrisks,includingforexamplebyputtinginplace
risk-managementpolicies,suchasaccountabilityandgovernanceprocesses,
implementingpost-marketmonitoring,takingappropriatemeasuresalongthe
entiremodel’slifecycleandcooperatingwithrelevantactorsalongtheAIvalue
chain.
(115)Providersofgeneral-purposeAImodelswithsystemicrisksshouldassessand
mitigatepossiblesystemicrisks.If,despiteeffortstoidentifyandpreventrisks
relatedtoageneral-purposeAImodelthatmaypresentsystemicrisks,the
developmentoruseofthemodelcausesaseriousincident,thegeneral-purpose
AImodelprovidershouldwithoutunduedelaykeeptrackoftheincidentand
reportanyrelevantinformationandpossiblecorrectivemeasurestothe
Commissionandnationalcompetentauthorities.Furthermore,providersshould
ensureanadequatelevelofcybersecurityprotectionforthemodelandits
physicalinfrastructure,ifappropriate,alongtheentiremodellifecycle.
Cybersecurityprotectionrelatedtosystemicrisksassociatedwithmalicioususe
orattacksshoulddulyconsideraccidentalmodelleakage,unauthorisedreleases,
circumventionofsafetymeasures,anddefenceagainstcyberattacks,
unauthorisedaccessormodeltheft.Thatprotectioncouldbefacilitatedby
securingmodelweights,algorithms,servers,anddatasets,suchasthrough
operationalsecuritymeasuresforinformationsecurity,specificcybersecurity
policies,adequatetechnicalandestablishedsolutions,andcyberandphysical
accesscontrols,appropriatetotherelevantcircumstancesandtherisksinvolved.
(116)TheAIOfficeshouldencourageandfacilitatethedrawingup,reviewand

--- Page 43 ---
adaptationofcodesofpractice,takingintoaccountinternationalapproaches.All
providersofgeneral-purposeAImodelscouldbeinvitedtoparticipate.To
ensurethatthecodesofpracticereflectthestateoftheartanddulytakeinto
accountadiversesetofperspectives,theAIOfficeshouldcollaboratewith
relevantnationalcompetentauthorities,andcould,whereappropriate,consult
withcivilsocietyorganisationsandotherrelevantstakeholdersandexperts,
includingtheScientificPanel,forthedrawingupofsuchcodes.Codesof
practiceshouldcoverobligationsforprovidersofgeneral-purposeAImodels
andofgeneral-purposeAImodelspresentingsystemicrisks.Inaddition,as
regardssystemicrisks,codesofpracticeshouldhelptoestablisharisk
taxonomyofthetypeandnatureofthesystemicrisksatUnionlevel,including
theirsources.Codesofpracticeshouldalsobefocusedonspecificrisk
assessmentandmitigationmeasures.
(117)Thecodesofpracticeshouldrepresentacentraltoolforthepropercompliance
withtheobligationsprovidedforunderthisRegulationforprovidersofgeneral-
purposeAImodels.Providersshouldbeabletorelyoncodesofpracticeto
demonstratecompliancewiththeobligations.Bymeansofimplementingacts,
theCommissionmaydecidetoapproveacodeofpracticeandgiveitageneral
validitywithintheUnion,or,alternatively,toprovidecommonrulesforthe
implementationoftherelevantobligations,if,bythetimethisRegulation
becomesapplicable,acodeofpracticecannotbefinalisedorisnotdeemed
adequatebytheAIOffice.Onceaharmonisedstandardispublishedand
assessedassuitabletocovertherelevantobligationsbytheAIOffice,
compliancewithaEuropeanharmonisedstandardshouldgrantprovidersthe
presumptionofconformity.Providersofgeneral-purposeAImodelsshould
furthermorebeabletodemonstratecomplianceusingalternativeadequate
means,ifcodesofpracticeorharmonisedstandardsarenotavailable,orthey
choosenottorelyonthose.
(118)ThisRegulationregulatesAIsystemsandAImodelsbyimposingcertain
requirementsandobligationsforrelevantmarketactorsthatareplacingthemon
themarket,puttingintoserviceoruseintheUnion,therebycomplementing
obligationsforprovidersofintermediaryservicesthatembedsuchsystemsor
modelsintotheirservicesregulatedbyRegulation(EU)2022/2065.Tothe
extentthatsuchsystemsormodelsareembeddedintodesignatedverylarge
onlineplatformsorverylargeonlinesearchengines,theyaresubjecttotherisk-
managementframeworkprovidedforinRegulation(EU)2022/2065.
Consequently,thecorrespondingobligationsofthisRegulationshouldbe
presumedtobefulfilled,unlesssignificantsystemicrisksnotcoveredby
Regulation(EU)2022/2065emergeandareidentifiedinsuchmodels.Within
thisframework,providersofverylargeonlineplatformsandverylargeonline
searchenginesareobligedtoassesspotentialsystemicrisksstemmingfromthe
design,functioninganduseoftheirservices,includinghowthedesignof
algorithmicsystemsusedintheservicemaycontributetosuchrisks,aswellas
systemicrisksstemmingfrompotentialmisuses.Thoseprovidersarealso
obligedtotakeappropriatemitigatingmeasuresinobservanceoffundamental
rights.
(119)Consideringthequickpaceofinnovationandthetechnologicalevolutionof
digitalservicesinscopeofdifferentinstrumentsofUnionlawinparticular

--- Page 44 ---
havinginmindtheusageandtheperceptionoftheirrecipients,theAIsystems
subjecttothisRegulationmaybeprovidedasintermediaryservicesorparts
thereofwithinthemeaningofRegulation(EU)2022/2065,whichshouldbe
interpretedinatechnology-neutralmanner.Forexample,AIsystemsmaybe
usedtoprovideonlinesearchengines,inparticular,totheextentthatanAI
systemsuchasanonlinechatbotperformssearchesof,inprinciple,allwebsites,
thenincorporatestheresultsintoitsexistingknowledgeandusestheupdated
knowledgetogenerateasingleoutputthatcombinesdifferentsourcesof
information.
(120)Furthermore,obligationsplacedonprovidersanddeployersofcertainAI
systemsinthisRegulationtoenablethedetectionanddisclosurethattheoutputs
ofthosesystemsareartificiallygeneratedormanipulatedareparticularly
relevanttofacilitatetheeffectiveimplementationofRegulation(EU)
2022/2065.Thisappliesinparticularasregardstheobligationsofprovidersof
verylargeonlineplatformsorverylargeonlinesearchenginestoidentifyand
mitigatesystemicrisksthatmayarisefromthedisseminationofcontentthathas
beenartificiallygeneratedormanipulated,inparticularriskoftheactualor
foreseeablenegativeeffectsondemocraticprocesses,civicdiscourseand
electoralprocesses,includingthroughdisinformation.
(121)Standardisationshouldplayakeyroletoprovidetechnicalsolutionstoproviders
toensurecompliancewiththisRegulation,inlinewiththestateoftheart,to
promoteinnovationaswellascompetitivenessandgrowthinthesinglemarket.
CompliancewithharmonisedstandardsasdefinedinArticle2,point(1)(c),of
Regulation(EU)No1025/2012oftheEuropeanParliamentandofthe
Council(41),whicharenormallyexpectedtoreflectthestateoftheart,shouldbe
ameansforproviderstodemonstrateconformitywiththerequirementsofthis
Regulation.Abalancedrepresentationofinterestsinvolvingallrelevant
stakeholdersinthedevelopmentofstandards,inparticularSMEs,consumer
organisationsandenvironmentalandsocialstakeholdersinaccordancewith
Articles5and6ofRegulation(EU)No1025/2012shouldthereforebe
encouraged.Inordertofacilitatecompliance,thestandardisationrequestsshould
beissuedbytheCommissionwithoutunduedelay.Whenpreparingthe
standardisationrequest,theCommissionshouldconsulttheadvisoryforumand
theBoardinordertocollectrelevantexpertise.However,intheabsenceof
relevantreferencestoharmonisedstandards,theCommissionshouldbeableto
establish,viaimplementingacts,andafterconsultationoftheadvisoryforum,
commonspecificationsforcertainrequirementsunderthisRegulation.The
commonspecificationshouldbeanexceptionalfallbacksolutiontofacilitate
theprovider’sobligationtocomplywiththerequirementsofthisRegulation,
whenthestandardisationrequesthasnotbeenacceptedbyanyoftheEuropean
standardisationorganisations,orwhentherelevantharmonisedstandards
insufficientlyaddressfundamentalrightsconcerns,orwhentheharmonised
standardsdonotcomplywiththerequest,orwhentherearedelaysinthe
adoptionofanappropriateharmonisedstandard.Wheresuchadelayinthe
adoptionofaharmonisedstandardisduetothetechnicalcomplexityofthat
standard,thisshouldbeconsideredbytheCommissionbeforecontemplatingthe
establishmentofcommonspecifications.Whendevelopingcommon
specifications,theCommissionisencouragedtocooperatewithinternational
partnersandinternationalstandardisationbodies.

--- Page 45 ---
(122)Itisappropriatethat,withoutprejudicetotheuseofharmonisedstandardsand
commonspecifications,providersofahigh-riskAIsystemthathasbeentrained
andtestedondatareflectingthespecificgeographical,behavioural,contextual
orfunctionalsettingwithinwhichtheAIsystemisintendedtobeused,should
bepresumedtocomplywiththerelevantmeasureprovidedforunderthe
requirementondatagovernancesetoutinthisRegulation.Withoutprejudiceto
therequirementsrelatedtorobustnessandaccuracysetoutinthisRegulation,in
accordancewithArticle54(3)ofRegulation(EU)2019/881,high-riskAI
systemsthathavebeencertifiedorforwhichastatementofconformityhasbeen
issuedunderacybersecurityschemepursuanttothatRegulationandthe
referencesofwhichhavebeenpublishedintheOfficialJournaloftheEuropean
Unionshouldbepresumedtocomplywiththecybersecurityrequirementofthis
Regulationinsofarasthecybersecuritycertificateorstatementofconformityor
partsthereofcoverthecybersecurityrequirementofthisRegulation.This
remainswithoutprejudicetothevoluntarynatureofthatcybersecurityscheme.
(123)Inordertoensureahighleveloftrustworthinessofhigh-riskAIsystems,those
systemsshouldbesubjecttoaconformityassessmentpriortotheirplacingon
themarketorputtingintoservice.
(124)Itisappropriatethat,inordertominimisetheburdenonoperatorsandavoidany
possibleduplication,forhigh-riskAIsystemsrelatedtoproductswhichare
coveredbyexistingUnionharmonisationlegislationbasedontheNew
LegislativeFramework,thecomplianceofthoseAIsystemswiththe
requirementsofthisRegulationshouldbeassessedaspartoftheconformity
assessmentalreadyprovidedforinthatlaw.Theapplicabilityofthe
requirementsofthisRegulationshouldthusnotaffectthespecificlogic,
methodologyorgeneralstructureofconformityassessmentundertherelevant
Unionharmonisationlegislation.
(125)Giventhecomplexityofhigh-riskAIsystemsandtherisksthatareassociated
withthem,itisimportanttodevelopanadequateconformityassessment
procedureforhigh-riskAIsystemsinvolvingnotifiedbodies,so-calledthird
partyconformityassessment.However,giventhecurrentexperienceof
professionalpre-marketcertifiersinthefieldofproductsafetyandthedifferent
natureofrisksinvolved,itisappropriatetolimit,atleastinaninitialphaseof
applicationofthisRegulation,thescopeofapplicationofthird-partyconformity
assessmentforhigh-riskAIsystemsotherthanthoserelatedtoproducts.
Therefore,theconformityassessmentofsuchsystemsshouldbecarriedoutas
ageneralrulebytheproviderunderitsownresponsibility,withtheonly
exceptionofAIsystemsintendedtobeusedforbiometrics.
(126)Inordertocarryoutthird-partyconformityassessmentswhensorequired,
notifiedbodiesshouldbenotifiedunderthisRegulationbythenational
competentauthorities,providedthattheycomplywithasetofrequirements,in
particularonindependence,competence,absenceofconflictsofinterestsand
suitablecybersecurityrequirements.Notificationofthosebodiesshouldbesent
bynationalcompetentauthoritiestotheCommissionandtheotherMember
Statesbymeansoftheelectronicnotificationtooldevelopedandmanagedby
theCommissionpursuanttoArticleR23ofAnnexItoDecision
No768/2008/EC.

--- Page 46 ---
(127)InlinewithUnioncommitmentsundertheWorldTradeOrganization
AgreementonTechnicalBarrierstoTrade,itisadequatetofacilitatethemutual
recognitionofconformityassessmentresultsproducedbycompetentconformity
assessmentbodies,independentoftheterritoryinwhichtheyareestablished,
providedthatthoseconformityassessmentbodiesestablishedunderthelawof
athirdcountrymeettheapplicablerequirementsofthisRegulationandthe
Unionhasconcludedanagreementtothatextent.Inthiscontext,the
Commissionshouldactivelyexplorepossibleinternationalinstrumentsforthat
purposeandinparticularpursuetheconclusionofmutualrecognition
agreementswiththirdcountries.
(128)Inlinewiththecommonlyestablishednotionofsubstantialmodificationfor
productsregulatedbyUnionharmonisationlegislation,itisappropriatethat
wheneverachangeoccurswhichmayaffectthecomplianceofahigh-riskAI
systemwiththisRegulation(e.g.changeofoperatingsystemorsoftware
architecture),orwhentheintendedpurposeofthesystemchanges,thatAI
systemshouldbeconsideredtobeanewAIsystemwhichshouldundergoanew
conformityassessment.However,changesoccurringtothealgorithmandthe
performanceofAIsystemswhichcontinueto‘learn’afterbeingplacedonthe
marketorputintoservice,namelyautomaticallyadaptinghowfunctionsare
carriedout,shouldnotconstituteasubstantialmodification,providedthatthose
changeshavebeenpre-determinedbytheproviderandassessedatthemoment
oftheconformityassessment.
(129)High-riskAIsystemsshouldbeartheCEmarkingtoindicatetheirconformity
withthisRegulationsothattheycanmovefreelywithintheinternalmarket.For
high-riskAIsystemsembeddedinaproduct,aphysicalCEmarkingshouldbe
affixed,andmaybecomplementedbyadigitalCEmarking.Forhigh-riskAI
systemsonlyprovideddigitally,adigitalCEmarkingshouldbeused.Member
Statesshouldnotcreateunjustifiedobstaclestotheplacingonthemarketorthe
puttingintoserviceofhigh-riskAIsystemsthatcomplywiththerequirements
laiddowninthisRegulationandbeartheCEmarking.
(130)Undercertainconditions,rapidavailabilityofinnovativetechnologiesmaybe
crucialforhealthandsafetyofpersons,theprotectionoftheenvironmentand
climatechangeandforsocietyasawhole.Itisthusappropriatethatunder
exceptionalreasonsofpublicsecurityorprotectionoflifeandhealthofnatural
persons,environmentalprotectionandtheprotectionofkeyindustrialand
infrastructuralassets,marketsurveillanceauthoritiescouldauthorisetheplacing
onthemarketortheputtingintoserviceofAIsystemswhichhavenot
undergoneaconformityassessment.Indulyjustifiedsituations,asprovidedfor
inthisRegulation,lawenforcementauthoritiesorcivilprotectionauthorities
mayputaspecifichigh-riskAIsystemintoservicewithouttheauthorisationof
themarketsurveillanceauthority,providedthatsuchauthorisationisrequested
duringoraftertheusewithoutunduedelay.
(131)InordertofacilitatetheworkoftheCommissionandtheMemberStatesinthe
AIfieldaswellastoincreasethetransparencytowardsthepublic,providersof
high-riskAIsystemsotherthanthoserelatedtoproductsfallingwithinthescope
ofrelevantexistingUnionharmonisationlegislation,aswellasproviderswho
considerthatanAIsystemlistedinthehigh-riskusecasesinanannextothis

--- Page 47 ---
Regulationisnothigh-riskonthebasisofaderogation,shouldberequiredto
registerthemselvesandinformationabouttheirAIsysteminanEUdatabase,to
beestablishedandmanagedbytheCommission.BeforeusinganAIsystem
listedinthehigh-riskusecasesinanannextothisRegulation,deployersof
high-riskAIsystemsthatarepublicauthorities,agenciesorbodies,should
registerthemselvesinsuchdatabaseandselectthesystemthattheyenvisageto
use.Otherdeployersshouldbeentitledtodosovoluntarily.Thissectionofthe
EUdatabaseshouldbepubliclyaccessible,freeofcharge,theinformation
shouldbeeasilynavigable,understandableandmachine-readable.TheEU
databaseshouldalsobeuser-friendly,forexamplebyprovidingsearch
functionalities,includingthroughkeywords,allowingthegeneralpublictofind
relevantinformationtobesubmittedupontheregistrationofhigh-riskAI
systemsandontheusecaseofhigh-riskAIsystems,setoutinanannextothis
Regulation,towhichthehigh-riskAIsystemscorrespond.Anysubstantial
modificationofhigh-riskAIsystemsshouldalsoberegisteredintheEU
database.Forhigh-riskAIsystemsintheareaoflawenforcement,migration,
asylumandbordercontrolmanagement,theregistrationobligationsshouldbe
fulfilledinasecurenon-publicsectionoftheEUdatabase.Accesstothesecure
non-publicsectionshouldbestrictlylimitedtotheCommissionaswellasto
marketsurveillanceauthoritieswithregardtotheirnationalsectionofthat
database.High-riskAIsystemsintheareaofcriticalinfrastructureshouldonly
beregisteredatnationallevel.TheCommissionshouldbethecontrollerofthe
EUdatabase,inaccordancewithRegulation(EU)2018/1725.Inordertoensure
thefullfunctionalityoftheEUdatabase,whendeployed,theprocedurefor
settingthedatabaseshouldincludethedevelopmentoffunctionalspecifications
bytheCommissionandanindependentauditreport.TheCommissionshould
takeintoaccountcybersecurityriskswhencarryingoutitstasksasdata
controllerontheEUdatabase.Inordertomaximisetheavailabilityanduseof
theEUdatabasebythepublic,theEUdatabase,includingtheinformationmade
availablethroughit,shouldcomplywithrequirementsundertheDirective(EU)
2019/882.
(132)CertainAIsystemsintendedtointeractwithnaturalpersonsortogenerate
contentmayposespecificrisksofimpersonationordeceptionirrespectiveof
whethertheyqualifyashigh-riskornot.Incertaincircumstances,theuseof
thesesystemsshouldthereforebesubjecttospecifictransparencyobligations
withoutprejudicetotherequirementsandobligationsforhigh-riskAIsystems
andsubjecttotargetedexceptionstotakeintoaccountthespecialneedoflaw
enforcement.Inparticular,naturalpersonsshouldbenotifiedthattheyare
interactingwithanAIsystem,unlessthisisobviousfromthepointofviewof
anaturalpersonwhoisreasonablywell-informed,observantandcircumspect
takingintoaccountthecircumstancesandthecontextofuse.When
implementingthatobligation,thecharacteristicsofnaturalpersonsbelongingto
vulnerablegroupsduetotheirageordisabilityshouldbetakenintoaccountto
theextenttheAIsystemisintendedtointeractwiththosegroupsaswell.
Moreover,naturalpersonsshouldbenotifiedwhentheyareexposedtoAI
systemsthat,byprocessingtheirbiometricdata,canidentifyorinferthe
emotionsorintentionsofthosepersonsorassignthemtospecificcategories.
Suchspecificcategoriescanrelatetoaspectssuchassex,age,haircolour,eye
colour,tattoos,personaltraits,ethnicorigin,personalpreferencesandinterests.

--- Page 48 ---
Suchinformationandnotificationsshouldbeprovidedinaccessibleformatsfor
personswithdisabilities.
(133)AvarietyofAIsystemscangeneratelargequantitiesofsyntheticcontentthat
becomesincreasinglyhardforhumanstodistinguishfromhuman-generatedand
authenticcontent.Thewideavailabilityandincreasingcapabilitiesofthose
systemshaveasignificantimpactontheintegrityandtrustintheinformation
ecosystem,raisingnewrisksofmisinformationandmanipulationatscale,fraud,
impersonationandconsumerdeception.Inlightofthoseimpacts,thefast
technologicalpaceandtheneedfornewmethodsandtechniquestotraceorigin
ofinformation,itisappropriatetorequireprovidersofthosesystemstoembed
technicalsolutionsthatenablemarkinginamachinereadableformatand
detectionthattheoutputhasbeengeneratedormanipulatedbyanAIsystemand
notahuman.Suchtechniquesandmethodsshouldbesufficientlyreliable,
interoperable,effectiveandrobustasfarasthisistechnicallyfeasible,taking
intoaccountavailabletechniquesoracombinationofsuchtechniques,suchas
watermarks,metadataidentifications,cryptographicmethodsforproving
provenanceandauthenticityofcontent,loggingmethods,fingerprintsorother
techniques,asmaybeappropriate.Whenimplementingthisobligation,
providersshouldalsotakeintoaccountthespecificitiesandthelimitationsofthe
differenttypesofcontentandtherelevanttechnologicalandmarket
developmentsinthefield,asreflectedinthegenerallyacknowledgedstateofthe
art.SuchtechniquesandmethodscanbeimplementedattheleveloftheAI
systemorattheleveloftheAImodel,includinggeneral-purposeAImodels
generatingcontent,therebyfacilitatingfulfilmentofthisobligationbythe
downstreamprovideroftheAIsystem.Toremainproportionate,itis
appropriatetoenvisagethatthismarkingobligationshouldnotcoverAIsystems
performingprimarilyanassistivefunctionforstandardeditingorAIsystemsnot
substantiallyalteringtheinputdataprovidedbythedeployerorthesemantics
thereof.
(134)FurthertothetechnicalsolutionsemployedbytheprovidersoftheAIsystem,
deployerswhouseanAIsystemtogenerateormanipulateimage,audioorvideo
contentthatappreciablyresemblesexistingpersons,objects,places,entitiesor
eventsandwouldfalselyappeartoapersontobeauthenticortruthful(deep
fakes),shouldalsoclearlyanddistinguishablydisclosethatthecontenthasbeen
artificiallycreatedormanipulatedbylabellingtheAIoutputaccordinglyand
disclosingitsartificialorigin.Compliancewiththistransparencyobligation
shouldnotbeinterpretedasindicatingthattheuseoftheAIsystemoritsoutput
impedestherighttofreedomofexpressionandtherighttofreedomofthearts
andsciencesguaranteedintheCharter,inparticularwherethecontentispartof
anevidentlycreative,satirical,artistic,fictionaloranalogousworkor
programme,subjecttoappropriatesafeguardsfortherightsandfreedomsof
thirdparties.Inthosecases,thetransparencyobligationfordeepfakessetoutin
thisRegulationislimitedtodisclosureoftheexistenceofsuchgeneratedor
manipulatedcontentinanappropriatemannerthatdoesnothamperthedisplay
orenjoymentofthework,includingitsnormalexploitationanduse,while
maintainingtheutilityandqualityofthework.Inaddition,itisalsoappropriate
toenvisageasimilardisclosureobligationinrelationtoAI-generatedor
manipulatedtexttotheextentitispublishedwiththepurposeofinformingthe
publiconmattersofpublicinterestunlesstheAI-generatedcontenthas

--- Page 49 ---
undergoneaprocessofhumanrevieworeditorialcontrolandanaturalorlegal
personholdseditorialresponsibilityforthepublicationofthecontent.
(135)Withoutprejudicetothemandatorynatureandfullapplicabilityofthe
transparencyobligations,theCommissionmayalsoencourageandfacilitatethe
drawingupofcodesofpracticeatUnionleveltofacilitatetheeffective
implementationoftheobligationsregardingthedetectionandlabellingof
artificiallygeneratedormanipulatedcontent,includingtosupportpractical
arrangementsformaking,asappropriate,thedetectionmechanismsaccessible
andfacilitatingcooperationwithotheractorsalongthevaluechain,
disseminatingcontentorcheckingitsauthenticityandprovenancetoenablethe
publictoeffectivelydistinguishAI-generatedcontent.
(136)TheobligationsplacedonprovidersanddeployersofcertainAIsystemsinthis
Regulationtoenablethedetectionanddisclosurethattheoutputsofthose
systemsareartificiallygeneratedormanipulatedareparticularlyrelevantto
facilitatetheeffectiveimplementationofRegulation(EU)2022/2065.This
appliesinparticularasregardstheobligationsofprovidersofverylargeonline
platformsorverylargeonlinesearchenginestoidentifyandmitigatesystemic
risksthatmayarisefromthedisseminationofcontentthathasbeenartificially
generatedormanipulated,inparticulartheriskoftheactualorforeseeable
negativeeffectsondemocraticprocesses,civicdiscourseandelectoral
processes,includingthroughdisinformation.Therequirementtolabelcontent
generatedbyAIsystemsunderthisRegulationiswithoutprejudicetothe
obligationinArticle16(6)ofRegulation(EU)2022/2065forprovidersof
hostingservicestoprocessnoticesonillegalcontentreceivedpursuantto
Article16(1)ofthatRegulationandshouldnotinfluencetheassessmentandthe
decisionontheillegalityofthespecificcontent.Thatassessmentshouldbe
performedsolelywithreferencetotherulesgoverningthelegalityofthe
content.
(137)CompliancewiththetransparencyobligationsfortheAIsystemscoveredbythis
RegulationshouldnotbeinterpretedasindicatingthattheuseoftheAIsystem
oritsoutputislawfulunderthisRegulationorotherUnionandMemberState
lawandshouldbewithoutprejudicetoothertransparencyobligationsfor
deployersofAIsystemslaiddowninUnionornationallaw.
(138)AIisarapidlydevelopingfamilyoftechnologiesthatrequiresregulatory
oversightandasafeandcontrolledspaceforexperimentation,whileensuring
responsibleinnovationandintegrationofappropriatesafeguardsandrisk
mitigationmeasures.Toensurealegalframeworkthatpromotesinnovation,is
future-proofandresilienttodisruption,MemberStatesshouldensurethattheir
nationalcompetentauthoritiesestablishatleastoneAIregulatorysandboxat
nationalleveltofacilitatethedevelopmentandtestingofinnovativeAIsystems
understrictregulatoryoversightbeforethesesystemsareplacedonthemarket
orotherwiseputintoservice.MemberStatescouldalsofulfilthisobligation
throughparticipatinginalreadyexistingregulatorysandboxesorestablishing
jointlyasandboxwithoneormoreMemberStates’competentauthorities,
insofarasthisparticipationprovidesequivalentlevelofnationalcoveragefor
theparticipatingMemberStates.AIregulatorysandboxescouldbeestablished
inphysical,digitalorhybridformandmayaccommodatephysicalaswellas
digitalproducts.EstablishingauthoritiesshouldalsoensurethattheAI

--- Page 50 ---
regulatorysandboxeshavetheadequateresourcesfortheirfunctioning,
includingfinancialandhumanresources.
(139)TheobjectivesoftheAIregulatorysandboxesshouldbetofosterAIinnovation
byestablishingacontrolledexperimentationandtestingenvironmentinthe
developmentandpre-marketingphasewithaviewtoensuringcomplianceofthe
innovativeAIsystemswiththisRegulationandotherrelevantUnionand
nationallaw.Moreover,theAIregulatorysandboxesshouldaimtoenhance
legalcertaintyforinnovatorsandthecompetentauthorities’oversightand
understandingoftheopportunities,emergingrisksandtheimpactsofAIuse,to
facilitateregulatorylearningforauthoritiesandundertakings,includingwith
aviewtofutureadaptionsofthelegalframework,tosupportcooperationandthe
sharingofbestpracticeswiththeauthoritiesinvolvedintheAIregulatory
sandbox,andtoaccelerateaccesstomarkets,includingbyremovingbarriersfor
SMEs,includingstart-ups.AIregulatorysandboxesshouldbewidelyavailable
throughouttheUnion,andparticularattentionshouldbegiventotheir
accessibilityforSMEs,includingstart-ups.TheparticipationintheAI
regulatorysandboxshouldfocusonissuesthatraiselegaluncertaintyfor
providersandprospectiveproviderstoinnovate,experimentwithAIinthe
Unionandcontributetoevidence-basedregulatorylearning.Thesupervisionof
theAIsystemsintheAIregulatorysandboxshouldthereforecovertheir
development,training,testingandvalidationbeforethesystemsareplacedon
themarketorputintoservice,aswellasthenotionandoccurrenceofsubstantial
modificationthatmayrequireanewconformityassessmentprocedure.Any
significantrisksidentifiedduringthedevelopmentandtestingofsuchAI
systemsshouldresultinadequatemitigationand,failingthat,inthesuspension
ofthedevelopmentandtestingprocess.Whereappropriate,nationalcompetent
authoritiesestablishingAIregulatorysandboxesshouldcooperatewithother
relevantauthorities,includingthosesupervisingtheprotectionoffundamental
rights,andcouldallowfortheinvolvementofotheractorswithintheAI
ecosystemsuchasnationalorEuropeanstandardisationorganisations,notified
bodies,testingandexperimentationfacilities,researchandexperimentationlabs,
EuropeanDigitalInnovationHubsandrelevantstakeholderandcivilsociety
organisations.ToensureuniformimplementationacrosstheUnionand
economiesofscale,itisappropriatetoestablishcommonrulesfortheAI
regulatorysandboxes’implementationandaframeworkforcooperationbetween
therelevantauthoritiesinvolvedinthesupervisionofthesandboxes.AI
regulatorysandboxesestablishedunderthisRegulationshouldbewithout
prejudicetootherlawallowingfortheestablishmentofothersandboxesaiming
toensurecompliancewithlawotherthanthisRegulation.Whereappropriate,
relevantcompetentauthoritiesinchargeofthoseotherregulatorysandboxes
shouldconsiderthebenefitsofusingthosesandboxesalsoforthepurposeof
ensuringcomplianceofAIsystemswiththisRegulation.Uponagreement
betweenthenationalcompetentauthoritiesandtheparticipantsintheAI
regulatorysandbox,testinginrealworldconditionsmayalsobeoperatedand
supervisedintheframeworkoftheAIregulatorysandbox.
(140)ThisRegulationshouldprovidethelegalbasisfortheprovidersandprospective
providersintheAIregulatorysandboxtousepersonaldatacollectedforother
purposesfordevelopingcertainAIsystemsinthepublicinterestwithintheAI
regulatorysandbox,onlyunderspecifiedconditions,inaccordancewith

--- Page 51 ---
Article6(4)andArticle9(2),point(g),ofRegulation(EU)2016/679,and
Articles5,6and10ofRegulation(EU)2018/1725,andwithoutprejudiceto
Article4(2)andArticle10ofDirective(EU)2016/680.Allotherobligationsof
datacontrollersandrightsofdatasubjectsunderRegulations(EU)2016/679and
(EU)2018/1725andDirective(EU)2016/680remainapplicable.Inparticular,
thisRegulationshouldnotprovidealegalbasisinthemeaningofArticle22(2),
point(b)ofRegulation(EU)2016/679andArticle24(2),point(b)ofRegulation
(EU)2018/1725.ProvidersandprospectiveprovidersintheAIregulatory
sandboxshouldensureappropriatesafeguardsandcooperatewiththecompetent
authorities,includingbyfollowingtheirguidanceandactingexpeditiouslyand
ingoodfaithtoadequatelymitigateanyidentifiedsignificantriskstosafety,
health,andfundamentalrightsthatmayariseduringthedevelopment,testing
andexperimentationinthatsandbox.
(141)Inordertoacceleratetheprocessofdevelopmentandtheplacingonthemarket
ofthehigh-riskAIsystemslistedinanannextothisRegulation,itisimportant
thatprovidersorprospectiveprovidersofsuchsystemsmayalsobenefitfrom
aspecificregimefortestingthosesystemsinrealworldconditions,without
participatinginanAIregulatorysandbox.However,insuchcases,takinginto
accountthepossibleconsequencesofsuchtestingonindividuals,itshouldbe
ensuredthatappropriateandsufficientguaranteesandconditionsareintroduced
bythisRegulationforprovidersorprospectiveproviders.Suchguarantees
shouldinclude,interalia,requestinginformedconsentofnaturalpersonsto
participateintestinginrealworldconditions,withtheexceptionoflaw
enforcementwheretheseekingofinformedconsentwouldpreventtheAI
systemfrombeingtested.Consentofsubjectstoparticipateinsuchtestingunder
thisRegulationisdistinctfrom,andwithoutprejudiceto,consentofdata
subjectsfortheprocessingoftheirpersonaldataundertherelevantdata
protectionlaw.Itisalsoimportanttominimisetherisksandenableoversightby
competentauthoritiesandthereforerequireprospectiveproviderstohaveareal-
worldtestingplansubmittedtocompetentmarketsurveillanceauthority,register
thetestingindedicatedsectionsintheEUdatabasesubjecttosomelimited
exceptions,setlimitationsontheperiodforwhichthetestingcanbedoneand
requireadditionalsafeguardsforpersonsbelongingtocertainvulnerablegroups,
aswellasawrittenagreementdefiningtherolesandresponsibilitiesof
prospectiveprovidersanddeployersandeffectiveoversightbycompetent
personnelinvolvedintherealworldtesting.Furthermore,itisappropriateto
envisageadditionalsafeguardstoensurethatthepredictions,recommendations
ordecisionsoftheAIsystemcanbeeffectivelyreversedanddisregardedand
thatpersonaldataisprotectedandisdeletedwhenthesubjectshavewithdrawn
theirconsenttoparticipateinthetestingwithoutprejudicetotheirrightsasdata
subjectsundertheUniondataprotectionlaw.Asregardstransferofdata,itis
alsoappropriatetoenvisagethatdatacollectedandprocessedforthepurposeof
testinginreal-worldconditionsshouldbetransferredtothirdcountriesonly
whereappropriateandapplicablesafeguardsunderUnionlawareimplemented,
inparticularinaccordancewithbasesfortransferofpersonaldataunderUnion
lawondataprotection,whilefornon-personaldataappropriatesafeguardsare
putinplaceinaccordancewithUnionlaw,suchasRegulations(EU)
2022/868(42)and(EU)2023/2854(43)oftheEuropeanParliamentandofthe
Council.

--- Page 52 ---
(142)ToensurethatAIleadstosociallyandenvironmentallybeneficialoutcomes,
MemberStatesareencouragedtosupportandpromoteresearchand
developmentofAIsolutionsinsupportofsociallyandenvironmentally
beneficialoutcomes,suchasAI-basedsolutionstoincreaseaccessibilityfor
personswithdisabilities,tacklesocio-economicinequalities,ormeet
environmentaltargets,byallocatingsufficientresources,includingpublicand
Unionfunding,and,whereappropriateandprovidedthattheeligibilityand
selectioncriteriaarefulfilled,consideringinparticularprojectswhichpursue
suchobjectives.Suchprojectsshouldbebasedontheprincipleof
interdisciplinarycooperationbetweenAIdevelopers,expertsoninequalityand
non-discrimination,accessibility,consumer,environmental,anddigitalrights,as
wellasacademics.
(143)Inordertopromoteandprotectinnovation,itisimportantthattheinterestsof
SMEs,includingstart-ups,thatareprovidersordeployersofAIsystemsare
takenintoparticularaccount.Tothatend,MemberStatesshoulddevelop
initiatives,whicharetargetedatthoseoperators,includingonawarenessraising
andinformationcommunication.MemberStatesshouldprovideSMEs,
includingstart-ups,thathavearegisteredofficeorabranchintheUnion,with
priorityaccesstotheAIregulatorysandboxesprovidedthattheyfulfilthe
eligibilityconditionsandselectioncriteriaandwithoutprecludingother
providersandprospectiveproviderstoaccessthesandboxesprovidedthesame
conditionsandcriteriaarefulfilled.MemberStatesshouldutiliseexisting
channelsandwhereappropriate,establishnewdedicatedchannelsfor
communicationwithSMEs,includingstart-ups,deployers,otherinnovatorsand,
asappropriate,localpublicauthorities,tosupportSMEsthroughouttheir
developmentpathbyprovidingguidanceandrespondingtoqueriesaboutthe
implementationofthisRegulation.Whereappropriate,thesechannelsshould
worktogethertocreatesynergiesandensurehomogeneityintheirguidanceto
SMEs,includingstart-ups,anddeployers.Additionally,MemberStatesshould
facilitatetheparticipationofSMEsandotherrelevantstakeholdersinthe
standardisationdevelopmentprocesses.Moreover,thespecificinterestsand
needsofprovidersthatareSMEs,includingstart-ups,shouldbetakeninto
accountwhennotifiedbodiessetconformityassessmentfees.TheCommission
shouldregularlyassessthecertificationandcompliancecostsforSMEs,
includingstart-ups,throughtransparentconsultationsandshouldworkwith
MemberStatestolowersuchcosts.Forexample,translationcostsrelatedto
mandatorydocumentationandcommunicationwithauthoritiesmayconstitute
asignificantcostforprovidersandotheroperators,inparticularthoseof
asmallerscale.MemberStatesshouldpossiblyensurethatoneofthelanguages
determinedandacceptedbythemforrelevantproviders’documentationandfor
communicationwithoperatorsisonewhichisbroadlyunderstoodbythelargest
possiblenumberofcross-borderdeployers.Inordertoaddressthespecificneeds
ofSMEs,includingstart-ups,theCommissionshouldprovidestandardised
templatesfortheareascoveredbythisRegulation,uponrequestoftheBoard.
Additionally,theCommissionshouldcomplementMemberStates’effortsby
providingasingleinformationplatformwitheasy-to-useinformationwith
regardstothisRegulationforallprovidersanddeployers,byorganising
appropriatecommunicationcampaignstoraiseawarenessabouttheobligations
arisingfromthisRegulation,andbyevaluatingandpromotingtheconvergence

--- Page 53 ---
ofbestpracticesinpublicprocurementproceduresinrelationtoAIsystems.
Medium-sizedenterpriseswhichuntilrecentlyqualifiedassmallenterprises
withinthemeaningoftheAnnextoCommissionRecommendation
2003/361/EC(44)shouldhaveaccesstothosesupportmeasures,asthosenew
medium-sizedenterprisesmaysometimeslackthelegalresourcesandtraining
necessarytoensureproperunderstandingof,andcompliancewith,this
Regulation.
(144)Inordertopromoteandprotectinnovation,theAI-on-demandplatform,all
relevantUnionfundingprogrammesandprojects,suchasDigitalEurope
Programme,HorizonEurope,implementedbytheCommissionandtheMember
StatesatUnionornationallevelshould,asappropriate,contributetothe
achievementoftheobjectivesofthisRegulation.
(145)Inordertominimisetheriskstoimplementationresultingfromlackof
knowledgeandexpertiseinthemarketaswellastofacilitatecomplianceof
providers,inparticularSMEs,includingstart-ups,andnotifiedbodieswiththeir
obligationsunderthisRegulation,theAI-on-demandplatform,theEuropean
DigitalInnovationHubsandthetestingandexperimentationfacilities
establishedbytheCommissionandtheMemberStatesatUnionornationallevel
shouldcontributetotheimplementationofthisRegulation.Withintheir
respectivemissionandfieldsofcompetence,theAI-on-demandplatform,the
EuropeanDigitalInnovationHubsandthetestingandexperimentationFacilities
areabletoprovideinparticulartechnicalandscientificsupporttoprovidersand
notifiedbodies.
(146)Moreover,inlightoftheverysmallsizeofsomeoperatorsandinorderto
ensureproportionalityregardingcostsofinnovation,itisappropriatetoallow
microenterprisestofulfiloneofthemostcostlyobligations,namelytoestablish
aqualitymanagementsystem,inasimplifiedmannerwhichwouldreducethe
administrativeburdenandthecostsforthoseenterpriseswithoutaffectingthe
levelofprotectionandtheneedforcompliancewiththerequirementsforhigh-
riskAIsystems.TheCommissionshoulddevelopguidelinestospecifythe
elementsofthequalitymanagementsystemtobefulfilledinthissimplified
mannerbymicroenterprises.
(147)ItisappropriatethattheCommissionfacilitates,totheextentpossible,accessto
testingandexperimentationfacilitiestobodies,groupsorlaboratories
establishedoraccreditedpursuanttoanyrelevantUnionharmonisation
legislationandwhichfulfiltasksinthecontextofconformityassessmentof
productsordevicescoveredbythatUnionharmonisationlegislation.Thisis,in
particular,thecaseasregardsexpertpanels,expertlaboratoriesandreference
laboratoriesinthefieldofmedicaldevicespursuanttoRegulations(EU)
2017/745and(EU)2017/746.
(148)ThisRegulationshouldestablishagovernanceframeworkthatbothallowsto
coordinateandsupporttheapplicationofthisRegulationatnationallevel,as
wellasbuildcapabilitiesatUnionlevelandintegratestakeholdersinthefieldof
AI.TheeffectiveimplementationandenforcementofthisRegulationrequire
agovernanceframeworkthatallowstocoordinateandbuildupcentralexpertise
atUnionlevel.TheAIOfficewasestablishedbyCommissionDecision(45)and
hasasitsmissiontodevelopUnionexpertiseandcapabilitiesinthefieldofAI

--- Page 54 ---
andtocontributetotheimplementationofUnionlawonAI.MemberStates
shouldfacilitatethetasksoftheAIOfficewithaviewtosupportthe
developmentofUnionexpertiseandcapabilitiesatUnionlevelandtostrengthen
thefunctioningofthedigitalsinglemarket.Furthermore,aBoardcomposedof
representativesoftheMemberStates,ascientificpaneltointegratethescientific
communityandanadvisoryforumtocontributestakeholderinputtothe
implementationofthisRegulation,atUnionandnationallevel,shouldbe
established.ThedevelopmentofUnionexpertiseandcapabilitiesshouldalso
includemakinguseofexistingresourcesandexpertise,inparticularthrough
synergieswithstructuresbuiltupinthecontextoftheUnionlevelenforcement
ofotherlawandsynergieswithrelatedinitiativesatUnionlevel,suchasthe
EuroHPCJointUndertakingandtheAItestingandexperimentationfacilities
undertheDigitalEuropeProgramme.
(149)Inordertofacilitateasmooth,effectiveandharmonisedimplementationofthis
RegulationaBoardshouldbeestablished.TheBoardshouldreflectthevarious
interestsoftheAIeco-systemandbecomposedofrepresentativesofthe
MemberStates.TheBoardshouldberesponsibleforanumberofadvisorytasks,
includingissuingopinions,recommendations,adviceorcontributingtoguidance
onmattersrelatedtotheimplementationofthisRegulation,includingon
enforcementmatters,technicalspecificationsorexistingstandardsregardingthe
requirementsestablishedinthisRegulationandprovidingadvicetothe
CommissionandtheMemberStatesandtheirnationalcompetentauthoritieson
specificquestionsrelatedtoAI.InordertogivesomeflexibilitytoMember
StatesinthedesignationoftheirrepresentativesintheBoard,such
representativesmaybeanypersonsbelongingtopublicentitieswhoshouldhave
therelevantcompetencesandpowerstofacilitatecoordinationatnationallevel
andcontributetotheachievementoftheBoard’stasks.TheBoardshould
establishtwostandingsub-groupstoprovideaplatformforcooperationand
exchangeamongmarketsurveillanceauthoritiesandnotifyingauthoritieson
issuesrelated,respectively,tomarketsurveillanceandnotifiedbodies.The
standingsubgroupformarketsurveillanceshouldactastheadministrative
cooperationgroup(ADCO)forthisRegulationwithinthemeaningofArticle30
ofRegulation(EU)2019/1020.InaccordancewithArticle33ofthatRegulation,
theCommissionshouldsupporttheactivitiesofthestandingsubgroupfor
marketsurveillancebyundertakingmarketevaluationsorstudies,inparticular
withaviewtoidentifyingaspectsofthisRegulationrequiringspecificand
urgentcoordinationamongmarketsurveillanceauthorities.TheBoardmay
establishotherstandingortemporarysub-groupsasappropriateforthepurpose
ofexaminingspecificissues.TheBoardshouldalsocooperate,asappropriate,
withrelevantUnionbodies,expertsgroupsandnetworksactiveinthecontextof
relevantUnionlaw,includinginparticularthoseactiveunderrelevantUnion
lawondata,digitalproductsandservices.
(150)Withaviewtoensuringtheinvolvementofstakeholdersintheimplementation
andapplicationofthisRegulation,anadvisoryforumshouldbeestablishedto
adviseandprovidetechnicalexpertisetotheBoardandtheCommission.To
ensureavariedandbalancedstakeholderrepresentationbetweencommercial
andnon-commercialinterestand,withinthecategoryofcommercialinterests,
withregardstoSMEsandotherundertakings,theadvisoryforumshould
compriseinteraliaindustry,start-ups,SMEs,academia,civilsociety,including

--- Page 55 ---
thesocialpartners,aswellastheFundamentalRightsAgency,ENISA,the
EuropeanCommitteeforStandardization(CEN),theEuropeanCommitteefor
ElectrotechnicalStandardization(CENELEC)andtheEuropean
TelecommunicationsStandardsInstitute(ETSI).
(151)TosupporttheimplementationandenforcementofthisRegulation,inparticular
themonitoringactivitiesoftheAIOfficeasregardsgeneral-purposeAImodels,
ascientificpanelofindependentexpertsshouldbeestablished.Theindependent
expertsconstitutingthescientificpanelshouldbeselectedonthebasisofup-to-
datescientificortechnicalexpertiseinthefieldofAIandshouldperformtheir
taskswithimpartiality,objectivityandensuretheconfidentialityofinformation
anddataobtainedincarryingouttheirtasksandactivities.Toallowthe
reinforcementofnationalcapacitiesnecessaryfortheeffectiveenforcementof
thisRegulation,MemberStatesshouldbeabletorequestsupportfromthepool
ofexpertsconstitutingthescientificpanelfortheirenforcementactivities.
(152)InordertosupportadequateenforcementasregardsAIsystemsandreinforce
thecapacitiesoftheMemberStates,UnionAItestingsupportstructuresshould
beestablishedandmadeavailabletotheMemberStates.
(153)MemberStatesholdakeyroleintheapplicationandenforcementofthis
Regulation.Inthatrespect,eachMemberStateshoulddesignateatleastone
notifyingauthorityandatleastonemarketsurveillanceauthorityasnational
competentauthoritiesforthepurposeofsupervisingtheapplicationand
implementationofthisRegulation.MemberStatesmaydecidetoappointany
kindofpublicentitytoperformthetasksofthenationalcompetentauthorities
withinthemeaningofthisRegulation,inaccordancewiththeirspecificnational
organisationalcharacteristicsandneeds.Inordertoincreaseorganisation
efficiencyonthesideofMemberStatesandtosetasinglepointofcontactvis-à-
visthepublicandothercounterpartsatMemberStateandUnionlevels,each
MemberStateshoulddesignateamarketsurveillanceauthoritytoactasasingle
pointofcontact.
(154)Thenationalcompetentauthoritiesshouldexercisetheirpowersindependently,
impartiallyandwithoutbias,soastosafeguardtheprinciplesofobjectivityof
theiractivitiesandtasksandtoensuretheapplicationandimplementationofthis
Regulation.Themembersoftheseauthoritiesshouldrefrainfromanyaction
incompatiblewiththeirdutiesandshouldbesubjecttoconfidentialityrules
underthisRegulation.
(155)Inordertoensurethatprovidersofhigh-riskAIsystemscantakeintoaccount
theexperienceontheuseofhigh-riskAIsystemsforimprovingtheirsystems
andthedesignanddevelopmentprocessorcantakeanypossiblecorrective
actioninatimelymanner,allprovidersshouldhaveapost-marketmonitoring
systeminplace.Whererelevant,post-marketmonitoringshouldincludean
analysisoftheinteractionwithotherAIsystemsincludingotherdevicesand
software.Post-marketmonitoringshouldnotcoversensitiveoperationaldataof
deployerswhicharelawenforcementauthorities.Thissystemisalsokeyto
ensurethatthepossiblerisksemergingfromAIsystemswhichcontinueto
‘learn’afterbeingplacedonthemarketorputintoservicecanbemore
efficientlyandtimelyaddressed.Inthiscontext,providersshouldalsobe
requiredtohaveasysteminplacetoreporttotherelevantauthoritiesany

--- Page 56 ---
seriousincidentsresultingfromtheuseoftheirAIsystems,meaningincidentor
malfunctioningleadingtodeathorseriousdamagetohealth,seriousand
irreversibledisruptionofthemanagementandoperationofcritical
infrastructure,infringementsofobligationsunderUnionlawintendedtoprotect
fundamentalrightsorseriousdamagetopropertyortheenvironment.
(156)Inordertoensureanappropriateandeffectiveenforcementoftherequirements
andobligationssetoutbythisRegulation,whichisUnionharmonisation
legislation,thesystemofmarketsurveillanceandcomplianceofproducts
establishedbyRegulation(EU)2019/1020shouldapplyinitsentirety.Market
surveillanceauthoritiesdesignatedpursuanttothisRegulationshouldhaveall
enforcementpowerslaiddowninthisRegulationandinRegulation(EU)
2019/1020andshouldexercisetheirpowersandcarryouttheirduties
independently,impartiallyandwithoutbias.AlthoughthemajorityofAI
systemsarenotsubjecttospecificrequirementsandobligationsunderthis
Regulation,marketsurveillanceauthoritiesmaytakemeasuresinrelationtoall
AIsystemswhentheypresentariskinaccordancewiththisRegulation.Dueto
thespecificnatureofUnioninstitutions,agenciesandbodiesfallingwithinthe
scopeofthisRegulation,itisappropriatetodesignatetheEuropeanData
ProtectionSupervisorasacompetentmarketsurveillanceauthorityforthem.
Thisshouldbewithoutprejudicetothedesignationofnationalcompetent
authoritiesbytheMemberStates.Marketsurveillanceactivitiesshouldnot
affecttheabilityofthesupervisedentitiestocarryouttheirtasksindependently,
whensuchindependenceisrequiredbyUnionlaw.
(157)ThisRegulationiswithoutprejudicetothecompetences,tasks,powersand
independenceofrelevantnationalpublicauthoritiesorbodieswhichsupervise
theapplicationofUnionlawprotectingfundamentalrights,includingequality
bodiesanddataprotectionauthorities.Wherenecessaryfortheirmandate,those
nationalpublicauthoritiesorbodiesshouldalsohaveaccesstoany
documentationcreatedunderthisRegulation.Aspecificsafeguardprocedure
shouldbesetforensuringadequateandtimelyenforcementagainstAIsystems
presentingarisktohealth,safetyandfundamentalrights.Theprocedurefor
suchAIsystemspresentingariskshouldbeappliedtohigh-riskAIsystems
presentingarisk,prohibitedsystemswhichhavebeenplacedonthemarket,put
intoserviceorusedinviolationoftheprohibitedpracticeslaiddowninthis
RegulationandAIsystemswhichhavebeenmadeavailableinviolationofthe
transparencyrequirementslaiddowninthisRegulationandpresentarisk.
(158)Unionfinancialserviceslawincludesinternalgovernanceandrisk-management
rulesandrequirementswhichareapplicabletoregulatedfinancialinstitutionsin
thecourseofprovisionofthoseservices,includingwhentheymakeuseofAI
systems.Inordertoensurecoherentapplicationandenforcementofthe
obligationsunderthisRegulationandrelevantrulesandrequirementsofthe
Unionfinancialserviceslegalacts,thecompetentauthoritiesforthesupervision
andenforcementofthoselegalacts,inparticularcompetentauthoritiesas
definedinRegulation(EU)No575/2013oftheEuropeanParliamentandofthe
Council(46)andDirectives2008/48/EC(47),2009/138/EC(48),2013/36/EU(49),
2014/17/EU(50)and(EU)2016/97(51)oftheEuropeanParliamentandofthe
Council,shouldbedesignated,withintheirrespectivecompetences,as
competentauthoritiesforthepurposeofsupervisingtheimplementationofthis

--- Page 57 ---
Regulation,includingformarketsurveillanceactivities,asregardsAIsystems
providedorusedbyregulatedandsupervisedfinancialinstitutionsunless
MemberStatesdecidetodesignateanotherauthoritytofulfilthesemarket
surveillancetasks.Thosecompetentauthoritiesshouldhaveallpowersunder
thisRegulationandRegulation(EU)2019/1020toenforcetherequirementsand
obligationsofthisRegulation,includingpowerstocarryourexpostmarket
surveillanceactivitiesthatcanbeintegrated,asappropriate,intotheirexisting
supervisorymechanismsandproceduresundertherelevantUnionfinancial
serviceslaw.Itisappropriatetoenvisagethat,whenactingasmarket
surveillanceauthoritiesunderthisRegulation,thenationalauthorities
responsibleforthesupervisionofcreditinstitutionsregulatedunderDirective
2013/36/EU,whichareparticipatingintheSingleSupervisoryMechanism
establishedbyCouncilRegulation(EU)No1024/2013(52),shouldreport,
withoutdelay,totheEuropeanCentralBankanyinformationidentifiedinthe
courseoftheirmarketsurveillanceactivitiesthatmaybeofpotentialinterestfor
theEuropeanCentralBank’sprudentialsupervisorytasksasspecifiedinthat
Regulation.TofurtherenhancetheconsistencybetweenthisRegulationandthe
rulesapplicabletocreditinstitutionsregulatedunderDirective2013/36/EU,itis
alsoappropriatetointegratesomeoftheproviders’proceduralobligationsin
relationtoriskmanagement,postmarketingmonitoringanddocumentationinto
theexistingobligationsandproceduresunderDirective2013/36/EU.Inorderto
avoidoverlaps,limitedderogationsshouldalsobeenvisagedinrelationtothe
qualitymanagementsystemofprovidersandthemonitoringobligationplaced
ondeployersofhigh-riskAIsystemstotheextentthattheseapplytocredit
institutionsregulatedbyDirective2013/36/EU.Thesameregimeshouldapply
toinsuranceandre-insuranceundertakingsandinsuranceholdingcompanies
underDirective2009/138/ECandtheinsuranceintermediariesunderDirective
(EU)2016/97andothertypesoffinancialinstitutionssubjecttorequirements
regardinginternalgovernance,arrangementsorprocessesestablishedpursuant
totherelevantUnionfinancialserviceslawtoensureconsistencyandequal
treatmentinthefinancialsector.
(159)Eachmarketsurveillanceauthorityforhigh-riskAIsystemsintheareaof
biometrics,aslistedinanannextothisRegulationinsofarasthosesystemsare
usedforthepurposesoflawenforcement,migration,asylumandbordercontrol
management,ortheadministrationofjusticeanddemocraticprocesses,should
haveeffectiveinvestigativeandcorrectivepowers,includingatleastthepower
toobtainaccesstoallpersonaldatathatarebeingprocessedandtoall
informationnecessaryfortheperformanceofitstasks.Themarketsurveillance
authoritiesshouldbeabletoexercisetheirpowersbyactingwithcomplete
independence.Anylimitationsoftheiraccesstosensitiveoperationaldataunder
thisRegulationshouldbewithoutprejudicetothepowersconferredtothemby
Directive(EU)2016/680.Noexclusionondisclosingdatatonationaldata
protectionauthoritiesunderthisRegulationshouldaffectthecurrentorfuture
powersofthoseauthoritiesbeyondthescopeofthisRegulation.
(160)ThemarketsurveillanceauthoritiesandtheCommissionshouldbeableto
proposejointactivities,includingjointinvestigations,tobeconductedbymarket
surveillanceauthoritiesormarketsurveillanceauthoritiesjointlywiththe
Commission,thathavetheaimofpromotingcompliance,identifyingnon-
compliance,raisingawarenessandprovidingguidanceinrelationtothis

--- Page 58 ---
Regulationwithrespecttospecificcategoriesofhigh-riskAIsystemsthatare
foundtopresentaseriousriskacrosstwoormoreMemberStates.Joint
activitiestopromotecomplianceshouldbecarriedoutinaccordancewith
Article9ofRegulation(EU)2019/1020.TheAIOfficeshouldprovide
coordinationsupportforjointinvestigations.
(161)ItisnecessarytoclarifytheresponsibilitiesandcompetencesatUnionand
nationallevelasregardsAIsystemsthatarebuiltongeneral-purposeAImodels.
Toavoidoverlappingcompetences,whereanAIsystemisbasedonageneral-
purposeAImodelandthemodelandsystemareprovidedbythesameprovider,
thesupervisionshouldtakeplaceatUnionlevelthroughtheAIOffice,which
shouldhavethepowersofamarketsurveillanceauthoritywithinthemeaningof
Regulation(EU)2019/1020forthispurpose.Inallothercases,nationalmarket
surveillanceauthoritiesremainresponsibleforthesupervisionofAIsystems.
However,forgeneral-purposeAIsystemsthatcanbeuseddirectlybydeployers
foratleastonepurposethatisclassifiedashigh-risk,marketsurveillance
authoritiesshouldcooperatewiththeAIOfficetocarryoutevaluationsof
complianceandinformtheBoardandothermarketsurveillanceauthorities
accordingly.Furthermore,marketsurveillanceauthoritiesshouldbeableto
requestassistancefromtheAIOfficewherethemarketsurveillanceauthorityis
unabletoconcludeaninvestigationonahigh-riskAIsystembecauseofits
inabilitytoaccesscertaininformationrelatedtothegeneral-purposeAImodel
onwhichthehigh-riskAIsystemisbuilt.Insuchcases,theprocedureregarding
mutualassistanceincross-bordercasesinChapterVIofRegulation(EU)
2019/1020shouldapplymutatismutandis.
(162)TomakebestuseofthecentralisedUnionexpertiseandsynergiesatUnion
level,thepowersofsupervisionandenforcementoftheobligationsonproviders
ofgeneral-purposeAImodelsshouldbeacompetenceoftheCommission.The
AIOfficeshouldbeabletocarryoutallnecessaryactionstomonitorthe
effectiveimplementationofthisRegulationasregardsgeneral-purposeAI
models.Itshouldbeabletoinvestigatepossibleinfringementsoftheruleson
providersofgeneral-purposeAImodelsbothonitsowninitiative,followingthe
resultsofitsmonitoringactivities,oruponrequestfrommarketsurveillance
authoritiesinlinewiththeconditionssetoutinthisRegulation.Tosupport
effectivemonitoringoftheAIOffice,itshouldprovideforthepossibilitythat
downstreamproviderslodgecomplaintsaboutpossibleinfringementsofthe
rulesonprovidersofgeneral-purposeAImodelsandsystems.
(163)Withaviewtocomplementingthegovernancesystemsforgeneral-purposeAI
models,thescientificpanelshouldsupportthemonitoringactivitiesoftheAI
Officeandmay,incertaincases,providequalifiedalertstotheAIOfficewhich
triggerfollow-ups,suchasinvestigations.Thisshouldbethecasewherethe
scientificpanelhasreasontosuspectthatageneral-purposeAImodelposes
aconcreteandidentifiableriskatUnionlevel.Furthermore,thisshouldbethe
casewherethescientificpanelhasreasontosuspectthatageneral-purposeAI
modelmeetsthecriteriathatwouldleadtoaclassificationasgeneral-purposeAI
modelwithsystemicrisk.Toequipthescientificpanelwiththeinformation
necessaryfortheperformanceofthosetasks,thereshouldbeamechanism
wherebythescientificpanelcanrequesttheCommissiontorequire
documentationorinformationfromaprovider.

--- Page 59 ---
(164)TheAIOfficeshouldbeabletotakethenecessaryactionstomonitorthe
effectiveimplementationofandcompliancewiththeobligationsforprovidersof
general-purposeAImodelslaiddowninthisRegulation.TheAIOfficeshould
beabletoinvestigatepossibleinfringementsinaccordancewiththepowers
providedforinthisRegulation,includingbyrequestingdocumentationand
information,byconductingevaluations,aswellasbyrequestingmeasuresfrom
providersofgeneral-purposeAImodels.Whenconductingevaluations,inorder
tomakeuseofindependentexpertise,theAIOfficeshouldbeabletoinvolve
independentexpertstocarryouttheevaluationsonitsbehalf.Compliancewith
theobligationsshouldbeenforceable,interalia,throughrequeststotake
appropriatemeasures,includingriskmitigationmeasuresinthecaseof
identifiedsystemicrisksaswellasrestrictingthemakingavailableonthe
market,withdrawingorrecallingthemodel.Asasafeguard,whereneeded
beyondtheproceduralrightsprovidedforinthisRegulation,providersof
general-purposeAImodelsshouldhavetheproceduralrightsprovidedforin
Article18ofRegulation(EU)2019/1020,whichshouldapplymutatismutandis,
withoutprejudicetomorespecificproceduralrightsprovidedforbythis
Regulation.
(165)ThedevelopmentofAIsystemsotherthanhigh-riskAIsystemsinaccordance
withtherequirementsofthisRegulationmayleadtoalargeruptakeofethical
andtrustworthyAIintheUnion.ProvidersofAIsystemsthatarenothigh-risk
shouldbeencouragedtocreatecodesofconduct,includingrelatedgovernance
mechanisms,intendedtofosterthevoluntaryapplicationofsomeorallofthe
mandatoryrequirementsapplicabletohigh-riskAIsystems,adaptedinlightof
theintendedpurposeofthesystemsandthelowerriskinvolvedandtakinginto
accounttheavailabletechnicalsolutionsandindustrybestpracticessuchas
modelanddatacards.Providersand,asappropriate,deployersofallAIsystems,
high-riskornot,andAImodelsshouldalsobeencouragedtoapplyon
avoluntarybasisadditionalrequirementsrelated,forexample,totheelementsof
theUnion’sEthicsGuidelinesforTrustworthyAI,environmentalsustainability,
AIliteracymeasures,inclusiveanddiversedesignanddevelopmentofAI
systems,includingattentiontovulnerablepersonsandaccessibilitytopersons
withdisability,stakeholders’participationwiththeinvolvement,asappropriate,
ofrelevantstakeholderssuchasbusinessandcivilsocietyorganisations,
academia,researchorganisations,tradeunionsandconsumerprotection
organisationsinthedesignanddevelopmentofAIsystems,anddiversityofthe
developmentteams,includinggenderbalance.Toensurethatthevoluntary
codesofconductareeffective,theyshouldbebasedonclearobjectivesandkey
performanceindicatorstomeasuretheachievementofthoseobjectives.They
shouldalsobedevelopedinaninclusiveway,asappropriate,withthe
involvementofrelevantstakeholderssuchasbusinessandcivilsociety
organisations,academia,researchorganisations,tradeunionsandconsumer
protectionorganisation.TheCommissionmaydevelopinitiatives,includingof
asectoralnature,tofacilitatetheloweringoftechnicalbarriershinderingcross-
borderexchangeofdataforAIdevelopment,includingondataaccess
infrastructure,semanticandtechnicalinteroperabilityofdifferenttypesofdata.
(166)ItisimportantthatAIsystemsrelatedtoproductsthatarenothigh-riskin
accordancewiththisRegulationandthusarenotrequiredtocomplywiththe

--- Page 60 ---
requirementssetoutforhigh-riskAIsystemsareneverthelesssafewhenplaced
onthemarketorputintoservice.Tocontributetothisobjective,Regulation
(EU)2023/988oftheEuropeanParliamentandoftheCouncil(53)wouldapply
asasafetynet.
(167)Inordertoensuretrustfulandconstructivecooperationofcompetentauthorities
onUnionandnationallevel,allpartiesinvolvedintheapplicationofthis
Regulationshouldrespecttheconfidentialityofinformationanddataobtainedin
carryingouttheirtasks,inaccordancewithUnionornationallaw.Theyshould
carryouttheirtasksandactivitiesinsuchamannerastoprotect,inparticular,
intellectualpropertyrights,confidentialbusinessinformationandtradesecrets,
theeffectiveimplementationofthisRegulation,publicandnationalsecurity
interests,theintegrityofcriminalandadministrativeproceedings,andthe
integrityofclassifiedinformation.
(168)CompliancewiththisRegulationshouldbeenforceablebymeansofthe
impositionofpenaltiesandotherenforcementmeasures.MemberStatesshould
takeallnecessarymeasurestoensurethattheprovisionsofthisRegulationare
implemented,includingbylayingdowneffective,proportionateanddissuasive
penaltiesfortheirinfringement,andtorespectthenebisinidemprinciple.In
ordertostrengthenandharmoniseadministrativepenaltiesforinfringementof
thisRegulation,theupperlimitsforsettingtheadministrativefinesforcertain
specificinfringementsshouldbelaiddown.Whenassessingtheamountofthe
fines,MemberStatesshould,ineachindividualcase,takeintoaccountall
relevantcircumstancesofthespecificsituation,withdueregardinparticularto
thenature,gravityanddurationoftheinfringementandofitsconsequencesand
tothesizeoftheprovider,inparticulariftheproviderisanSME,including
astart-up.TheEuropeanDataProtectionSupervisorshouldhavethepowerto
imposefinesonUnioninstitutions,agenciesandbodiesfallingwithinthescope
ofthisRegulation.
(169)Compliancewiththeobligationsonprovidersofgeneral-purposeAImodels
imposedunderthisRegulationshouldbeenforceable,interalia,bymeansof
fines.Tothatend,appropriatelevelsoffinesshouldalsobelaiddownfor
infringementofthoseobligations,includingthefailuretocomplywithmeasures
requestedbytheCommissioninaccordancewiththisRegulation,subjectto
appropriatelimitationperiodsinaccordancewiththeprincipleof
proportionality.AlldecisionstakenbytheCommissionunderthisRegulation
aresubjecttoreviewbytheCourtofJusticeoftheEuropeanUnionin
accordancewiththeTFEU,includingtheunlimitedjurisdictionoftheCourtof
JusticewithregardtopenaltiespursuanttoArticle261TFEU.
(170)Unionandnationallawalreadyprovideeffectiveremediestonaturalandlegal
personswhoserightsandfreedomsareadverselyaffectedbytheuseofAI
systems.Withoutprejudicetothoseremedies,anynaturalorlegalpersonthat
hasgroundstoconsiderthattherehasbeenaninfringementofthisRegulation
shouldbeentitledtolodgeacomplainttotherelevantmarketsurveillance
authority.
(171)Affectedpersonsshouldhavetherighttoobtainanexplanationwhere
adeployer’sdecisionisbasedmainlyupontheoutputfromcertainhigh-riskAI
systemsthatfallwithinthescopeofthisRegulationandwherethatdecision

--- Page 61 ---
produceslegaleffectsorsimilarlysignificantlyaffectsthosepersonsinaway
thattheyconsidertohaveanadverseimpactontheirhealth,safetyor
fundamentalrights.Thatexplanationshouldbeclearandmeaningfulandshould
provideabasisonwhichtheaffectedpersonsareabletoexercisetheirrights.
TherighttoobtainanexplanationshouldnotapplytotheuseofAIsystemsfor
whichexceptionsorrestrictionsfollowfromUnionornationallawandshould
applyonlytotheextentthisrightisnotalreadyprovidedforunderUnionlaw.
(172)PersonsactingaswhistleblowersontheinfringementsofthisRegulationshould
beprotectedundertheUnionlaw.Directive(EU)2019/1937oftheEuropean
ParliamentandoftheCouncil(54)shouldthereforeapplytothereportingof
infringementsofthisRegulationandtheprotectionofpersonsreportingsuch
infringements.
(173)Inordertoensurethattheregulatoryframeworkcanbeadaptedwhere
necessary,thepowertoadoptactsinaccordancewithArticle290TFEUshould
bedelegatedtotheCommissiontoamendtheconditionsunderwhichanAI
systemisnottobeconsideredtobehigh-risk,thelistofhigh-riskAIsystems,
theprovisionsregardingtechnicaldocumentation,thecontentoftheEU
declarationofconformitytheprovisionsregardingtheconformityassessment
procedures,theprovisionsestablishingthehigh-riskAIsystemstowhichthe
conformityassessmentprocedurebasedonassessmentofthequality
managementsystemandassessmentofthetechnicaldocumentationshould
apply,thethreshold,benchmarksandindicators,includingbysupplementing
thosebenchmarksandindicators,intherulesfortheclassificationofgeneral-
purposeAImodelswithsystemicrisk,thecriteriaforthedesignationofgeneral-
purposeAImodelswithsystemicrisk,thetechnicaldocumentationforproviders
ofgeneral-purposeAImodelsandthetransparencyinformationforprovidersof
general-purposeAImodels.ItisofparticularimportancethattheCommission
carryoutappropriateconsultationsduringitspreparatorywork,includingat
expertlevel,andthatthoseconsultationsbeconductedinaccordancewiththe
principleslaiddownintheInterinstitutionalAgreementof13April2016on
BetterLaw-Making(55).Inparticular,toensureequalparticipationinthe
preparationofdelegatedacts,theEuropeanParliamentandtheCouncilreceive
alldocumentsatthesametimeasMemberStates’experts,andtheirexperts
systematicallyhaveaccesstomeetingsofCommissionexpertgroupsdealing
withthepreparationofdelegatedacts.
(174)Giventherapidtechnologicaldevelopmentsandthetechnicalexpertiserequired
toeffectivelyapplythisRegulation,theCommissionshouldevaluateandreview
thisRegulationby2August2029andeveryfouryearsthereafterandreportto
theEuropeanParliamentandtheCouncil.Inaddition,takingintoaccountthe
implicationsforthescopeofthisRegulation,theCommissionshouldcarryout
anassessmentoftheneedtoamendthelistofhigh-riskAIsystemsandthelist
ofprohibitedpracticesonceayear.Moreover,by2August2028andeveryfour
yearsthereafter,theCommissionshouldevaluateandreporttotheEuropean
ParliamentandtotheCouncilontheneedtoamendthelistofhigh-riskareas
headingsintheannextothisRegulation,theAIsystemswithinthescopeofthe
transparencyobligations,theeffectivenessofthesupervisionandgovernance
systemandtheprogressonthedevelopmentofstandardisationdeliverableson
energyefficientdevelopmentofgeneral-purposeAImodels,includingtheneed

--- Page 62 ---
forfurthermeasuresoractions.Finally,by2August2028andeverythreeyears
thereafter,theCommissionshouldevaluatetheimpactandeffectivenessof
voluntarycodesofconducttofostertheapplicationoftherequirementsprovided
forhigh-riskAIsystemsinthecaseofAIsystemsotherthanhigh-riskAI
systemsandpossiblyotheradditionalrequirementsforsuchAIsystems.
(175)InordertoensureuniformconditionsfortheimplementationofthisRegulation,
implementingpowersshouldbeconferredontheCommission.Thosepowers
shouldbeexercisedinaccordancewithRegulation(EU)No182/2011ofthe
EuropeanParliamentandoftheCouncil(56).
(176)SincetheobjectiveofthisRegulation,namelytoimprovethefunctioningofthe
internalmarketandtopromotetheuptakeofhumancentricandtrustworthyAI,
whileensuringahighlevelofprotectionofhealth,safety,fundamentalrights
enshrinedintheCharter,includingdemocracy,theruleoflawand
environmentalprotectionagainstharmfuleffectsofAIsystemsintheUnionand
supportinginnovation,cannotbesufficientlyachievedbytheMemberStates
andcanrather,byreasonofthescaleoreffectsoftheaction,bebetterachieved
atUnionlevel,theUnionmayadoptmeasuresinaccordancewiththeprinciple
ofsubsidiarityassetoutinArticle5TEU.Inaccordancewiththeprincipleof
proportionalityassetoutinthatArticle,thisRegulationdoesnotgobeyond
whatisnecessaryinordertoachievethatobjective.
(177)Inordertoensurelegalcertainty,ensureanappropriateadaptationperiodfor
operatorsandavoiddisruptiontothemarket,includingbyensuringcontinuityof
theuseofAIsystems,itisappropriatethatthisRegulationappliestothehigh-
riskAIsystemsthathavebeenplacedonthemarketorputintoservicebefore
thegeneraldateofapplicationthereof,onlyif,fromthatdate,thosesystemsare
subjecttosignificantchangesintheirdesignorintendedpurpose.Itis
appropriatetoclarifythat,inthisrespect,theconceptofsignificantchange
shouldbeunderstoodasequivalentinsubstancetothenotionofsubstantial
modification,whichisusedwithregardonlytohigh-riskAIsystemspursuantto
thisRegulation.Onanexceptionalbasisandinlightofpublicaccountability,
operatorsofAIsystemswhicharecomponentsofthelarge-scaleITsystems
establishedbythelegalactslistedinanannextothisRegulationandoperators
ofhigh-riskAIsystemsthatareintendedtobeusedbypublicauthoritiesshould,
respectively,takethenecessarystepstocomplywiththerequirementsofthis
Regulationbyendof2030andby2August2030.
(178)Providersofhigh-riskAIsystemsareencouragedtostarttocomply,on
avoluntarybasis,withtherelevantobligationsofthisRegulationalreadyduring
thetransitionalperiod.
(179)ThisRegulationshouldapplyfrom2August2026.However,takinginto
accounttheunacceptableriskassociatedwiththeuseofAIincertainways,the
prohibitionsaswellasthegeneralprovisionsofthisRegulationshouldalready
applyfrom2February2025.Whilethefulleffectofthoseprohibitionsfollows
withtheestablishmentofthegovernanceandenforcementofthisRegulation,
anticipatingtheapplicationoftheprohibitionsisimportanttotakeaccountof
unacceptablerisksandtohaveaneffectonotherprocedures,suchasincivil
law.Moreover,theinfrastructurerelatedtothegovernanceandtheconformity
assessmentsystemshouldbeoperationalbefore2August2026,thereforethe

--- Page 63 ---
provisionsonnotifiedbodiesandgovernancestructureshouldapplyfrom
2August2025.Giventherapidpaceoftechnologicaladvancementsand
adoptionofgeneral-purposeAImodels,obligationsforprovidersofgeneral-
purposeAImodelsshouldapplyfrom2August2025.Codesofpracticeshould
bereadyby2May2025inviewofenablingproviderstodemonstrate
complianceontime.TheAIOfficeshouldensurethatclassificationrulesand
proceduresareuptodateinlightoftechnologicaldevelopments.Inaddition,
MemberStatesshouldlaydownandnotifytotheCommissiontheruleson
penalties,includingadministrativefines,andensurethattheyareproperlyand
effectivelyimplementedbythedateofapplicationofthisRegulation.Therefore
theprovisionsonpenaltiesshouldapplyfrom2August2025.
(180)TheEuropeanDataProtectionSupervisorandtheEuropeanDataProtection
BoardwereconsultedinaccordancewithArticle42(1)and(2)ofRegulation
(EU)2018/1725anddeliveredtheirjointopinionon18June2021,
HAVEADOPTEDTHISREGULATION:
CHAPTERI
GENERALPROVISIONS
Article1
Subjectmatter`
1.ThepurposeofthisRegulationistoimprovethefunctioningofthe
internalmarketandpromotetheuptakeofhuman-centricandtrustworthy
artificialintelligence(AI),whileensuringahighlevelofprotectionof
health,safety,fundamentalrightsenshrinedintheCharter,including
democracy,theruleoflawandenvironmentalprotection,againstthe
harmfuleffectsofAIsystemsintheUnionandsupportinginnovation.
2.ThisRegulationlaysdown:
(a)harmonisedrulesfortheplacingonthemarket,theputtingintoservice,andtheuse
ofAIsystemsintheUnion;
(b)prohibitionsofcertainAIpractices;
(c)specificrequirementsforhigh-riskAIsystemsandobligationsforoperatorsof
suchsystems;
(d)harmonisedtransparencyrulesforcertainAIsystems;
(e)harmonisedrulesfortheplacingonthemarketofgeneral-purposeAImodels;
(f)rulesonmarketmonitoring,marketsurveillance,governanceandenforcement;
(g)measurestosupportinnovation,withaparticularfocusonSMEs,includingstart-
ups.

--- Page 64 ---
Article2
Scope
1.ThisRegulationappliesto:
(a)providersplacingonthemarketorputtingintoserviceAIsystemsorplacingonthe
marketgeneral-purposeAImodelsintheUnion,irrespectiveofwhetherthose
providersareestablishedorlocatedwithintheUnionorinathirdcountry;
(b)deployersofAIsystemsthathavetheirplaceofestablishmentorarelocatedwithin
theUnion;
(c)providersanddeployersofAIsystemsthathavetheirplaceofestablishmentorare
locatedinathirdcountry,wheretheoutputproducedbytheAIsystemisusedin
theUnion;
(d)importersanddistributorsofAIsystems;
(e)productmanufacturersplacingonthemarketorputtingintoserviceanAIsystem
togetherwiththeirproductandundertheirownnameortrademark;
(f)authorisedrepresentativesofproviders,whicharenotestablishedintheUnion;
(g)affectedpersonsthatarelocatedintheUnion.
2.ForAIsystemsclassifiedashigh-riskAIsystemsinaccordancewith
Article6(1)relatedtoproductscoveredbytheUnionharmonisation
legislationlistedinSectionBofAnnexI,onlyArticle6(1),Articles102to
109andArticle112apply.Article57appliesonlyinsofarasthe
requirementsforhigh-riskAIsystemsunderthisRegulationhavebeen
integratedinthatUnionharmonisationlegislation.
3.ThisRegulationdoesnotapplytoareasoutsidethescopeofUnionlaw,
andshallnot,inanyevent,affectthecompetencesoftheMemberStates
concerningnationalsecurity,regardlessofthetypeofentityentrustedbythe
MemberStateswithcarryingouttasksinrelationtothosecompetences.
ThisRegulationdoesnotapplytoAIsystemswhereandinsofartheyare
placedonthemarket,putintoservice,orusedwithorwithoutmodification
exclusivelyformilitary,defenceornationalsecuritypurposes,regardlessof
thetypeofentitycarryingoutthoseactivities.
ThisRegulationdoesnotapplytoAIsystemswhicharenotplacedonthe
marketorputintoserviceintheUnion,wheretheoutputisusedinthe
Unionexclusivelyformilitary,defenceornationalsecuritypurposes,
regardlessofthetypeofentitycarryingoutthoseactivities.
4.ThisRegulationappliesneithertopublicauthoritiesinathirdcountry
nortointernationalorganisationsfallingwithinthescopeofthisRegulation
pursuanttoparagraph1,wherethoseauthoritiesororganisationsuseAI
systemsintheframeworkofinternationalcooperationoragreementsforlaw
enforcementandjudicialcooperationwiththeUnionorwithoneormore

--- Page 65 ---
MemberStates,providedthatsuchathirdcountryorinternational
organisationprovidesadequatesafeguardswithrespecttotheprotectionof
fundamentalrightsandfreedomsofindividuals.
5.ThisRegulationshallnotaffecttheapplicationoftheprovisionsonthe
liabilityofprovidersofintermediaryservicesassetoutinChapterIIof
Regulation(EU)2022/2065.
6.ThisRegulationdoesnotapplytoAIsystemsorAImodels,including
theiroutput,specificallydevelopedandputintoserviceforthesolepurpose
ofscientificresearchanddevelopment.
7.Unionlawontheprotectionofpersonaldata,privacyandthe
confidentialityofcommunicationsappliestopersonaldataprocessedin
connectionwiththerightsandobligationslaiddowninthisRegulation.This
RegulationshallnotaffectRegulation(EU)2016/679or(EU)2018/1725,or
Directive2002/58/ECor(EU)2016/680,withoutprejudicetoArticle10(5)
andArticle59ofthisRegulation.
8.ThisRegulationdoesnotapplytoanyresearch,testingordevelopment
activityregardingAIsystemsorAImodelspriortotheirbeingplacedonthe
marketorputintoservice.Suchactivitiesshallbeconductedinaccordance
withapplicableUnionlaw.Testinginrealworldconditionsshallnotbe
coveredbythatexclusion.
9.ThisRegulationiswithoutprejudicetotheruleslaiddownbyother
Unionlegalactsrelatedtoconsumerprotectionandproductsafety.
10.ThisRegulationdoesnotapplytoobligationsofdeployerswhoare
naturalpersonsusingAIsystemsinthecourseofapurelypersonalnon-
professionalactivity.
11.ThisRegulationdoesnotprecludetheUnionorMemberStatesfrom
maintainingorintroducinglaws,regulationsoradministrativeprovisions
whicharemorefavourabletoworkersintermsofprotectingtheirrightsin
respectoftheuseofAIsystemsbyemployers,orfromencouragingor
allowingtheapplicationofcollectiveagreementswhicharemorefavourable
toworkers.
12.ThisRegulationdoesnotapplytoAIsystemsreleasedunderfreeand
open-sourcelicences,unlesstheyareplacedonthemarketorputinto
serviceashigh-riskAIsystemsorasanAIsystemthatfallsunderArticle5
or50.
Article3
Definitions
ForthepurposesofthisRegulation,thefollowingdefinitionsapply:

--- Page 66 ---
(1)‘AIsystem’meansamachine-basedsystemthatisdesignedtooperatewith
varyinglevelsofautonomyandthatmayexhibitadaptivenessafterdeployment,
andthat,forexplicitorimplicitobjectives,infers,fromtheinputitreceives,howto
generateoutputssuchaspredictions,content,recommendations,ordecisionsthat
caninfluencephysicalorvirtualenvironments;
(2)‘risk’meansthecombinationoftheprobabilityofanoccurrenceofharmandthe
severityofthatharm;
(3)‘provider’meansanaturalorlegalperson,publicauthority,agencyorotherbody
thatdevelopsanAIsystemorageneral-purposeAImodelorthathasanAIsystem
orageneral-purposeAImodeldevelopedandplacesitonthemarketorputstheAI
systemintoserviceunderitsownnameortrademark,whetherforpaymentorfree
ofcharge;
(4)‘deployer’meansanaturalorlegalperson,publicauthority,agencyorotherbody
usinganAIsystemunderitsauthorityexceptwheretheAIsystemisusedinthe
courseofapersonalnon-professionalactivity;
(5)‘authorisedrepresentative’meansanaturalorlegalpersonlocatedorestablishedin
theUnionwhohasreceivedandacceptedawrittenmandatefromaproviderofan
AIsystemorageneral-purposeAImodelto,respectively,performandcarryout
onitsbehalftheobligationsandproceduresestablishedbythisRegulation;
(6)‘importer’meansanaturalorlegalpersonlocatedorestablishedintheUnionthat
placesonthemarketanAIsystemthatbearsthenameortrademarkofanaturalor
legalpersonestablishedinathirdcountry;
(7)‘distributor’meansanaturalorlegalpersoninthesupplychain,otherthanthe
providerortheimporter,thatmakesanAIsystemavailableontheUnionmarket;
(8)‘operator’meansaprovider,productmanufacturer,deployer,authorised
representative,importerordistributor;
(9)‘placingonthemarket’meansthefirstmakingavailableofanAIsystemor
ageneral-purposeAImodelontheUnionmarket;
(10)‘makingavailableonthemarket’meansthesupplyofanAIsystemorageneral-
purposeAImodelfordistributionoruseontheUnionmarketinthecourseof
acommercialactivity,whetherinreturnforpaymentorfreeofcharge;
(11)‘puttingintoservice’meansthesupplyofanAIsystemforfirstusedirectlytothe
deployerorforownuseintheUnionforitsintendedpurpose;
(12)‘intendedpurpose’meanstheuseforwhichanAIsystemisintendedbythe
provider,includingthespecificcontextandconditionsofuse,asspecifiedinthe
informationsuppliedbytheproviderintheinstructionsforuse,promotionalor
salesmaterialsandstatements,aswellasinthetechnicaldocumentation;
(13)‘reasonablyforeseeablemisuse’meanstheuseofanAIsysteminawaythatis
notinaccordancewithitsintendedpurpose,butwhichmayresultfrom
reasonablyforeseeablehumanbehaviourorinteractionwithothersystems,
includingotherAIsystems;
(14)‘safetycomponent’meansacomponentofaproductorofanAIsystemwhich

--- Page 67 ---
fulfilsasafetyfunctionforthatproductorAIsystem,orthefailureor
malfunctioningofwhichendangersthehealthandsafetyofpersonsorproperty;
(15)‘instructionsforuse’meanstheinformationprovidedbytheprovidertoinform
thedeployerof,inparticular,anAIsystem’sintendedpurposeandproperuse;
(16)‘recallofanAIsystem’meansanymeasureaimingtoachievethereturntothe
providerortakingoutofserviceordisablingtheuseofanAIsystemmade
availabletodeployers;
(17)‘withdrawalofanAIsystem’meansanymeasureaimingtopreventanAIsystem
inthesupplychainbeingmadeavailableonthemarket;
(18)‘performanceofanAIsystem’meanstheabilityofanAIsystemtoachieveits
intendedpurpose;
(19)‘notifyingauthority’meansthenationalauthorityresponsibleforsettingupand
carryingoutthenecessaryproceduresfortheassessment,designationand
notificationofconformityassessmentbodiesandfortheirmonitoring;
(20)‘conformityassessment’meanstheprocessofdemonstratingwhetherthe
requirementssetoutinChapterIII,Section2relatingtoahigh-riskAIsystem
havebeenfulfilled;
(21)‘conformityassessmentbody’meansabodythatperformsthird-partyconformity
assessmentactivities,includingtesting,certificationandinspection;
(22)‘notifiedbody’meansaconformityassessmentbodynotifiedinaccordancewith
thisRegulationandotherrelevantUnionharmonisationlegislation;
(23)‘substantialmodification’meansachangetoanAIsystemafteritsplacingonthe
marketorputtingintoservicewhichisnotforeseenorplannedintheinitial
conformityassessmentcarriedoutbytheproviderandasaresultofwhichthe
complianceoftheAIsystemwiththerequirementssetoutinChapterIII,
Section2isaffectedorresultsinamodificationtotheintendedpurposeforwhich
theAIsystemhasbeenassessed;
(24)‘CEmarking’meansamarkingbywhichaproviderindicatesthatanAIsystemis
inconformitywiththerequirementssetoutinChapterIII,Section2andother
applicableUnionharmonisationlegislationprovidingforitsaffixing;
(25)‘post-marketmonitoringsystem’meansallactivitiescarriedoutbyprovidersof
AIsystemstocollectandreviewexperiencegainedfromtheuseofAIsystems
theyplaceonthemarketorputintoserviceforthepurposeofidentifyingany
needtoimmediatelyapplyanynecessarycorrectiveorpreventiveactions;
(26)‘marketsurveillanceauthority’meansthenationalauthoritycarryingoutthe
activitiesandtakingthemeasurespursuanttoRegulation(EU)2019/1020;
(27)‘harmonisedstandard’meansaharmonisedstandardasdefinedinArticle2(1),
point(c),ofRegulation(EU)No1025/2012;
(28)‘commonspecification’meansasetoftechnicalspecificationsasdefinedin
Article2,point(4)ofRegulation(EU)No1025/2012,providingmeanstocomply
withcertainrequirementsestablishedunderthisRegulation;

--- Page 68 ---
(29)‘trainingdata’meansdatausedfortraininganAIsystemthroughfittingits
learnableparameters;
(30)‘validationdata’meansdatausedforprovidinganevaluationofthetrainedAI
systemandfortuningitsnon-learnableparametersanditslearningprocessin
order,interalia,topreventunderfittingoroverfitting;
(31)‘validationdataset’meansaseparatedatasetorpartofthetrainingdataset,
eitherasafixedorvariablesplit;
(32)‘testingdata’meansdatausedforprovidinganindependentevaluationoftheAI
systeminordertoconfirmtheexpectedperformanceofthatsystembeforeits
placingonthemarketorputtingintoservice;
(33)‘inputdata’meansdataprovidedtoordirectlyacquiredbyanAIsystemonthe
basisofwhichthesystemproducesanoutput;
(34)‘biometricdata’meanspersonaldataresultingfromspecifictechnicalprocessing
relatingtothephysical,physiologicalorbehaviouralcharacteristicsofanatural
person,suchasfacialimagesordactyloscopicdata;
(35)‘biometricidentification’meanstheautomatedrecognitionofphysical,
physiological,behavioural,orpsychologicalhumanfeaturesforthepurposeof
establishingtheidentityofanaturalpersonbycomparingbiometricdataofthat
individualtobiometricdataofindividualsstoredinadatabase;
(36)‘biometricverification’meanstheautomated,one-to-oneverification,including
authentication,oftheidentityofnaturalpersonsbycomparingtheirbiometric
datatopreviouslyprovidedbiometricdata;
(37)‘specialcategoriesofpersonaldata’meansthecategoriesofpersonaldata
referredtoinArticle9(1)ofRegulation(EU)2016/679,Article10ofDirective
(EU)2016/680andArticle10(1)ofRegulation(EU)2018/1725;
(38)‘sensitiveoperationaldata’meansoperationaldatarelatedtoactivitiesof
prevention,detection,investigationorprosecutionofcriminaloffences,the
disclosureofwhichcouldjeopardisetheintegrityofcriminalproceedings;
(39)‘emotionrecognitionsystem’meansanAIsystemforthepurposeofidentifying
orinferringemotionsorintentionsofnaturalpersonsonthebasisoftheir
biometricdata;
(40)‘biometriccategorisationsystem’meansanAIsystemforthepurposeof
assigningnaturalpersonstospecificcategoriesonthebasisoftheirbiometric
data,unlessitisancillarytoanothercommercialserviceandstrictlynecessaryfor
objectivetechnicalreasons;
(41)‘remotebiometricidentificationsystem’meansanAIsystemforthepurposeof
identifyingnaturalpersons,withouttheiractiveinvolvement,typicallyat
adistancethroughthecomparisonofaperson’sbiometricdatawiththebiometric
datacontainedinareferencedatabase;
(42)‘real-timeremotebiometricidentificationsystem’meansaremotebiometric
identificationsystem,wherebythecapturingofbiometricdata,thecomparison
andtheidentificationalloccurwithoutasignificantdelay,comprisingnotonly

--- Page 69 ---
instantidentification,butalsolimitedshortdelaysinordertoavoid
circumvention;
(43)‘post-remotebiometricidentificationsystem’meansaremotebiometric
identificationsystemotherthanareal-timeremotebiometricidentification
system;
(44)‘publiclyaccessiblespace’meansanypubliclyorprivatelyownedphysicalplace
accessibletoanundeterminednumberofnaturalpersons,regardlessofwhether
certainconditionsforaccessmayapply,andregardlessofthepotentialcapacity
restrictions;
(45)‘lawenforcementauthority’means:
(a)anypublicauthoritycompetentfortheprevention,investigation,detectionor
prosecutionofcriminaloffencesortheexecutionofcriminalpenalties,
includingthesafeguardingagainstandthepreventionofthreatstopublic
security;or
(b)anyotherbodyorentityentrustedbyMemberStatelawtoexercisepublic
authorityandpublicpowersforthepurposesoftheprevention,investigation,
detectionorprosecutionofcriminaloffencesortheexecutionofcriminal
penalties,includingthesafeguardingagainstandthepreventionofthreatsto
publicsecurity;
(46)‘lawenforcement’meansactivitiescarriedoutbylawenforcementauthoritiesor
ontheirbehalffortheprevention,investigation,detectionorprosecutionof
criminaloffencesortheexecutionofcriminalpenalties,includingsafeguarding
againstandpreventingthreatstopublicsecurity;
(47)‘AIOffice’meanstheCommission’sfunctionofcontributingtothe
implementation,monitoringandsupervisionofAIsystemsandgeneral-purpose
AImodels,andAIgovernance,providedforinCommissionDecisionof
24January2024;referencesinthisRegulationtotheAIOfficeshallbeconstrued
asreferencestotheCommission;
(48)‘nationalcompetentauthority’meansanotifyingauthorityoramarket
surveillanceauthority;asregardsAIsystemsputintoserviceorusedbyUnion
institutions,agencies,officesandbodies,referencestonationalcompetent
authoritiesormarketsurveillanceauthoritiesinthisRegulationshallbeconstrued
asreferencestotheEuropeanDataProtectionSupervisor;
(49)‘seriousincident’meansanincidentormalfunctioningofanAIsystemthat
directlyorindirectlyleadstoanyofthefollowing:
(a)thedeathofaperson,orseriousharmtoaperson’shealth;
(b)aseriousandirreversibledisruptionofthemanagementoroperationofcritical
infrastructure;
(c)theinfringementofobligationsunderUnionlawintendedtoprotect
fundamentalrights;
(d)seriousharmtopropertyortheenvironment;
(50)‘personaldata’meanspersonaldataasdefinedinArticle4,point(1),of

--- Page 70 ---
Regulation(EU)2016/679;
(51)‘non-personaldata’meansdataotherthanpersonaldataasdefinedinArticle4,
point(1),ofRegulation(EU)2016/679;
(52)‘profiling’meansprofilingasdefinedinArticle4,point(4),ofRegulation(EU)
2016/679;
(53)‘real-worldtestingplan’meansadocumentthatdescribestheobjectives,
methodology,geographical,populationandtemporalscope,monitoring,
organisationandconductoftestinginreal-worldconditions;
(54)‘sandboxplan’meansadocumentagreedbetweentheparticipatingproviderand
thecompetentauthoritydescribingtheobjectives,conditions,timeframe,
methodologyandrequirementsfortheactivitiescarriedoutwithinthesandbox;
(55)‘AIregulatorysandbox’meansacontrolledframeworksetupbyacompetent
authoritywhichoffersprovidersorprospectiveprovidersofAIsystemsthe
possibilitytodevelop,train,validateandtest,whereappropriateinreal-world
conditions,aninnovativeAIsystem,pursuanttoasandboxplanforalimitedtime
underregulatorysupervision;
(56)‘AIliteracy’meansskills,knowledgeandunderstandingthatallowproviders,
deployersandaffectedpersons,takingintoaccounttheirrespectiverightsand
obligationsinthecontextofthisRegulation,tomakeaninformeddeploymentof
AIsystems,aswellastogainawarenessabouttheopportunitiesandrisksofAI
andpossibleharmitcancause;
(57)‘testinginreal-worldconditions’meansthetemporarytestingofanAIsystemfor
itsintendedpurposeinreal-worldconditionsoutsidealaboratoryorotherwise
simulatedenvironment,withaviewtogatheringreliableandrobustdataandto
assessingandverifyingtheconformityoftheAIsystemwiththerequirementsof
thisRegulationanditdoesnotqualifyasplacingtheAIsystemonthemarketor
puttingitintoservicewithinthemeaningofthisRegulation,providedthatallthe
conditionslaiddowninArticle57or60arefulfilled;
(58)‘subject’,forthepurposeofreal-worldtesting,meansanaturalpersonwho
participatesintestinginreal-worldconditions;
(59)‘informedconsent’meansasubject’sfreelygiven,specific,unambiguousand
voluntaryexpressionofhisorherwillingnesstoparticipateinaparticulartesting
inreal-worldconditions,afterhavingbeeninformedofallaspectsofthetesting
thatarerelevanttothesubject’sdecisiontoparticipate;
(60)‘deepfake’meansAI-generatedormanipulatedimage,audioorvideocontent
thatresemblesexistingpersons,objects,places,entitiesoreventsandwould
falselyappeartoapersontobeauthenticortruthful;
(61)‘widespreadinfringement’meansanyactoromissioncontrarytoUnionlaw
protectingtheinterestofindividuals,which:
(a)hasharmedorislikelytoharmthecollectiveinterestsofindividualsresiding
inatleasttwoMemberStatesotherthantheMemberStateinwhich:
(i)theactoromissionoriginatedortookplace;

--- Page 71 ---
(ii)theproviderconcerned,or,whereapplicable,itsauthorisedrepresentativeis
locatedorestablished;or
(iii)thedeployerisestablished,whentheinfringementiscommittedbythe
deployer;
(b)hascaused,causesorislikelytocauseharmtothecollectiveinterestsof
individualsandhascommonfeatures,includingthesameunlawfulpracticeor
thesameinterestbeinginfringed,andisoccurringconcurrently,committedby
thesameoperator,inatleastthreeMemberStates;
(62)‘criticalinfrastructure’meanscriticalinfrastructureasdefinedinArticle2,point
(4),ofDirective(EU)2022/2557;
(63)‘general-purposeAImodel’meansanAImodel,includingwheresuchanAI
modelistrainedwithalargeamountofdatausingself-supervisionatscale,that
displayssignificantgeneralityandiscapableofcompetentlyperformingawide
rangeofdistincttasksregardlessofthewaythemodelisplacedonthemarket
andthatcanbeintegratedintoavarietyofdownstreamsystemsorapplications,
exceptAImodelsthatareusedforresearch,developmentorprototypingactivities
beforetheyareplacedonthemarket;
(64)‘high-impactcapabilities’meanscapabilitiesthatmatchorexceedthecapabilities
recordedinthemostadvancedgeneral-purposeAImodels;
(65)‘systemicrisk’meansariskthatisspecifictothehigh-impactcapabilitiesof
general-purposeAImodels,havingasignificantimpactontheUnionmarketdue
totheirreach,orduetoactualorreasonablyforeseeablenegativeeffectson
publichealth,safety,publicsecurity,fundamentalrights,orthesocietyas
awhole,thatcanbepropagatedatscaleacrossthevaluechain;
(66)‘general-purposeAIsystem’meansanAIsystemwhichisbasedonageneral-
purposeAImodelandwhichhasthecapabilitytoserveavarietyofpurposes,
bothfordirectuseaswellasforintegrationinotherAIsystems;
(67)‘floating-pointoperation’meansanymathematicaloperationorassignment
involvingfloating-pointnumbers,whichareasubsetoftherealnumberstypically
representedoncomputersbyanintegeroffixedprecisionscaledbyaninteger
exponentofafixedbase;
(68)‘downstreamprovider’meansaproviderofanAIsystem,includingageneral-
purposeAIsystem,whichintegratesanAImodel,regardlessofwhethertheAI
modelisprovidedbythemselvesandverticallyintegratedorprovidedbyanother
entitybasedoncontractualrelations.
Article4
AIliteracy
ProvidersanddeployersofAIsystemsshalltakemeasurestoensure,totheir
bestextent,asufficientlevelofAIliteracyoftheirstaffandotherpersons
dealingwiththeoperationanduseofAIsystemsontheirbehalf,takinginto
accounttheirtechnicalknowledge,experience,educationandtrainingand

--- Page 72 ---
thecontexttheAIsystemsaretobeusedin,andconsideringthepersonsor
groupsofpersonsonwhomtheAIsystemsaretobeused.
CHAPTERII
PROHIBITEDAIPRACTICES
Article5
ProhibitedAIpractices
1.ThefollowingAIpracticesshallbeprohibited:
(a)theplacingonthemarket,theputtingintoserviceortheuseofanAIsystemthat
deployssubliminaltechniquesbeyondaperson’sconsciousnessorpurposefully
manipulativeordeceptivetechniques,withtheobjective,ortheeffectofmaterially
distortingthebehaviourofapersonoragroupofpersonsbyappreciablyimpairing
theirabilitytomakeaninformeddecision,therebycausingthemtotakeadecision
thattheywouldnothaveotherwisetakeninamannerthatcausesorisreasonably
likelytocausethatperson,anotherpersonorgroupofpersonssignificantharm;
(b)theplacingonthemarket,theputtingintoserviceortheuseofanAIsystemthat
exploitsanyofthevulnerabilitiesofanaturalpersonoraspecificgroupofpersons
duetotheirage,disabilityoraspecificsocialoreconomicsituation,withthe
objective,ortheeffect,ofmateriallydistortingthebehaviourofthatpersonor
apersonbelongingtothatgroupinamannerthatcausesorisreasonablylikelyto
causethatpersonoranotherpersonsignificantharm;
(c)theplacingonthemarket,theputtingintoserviceortheuseofAIsystemsforthe
evaluationorclassificationofnaturalpersonsorgroupsofpersonsoveracertain
periodoftimebasedontheirsocialbehaviourorknown,inferredorpredicted
personalorpersonalitycharacteristics,withthesocialscoreleadingtoeitheror
bothofthefollowing:
(i)detrimentalorunfavourabletreatmentofcertainnaturalpersonsorgroupsof
personsinsocialcontextsthatareunrelatedtothecontextsinwhichthedatawas
originallygeneratedorcollected;
(ii)detrimentalorunfavourabletreatmentofcertainnaturalpersonsorgroupsof
personsthatisunjustifiedordisproportionatetotheirsocialbehaviourorits
gravity;
(d)theplacingonthemarket,theputtingintoserviceforthisspecificpurpose,orthe
useofanAIsystemformakingriskassessmentsofnaturalpersonsinorderto
assessorpredicttheriskofanaturalpersoncommittingacriminaloffence,based
solelyontheprofilingofanaturalpersonoronassessingtheirpersonalitytraits
andcharacteristics;thisprohibitionshallnotapplytoAIsystemsusedtosupport
thehumanassessmentoftheinvolvementofapersoninacriminalactivity,which
isalreadybasedonobjectiveandverifiablefactsdirectlylinkedtoacriminal
activity;
(e)theplacingonthemarket,theputtingintoserviceforthisspecificpurpose,orthe

--- Page 73 ---
useofAIsystemsthatcreateorexpandfacialrecognitiondatabasesthroughthe
untargetedscrapingoffacialimagesfromtheinternetorCCTVfootage;
(f)theplacingonthemarket,theputtingintoserviceforthisspecificpurpose,orthe
useofAIsystemstoinferemotionsofanaturalpersonintheareasofworkplace
andeducationinstitutions,exceptwheretheuseoftheAIsystemisintendedtobe
putinplaceorintothemarketformedicalorsafetyreasons;
(g)theplacingonthemarket,theputtingintoserviceforthisspecificpurpose,orthe
useofbiometriccategorisationsystemsthatcategoriseindividuallynaturalpersons
basedontheirbiometricdatatodeduceorinfertheirrace,politicalopinions,trade
unionmembership,religiousorphilosophicalbeliefs,sexlifeorsexualorientation;
thisprohibitiondoesnotcoveranylabellingorfilteringoflawfullyacquired
biometricdatasets,suchasimages,basedonbiometricdataorcategorizingof
biometricdataintheareaoflawenforcement;
(h)theuseof‘real-time’remotebiometricidentificationsystemsinpubliclyaccessible
spacesforthepurposesoflawenforcement,unlessandinsofarassuchuseis
strictlynecessaryforoneofthefollowingobjectives:
(i)thetargetedsearchforspecificvictimsofabduction,traffickinginhumanbeings
orsexualexploitationofhumanbeings,aswellasthesearchformissing
persons;
(ii)thepreventionofaspecific,substantialandimminentthreattothelifeor
physicalsafetyofnaturalpersonsoragenuineandpresentorgenuineand
foreseeablethreatofaterroristattack;
(iii)thelocalisationoridentificationofapersonsuspectedofhavingcommitted
acriminaloffence,forthepurposeofconductingacriminalinvestigationor
prosecutionorexecutingacriminalpenaltyforoffencesreferredtoinAnnexII
andpunishableintheMemberStateconcernedbyacustodialsentenceor
adetentionorderforamaximumperiodofatleastfouryears.
Point(h)ofthefirstsubparagraphiswithoutprejudicetoArticle9of
Regulation(EU)2016/679fortheprocessingofbiometricdataforpurposes
otherthanlawenforcement.
2.Theuseof‘real-time’remotebiometricidentificationsystemsin
publiclyaccessiblespacesforthepurposesoflawenforcementforanyof
theobjectivesreferredtoinparagraph1,firstsubparagraph,point(h),shall
bedeployedforthepurposessetoutinthatpointonlytoconfirmthe
identityofthespecificallytargetedindividual,anditshalltakeintoaccount
thefollowingelements:
(a)thenatureofthesituationgivingrisetothepossibleuse,inparticularthe
seriousness,probabilityandscaleoftheharmthatwouldbecausedifthesystem
werenotused;
(b)theconsequencesoftheuseofthesystemfortherightsandfreedomsofallpersons
concerned,inparticulartheseriousness,probabilityandscaleofthose
consequences.

--- Page 74 ---
Inaddition,theuseof‘real-time’remotebiometricidentificationsystemsin
publiclyaccessiblespacesforthepurposesoflawenforcementforanyof
theobjectivesreferredtoinparagraph1,firstsubparagraph,point(h),ofthis
Articleshallcomplywithnecessaryandproportionatesafeguardsand
conditionsinrelationtotheuseinaccordancewiththenationallaw
authorisingtheusethereof,inparticularasregardsthetemporal,geographic
andpersonallimitations.Theuseofthe‘real-time’remotebiometric
identificationsysteminpubliclyaccessiblespacesshallbeauthorisedonlyif
thelawenforcementauthorityhascompletedafundamentalrightsimpact
assessmentasprovidedforinArticle27andhasregisteredthesysteminthe
EUdatabaseaccordingtoArticle49.However,indulyjustifiedcasesof
urgency,theuseofsuchsystemsmaybecommencedwithoutthe
registrationintheEUdatabase,providedthatsuchregistrationiscompleted
withoutunduedelay.
3.Forthepurposesofparagraph1,firstsubparagraph,point(h)and
paragraph2,eachuseforthepurposesoflawenforcementofa‘real-time’
remotebiometricidentificationsysteminpubliclyaccessiblespacesshallbe
subjecttoapriorauthorisationgrantedbyajudicialauthorityoran
independentadministrativeauthoritywhosedecisionisbindingofthe
MemberStateinwhichtheuseistotakeplace,issueduponareasoned
requestandinaccordancewiththedetailedrulesofnationallawreferredto
inparagraph5.However,inadulyjustifiedsituationofurgency,theuseof
suchsystemmaybecommencedwithoutanauthorisationprovidedthatsuch
authorisationisrequestedwithoutunduedelay,atthelatestwithin24hours.
Ifsuchauthorisationisrejected,theuseshallbestoppedwithimmediate
effectandallthedata,aswellastheresultsandoutputsofthatuseshallbe
immediatelydiscardedanddeleted.
Thecompetentjudicialauthorityoranindependentadministrativeauthority
whosedecisionisbindingshallgranttheauthorisationonlywhereitis
satisfied,onthebasisofobjectiveevidenceorclearindicationspresentedto
it,thattheuseofthe‘real-time’remotebiometricidentificationsystem
concernedisnecessaryfor,andproportionateto,achievingoneofthe
objectivesspecifiedinparagraph1,firstsubparagraph,point(h),as
identifiedintherequestand,inparticular,remainslimitedtowhatisstrictly
necessaryconcerningtheperiodoftimeaswellasthegeographicand
personalscope.Indecidingontherequest,thatauthorityshalltakeinto
accounttheelementsreferredtoinparagraph2.Nodecisionthatproduces
anadverselegaleffectonapersonmaybetakenbasedsolelyontheoutput
ofthe‘real-time’remotebiometricidentificationsystem.
4.Withoutprejudicetoparagraph3,eachuseofa‘real-time’remote
biometricidentificationsysteminpubliclyaccessiblespacesforlaw
enforcementpurposesshallbenotifiedtotherelevantmarketsurveillance
authorityandthenationaldataprotectionauthorityinaccordancewiththe

--- Page 75 ---
nationalrulesreferredtoinparagraph5.Thenotificationshall,as
aminimum,containtheinformationspecifiedunderparagraph6andshall
notincludesensitiveoperationaldata.
5.AMemberStatemaydecidetoprovideforthepossibilitytofullyor
partiallyauthorisetheuseof‘real-time’remotebiometricidentification
systemsinpubliclyaccessiblespacesforthepurposesoflawenforcement
withinthelimitsandundertheconditionslistedinparagraph1,first
subparagraph,point(h),andparagraphs2and3.MemberStatesconcerned
shalllaydownintheirnationallawthenecessarydetailedrulesforthe
request,issuanceandexerciseof,aswellassupervisionandreporting
relatingto,theauthorisationsreferredtoinparagraph3.Thoserulesshall
alsospecifyinrespectofwhichoftheobjectiveslistedinparagraph1,first
subparagraph,point(h),includingwhichofthecriminaloffencesreferredto
inpoint(h)(iii)thereof,thecompetentauthoritiesmaybeauthorisedtouse
thosesystemsforthepurposesoflawenforcement.MemberStatesshall
notifythoserulestotheCommissionatthelatest30daysfollowingthe
adoptionthereof.MemberStatesmayintroduce,inaccordancewithUnion
law,morerestrictivelawsontheuseofremotebiometricidentification
systems.
6.Nationalmarketsurveillanceauthoritiesandthenationaldataprotection
authoritiesofMemberStatesthathavebeennotifiedoftheuseof‘real-time’
remotebiometricidentificationsystemsinpubliclyaccessiblespacesforlaw
enforcementpurposespursuanttoparagraph4shallsubmittothe
Commissionannualreportsonsuchuse.Forthatpurpose,theCommission
shallprovideMemberStatesandnationalmarketsurveillanceanddata
protectionauthoritieswithatemplate,includinginformationonthenumber
ofthedecisionstakenbycompetentjudicialauthoritiesoranindependent
administrativeauthoritywhosedecisionisbindinguponrequestsfor
authorisationsinaccordancewithparagraph3andtheirresult.
7.TheCommissionshallpublishannualreportsontheuseofreal-time
remotebiometricidentificationsystemsinpubliclyaccessiblespacesforlaw
enforcementpurposes,basedonaggregateddatainMemberStatesonthe
basisoftheannualreportsreferredtoinparagraph6.Thoseannualreports
shallnotincludesensitiveoperationaldataoftherelatedlawenforcement
activities.
8.ThisArticleshallnotaffecttheprohibitionsthatapplywhereanAI
practiceinfringesotherUnionlaw.
CHAPTERIII
HIGH-RISKAISYSTEMS

--- Page 76 ---
SECTION1
ClassificationofAIsystemsashigh-risk
Article6
Classificationrulesforhigh-riskAIsystems
1.IrrespectiveofwhetheranAIsystemisplacedonthemarketorputinto
serviceindependentlyoftheproductsreferredtoinpoints(a)and(b),that
AIsystemshallbeconsideredtobehigh-riskwherebothofthefollowing
conditionsarefulfilled:
(a)theAIsystemisintendedtobeusedasasafetycomponentofaproduct,ortheAI
systemisitselfaproduct,coveredbytheUnionharmonisationlegislationlistedin
AnnexI;
(b)theproductwhosesafetycomponentpursuanttopoint(a)istheAIsystem,orthe
AIsystemitselfasaproduct,isrequiredtoundergoathird-partyconformity
assessment,withaviewtotheplacingonthemarketortheputtingintoserviceof
thatproductpursuanttotheUnionharmonisationlegislationlistedinAnnexI.
2.Inadditiontothehigh-riskAIsystemsreferredtoinparagraph1,AI
systemsreferredtoinAnnexIIIshallbeconsideredtobehigh-risk.
3.Byderogationfromparagraph2,anAIsystemreferredtoinAnnexIII
shallnotbeconsideredtobehigh-riskwhereitdoesnotposeasignificant
riskofharmtothehealth,safetyorfundamentalrightsofnaturalpersons,
includingbynotmateriallyinfluencingtheoutcomeofdecisionmaking.
Thefirstsubparagraphshallapplywhereanyofthefollowingconditionsis
fulfilled:
(a)theAIsystemisintendedtoperformanarrowproceduraltask;
(b)theAIsystemisintendedtoimprovetheresultofapreviouslycompletedhuman
activity;
(c)theAIsystemisintendedtodetectdecision-makingpatternsordeviationsfrom
priordecision-makingpatternsandisnotmeanttoreplaceorinfluencethe
previouslycompletedhumanassessment,withoutproperhumanreview;or
(d)theAIsystemisintendedtoperformapreparatorytasktoanassessmentrelevant
forthepurposesoftheusecaseslistedinAnnexIII.
Notwithstandingthefirstsubparagraph,anAIsystemreferredtoin
AnnexIIIshallalwaysbeconsideredtobehigh-riskwheretheAIsystem
performsprofilingofnaturalpersons.
4.AproviderwhoconsidersthatanAIsystemreferredtoinAnnexIIIis
nothigh-riskshalldocumentitsassessmentbeforethatsystemisplacedon
themarketorputintoservice.Suchprovidershallbesubjecttothe
registrationobligationsetoutinArticle49(2).Uponrequestofnational

--- Page 77 ---
competentauthorities,theprovidershallprovidethedocumentationofthe
assessment.
5.TheCommissionshall,afterconsultingtheEuropeanArtificial
IntelligenceBoard(the‘Board’),andnolaterthan2February2026,provide
guidelinesspecifyingthepracticalimplementationofthisArticleinline
withArticle96togetherwithacomprehensivelistofpracticalexamplesof
usecasesofAIsystemsthatarehigh-riskandnothigh-risk.
6.TheCommissionisempoweredtoadoptdelegatedactsinaccordance
withArticle97inordertoamendparagraph3,secondsubparagraph,ofthis
Articlebyaddingnewconditionstothoselaiddowntherein,orby
modifyingthem,wherethereisconcreteandreliableevidenceofthe
existenceofAIsystemsthatfallunderthescopeofAnnexIII,butdonot
poseasignificantriskofharmtothehealth,safetyorfundamentalrightsof
naturalpersons.
7.TheCommissionshalladoptdelegatedactsinaccordancewith
Article97inordertoamendparagraph3,secondsubparagraph,ofthis
Articlebydeletinganyoftheconditionslaiddowntherein,wherethereis
concreteandreliableevidencethatthisisnecessarytomaintainthelevelof
protectionofhealth,safetyandfundamentalrightsprovidedforbythis
Regulation.
8.Anyamendmenttotheconditionslaiddowninparagraph3,second
subparagraph,adoptedinaccordancewithparagraphs6and7ofthisArticle
shallnotdecreasetheoveralllevelofprotectionofhealth,safetyand
fundamentalrightsprovidedforbythisRegulationandshallensure
consistencywiththedelegatedactsadoptedpursuanttoArticle7(1),and
takeaccountofmarketandtechnologicaldevelopments.
Article7
AmendmentstoAnnexIII
1.TheCommissionisempoweredtoadoptdelegatedactsinaccordance
withArticle97toamendAnnexIIIbyaddingormodifyinguse-casesof
high-riskAIsystemswherebothofthefollowingconditionsarefulfilled:
(a)theAIsystemsareintendedtobeusedinanyoftheareaslistedinAnnexIII;
(b)theAIsystemsposeariskofharmtohealthandsafety,oranadverseimpacton
fundamentalrights,andthatriskisequivalentto,orgreaterthan,theriskofharm
orofadverseimpactposedbythehigh-riskAIsystemsalreadyreferredtoin
AnnexIII.
2.Whenassessingtheconditionunderparagraph1,point(b),the
Commissionshalltakeintoaccountthefollowingcriteria:

--- Page 78 ---
(a)theintendedpurposeoftheAIsystem;
(b)theextenttowhichanAIsystemhasbeenusedorislikelytobeused;
(c)thenatureandamountofthedataprocessedandusedbytheAIsystem,in
particularwhetherspecialcategoriesofpersonaldataareprocessed;
(d)theextenttowhichtheAIsystemactsautonomouslyandthepossibilityfor
ahumantooverrideadecisionorrecommendationsthatmayleadtopotential
harm;
(e)theextenttowhichtheuseofanAIsystemhasalreadycausedharmtohealthand
safety,hashadanadverseimpactonfundamentalrightsorhasgivenriseto
significantconcernsinrelationtothelikelihoodofsuchharmoradverseimpact,as
demonstrated,forexample,byreportsordocumentedallegationssubmittedto
nationalcompetentauthoritiesorbyotherreports,asappropriate;
(f)thepotentialextentofsuchharmorsuchadverseimpact,inparticularintermsof
itsintensityanditsabilitytoaffectmultiplepersonsortodisproportionatelyaffect
aparticulargroupofpersons;
(g)theextenttowhichpersonswhoarepotentiallyharmedorsufferanadverseimpact
aredependentontheoutcomeproducedwithanAIsystem,inparticularbecause
forpracticalorlegalreasonsitisnotreasonablypossibletoopt-outfromthat
outcome;
(h)theextenttowhichthereisanimbalanceofpower,orthepersonswhoare
potentiallyharmedorsufferanadverseimpactareinavulnerablepositionin
relationtothedeployerofanAIsystem,inparticularduetostatus,authority,
knowledge,economicorsocialcircumstances,orage;
(i)theextenttowhichtheoutcomeproducedinvolvinganAIsystemiseasily
corrigibleorreversible,takingintoaccountthetechnicalsolutionsavailableto
correctorreverseit,wherebyoutcomeshavinganadverseimpactonhealth,safety
orfundamentalrights,shallnotbeconsideredtobeeasilycorrigibleorreversible;
(j)themagnitudeandlikelihoodofbenefitofthedeploymentoftheAIsystemfor
individuals,groups,orsocietyatlarge,includingpossibleimprovementsinproduct
safety;
(k)theextenttowhichexistingUnionlawprovidesfor:
(i)effectivemeasuresofredressinrelationtotherisksposedbyanAIsystem,with
theexclusionofclaimsfordamages;
(ii)effectivemeasurestopreventorsubstantiallyminimisethoserisks.
3.TheCommissionisempoweredtoadoptdelegatedactsinaccordance
withArticle97toamendthelistinAnnexIIIbyremovinghigh-riskAI
systemswherebothofthefollowingconditionsarefulfilled:
(a)thehigh-riskAIsystemconcernednolongerposesanysignificantrisksto
fundamentalrights,healthorsafety,takingintoaccountthecriterialistedin
paragraph2;

--- Page 79 ---
(b)thedeletiondoesnotdecreasetheoveralllevelofprotectionofhealth,safetyand
fundamentalrightsunderUnionlaw.
SECTION2
Requirementsforhigh-riskAIsystems
Article8
Compliancewiththerequirements
1.High-riskAIsystemsshallcomplywiththerequirementslaiddownin
thisSection,takingintoaccounttheirintendedpurposeaswellasthe
generallyacknowledgedstateoftheartonAIandAI-relatedtechnologies.
TheriskmanagementsystemreferredtoinArticle9shallbetakeninto
accountwhenensuringcompliancewiththoserequirements.
2.WhereaproductcontainsanAIsystem,towhichtherequirementsof
thisRegulationaswellasrequirementsoftheUnionharmonisation
legislationlistedinSectionAofAnnexIapply,providersshallbe
responsibleforensuringthattheirproductisfullycompliantwithall
applicablerequirementsunderapplicableUnionharmonisationlegislation.
Inensuringthecomplianceofhigh-riskAIsystemsreferredtoin
paragraph1withtherequirementssetoutinthisSection,andinorderto
ensureconsistency,avoidduplicationandminimiseadditionalburdens,
providersshallhaveachoiceofintegrating,asappropriate,thenecessary
testingandreportingprocesses,informationanddocumentationtheyprovide
withregardtotheirproductintodocumentationandproceduresthatalready
existandarerequiredundertheUnionharmonisationlegislationlistedin
SectionAofAnnexI.
Article9
Riskmanagementsystem
1.Ariskmanagementsystemshallbeestablished,implemented,
documentedandmaintainedinrelationtohigh-riskAIsystems.
2.Theriskmanagementsystemshallbeunderstoodasacontinuous
iterativeprocessplannedandrunthroughouttheentirelifecycleofahigh-
riskAIsystem,requiringregularsystematicreviewandupdating.Itshall
comprisethefollowingsteps:
(a)theidentificationandanalysisoftheknownandthereasonablyforeseeablerisks
thatthehigh-riskAIsystemcanposetohealth,safetyorfundamentalrightswhen
thehigh-riskAIsystemisusedinaccordancewithitsintendedpurpose;

--- Page 80 ---
(b)theestimationandevaluationoftherisksthatmayemergewhenthehigh-riskAI
systemisusedinaccordancewithitsintendedpurpose,andunderconditionsof
reasonablyforeseeablemisuse;
(c)theevaluationofotherriskspossiblyarising,basedontheanalysisofdatagathered
fromthepost-marketmonitoringsystemreferredtoinArticle72;
(d)theadoptionofappropriateandtargetedriskmanagementmeasuresdesignedto
addresstherisksidentifiedpursuanttopoint(a).
3.TherisksreferredtointhisArticleshallconcernonlythosewhichmay
bereasonablymitigatedoreliminatedthroughthedevelopmentordesignof
thehigh-riskAIsystem,ortheprovisionofadequatetechnicalinformation.
4.Theriskmanagementmeasuresreferredtoinparagraph2,point(d),
shallgivedueconsiderationtotheeffectsandpossibleinteractionresulting
fromthecombinedapplicationoftherequirementssetoutinthisSection,
withaviewtominimisingrisksmoreeffectivelywhileachievingan
appropriatebalanceinimplementingthemeasurestofulfilthose
requirements.
5.Theriskmanagementmeasuresreferredtoinparagraph2,point(d),
shallbesuchthattherelevantresidualriskassociatedwitheachhazard,as
wellastheoverallresidualriskofthehigh-riskAIsystemsisjudgedtobe
acceptable.
Inidentifyingthemostappropriateriskmanagementmeasures,the
followingshallbeensured:
(a)eliminationorreductionofrisksidentifiedandevaluatedpursuanttoparagraph2in
asfarastechnicallyfeasiblethroughadequatedesignanddevelopmentofthehigh-
riskAIsystem;
(b)whereappropriate,implementationofadequatemitigationandcontrolmeasures
addressingrisksthatcannotbeeliminated;
(c)provisionofinformationrequiredpursuanttoArticle13and,whereappropriate,
trainingtodeployers.
Withaviewtoeliminatingorreducingrisksrelatedtotheuseofthehigh-
riskAIsystem,dueconsiderationshallbegiventothetechnicalknowledge,
experience,education,thetrainingtobeexpectedbythedeployer,andthe
presumablecontextinwhichthesystemisintendedtobeused.
6.High-riskAIsystemsshallbetestedforthepurposeofidentifyingthe
mostappropriateandtargetedriskmanagementmeasures.Testingshall
ensurethathigh-riskAIsystemsperformconsistentlyfortheirintended
purposeandthattheyareincompliancewiththerequirementssetoutinthis
Section.

--- Page 81 ---
7.Testingproceduresmayincludetestinginreal-worldconditionsin
accordancewithArticle60.
8.Thetestingofhigh-riskAIsystemsshallbeperformed,asappropriate,at
anytimethroughoutthedevelopmentprocess,and,inanyevent,priorto
theirbeingplacedonthemarketorputintoservice.Testingshallbecarried
outagainstpriordefinedmetricsandprobabilisticthresholdsthatare
appropriatetotheintendedpurposeofthehigh-riskAIsystem.
9.Whenimplementingtheriskmanagementsystemasprovidedforin
paragraphs1to7,providersshallgiveconsiderationtowhetherinviewof
itsintendedpurposethehigh-riskAIsystemislikelytohaveanadverse
impactonpersonsundertheageof18and,asappropriate,othervulnerable
groups.
10.Forprovidersofhigh-riskAIsystemsthataresubjecttorequirements
regardinginternalriskmanagementprocessesunderotherrelevant
provisionsofUnionlaw,theaspectsprovidedinparagraphs1to9maybe
partof,orcombinedwith,theriskmanagementproceduresestablished
pursuanttothatlaw.
Article10
Dataanddatagovernance
1.High-riskAIsystemswhichmakeuseoftechniquesinvolvingthe
trainingofAImodelswithdatashallbedevelopedonthebasisoftraining,
validationandtestingdatasetsthatmeetthequalitycriteriareferredtoin
paragraphs2to5wheneversuchdatasetsareused.
2.Training,validationandtestingdatasetsshallbesubjecttodata
governanceandmanagementpracticesappropriatefortheintendedpurpose
ofthehigh-riskAIsystem.Thosepracticesshallconcerninparticular:
(a)therelevantdesignchoices;
(b)datacollectionprocessesandtheoriginofdata,andinthecaseofpersonaldata,
theoriginalpurposeofthedatacollection;
(c)relevantdata-preparationprocessingoperations,suchasannotation,labelling,
cleaning,updating,enrichmentandaggregation;
(d)theformulationofassumptions,inparticularwithrespecttotheinformationthat
thedataaresupposedtomeasureandrepresent;
(e)anassessmentoftheavailability,quantityandsuitabilityofthedatasetsthatare
needed;
(f)examinationinviewofpossiblebiasesthatarelikelytoaffectthehealthandsafety
ofpersons,haveanegativeimpactonfundamentalrightsorleadtodiscrimination
prohibitedunderUnionlaw,especiallywheredataoutputsinfluenceinputsfor

--- Page 82 ---
futureoperations;
(g)appropriatemeasurestodetect,preventandmitigatepossiblebiasesidentified
accordingtopoint(f);
(h)theidentificationofrelevantdatagapsorshortcomingsthatpreventcompliance
withthisRegulation,andhowthosegapsandshortcomingscanbeaddressed.
3.Training,validationandtestingdatasetsshallberelevant,sufficiently
representative,andtothebestextentpossible,freeoferrorsandcompletein
viewoftheintendedpurpose.Theyshallhavetheappropriatestatistical
properties,including,whereapplicable,asregardsthepersonsorgroupsof
personsinrelationtowhomthehigh-riskAIsystemisintendedtobeused.
Thosecharacteristicsofthedatasetsmaybemetatthelevelofindividual
datasetsoratthelevelofacombinationthereof.
4.Datasetsshalltakeintoaccount,totheextentrequiredbytheintended
purpose,thecharacteristicsorelementsthatareparticulartothespecific
geographical,contextual,behaviouralorfunctionalsettingwithinwhichthe
high-riskAIsystemisintendedtobeused.
5.Totheextentthatitisstrictlynecessaryforthepurposeofensuringbias
detectionandcorrectioninrelationtothehigh-riskAIsystemsin
accordancewithparagraph(2),points(f)and(g)ofthisArticle,the
providersofsuchsystemsmayexceptionallyprocessspecialcategoriesof
personaldata,subjecttoappropriatesafeguardsforthefundamentalrights
andfreedomsofnaturalpersons.Inadditiontotheprovisionssetoutin
Regulations(EU)2016/679and(EU)2018/1725andDirective
(EU)2016/680,allthefollowingconditionsmustbemetinorderforsuch
processingtooccur:
(a)thebiasdetectionandcorrectioncannotbeeffectivelyfulfilledbyprocessingother
data,includingsyntheticoranonymiseddata;
(b)thespecialcategoriesofpersonaldataaresubjecttotechnicallimitationsonthere-
useofthepersonaldata,andstate-of-the-artsecurityandprivacy-preserving
measures,includingpseudonymisation;
(c)thespecialcategoriesofpersonaldataaresubjecttomeasurestoensurethatthe
personaldataprocessedaresecured,protected,subjecttosuitablesafeguards,
includingstrictcontrolsanddocumentationoftheaccess,toavoidmisuseand
ensurethatonlyauthorisedpersonshaveaccesstothosepersonaldatawith
appropriateconfidentialityobligations;
(d)thespecialcategoriesofpersonaldataarenottobetransmitted,transferredor
otherwiseaccessedbyotherparties;
(e)thespecialcategoriesofpersonaldataaredeletedoncethebiashasbeencorrected
orthepersonaldatahasreachedtheendofitsretentionperiod,whichevercomes
first;
(f)therecordsofprocessingactivitiespursuanttoRegulations(EU)2016/679and

--- Page 83 ---
(EU)2018/1725andDirective(EU)2016/680includethereasonswhythe
processingofspecialcategoriesofpersonaldatawasstrictlynecessarytodetect
andcorrectbiases,andwhythatobjectivecouldnotbeachievedbyprocessing
otherdata.
6.Forthedevelopmentofhigh-riskAIsystemsnotusingtechniques
involvingthetrainingofAImodels,paragraphs2to5applyonlytothe
testingdatasets.
Article11
Technicaldocumentation
1.Thetechnicaldocumentationofahigh-riskAIsystemshallbedrawnup
beforethatsystemisplacedonthemarketorputintoserviceandshallbe
keptup-todate.
Thetechnicaldocumentationshallbedrawnupinsuchawayasto
demonstratethatthehigh-riskAIsystemcomplieswiththerequirementsset
outinthisSectionandtoprovidenationalcompetentauthoritiesandnotified
bodieswiththenecessaryinformationinaclearandcomprehensiveformto
assessthecomplianceoftheAIsystemwiththoserequirements.Itshall
contain,ataminimum,theelementssetoutinAnnexIV.SMEs,including
start-ups,mayprovidetheelementsofthetechnicaldocumentationspecified
inAnnexIVinasimplifiedmanner.Tothatend,theCommissionshall
establishasimplifiedtechnicaldocumentationformtargetedattheneedsof
smallandmicroenterprises.WhereanSME,includingastart-up,optsto
providetheinformationrequiredinAnnexIVinasimplifiedmanner,it
shallusetheformreferredtointhisparagraph.Notifiedbodiesshallaccept
theformforthepurposesoftheconformityassessment.
2.Whereahigh-riskAIsystemrelatedtoaproductcoveredbytheUnion
harmonisationlegislationlistedinSectionAofAnnexIisplacedonthe
marketorputintoservice,asinglesetoftechnicaldocumentationshallbe
drawnupcontainingalltheinformationsetoutinparagraph1,aswellasthe
informationrequiredunderthoselegalacts.
3.TheCommissionisempoweredtoadoptdelegatedactsinaccordance
withArticle97inordertoamendAnnexIV,wherenecessary,toensurethat,
inlightoftechnicalprogress,thetechnicaldocumentationprovidesallthe
informationnecessarytoassessthecomplianceofthesystemwiththe
requirementssetoutinthisSection.
Article12
Record-keeping

--- Page 84 ---
1.High-riskAIsystemsshalltechnicallyallowfortheautomaticrecording
ofevents(logs)overthelifetimeofthesystem.
2.Inordertoensurealeveloftraceabilityofthefunctioningofahigh-risk
AIsystemthatisappropriatetotheintendedpurposeofthesystem,logging
capabilitiesshallenabletherecordingofeventsrelevantfor:
(a)identifyingsituationsthatmayresultinthehigh-riskAIsystempresentingarisk
withinthemeaningofArticle79(1)orinasubstantialmodification;
(b)facilitatingthepost-marketmonitoringreferredtoinArticle72;and
(c)monitoringtheoperationofhigh-riskAIsystemsreferredtoinArticle26(5).
3.Forhigh-riskAIsystemsreferredtoinpoint1(a),ofAnnexIII,the
loggingcapabilitiesshallprovide,ataminimum:
(a)recordingoftheperiodofeachuseofthesystem(startdateandtimeandenddate
andtimeofeachuse);
(b)thereferencedatabaseagainstwhichinputdatahasbeencheckedbythesystem;
(c)theinputdataforwhichthesearchhasledtoamatch;
(d)theidentificationofthenaturalpersonsinvolvedintheverificationoftheresults,
asreferredtoinArticle14(5).
Article13
Transparencyandprovisionofinformationtodeployers
1.High-riskAIsystemsshallbedesignedanddevelopedinsuchawayas
toensurethattheiroperationissufficientlytransparenttoenabledeployers
tointerpretasystem’soutputanduseitappropriately.Anappropriatetype
anddegreeoftransparencyshallbeensuredwithaviewtoachieving
compliancewiththerelevantobligationsoftheprovideranddeployerset
outinSection3.
2.High-riskAIsystemsshallbeaccompaniedbyinstructionsforuseinan
appropriatedigitalformatorotherwisethatincludeconcise,complete,
correctandclearinformationthatisrelevant,accessibleandcomprehensible
todeployers.
3.Theinstructionsforuseshallcontainatleastthefollowinginformation:
(a)theidentityandthecontactdetailsoftheproviderand,whereapplicable,ofits
authorisedrepresentative;
(b)thecharacteristics,capabilitiesandlimitationsofperformanceofthehigh-riskAI
system,including:
(i)itsintendedpurpose;
(ii)thelevelofaccuracy,includingitsmetrics,robustnessandcybersecurity

--- Page 85 ---
referredtoinArticle15againstwhichthehigh-riskAIsystemhasbeentested
andvalidatedandwhichcanbeexpected,andanyknownandforeseeable
circumstancesthatmayhaveanimpactonthatexpectedlevelofaccuracy,
robustnessandcybersecurity;
(iii)anyknownorforeseeablecircumstance,relatedtotheuseofthehigh-riskAI
systeminaccordancewithitsintendedpurposeorunderconditionsof
reasonablyforeseeablemisuse,whichmayleadtoriskstothehealthandsafety
orfundamentalrightsreferredtoinArticle9(2);
(iv)whereapplicable,thetechnicalcapabilitiesandcharacteristicsofthehigh-risk
AIsystemtoprovideinformationthatisrelevanttoexplainitsoutput;
(v)whenappropriate,itsperformanceregardingspecificpersonsorgroupsof
personsonwhichthesystemisintendedtobeused;
(vi)whenappropriate,specificationsfortheinputdata,oranyotherrelevant
informationintermsofthetraining,validationandtestingdatasetsused,taking
intoaccounttheintendedpurposeofthehigh-riskAIsystem;
(vii)whereapplicable,informationtoenabledeployerstointerprettheoutputofthe
high-riskAIsystemanduseitappropriately;
(c)thechangestothehigh-riskAIsystemanditsperformancewhichhavebeenpre-
determinedbytheprovideratthemomentoftheinitialconformityassessment,if
any;
(d)thehumanoversightmeasuresreferredtoinArticle14,includingthetechnical
measuresputinplacetofacilitatetheinterpretationoftheoutputsofthehigh-risk
AIsystemsbythedeployers;
(e)thecomputationalandhardwareresourcesneeded,theexpectedlifetimeofthe
high-riskAIsystemandanynecessarymaintenanceandcaremeasures,including
theirfrequency,toensuretheproperfunctioningofthatAIsystem,includingas
regardssoftwareupdates;
(f)whererelevant,adescriptionofthemechanismsincludedwithinthehigh-riskAI
systemthatallowsdeployerstoproperlycollect,storeandinterpretthelogsin
accordancewithArticle12.
Article14
Humanoversight
1.High-riskAIsystemsshallbedesignedanddevelopedinsuchaway,
includingwithappropriatehuman-machineinterfacetools,thattheycanbe
effectivelyoverseenbynaturalpersonsduringtheperiodinwhichtheyare
inuse.
2.Humanoversightshallaimtopreventorminimisetheriskstohealth,
safetyorfundamentalrightsthatmayemergewhenahigh-riskAIsystemis
usedinaccordancewithitsintendedpurposeorunderconditionsof

--- Page 86 ---
reasonablyforeseeablemisuse,inparticularwheresuchriskspersistdespite
theapplicationofotherrequirementssetoutinthisSection.
3.Theoversightmeasuresshallbecommensuratewiththerisks,levelof
autonomyandcontextofuseofthehigh-riskAIsystem,andshallbe
ensuredthrougheitheroneorbothofthefollowingtypesofmeasures:
(a)measuresidentifiedandbuilt,whentechnicallyfeasible,intothehigh-riskAI
systembytheproviderbeforeitisplacedonthemarketorputintoservice;
(b)measuresidentifiedbytheproviderbeforeplacingthehigh-riskAIsystemonthe
marketorputtingitintoserviceandthatareappropriatetobeimplementedbythe
deployer.
4.Forthepurposeofimplementingparagraphs1,2and3,thehigh-riskAI
systemshallbeprovidedtothedeployerinsuchawaythatnaturalpersons
towhomhumanoversightisassignedareenabled,asappropriateand
proportionate:
(a)toproperlyunderstandtherelevantcapacitiesandlimitationsofthehigh-riskAI
systemandbeabletodulymonitoritsoperation,includinginviewofdetectingand
addressinganomalies,dysfunctionsandunexpectedperformance;
(b)toremainawareofthepossibletendencyofautomaticallyrelyingorover-relying
ontheoutputproducedbyahigh-riskAIsystem(automationbias),inparticularfor
high-riskAIsystemsusedtoprovideinformationorrecommendationsfor
decisionstobetakenbynaturalpersons;
(c)tocorrectlyinterpretthehigh-riskAIsystem’soutput,takingintoaccount,for
example,theinterpretationtoolsandmethodsavailable;
(d)todecide,inanyparticularsituation,nottousethehigh-riskAIsystemorto
otherwisedisregard,overrideorreversetheoutputofthehigh-riskAIsystem;
(e)tointerveneintheoperationofthehigh-riskAIsystemorinterruptthesystem
througha‘stop’buttonorasimilarprocedurethatallowsthesystemtocometo
ahaltinasafestate.
5.Forhigh-riskAIsystemsreferredtoinpoint1(a)ofAnnexIII,the
measuresreferredtoinparagraph3ofthisArticleshallbesuchastoensure
that,inaddition,noactionordecisionistakenbythedeployeronthebasis
oftheidentificationresultingfromthesystemunlessthatidentificationhas
beenseparatelyverifiedandconfirmedbyatleasttwonaturalpersonswith
thenecessarycompetence,trainingandauthority.
Therequirementforaseparateverificationbyatleasttwonaturalpersons
shallnotapplytohigh-riskAIsystemsusedforthepurposesoflaw
enforcement,migration,bordercontrolorasylum,whereUnionornational
lawconsiderstheapplicationofthisrequirementtobedisproportionate.
Article15

--- Page 87 ---
Accuracy,robustnessandcybersecurity
1.High-riskAIsystemsshallbedesignedanddevelopedinsuchawaythat
theyachieveanappropriatelevelofaccuracy,robustness,andcybersecurity,
andthattheyperformconsistentlyinthoserespectsthroughouttheir
lifecycle.
2.Toaddressthetechnicalaspectsofhowtomeasuretheappropriate
levelsofaccuracyandrobustnesssetoutinparagraph1andanyother
relevantperformancemetrics,theCommissionshall,incooperationwith
relevantstakeholdersandorganisationssuchasmetrologyand
benchmarkingauthorities,encourage,asappropriate,thedevelopmentof
benchmarksandmeasurementmethodologies.
3.Thelevelsofaccuracyandtherelevantaccuracymetricsofhigh-riskAI
systemsshallbedeclaredintheaccompanyinginstructionsofuse.
4.High-riskAIsystemsshallbeasresilientaspossibleregardingerrors,
faultsorinconsistenciesthatmayoccurwithinthesystemorthe
environmentinwhichthesystemoperates,inparticularduetotheir
interactionwithnaturalpersonsorothersystems.Technicaland
organisationalmeasuresshallbetakeninthisregard.
Therobustnessofhigh-riskAIsystemsmaybeachievedthroughtechnical
redundancysolutions,whichmayincludebackuporfail-safeplans.
High-riskAIsystemsthatcontinuetolearnafterbeingplacedonthemarket
orputintoserviceshallbedevelopedinsuchawayastoeliminateorreduce
asfaraspossibletheriskofpossiblybiasedoutputsinfluencinginputfor
futureoperations(feedbackloops),andastoensurethatanysuchfeedback
loopsaredulyaddressedwithappropriatemitigationmeasures.
5.High-riskAIsystemsshallberesilientagainstattemptsbyunauthorised
thirdpartiestoaltertheiruse,outputsorperformancebyexploitingsystem
vulnerabilities.
Thetechnicalsolutionsaimingtoensurethecybersecurityofhigh-riskAI
systemsshallbeappropriatetotherelevantcircumstancesandtherisks.
ThetechnicalsolutionstoaddressAIspecificvulnerabilitiesshallinclude,
whereappropriate,measurestoprevent,detect,respondto,resolveand
controlforattackstryingtomanipulatethetrainingdataset(datapoisoning),
orpre-trainedcomponentsusedintraining(modelpoisoning),inputs
designedtocausetheAImodeltomakeamistake(adversarialexamplesor
modelevasion),confidentialityattacksormodelflaws.
SECTION3

--- Page 88 ---
Obligationsofprovidersanddeployersofhigh-riskAIsystemsandother
parties
Article16
Obligationsofprovidersofhigh-riskAIsystems
Providersofhigh-riskAIsystemsshall:
(a)ensurethattheirhigh-riskAIsystemsarecompliantwiththerequirementssetout
inSection2;
(b)indicateonthehigh-riskAIsystemor,wherethatisnotpossible,onitspackaging
oritsaccompanyingdocumentation,asapplicable,theirname,registeredtrade
nameorregisteredtrademark,theaddressatwhichtheycanbecontacted;
(c)haveaqualitymanagementsysteminplacewhichcomplieswithArticle17;
(d)keepthedocumentationreferredtoinArticle18;
(e)whenundertheircontrol,keepthelogsautomaticallygeneratedbytheirhigh-risk
AIsystemsasreferredtoinArticle19;
(f)ensurethatthehigh-riskAIsystemundergoestherelevantconformityassessment
procedureasreferredtoinArticle43,priortoitsbeingplacedonthemarketorput
intoservice;
(g)drawupanEUdeclarationofconformityinaccordancewithArticle47;
(h)affixtheCEmarkingtothehigh-riskAIsystemor,wherethatisnotpossible,on
itspackagingoritsaccompanyingdocumentation,toindicateconformitywiththis
Regulation,inaccordancewithArticle48;
(i)complywiththeregistrationobligationsreferredtoinArticle49(1);
(j)takethenecessarycorrectiveactionsandprovideinformationasrequiredin
Article20;
(k)uponareasonedrequestofanationalcompetentauthority,demonstratethe
conformityofthehigh-riskAIsystemwiththerequirementssetoutinSection2;
(l)ensurethatthehigh-riskAIsystemcomplieswithaccessibilityrequirementsin
accordancewithDirectives(EU)2016/2102and(EU)2019/882.
Article17
Qualitymanagementsystem
1.Providersofhigh-riskAIsystemsshallputaqualitymanagement
systeminplacethatensurescompliancewiththisRegulation.Thatsystem
shallbedocumentedinasystematicandorderlymannerintheformof
writtenpolicies,proceduresandinstructions,andshallincludeatleastthe
followingaspects:

--- Page 89 ---
(a)astrategyforregulatorycompliance,includingcompliancewithconformity
assessmentproceduresandproceduresforthemanagementofmodificationstothe
high-riskAIsystem;
(b)techniques,proceduresandsystematicactionstobeusedforthedesign,design
controlanddesignverificationofthehigh-riskAIsystem;
(c)techniques,proceduresandsystematicactionstobeusedforthedevelopment,
qualitycontrolandqualityassuranceofthehigh-riskAIsystem;
(d)examination,testandvalidationprocedurestobecarriedoutbefore,duringand
afterthedevelopmentofthehigh-riskAIsystem,andthefrequencywithwhich
theyhavetobecarriedout;
(e)technicalspecifications,includingstandards,tobeappliedand,wheretherelevant
harmonisedstandardsarenotappliedinfullordonotcoveralloftherelevant
requirementssetoutinSection2,themeanstobeusedtoensurethatthehigh-risk
AIsystemcomplieswiththoserequirements;
(f)systemsandproceduresfordatamanagement,includingdataacquisition,data
collection,dataanalysis,datalabelling,datastorage,datafiltration,datamining,
dataaggregation,dataretentionandanyotheroperationregardingthedatathatis
performedbeforeandforthepurposeoftheplacingonthemarketortheputting
intoserviceofhigh-riskAIsystems;
(g)theriskmanagementsystemreferredtoinArticle9;
(h)thesetting-up,implementationandmaintenanceofapost-marketmonitoring
system,inaccordancewithArticle72;
(i)proceduresrelatedtothereportingofaseriousincidentinaccordancewith
Article73;
(j)thehandlingofcommunicationwithnationalcompetentauthorities,otherrelevant
authorities,includingthoseprovidingorsupportingtheaccesstodata,notified
bodies,otheroperators,customersorotherinterestedparties;
(k)systemsandproceduresforrecord-keepingofallrelevantdocumentationand
information;
(l)resourcemanagement,includingsecurity-of-supplyrelatedmeasures;
(m)anaccountabilityframeworksettingouttheresponsibilitiesofthemanagement
andotherstaffwithregardtoalltheaspectslistedinthisparagraph.
2.Theimplementationoftheaspectsreferredtoinparagraph1shallbe
proportionatetothesizeoftheprovider’sorganisation.Providersshall,in
anyevent,respectthedegreeofrigourandthelevelofprotectionrequiredto
ensurethecomplianceoftheirhigh-riskAIsystemswiththisRegulation.
3.Providersofhigh-riskAIsystemsthataresubjecttoobligations
regardingqualitymanagementsystemsoranequivalentfunctionunder
relevantsectoralUnionlawmayincludetheaspectslistedinparagraph1as
partofthequalitymanagementsystemspursuanttothatlaw.

--- Page 90 ---
4.Forprovidersthatarefinancialinstitutionssubjecttorequirements
regardingtheirinternalgovernance,arrangementsorprocessesunderUnion
financialserviceslaw,theobligationtoputinplaceaqualitymanagement
system,withtheexceptionofparagraph1,points(g),(h)and(i)ofthis
Article,shallbedeemedtobefulfilledbycomplyingwiththeruleson
internalgovernancearrangementsorprocessespursuanttotherelevant
Unionfinancialserviceslaw.Tothatend,anyharmonisedstandards
referredtoinArticle40shallbetakenintoaccount.
Article18
Documentationkeeping
1.Theprovidershall,foraperiodending10yearsafterthehigh-riskAI
systemhasbeenplacedonthemarketorputintoservice,keepatthe
disposalofthenationalcompetentauthorities:
(a)thetechnicaldocumentationreferredtoinArticle11;
(b)thedocumentationconcerningthequalitymanagementsystemreferredto
inArticle17;
(c)thedocumentationconcerningthechangesapprovedbynotifiedbodies,where
applicable;
(d)thedecisionsandotherdocumentsissuedbythenotifiedbodies,whereapplicable;
(e)theEUdeclarationofconformityreferredtoinArticle47.
2.EachMemberStateshalldetermineconditionsunderwhichthe
documentationreferredtoinparagraph1remainsatthedisposalofthe
nationalcompetentauthoritiesfortheperiodindicatedinthatparagraphfor
thecaseswhenaprovideroritsauthorisedrepresentativeestablishedonits
territorygoesbankruptorceasesitsactivitypriortotheendofthatperiod.
3.Providersthatarefinancialinstitutionssubjecttorequirementsregarding
theirinternalgovernance,arrangementsorprocessesunderUnionfinancial
serviceslawshallmaintainthetechnicaldocumentationaspartofthe
documentationkeptundertherelevantUnionfinancialserviceslaw.
Article19
Automaticallygeneratedlogs
1.Providersofhigh-riskAIsystemsshallkeepthelogsreferredtoin
Article12(1),automaticallygeneratedbytheirhigh-riskAIsystems,tothe
extentsuchlogsareundertheircontrol.Withoutprejudicetoapplicable
Unionornationallaw,thelogsshallbekeptforaperiodappropriatetothe
intendedpurposeofthehigh-riskAIsystem,ofatleastsixmonths,unless

--- Page 91 ---
providedotherwiseintheapplicableUnionornationallaw,inparticularin
Unionlawontheprotectionofpersonaldata.
2.Providersthatarefinancialinstitutionssubjecttorequirementsregarding
theirinternalgovernance,arrangementsorprocessesunderUnionfinancial
serviceslawshallmaintainthelogsautomaticallygeneratedbytheirhigh-
riskAIsystemsaspartofthedocumentationkeptundertherelevant
financialserviceslaw.
Article20
Correctiveactionsanddutyofinformation
1.Providersofhigh-riskAIsystemswhichconsiderorhavereasonto
considerthatahigh-riskAIsystemthattheyhaveplacedonthemarketor
putintoserviceisnotinconformitywiththisRegulationshallimmediately
takethenecessarycorrectiveactionstobringthatsystemintoconformity,to
withdrawit,todisableit,ortorecallit,asappropriate.Theyshallinformthe
distributorsofthehigh-riskAIsystemconcernedand,whereapplicable,the
deployers,theauthorisedrepresentativeandimportersaccordingly.
2.Wherethehigh-riskAIsystempresentsariskwithinthemeaningof
Article79(1)andtheproviderbecomesawareofthatrisk,itshall
immediatelyinvestigatethecauses,incollaborationwiththereporting
deployer,whereapplicable,andinformthemarketsurveillanceauthorities
competentforthehigh-riskAIsystemconcernedand,whereapplicable,the
notifiedbodythatissuedacertificateforthathigh-riskAIsystemin
accordancewithArticle44,inparticular,ofthenatureofthenon-
complianceandofanyrelevantcorrectiveactiontaken.
Article21
Cooperationwithcompetentauthorities
1.Providersofhigh-riskAIsystemsshall,uponareasonedrequestby
acompetentauthority,providethatauthorityalltheinformationand
documentationnecessarytodemonstratetheconformityofthehigh-riskAI
systemwiththerequirementssetoutinSection2,inalanguagewhichcan
beeasilyunderstoodbytheauthorityinoneoftheofficiallanguagesofthe
institutionsoftheUnionasindicatedbytheMemberStateconcerned.
2.Uponareasonedrequestbyacompetentauthority,providersshallalso
givetherequestingcompetentauthority,asapplicable,accesstothe
automaticallygeneratedlogsofthehigh-riskAIsystemreferredtoin
Article12(1),totheextentsuchlogsareundertheircontrol.

--- Page 92 ---
3.Anyinformationobtainedbyacompetentauthoritypursuanttothis
Articleshallbetreatedinaccordancewiththeconfidentialityobligationsset
outinArticle78.
Article22
Authorisedrepresentativesofprovidersofhigh-riskAIsystems
1.Priortomakingtheirhigh-riskAIsystemsavailableontheUnion
market,providersestablishedinthirdcountriesshall,bywrittenmandate,
appointanauthorisedrepresentativewhichisestablishedintheUnion.
2.Theprovidershallenableitsauthorisedrepresentativetoperformthe
tasksspecifiedinthemandatereceivedfromtheprovider.
3.Theauthorisedrepresentativeshallperformthetasksspecifiedinthe
mandatereceivedfromtheprovider.Itshallprovideacopyofthemandate
tothemarketsurveillanceauthoritiesuponrequest,inoneoftheofficial
languagesoftheinstitutionsoftheUnion,asindicatedbythecompetent
authority.ForthepurposesofthisRegulation,themandateshallempower
theauthorisedrepresentativetocarryoutthefollowingtasks:
(a)verifythattheEUdeclarationofconformityreferredtoinArticle47andthe
technicaldocumentationreferredtoinArticle11havebeendrawnupandthatan
appropriateconformityassessmentprocedurehasbeencarriedoutbytheprovider;
(b)keepatthedisposalofthecompetentauthoritiesandnationalauthoritiesorbodies
referredtoinArticle74(10),foraperiodof10yearsafterthehigh-riskAIsystem
hasbeenplacedonthemarketorputintoservice,thecontactdetailsofthe
providerthatappointedtheauthorisedrepresentative,acopyoftheEUdeclaration
ofconformityreferredtoinArticle47,thetechnicaldocumentationand,if
applicable,thecertificateissuedbythenotifiedbody;
(c)provideacompetentauthority,uponareasonedrequest,withalltheinformation
anddocumentation,includingthatreferredtoinpoint(b)ofthissubparagraph,
necessarytodemonstratetheconformityofahigh-riskAIsystemwiththe
requirementssetoutinSection2,includingaccesstothelogs,asreferredtoin
Article12(1),automaticallygeneratedbythehigh-riskAIsystem,totheextent
suchlogsareunderthecontroloftheprovider;
(d)cooperatewithcompetentauthorities,uponareasonedrequest,inanyactionthe
lattertakeinrelationtothehigh-riskAIsystem,inparticulartoreduceand
mitigatetherisksposedbythehigh-riskAIsystem;
(e)whereapplicable,complywiththeregistrationobligationsreferredtoin
Article49(1),or,iftheregistrationiscarriedoutbytheprovideritself,ensurethat
theinformationreferredtoinpoint3ofSectionAofAnnexVIIIiscorrect.
Themandateshallempowertheauthorisedrepresentativetobeaddressed,in
additiontoorinsteadoftheprovider,bythecompetentauthorities,onall
issuesrelatedtoensuringcompliancewiththisRegulation.

--- Page 93 ---
4.Theauthorisedrepresentativeshallterminatethemandateifitconsiders
orhasreasontoconsidertheprovidertobeactingcontrarytoitsobligations
pursuanttothisRegulation.Insuchacase,itshallimmediatelyinformthe
relevantmarketsurveillanceauthority,aswellas,whereapplicable,the
relevantnotifiedbody,abouttheterminationofthemandateandthereasons
therefor.
Article23
Obligationsofimporters
1.Beforeplacingahigh-riskAIsystemonthemarket,importersshall
ensurethatthesystemisinconformitywiththisRegulationbyverifying
that:
(a)therelevantconformityassessmentprocedurereferredtoinArticle43hasbeen
carriedoutbytheproviderofthehigh-riskAIsystem;
(b)theproviderhasdrawnupthetechnicaldocumentationinaccordancewith
Article11andAnnexIV;
(c)thesystembearstherequiredCEmarkingandisaccompaniedbytheEU
declarationofconformityreferredtoinArticle47andinstructionsforuse;
(d)theproviderhasappointedanauthorisedrepresentativeinaccordancewith
Article22(1).
2.Whereanimporterhassufficientreasontoconsiderthatahigh-riskAI
systemisnotinconformitywiththisRegulation,orisfalsified,or
accompaniedbyfalsifieddocumentation,itshallnotplacethesystemonthe
marketuntilithasbeenbroughtintoconformity.Wherethehigh-riskAI
systempresentsariskwithinthemeaningofArticle79(1),theimporter
shallinformtheproviderofthesystem,theauthorisedrepresentativeandthe
marketsurveillanceauthoritiestothateffect.
3.Importersshallindicatetheirname,registeredtradenameorregistered
trademark,andtheaddressatwhichtheycanbecontactedonthehigh-risk
AIsystemandonitspackagingoritsaccompanyingdocumentation,where
applicable.
4.Importersshallensurethat,whileahigh-riskAIsystemisundertheir
responsibility,storageortransportconditions,whereapplicable,donot
jeopardiseitscompliancewiththerequirementssetoutinSection2.
5.Importersshallkeep,foraperiodof10yearsafterthehigh-riskAI
systemhasbeenplacedonthemarketorputintoservice,acopyofthe
certificateissuedbythenotifiedbody,whereapplicable,oftheinstructions
foruse,andoftheEUdeclarationofconformityreferredtoinArticle47.

--- Page 94 ---
6.Importersshallprovidetherelevantcompetentauthorities,upon
areasonedrequest,withallthenecessaryinformationanddocumentation,
includingthatreferredtoinparagraph5,todemonstratetheconformityof
ahigh-riskAIsystemwiththerequirementssetoutinSection2in
alanguagewhichcanbeeasilyunderstoodbythem.Forthispurpose,they
shallalsoensurethatthetechnicaldocumentationcanbemadeavailableto
thoseauthorities.
7.Importersshallcooperatewiththerelevantcompetentauthoritiesinany
actionthoseauthoritiestakeinrelationtoahigh-riskAIsystemplacedon
themarketbytheimporters,inparticulartoreduceandmitigatetherisks
posedbyit.
Article24
Obligationsofdistributors
1.Beforemakingahigh-riskAIsystemavailableonthemarket,
distributorsshallverifythatitbearstherequiredCEmarking,thatitis
accompaniedbyacopyoftheEUdeclarationofconformityreferredtoin
Article47andinstructionsforuse,andthattheproviderandtheimporterof
thatsystem,asapplicable,havecompliedwiththeirrespectiveobligations
aslaiddowninArticle16,points(b)and(c)andArticle23(3).
2.Whereadistributorconsidersorhasreasontoconsider,onthebasisof
theinformationinitspossession,thatahigh-riskAIsystemisnotin
conformitywiththerequirementssetoutinSection2,itshallnotmakethe
high-riskAIsystemavailableonthemarketuntilthesystemhasbeen
broughtintoconformitywiththoserequirements.Furthermore,wherethe
high-riskAIsystempresentsariskwithinthemeaningofArticle79(1),the
distributorshallinformtheproviderortheimporterofthesystem,as
applicable,tothateffect.
3.Distributorsshallensurethat,whileahigh-riskAIsystemisundertheir
responsibility,storageortransportconditions,whereapplicable,donot
jeopardisethecomplianceofthesystemwiththerequirementssetoutin
Section2.
4.Adistributorthatconsidersorhasreasontoconsider,onthebasisofthe
informationinitspossession,ahigh-riskAIsystemwhichithasmade
availableonthemarketnottobeinconformitywiththerequirementssetout
inSection2,shalltakethecorrectiveactionsnecessarytobringthatsystem
intoconformitywiththoserequirements,towithdrawitorrecallit,orshall
ensurethattheprovider,theimporteroranyrelevantoperator,as
appropriate,takesthosecorrectiveactions.Wherethehigh-riskAIsystem
presentsariskwithinthemeaningofArticle79(1),thedistributorshall
immediatelyinformtheproviderorimporterofthesystemandthe

--- Page 95 ---
authoritiescompetentforthehigh-riskAIsystemconcerned,givingdetails,
inparticular,ofthenon-complianceandofanycorrectiveactionstaken.
5.Uponareasonedrequestfromarelevantcompetentauthority,
distributorsofahigh-riskAIsystemshallprovidethatauthoritywithallthe
informationanddocumentationregardingtheiractionspursuantto
paragraphs1to4necessarytodemonstratetheconformityofthatsystem
withtherequirementssetoutinSection2.
6.Distributorsshallcooperatewiththerelevantcompetentauthoritiesin
anyactionthoseauthoritiestakeinrelationtoahigh-riskAIsystemmade
availableonthemarketbythedistributors,inparticulartoreduceor
mitigatetheriskposedbyit.
Article25
ResponsibilitiesalongtheAIvaluechain
1.Anydistributor,importer,deployerorotherthird-partyshallbe
consideredtobeaproviderofahigh-riskAIsystemforthepurposesofthis
Regulationandshallbesubjecttotheobligationsoftheproviderunder
Article16,inanyofthefollowingcircumstances:
(a)theyputtheirnameortrademarkonahigh-riskAIsystemalreadyplacedonthe
marketorputintoservice,withoutprejudicetocontractualarrangements
stipulatingthattheobligationsareotherwiseallocated;
(b)theymakeasubstantialmodificationtoahigh-riskAIsystemthathasalreadybeen
placedonthemarketorhasalreadybeenputintoserviceinsuchawaythatit
remainsahigh-riskAIsystempursuanttoArticle6;
(c)theymodifytheintendedpurposeofanAIsystem,includingageneral-purposeAI
system,whichhasnotbeenclassifiedashigh-riskandhasalreadybeenplacedon
themarketorputintoserviceinsuchawaythattheAIsystemconcernedbecomes
ahigh-riskAIsysteminaccordancewithArticle6.
2.Wherethecircumstancesreferredtoinparagraph1occur,theprovider
thatinitiallyplacedtheAIsystemonthemarketorputitintoserviceshall
nolongerbeconsideredtobeaproviderofthatspecificAIsystemforthe
purposesofthisRegulation.Thatinitialprovidershallcloselycooperate
withnewprovidersandshallmakeavailablethenecessaryinformationand
providethereasonablyexpectedtechnicalaccessandotherassistancethat
arerequiredforthefulfilmentoftheobligationssetoutinthisRegulation,in
particularregardingthecompliancewiththeconformityassessmentofhigh-
riskAIsystems.Thisparagraphshallnotapplyincaseswheretheinitial
providerhasclearlyspecifiedthatitsAIsystemisnottobechangedinto
ahigh-riskAIsystemandthereforedoesnotfallundertheobligationto
handoverthedocumentation.

--- Page 96 ---
3.Inthecaseofhigh-riskAIsystemsthataresafetycomponentsof
productscoveredbytheUnionharmonisationlegislationlistedinSection
AofAnnexI,theproductmanufacturershallbeconsideredtobethe
providerofthehigh-riskAIsystem,andshallbesubjecttotheobligations
underArticle16undereitherofthefollowingcircumstances:
(a)thehigh-riskAIsystemisplacedonthemarkettogetherwiththeproductunderthe
nameortrademarkoftheproductmanufacturer;
(b)thehigh-riskAIsystemisputintoserviceunderthenameortrademarkofthe
productmanufactureraftertheproducthasbeenplacedonthemarket.
4.Theproviderofahigh-riskAIsystemandthethirdpartythatsuppliesan
AIsystem,tools,services,components,orprocessesthatareusedor
integratedinahigh-riskAIsystemshall,bywrittenagreement,specifythe
necessaryinformation,capabilities,technicalaccessandotherassistance
basedonthegenerallyacknowledgedstateoftheart,inordertoenablethe
providerofthehigh-riskAIsystemtofullycomplywiththeobligationsset
outinthisRegulation.Thisparagraphshallnotapplytothirdpartiesmaking
accessibletothepublictools,services,processes,orcomponents,otherthan
general-purposeAImodels,underafreeandopen-sourcelicence.
TheAIOfficemaydevelopandrecommendvoluntarymodeltermsfor
contractsbetweenprovidersofhigh-riskAIsystemsandthirdpartiesthat
supplytools,services,componentsorprocessesthatareusedforor
integratedintohigh-riskAIsystems.Whendevelopingthosevoluntary
modelterms,theAIOfficeshalltakeintoaccountpossiblecontractual
requirementsapplicableinspecificsectorsorbusinesscases.Thevoluntary
modeltermsshallbepublishedandbeavailablefreeofchargeinaneasily
usableelectronicformat.
5.Paragraphs2and3arewithoutprejudicetotheneedtoobserveand
protectintellectualpropertyrights,confidentialbusinessinformationand
tradesecretsinaccordancewithUnionandnationallaw.
Article26
Obligationsofdeployersofhigh-riskAIsystems
1.Deployersofhigh-riskAIsystemsshalltakeappropriatetechnicaland
organisationalmeasurestoensuretheyusesuchsystemsinaccordancewith
theinstructionsforuseaccompanyingthesystems,pursuanttoparagraphs3
and6.
2.Deployersshallassignhumanoversighttonaturalpersonswhohavethe
necessarycompetence,trainingandauthority,aswellasthenecessary
support.

--- Page 97 ---
3.Theobligationssetoutinparagraphs1and2,arewithoutprejudiceto
otherdeployerobligationsunderUnionornationallawandtothedeployer’s
freedomtoorganiseitsownresourcesandactivitiesforthepurposeof
implementingthehumanoversightmeasuresindicatedbytheprovider.
4.Withoutprejudicetoparagraphs1and2,totheextentthedeployer
exercisescontrolovertheinputdata,thatdeployershallensurethatinput
dataisrelevantandsufficientlyrepresentativeinviewoftheintended
purposeofthehigh-riskAIsystem.
5.Deployersshallmonitortheoperationofthehigh-riskAIsystemonthe
basisoftheinstructionsforuseand,whererelevant,informprovidersin
accordancewithArticle72.Wheredeployershavereasontoconsiderthat
theuseofthehigh-riskAIsysteminaccordancewiththeinstructionsmay
resultinthatAIsystempresentingariskwithinthemeaningofArticle79(1),
theyshall,withoutunduedelay,informtheproviderordistributorandthe
relevantmarketsurveillanceauthority,andshallsuspendtheuseofthat
system.Wheredeployershaveidentifiedaseriousincident,theyshallalso
immediatelyinformfirsttheprovider,andthentheimporterordistributor
andtherelevantmarketsurveillanceauthoritiesofthatincident.Ifthe
deployerisnotabletoreachtheprovider,Article73shallapplymutatis
mutandis.Thisobligationshallnotcoversensitiveoperationaldataof
deployersofAIsystemswhicharelawenforcementauthorities.
Fordeployersthatarefinancialinstitutionssubjecttorequirements
regardingtheirinternalgovernance,arrangementsorprocessesunderUnion
financialserviceslaw,themonitoringobligationsetoutinthefirst
subparagraphshallbedeemedtobefulfilledbycomplyingwiththeruleson
internalgovernancearrangements,processesandmechanismspursuantto
therelevantfinancialservicelaw.
6.Deployersofhigh-riskAIsystemsshallkeepthelogsautomatically
generatedbythathigh-riskAIsystemtotheextentsuchlogsareundertheir
control,foraperiodappropriatetotheintendedpurposeofthehigh-riskAI
system,ofatleastsixmonths,unlessprovidedotherwiseinapplicable
Unionornationallaw,inparticularinUnionlawontheprotectionof
personaldata.
Deployersthatarefinancialinstitutionssubjecttorequirementsregarding
theirinternalgovernance,arrangementsorprocessesunderUnionfinancial
serviceslawshallmaintainthelogsaspartofthedocumentationkept
pursuanttotherelevantUnionfinancialservicelaw.
7.Beforeputtingintoserviceorusingahigh-riskAIsystematthe
workplace,deployerswhoareemployersshallinformworkers’
representativesandtheaffectedworkersthattheywillbesubjecttotheuse
ofthehigh-riskAIsystem.Thisinformationshallbeprovided,where

--- Page 98 ---
applicable,inaccordancewiththerulesandprocedureslaiddowninUnion
andnationallawandpracticeoninformationofworkersandtheir
representatives.
8.Deployersofhigh-riskAIsystemsthatarepublicauthorities,orUnion
institutions,bodies,officesoragenciesshallcomplywiththeregistration
obligationsreferredtoinArticle49.Whensuchdeployersfindthatthehigh-
riskAIsystemthattheyenvisageusinghasnotbeenregisteredintheEU
databasereferredtoinArticle71,theyshallnotusethatsystemandshall
informtheproviderorthedistributor.
9.Whereapplicable,deployersofhigh-riskAIsystemsshallusethe
informationprovidedunderArticle13ofthisRegulationtocomplywith
theirobligationtocarryoutadataprotectionimpactassessmentunder
Article35ofRegulation(EU)2016/679orArticle27ofDirective(EU)
2016/680.
10.WithoutprejudicetoDirective(EU)2016/680,intheframeworkofan
investigationforthetargetedsearchofapersonsuspectedorconvictedof
havingcommittedacriminaloffence,thedeployerofahigh-riskAIsystem
forpost-remotebiometricidentificationshallrequestanauthorisation,ex
ante,orwithoutunduedelayandnolaterthan48hours,byajudicial
authorityoranadministrativeauthoritywhosedecisionisbindingand
subjecttojudicialreview,fortheuseofthatsystem,exceptwhenitisused
fortheinitialidentificationofapotentialsuspectbasedonobjectiveand
verifiablefactsdirectlylinkedtotheoffence.Eachuseshallbelimitedto
whatisstrictlynecessaryfortheinvestigationofaspecificcriminaloffence.
Iftheauthorisationrequestedpursuanttothefirstsubparagraphisrejected,
theuseofthepost-remotebiometricidentificationsystemlinkedtothat
requestedauthorisationshallbestoppedwithimmediateeffectandthe
personaldatalinkedtotheuseofthehigh-riskAIsystemforwhichthe
authorisationwasrequestedshallbedeleted.
Innocaseshallsuchhigh-riskAIsystemforpost-remotebiometric
identificationbeusedforlawenforcementpurposesinanuntargetedway,
withoutanylinktoacriminaloffence,acriminalproceeding,agenuineand
presentorgenuineandforeseeablethreatofacriminaloffence,orthesearch
foraspecificmissingperson.Itshallbeensuredthatnodecisionthat
producesanadverselegaleffectonapersonmaybetakenbythelaw
enforcementauthoritiesbasedsolelyontheoutputofsuchpost-remote
biometricidentificationsystems.
ThisparagraphiswithoutprejudicetoArticle9ofRegulation(EU)
2016/679andArticle10ofDirective(EU)2016/680fortheprocessingof
biometricdata.

--- Page 99 ---
Regardlessofthepurposeordeployer,eachuseofsuchhigh-riskAI
systemsshallbedocumentedintherelevantpolicefileandshallbemade
availabletotherelevantmarketsurveillanceauthorityandthenationaldata
protectionauthorityuponrequest,excludingthedisclosureofsensitive
operationaldatarelatedtolawenforcement.Thissubparagraphshallbe
withoutprejudicetothepowersconferredbyDirective(EU)2016/680on
supervisoryauthorities.
Deployersshallsubmitannualreportstotherelevantmarketsurveillance
andnationaldataprotectionauthoritiesontheiruseofpost-remotebiometric
identificationsystems,excludingthedisclosureofsensitiveoperationaldata
relatedtolawenforcement.Thereportsmaybeaggregatedtocovermore
thanonedeployment.
MemberStatesmayintroduce,inaccordancewithUnionlaw,more
restrictivelawsontheuseofpost-remotebiometricidentificationsystems.
11.WithoutprejudicetoArticle50ofthisRegulation,deployersofhigh-
riskAIsystemsreferredtoinAnnexIIIthatmakedecisionsorassistin
makingdecisionsrelatedtonaturalpersonsshallinformthenaturalpersons
thattheyaresubjecttotheuseofthehigh-riskAIsystem.Forhigh-riskAI
systemsusedforlawenforcementpurposesArticle13ofDirective(EU)
2016/680shallapply.
12.Deployersshallcooperatewiththerelevantcompetentauthoritiesin
anyactionthoseauthoritiestakeinrelationtothehigh-riskAIsystemin
ordertoimplementthisRegulation.
Article27
Fundamentalrightsimpactassessmentforhigh-riskAIsystems
1.Priortodeployingahigh-riskAIsystemreferredtoinArticle6(2),with
theexceptionofhigh-riskAIsystemsintendedtobeusedinthearealisted
inpoint2ofAnnexIII,deployersthatarebodiesgovernedbypubliclaw,or
areprivateentitiesprovidingpublicservices,anddeployersofhigh-riskAI
systemsreferredtoinpoints5(b)and(c)ofAnnexIII,shallperforman
assessmentoftheimpactonfundamentalrightsthattheuseofsuchsystem
mayproduce.Forthatpurpose,deployersshallperformanassessment
consistingof:
(a)adescriptionofthedeployer’sprocessesinwhichthehigh-riskAIsystemwillbe
usedinlinewithitsintendedpurpose;
(b)adescriptionoftheperiodoftimewithinwhich,andthefrequencywithwhich,
eachhigh-riskAIsystemisintendedtobeused;
(c)thecategoriesofnaturalpersonsandgroupslikelytobeaffectedbyitsuseinthe
specificcontext;

--- Page 100 ---
(d)thespecificrisksofharmlikelytohaveanimpactonthecategoriesofnatural
personsorgroupsofpersonsidentifiedpursuanttopoint(c)ofthisparagraph,
takingintoaccounttheinformationgivenbytheproviderpursuanttoArticle13;
(e)adescriptionoftheimplementationofhumanoversightmeasures,accordingtothe
instructionsforuse;
(f)themeasurestobetakeninthecaseofthematerialisationofthoserisks,including
thearrangementsforinternalgovernanceandcomplaintmechanisms.
2.Theobligationlaiddowninparagraph1appliestothefirstuseofthe
high-riskAIsystem.Thedeployermay,insimilarcases,relyonpreviously
conductedfundamentalrightsimpactassessmentsorexistingimpact
assessmentscarriedoutbyprovider.If,duringtheuseofthehigh-riskAI
system,thedeployerconsidersthatanyoftheelementslistedinparagraph1
haschangedorisnolongeruptodate,thedeployershalltakethenecessary
stepstoupdatetheinformation.
3.Oncetheassessmentreferredtoinparagraph1ofthisArticlehasbeen
performed,thedeployershallnotifythemarketsurveillanceauthorityofits
results,submittingthefilled-outtemplatereferredtoinparagraph5ofthis
Articleaspartofthenotification.InthecasereferredtoinArticle46(1),
deployersmaybeexemptfromthatobligationtonotify.
4.IfanyoftheobligationslaiddowninthisArticleisalreadymetthrough
thedataprotectionimpactassessmentconductedpursuanttoArticle35of
Regulation(EU)2016/679orArticle27ofDirective(EU)2016/680,the
fundamentalrightsimpactassessmentreferredtoinparagraph1ofthis
Articleshallcomplementthatdataprotectionimpactassessment.
5.TheAIOfficeshalldevelopatemplateforaquestionnaire,including
throughanautomatedtool,tofacilitatedeployersincomplyingwiththeir
obligationsunderthisArticleinasimplifiedmanner.
SECTION4
Notifyingauthoritiesandnotifiedbodies
Article28
Notifyingauthorities
1.EachMemberStateshalldesignateorestablishatleastonenotifying
authorityresponsibleforsettingupandcarryingoutthenecessary
proceduresfortheassessment,designationandnotificationofconformity
assessmentbodiesandfortheirmonitoring.Thoseproceduresshallbe
developedincooperationbetweenthenotifyingauthoritiesofallMember
States.

--- Page 101 ---
2.MemberStatesmaydecidethattheassessmentandmonitoringreferred
toinparagraph1istobecarriedoutbyanationalaccreditationbodywithin
themeaningof,andinaccordancewith,Regulation(EC)No765/2008.
3.Notifyingauthoritiesshallbeestablished,organisedandoperatedin
suchawaythatnoconflictofinterestariseswithconformityassessment
bodies,andthattheobjectivityandimpartialityoftheiractivitiesare
safeguarded.
4.Notifyingauthoritiesshallbeorganisedinsuchawaythatdecisions
relatingtothenotificationofconformityassessmentbodiesaretakenby
competentpersonsdifferentfromthosewhocarriedouttheassessmentof
thosebodies.
5.Notifyingauthoritiesshallofferorprovideneitheranyactivitiesthat
conformityassessmentbodiesperform,noranyconsultancyserviceson
acommercialorcompetitivebasis.
6.Notifyingauthoritiesshallsafeguardtheconfidentialityofthe
informationthattheyobtain,inaccordancewithArticle78.
7.Notifyingauthoritiesshallhaveanadequatenumberofcompetent
personnelattheirdisposalfortheproperperformanceoftheirtasks.
Competentpersonnelshallhavethenecessaryexpertise,whereapplicable,
fortheirfunction,infieldssuchasinformationtechnologies,AIandlaw,
includingthesupervisionoffundamentalrights.
Article29
Applicationofaconformityassessmentbodyfornotification
1.Conformityassessmentbodiesshallsubmitanapplicationfor
notificationtothenotifyingauthorityoftheMemberStateinwhichtheyare
established.
2.Theapplicationfornotificationshallbeaccompaniedbyadescriptionof
theconformityassessmentactivities,theconformityassessmentmoduleor
modulesandthetypesofAIsystemsforwhichtheconformityassessment
bodyclaimstobecompetent,aswellasbyanaccreditationcertificate,
whereoneexists,issuedbyanationalaccreditationbodyattestingthatthe
conformityassessmentbodyfulfilstherequirementslaiddowninArticle31.
Anyvaliddocumentrelatedtoexistingdesignationsoftheapplicantnotified
bodyunderanyotherUnionharmonisationlegislationshallbeadded.
3.Wheretheconformityassessmentbodyconcernedcannotprovidean
accreditationcertificate,itshallprovidethenotifyingauthoritywithallthe
documentaryevidencenecessaryfortheverification,recognitionandregular
monitoringofitscompliancewiththerequirementslaiddowninArticle31.

--- Page 102 ---
4.FornotifiedbodieswhicharedesignatedunderanyotherUnion
harmonisationlegislation,alldocumentsandcertificateslinkedtothose
designationsmaybeusedtosupporttheirdesignationprocedureunderthis
Regulation,asappropriate.Thenotifiedbodyshallupdatethe
documentationreferredtoinparagraphs2and3ofthisArticlewhenever
relevantchangesoccur,inordertoenabletheauthorityresponsiblefor
notifiedbodiestomonitorandverifycontinuouscompliancewithallthe
requirementslaiddowninArticle31.
Article30
Notificationprocedure
1.Notifyingauthoritiesmaynotifyonlyconformityassessmentbodies
whichhavesatisfiedtherequirementslaiddowninArticle31.
2.NotifyingauthoritiesshallnotifytheCommissionandtheotherMember
States,usingtheelectronicnotificationtooldevelopedandmanagedbythe
Commission,ofeachconformityassessmentbodyreferredtoinparagraph1.
3.Thenotificationreferredtoinparagraph2ofthisArticleshallinclude
fulldetailsoftheconformityassessmentactivities,theconformity
assessmentmoduleormodules,thetypesofAIsystemsconcerned,andthe
relevantattestationofcompetence.Whereanotificationisnotbasedonan
accreditationcertificateasreferredtoinArticle29(2),thenotifying
authorityshallprovidetheCommissionandtheotherMemberStateswith
documentaryevidencewhichatteststothecompetenceoftheconformity
assessmentbodyandtothearrangementsinplacetoensurethatthatbody
willbemonitoredregularlyandwillcontinuetosatisfytherequirementslaid
downinArticle31.
4.Theconformityassessmentbodyconcernedmayperformtheactivities
ofanotifiedbodyonlywherenoobjectionsareraisedbytheCommissionor
theotherMemberStateswithintwoweeksofanotificationbyanotifying
authoritywhereitincludesanaccreditationcertificatereferredtoin
Article29(2),orwithintwomonthsofanotificationbythenotifying
authoritywhereitincludesdocumentaryevidencereferredtoin
Article29(3).
5.Whereobjectionsareraised,theCommissionshall,withoutdelay,enter
intoconsultationswiththerelevantMemberStatesandtheconformity
assessmentbody.Inviewthereof,theCommissionshalldecidewhetherthe
authorisationisjustified.TheCommissionshalladdressitsdecisiontothe
MemberStateconcernedandtotherelevantconformityassessmentbody.
Article31

--- Page 103 ---
Requirementsrelatingtonotifiedbodies
1.AnotifiedbodyshallbeestablishedunderthenationallawofaMember
Stateandshallhavelegalpersonality.
2.Notifiedbodiesshallsatisfytheorganisational,qualitymanagement,
resourcesandprocessrequirementsthatarenecessarytofulfiltheirtasks,as
wellassuitablecybersecurityrequirements.
3.Theorganisationalstructure,allocationofresponsibilities,reporting
linesandoperationofnotifiedbodiesshallensureconfidenceintheir
performance,andintheresultsoftheconformityassessmentactivitiesthat
thenotifiedbodiesconduct.
4.Notifiedbodiesshallbeindependentoftheproviderofahigh-riskAI
systeminrelationtowhichtheyperformconformityassessmentactivities.
Notifiedbodiesshallalsobeindependentofanyotheroperatorhavingan
economicinterestinhigh-riskAIsystemsassessed,aswellasofany
competitorsoftheprovider.Thisshallnotprecludetheuseofassessedhigh-
riskAIsystemsthatarenecessaryfortheoperationsoftheconformity
assessmentbody,ortheuseofsuchhigh-riskAIsystemsforpersonal
purposes.
5.Neitheraconformityassessmentbody,itstop-levelmanagementnorthe
personnelresponsibleforcarryingoutitsconformityassessmenttasksshall
bedirectlyinvolvedinthedesign,development,marketingoruseofhigh-
riskAIsystems,norshalltheyrepresentthepartiesengagedinthose
activities.Theyshallnotengageinanyactivitythatmightconflictwiththeir
independenceofjudgementorintegrityinrelationtoconformityassessment
activitiesforwhichtheyarenotified.Thisshall,inparticular,applyto
consultancyservices.
6.Notifiedbodiesshallbeorganisedandoperatedsoastosafeguardthe
independence,objectivityandimpartialityoftheiractivities.Notifiedbodies
shalldocumentandimplementastructureandprocedurestosafeguard
impartialityandtopromoteandapplytheprinciplesofimpartiality
throughouttheirorganisation,personnelandassessmentactivities.
7.Notifiedbodiesshallhavedocumentedproceduresinplaceensuringthat
theirpersonnel,committees,subsidiaries,subcontractorsandanyassociated
bodyorpersonnelofexternalbodiesmaintain,inaccordancewithArticle78,
theconfidentialityoftheinformationwhichcomesintotheirpossession
duringtheperformanceofconformityassessmentactivities,exceptwhenits
disclosureisrequiredbylaw.Thestaffofnotifiedbodiesshallbeboundto
observeprofessionalsecrecywithregardtoallinformationobtainedin
carryingouttheirtasksunderthisRegulation,exceptinrelationtothe
notifyingauthoritiesoftheMemberStateinwhichtheiractivitiesarecarried
out.

--- Page 104 ---
8.Notifiedbodiesshallhaveproceduresfortheperformanceofactivities
whichtakedueaccountofthesizeofaprovider,thesectorinwhichit
operates,itsstructure,andthedegreeofcomplexityoftheAIsystem
concerned.
9.Notifiedbodiesshalltakeoutappropriateliabilityinsurancefortheir
conformityassessmentactivities,unlessliabilityisassumedbytheMember
Stateinwhichtheyareestablishedinaccordancewithnationallaworthat
MemberStateisitselfdirectlyresponsiblefortheconformityassessment.
10.Notifiedbodiesshallbecapableofcarryingoutalltheirtasksunder
thisRegulationwiththehighestdegreeofprofessionalintegrityandthe
requisitecompetenceinthespecificfield,whetherthosetasksarecarried
outbynotifiedbodiesthemselvesorontheirbehalfandundertheir
responsibility.
11.Notifiedbodiesshallhavesufficientinternalcompetencestobeable
effectivelytoevaluatethetasksconductedbyexternalpartiesontheirbehalf.
Thenotifiedbodyshallhavepermanentavailabilityofsufficient
administrative,technical,legalandscientificpersonnelwhopossess
experienceandknowledgerelatingtotherelevanttypesofAIsystems,data
anddatacomputing,andrelatingtotherequirementssetoutinSection2.
12.Notifiedbodiesshallparticipateincoordinationactivitiesasreferredto
inArticle38.Theyshallalsotakepartdirectly,orberepresentedin,
Europeanstandardisationorganisations,orensurethattheyareawareandup
todateinrespectofrelevantstandards.
Article32
Presumptionofconformitywithrequirementsrelatingtonotified
bodies
Whereaconformityassessmentbodydemonstratesitsconformitywiththe
criterialaiddownintherelevantharmonisedstandardsorpartsthereof,the
referencesofwhichhavebeenpublishedintheOfficialJournalofthe
EuropeanUnion,itshallbepresumedtocomplywiththerequirementsset
outinArticle31insofarastheapplicableharmonisedstandardscover
thoserequirements.
Article33
Subsidiariesofnotifiedbodiesandsubcontracting
1.Whereanotifiedbodysubcontractsspecifictasksconnectedwiththe
conformityassessmentorhasrecoursetoasubsidiary,itshallensurethat

--- Page 105 ---
thesubcontractororthesubsidiarymeetstherequirementslaiddownin
Article31,andshallinformthenotifyingauthorityaccordingly.
2.Notifiedbodiesshalltakefullresponsibilityforthetasksperformedby
anysubcontractorsorsubsidiaries.
3.Activitiesmaybesubcontractedorcarriedoutbyasubsidiaryonlywith
theagreementoftheprovider.Notifiedbodiesshallmakealistoftheir
subsidiariespubliclyavailable.
4.Therelevantdocumentsconcerningtheassessmentofthequalifications
ofthesubcontractororthesubsidiaryandtheworkcarriedoutbythem
underthisRegulationshallbekeptatthedisposalofthenotifyingauthority
foraperiodoffiveyearsfromtheterminationdateofthesubcontracting.
Article34
Operationalobligationsofnotifiedbodies
1.Notifiedbodiesshallverifytheconformityofhigh-riskAIsystemsin
accordancewiththeconformityassessmentproceduressetoutinArticle43.
2.Notifiedbodiesshallavoidunnecessaryburdensforproviderswhen
performingtheiractivities,andtakedueaccountofthesizeoftheprovider,
thesectorinwhichitoperates,itsstructureandthedegreeofcomplexityof
thehigh-riskAIsystemconcerned,inparticularinviewofminimising
administrativeburdensandcompliancecostsformicro-andsmall
enterpriseswithinthemeaningofRecommendation2003/361/EC.The
notifiedbodyshall,nevertheless,respectthedegreeofrigourandthelevel
ofprotectionrequiredforthecomplianceofthehigh-riskAIsystemwiththe
requirementsofthisRegulation.
3.Notifiedbodiesshallmakeavailableandsubmituponrequestall
relevantdocumentation,includingtheproviders’documentation,tothe
notifyingauthorityreferredtoinArticle28toallowthatauthorityto
conductitsassessment,designation,notificationandmonitoringactivities,
andtofacilitatetheassessmentoutlinedinthisSection.
Article35
Identificationnumbersandlistsofnotifiedbodies
1.TheCommissionshallassignasingleidentificationnumbertoeach
notifiedbody,evenwhereabodyisnotifiedundermorethanoneUnionact.
2.TheCommissionshallmakepubliclyavailablethelistofthebodies
notifiedunderthisRegulation,includingtheiridentificationnumbersand

--- Page 106 ---
theactivitiesforwhichtheyhavebeennotified.TheCommissionshall
ensurethatthelistiskeptuptodate.
Article36
Changestonotifications
1.ThenotifyingauthorityshallnotifytheCommissionandtheother
MemberStatesofanyrelevantchangestothenotificationofanotifiedbody
viatheelectronicnotificationtoolreferredtoinArticle30(2).
2.TheprocedureslaiddowninArticles29and30shallapplytoextensions
ofthescopeofthenotification.
Forchangestothenotificationotherthanextensionsofitsscope,the
procedureslaiddowninparagraphs(3)to(9)shallapply.
3.Whereanotifiedbodydecidestoceaseitsconformityassessment
activities,itshallinformthenotifyingauthorityandtheprovidersconcerned
assoonaspossibleand,inthecaseofaplannedcessation,atleastoneyear
beforeceasingitsactivities.Thecertificatesofthenotifiedbodymayremain
validforaperiodofninemonthsaftercessationofthenotifiedbody’s
activities,onconditionthatanothernotifiedbodyhasconfirmedinwriting
thatitwillassumeresponsibilitiesforthehigh-riskAIsystemscoveredby
thosecertificates.Thelatternotifiedbodyshallcompleteafullassessment
ofthehigh-riskAIsystemsaffectedbytheendofthatnine-month-period
beforeissuingnewcertificatesforthosesystems.Wherethenotifiedbody
hasceaseditsactivity,thenotifyingauthorityshallwithdrawthedesignation.
4.Whereanotifyingauthorityhassufficientreasontoconsiderthat
anotifiedbodynolongermeetstherequirementslaiddowninArticle31,or
thatitisfailingtofulfilitsobligations,thenotifyingauthorityshallwithout
delayinvestigatethematterwiththeutmostdiligence.Inthatcontext,it
shallinformthenotifiedbodyconcernedabouttheobjectionsraisedand
giveitthepossibilitytomakeitsviewsknown.Ifthenotifyingauthority
comestotheconclusionthatthenotifiedbodynolongermeetsthe
requirementslaiddowninArticle31orthatitisfailingtofulfilits
obligations,itshallrestrict,suspendorwithdrawthedesignationas
appropriate,dependingontheseriousnessofthefailuretomeetthose
requirementsorfulfilthoseobligations.Itshallimmediatelyinformthe
CommissionandtheotherMemberStatesaccordingly.
5.Whereitsdesignationhasbeensuspended,restricted,orfullyorpartially
withdrawn,thenotifiedbodyshallinformtheprovidersconcernedwithin10
days.
6.Intheeventoftherestriction,suspensionorwithdrawalofadesignation,
thenotifyingauthorityshalltakeappropriatestepstoensurethatthefilesof

--- Page 107 ---
thenotifiedbodyconcernedarekept,andtomakethemavailableto
notifyingauthoritiesinotherMemberStatesandtomarketsurveillance
authoritiesattheirrequest.
7.Intheeventoftherestriction,suspensionorwithdrawalofadesignation,
thenotifyingauthorityshall:
(a)assesstheimpactonthecertificatesissuedbythenotifiedbody;
(b)submitareportonitsfindingstotheCommissionandtheotherMemberStates
withinthreemonthsofhavingnotifiedthechangestothedesignation;
(c)requirethenotifiedbodytosuspendorwithdraw,withinareasonableperiodof
timedeterminedbytheauthority,anycertificateswhichwereundulyissued,in
ordertoensurethecontinuingconformityofhigh-riskAIsystemsonthemarket;
(d)informtheCommissionandtheMemberStatesaboutcertificatesthesuspensionor
withdrawalofwhichithasrequired;
(e)providethenationalcompetentauthoritiesoftheMemberStateinwhichthe
providerhasitsregisteredplaceofbusinesswithallrelevantinformationaboutthe
certificatesofwhichithasrequiredthesuspensionorwithdrawal;thatauthority
shalltaketheappropriatemeasures,wherenecessary,toavoidapotentialriskto
health,safetyorfundamentalrights.
8.Withtheexceptionofcertificatesundulyissued,andwhere
adesignationhasbeensuspendedorrestricted,thecertificatesshallremain
validinoneofthefollowingcircumstances:
(a)thenotifyingauthorityhasconfirmed,withinonemonthofthesuspensionor
restriction,thatthereisnorisktohealth,safetyorfundamentalrightsinrelationto
certificatesaffectedbythesuspensionorrestriction,andthenotifyingauthorityhas
outlinedatimelineforactionstoremedythesuspensionorrestriction;or
(b)thenotifyingauthorityhasconfirmedthatnocertificatesrelevanttothesuspension
willbeissued,amendedorre-issuedduringthecourseofthesuspensionor
restriction,andstateswhetherthenotifiedbodyhasthecapabilityofcontinuingto
monitorandremainresponsibleforexistingcertificatesissuedfortheperiodofthe
suspensionorrestriction;intheeventthatthenotifyingauthoritydeterminesthat
thenotifiedbodydoesnothavethecapabilitytosupportexistingcertificates
issued,theproviderofthesystemcoveredbythecertificateshallconfirmin
writingtothenationalcompetentauthoritiesoftheMemberStateinwhichithas
itsregisteredplaceofbusiness,withinthreemonthsofthesuspensionor
restriction,thatanotherqualifiednotifiedbodyistemporarilyassumingthe
functionsofthenotifiedbodytomonitorandremainresponsibleforthecertificates
duringtheperiodofsuspensionorrestriction.
9.Withtheexceptionofcertificatesundulyissued,andwhere
adesignationhasbeenwithdrawn,thecertificatesshallremainvalidfor
aperiodofninemonthsunderthefollowingcircumstances:
(a)thenationalcompetentauthorityoftheMemberStateinwhichtheproviderofthe
high-riskAIsystemcoveredbythecertificatehasitsregisteredplaceofbusiness

--- Page 108 ---
hasconfirmedthatthereisnorisktohealth,safetyorfundamentalrightsassociated
withthehigh-riskAIsystemsconcerned;and
(b)anothernotifiedbodyhasconfirmedinwritingthatitwillassumeimmediate
responsibilityforthoseAIsystemsandcompletesitsassessmentwithin12months
ofthewithdrawalofthedesignation.
Inthecircumstancesreferredtointhefirstsubparagraph,thenational
competentauthorityoftheMemberStateinwhichtheproviderofthe
systemcoveredbythecertificatehasitsplaceofbusinessmayextendthe
provisionalvalidityofthecertificatesforadditionalperiodsofthreemonths,
whichshallnotexceed12monthsintotal.
Thenationalcompetentauthorityorthenotifiedbodyassumingthe
functionsofthenotifiedbodyaffectedbythechangeofdesignationshall
immediatelyinformtheCommission,theotherMemberStatesandtheother
notifiedbodiesthereof.
Article37
Challengetothecompetenceofnotifiedbodies
1.TheCommissionshall,wherenecessary,investigateallcaseswhere
therearereasonstodoubtthecompetenceofanotifiedbodyorthe
continuedfulfilmentbyanotifiedbodyoftherequirementslaiddownin
Article31andofitsapplicableresponsibilities.
2.ThenotifyingauthorityshallprovidetheCommission,onrequest,with
allrelevantinformationrelatingtothenotificationorthemaintenanceofthe
competenceofthenotifiedbodyconcerned.
3.TheCommissionshallensurethatallsensitiveinformationobtainedin
thecourseofitsinvestigationspursuanttothisArticleistreated
confidentiallyinaccordancewithArticle78.
4.WheretheCommissionascertainsthatanotifiedbodydoesnotmeetor
nolongermeetstherequirementsforitsnotification,itshallinformthe
notifyingMemberStateaccordinglyandrequestittotakethenecessary
correctivemeasures,includingthesuspensionorwithdrawalofthe
notificationifnecessary.WheretheMemberStatefailstotakethenecessary
correctivemeasures,theCommissionmay,bymeansofanimplementing
act,suspend,restrictorwithdrawthedesignation.Thatimplementingact
shallbeadoptedinaccordancewiththeexaminationprocedurereferredtoin
Article98(2).
Article38
Coordinationofnotifiedbodies

--- Page 109 ---
1.TheCommissionshallensurethat,withregardtohigh-riskAIsystems,
appropriatecoordinationandcooperationbetweennotifiedbodiesactivein
theconformityassessmentprocedurespursuanttothisRegulationareputin
placeandproperlyoperatedintheformofasectoralgroupofnotified
bodies.
2.Eachnotifyingauthorityshallensurethatthebodiesnotifiedbyit
participateintheworkofagroupreferredtoinparagraph1,directlyor
throughdesignatedrepresentatives.
3.TheCommissionshallprovidefortheexchangeofknowledgeandbest
practicesbetweennotifyingauthorities.
Article39
Conformityassessmentbodiesofthirdcountries
Conformityassessmentbodiesestablishedunderthelawofathirdcountry
withwhichtheUnionhasconcludedanagreementmaybeauthorisedto
carryouttheactivitiesofnotifiedbodiesunderthisRegulation,provided
thattheymeettherequirementslaiddowninArticle31ortheyensurean
equivalentlevelofcompliance.
SECTION5
Standards,conformityassessment,certificates,registration
Article40
Harmonisedstandardsandstandardisationdeliverables
1.High-riskAIsystemsorgeneral-purposeAImodelswhicharein
conformitywithharmonisedstandardsorpartsthereofthereferencesof
whichhavebeenpublishedintheOfficialJournaloftheEuropeanUnionin
accordancewithRegulation(EU)No1025/2012shallbepresumedtobein
conformitywiththerequirementssetoutinSection2ofthisChapteror,as
applicable,withtheobligationssetoutinofChapterV,Sections2and3,of
thisRegulation,totheextentthatthosestandardscoverthoserequirements
orobligations.
2.InaccordancewithArticle10ofRegulation(EU)No1025/2012,the
Commissionshallissue,withoutunduedelay,standardisationrequests
coveringallrequirementssetoutinSection2ofthisChapterand,as
applicable,standardisationrequestscoveringobligationssetoutin
ChapterV,Sections2and3,ofthisRegulation.Thestandardisationrequest
shallalsoaskfordeliverablesonreportinganddocumentationprocessesto

--- Page 110 ---
improveAIsystems’resourceperformance,suchasreducingthehigh-risk
AIsystem’sconsumptionofenergyandofotherresourcesduringits
lifecycle,andontheenergy-efficientdevelopmentofgeneral-purposeAI
models.Whenpreparingastandardisationrequest,theCommissionshall
consulttheBoardandrelevantstakeholders,includingtheadvisoryforum.
WhenissuingastandardisationrequesttoEuropeanstandardisation
organisations,theCommissionshallspecifythatstandardshavetobeclear,
consistent,includingwiththestandardsdevelopedinthevarioussectorsfor
productscoveredbytheexistingUnionharmonisationlegislationlistedin
AnnexI,andaimingtoensurethathigh-riskAIsystemsorgeneral-purpose
AImodelsplacedonthemarketorputintoserviceintheUnionmeetthe
relevantrequirementsorobligationslaiddowninthisRegulation.
TheCommissionshallrequesttheEuropeanstandardisationorganisationsto
provideevidenceoftheirbesteffortstofulfiltheobjectivesreferredtointhe
firstandthesecondsubparagraphofthisparagraphinaccordancewith
Article24ofRegulation(EU)No1025/2012.
3.Theparticipantsinthestandardisationprocessshallseektopromote
investmentandinnovationinAI,includingthroughincreasinglegal
certainty,aswellasthecompetitivenessandgrowthoftheUnionmarket,to
contributetostrengtheningglobalcooperationonstandardisationandtaking
intoaccountexistinginternationalstandardsinthefieldofAIthatare
consistentwithUnionvalues,fundamentalrightsandinterests,andto
enhancemulti-stakeholdergovernanceensuringabalancedrepresentationof
interestsandtheeffectiveparticipationofallrelevantstakeholdersin
accordancewithArticles5,6,and7ofRegulation(EU)No1025/2012.
Article41
Commonspecifications
1.TheCommissionmayadopt,implementingactsestablishingcommon
specificationsfortherequirementssetoutinSection2ofthisChapteror,as
applicable,fortheobligationssetoutinSections2and3of
ChapterVwherethefollowingconditionshavebeenfulfilled:
(a)theCommissionhasrequested,pursuanttoArticle10(1)ofRegulation
(EU)No1025/2012,oneormoreEuropeanstandardisationorganisationstodraft
aharmonisedstandardfortherequirementssetoutinSection2ofthisChapter,or,
asapplicable,fortheobligationssetoutinSections2and3ofChapterV,and:
(i)therequesthasnotbeenacceptedbyanyoftheEuropeanstandardisation
organisations;or
(ii)theharmonisedstandardsaddressingthatrequestarenotdeliveredwithinthe
deadlinesetinaccordancewithArticle10(1)ofRegulation(EU)No1025/2012;
or

--- Page 111 ---
(iii)therelevantharmonisedstandardsinsufficientlyaddressfundamentalrights
concerns;or
(iv)theharmonisedstandardsdonotcomplywiththerequest;and
(b)noreferencetoharmonisedstandardscoveringtherequirementsreferredtoin
Section2ofthisChapteror,asapplicable,theobligationsreferredtoinSections2
and3ofChapterVhasbeenpublishedintheOfficialJournaloftheEuropean
UnioninaccordancewithRegulation(EU)No1025/2012,andnosuchreferenceis
expectedtobepublishedwithinareasonableperiod.
Whendraftingthecommonspecifications,theCommissionshallconsultthe
advisoryforumreferredtoinArticle67.
Theimplementingactsreferredtointhefirstsubparagraphofthisparagraph
shallbeadoptedinaccordancewiththeexaminationprocedurereferredtoin
Article98(2).
2.Beforepreparingadraftimplementingact,theCommissionshallinform
thecommitteereferredtoinArticle22ofRegulation(EU)No1025/2012
thatitconsiderstheconditionslaiddowninparagraph1ofthisArticletobe
fulfilled.
3.High-riskAIsystemsorgeneral-purposeAImodelswhicharein
conformitywiththecommonspecificationsreferredtoinparagraph1,or
partsofthosespecifications,shallbepresumedtobeinconformitywiththe
requirementssetoutinSection2ofthisChapteror,asapplicable,tocomply
withtheobligationsreferredtoinSections2and3ofChapterV,tothe
extentthosecommonspecificationscoverthoserequirementsorthose
obligations.
4.WhereaharmonisedstandardisadoptedbyaEuropeanstandardisation
organisationandproposedtotheCommissionforthepublicationofits
referenceintheOfficialJournaloftheEuropeanUnion,theCommission
shallassesstheharmonisedstandardinaccordancewithRegulation(EU)
No1025/2012.Whenreferencetoaharmonisedstandardispublishedin
theOfficialJournaloftheEuropeanUnion,theCommissionshallrepealthe
implementingactsreferredtoinparagraph1,orpartsthereofwhichcover
thesamerequirementssetoutinSection2ofthisChapteror,asapplicable,
thesameobligationssetoutinSections2and3ofChapterV.
5.Whereprovidersofhigh-riskAIsystemsorgeneral-purposeAImodels
donotcomplywiththecommonspecificationsreferredtoinparagraph1,
theyshalldulyjustifythattheyhaveadoptedtechnicalsolutionsthatmeet
therequirementsreferredtoinSection2ofthisChapteror,asapplicable,
complywiththeobligationssetoutinSections2and3ofChapterVto
alevelatleastequivalentthereto.

--- Page 112 ---
6.WhereaMemberStateconsidersthatacommonspecificationdoesnot
entirelymeettherequirementssetoutinSection2or,asapplicable,comply
withobligationssetoutinSections2and3ofChapterV,itshallinformthe
Commissionthereofwithadetailedexplanation.TheCommissionshall
assessthatinformationand,ifappropriate,amendtheimplementingact
establishingthecommonspecificationconcerned.
Article42
Presumptionofconformitywithcertainrequirements
1.High-riskAIsystemsthathavebeentrainedandtestedondatareflecting
thespecificgeographical,behavioural,contextualorfunctionalsetting
withinwhichtheyareintendedtobeusedshallbepresumedtocomplywith
therelevantrequirementslaiddowninArticle10(4).
2.High-riskAIsystemsthathavebeencertifiedorforwhichastatementof
conformityhasbeenissuedunderacybersecurityschemepursuantto
Regulation(EU)2019/881andthereferencesofwhichhavebeenpublished
intheOfficialJournaloftheEuropeanUnionshallbepresumedtocomply
withthecybersecurityrequirementssetoutinArticle15ofthisRegulation
insofarasthecybersecuritycertificateorstatementofconformityorparts
thereofcoverthoserequirements.
Article43
Conformityassessment
1.Forhigh-riskAIsystemslistedinpoint1ofAnnexIII,where,in
demonstratingthecomplianceofahigh-riskAIsystemwiththe
requirementssetoutinSection2,theproviderhasappliedharmonised
standardsreferredtoinArticle40,or,whereapplicable,common
specificationsreferredtoinArticle41,theprovidershalloptforoneofthe
followingconformityassessmentproceduresbasedon:
(a)theinternalcontrolreferredtoinAnnexVI;or
(b)theassessmentofthequalitymanagementsystemandtheassessmentofthe
technicaldocumentation,withtheinvolvementofanotifiedbody,referredtoin
AnnexVII.
Indemonstratingthecomplianceofahigh-riskAIsystemwiththe
requirementssetoutinSection2,theprovidershallfollowtheconformity
assessmentproceduresetoutinAnnexVIIwhere:
(a)harmonisedstandardsreferredtoinArticle40donotexist,andcommon
specificationsreferredtoinArticle41arenotavailable;
(b)theproviderhasnotapplied,orhasappliedonlypartof,theharmonisedstandard;

--- Page 113 ---
(c)thecommonspecificationsreferredtoinpoint(a)exist,buttheproviderhasnot
appliedthem;
(d)oneormoreoftheharmonisedstandardsreferredtoinpoint(a)hasbeenpublished
witharestriction,andonlyonthepartofthestandardthatwasrestricted.
Forthepurposesoftheconformityassessmentprocedurereferredtoin
AnnexVII,theprovidermaychooseanyofthenotifiedbodies.However,
wherethehigh-riskAIsystemisintendedtobeputintoservicebylaw
enforcement,immigrationorasylumauthoritiesorbyUnioninstitutions,
bodies,officesoragencies,themarketsurveillanceauthorityreferredtoin
Article74(8)or(9),asapplicable,shallactasanotifiedbody.
2.Forhigh-riskAIsystemsreferredtoinpoints2to8ofAnnexIII,
providersshallfollowtheconformityassessmentprocedurebasedon
internalcontrolasreferredtoinAnnexVI,whichdoesnotprovideforthe
involvementofanotifiedbody.
3.Forhigh-riskAIsystemscoveredbytheUnionharmonisationlegislation
listedinSectionAofAnnexI,theprovidershallfollowtherelevant
conformityassessmentprocedureasrequiredunderthoselegalacts.The
requirementssetoutinSection2ofthisChaptershallapplytothosehigh-
riskAIsystemsandshallbepartofthatassessment.Points4.3.,4.4.,4.5.
andthefifthparagraphofpoint4.6ofAnnexVIIshallalsoapply.
Forthepurposesofthatassessment,notifiedbodieswhichhavebeen
notifiedunderthoselegalactsshallbeentitledtocontroltheconformityof
thehigh-riskAIsystemswiththerequirementssetoutinSection2,provided
thatthecomplianceofthosenotifiedbodieswithrequirementslaiddownin
Article31(4),(5),(10)and(11)hasbeenassessedinthecontextofthe
notificationprocedureunderthoselegalacts.
WherealegalactlistedinSectionAofAnnexIenablestheproduct
manufacturertooptoutfromathird-partyconformityassessment,provided
thatthatmanufacturerhasappliedallharmonisedstandardscoveringallthe
relevantrequirements,thatmanufacturermayusethatoptiononlyifithas
alsoappliedharmonisedstandardsor,whereapplicable,common
specificationsreferredtoinArticle41,coveringallrequirementssetoutin
Section2ofthisChapter.
4.High-riskAIsystemsthathavealreadybeensubjecttoaconformity
assessmentprocedureshallundergoanewconformityassessmentprocedure
intheeventofasubstantialmodification,regardlessofwhetherthe
modifiedsystemisintendedtobefurtherdistributedorcontinuestobeused
bythecurrentdeployer.
Forhigh-riskAIsystemsthatcontinuetolearnafterbeingplacedonthe
marketorputintoservice,changestothehigh-riskAIsystemandits

--- Page 114 ---
performancethathavebeenpre-determinedbytheprovideratthemoment
oftheinitialconformityassessmentandarepartoftheinformation
containedinthetechnicaldocumentationreferredtoinpoint2(f)of
AnnexIV,shallnotconstituteasubstantialmodification.
5.TheCommissionisempoweredtoadoptdelegatedactsinaccordance
withArticle97inordertoamendAnnexesVIandVIIbyupdatingthemin
lightoftechnicalprogress.
6.TheCommissionisempoweredtoadoptdelegatedactsinaccordance
withArticle97inordertoamendparagraphs1and2ofthisArticleinorder
tosubjecthigh-riskAIsystemsreferredtoinpoints2to8ofAnnexIIIto
theconformityassessmentprocedurereferredtoinAnnexVIIorparts
thereof.TheCommissionshalladoptsuchdelegatedactstakingintoaccount
theeffectivenessoftheconformityassessmentprocedurebasedoninternal
controlreferredtoinAnnexVIinpreventingorminimisingtherisksto
healthandsafetyandprotectionoffundamentalrightsposedbysuch
systems,aswellastheavailabilityofadequatecapacitiesandresources
amongnotifiedbodies.
Article44
Certificates
1.CertificatesissuedbynotifiedbodiesinaccordancewithAnnexVII
shallbedrawn-upinalanguagewhichcanbeeasilyunderstoodbythe
relevantauthoritiesintheMemberStateinwhichthenotifiedbodyis
established.
2.Certificatesshallbevalidfortheperiodtheyindicate,whichshallnot
exceedfiveyearsforAIsystemscoveredbyAnnexI,andfouryearsforAI
systemscoveredbyAnnexIII.Attherequestoftheprovider,thevalidityof
acertificatemaybeextendedforfurtherperiods,eachnotexceedingfive
yearsforAIsystemscoveredbyAnnexI,andfouryearsforAIsystems
coveredbyAnnexIII,basedonare-assessmentinaccordancewiththe
applicableconformityassessmentprocedures.Anysupplementto
acertificateshallremainvalid,providedthatthecertificatewhichit
supplementsisvalid.
3.WhereanotifiedbodyfindsthatanAIsystemnolongermeetsthe
requirementssetoutinSection2,itshall,takingaccountoftheprincipleof
proportionality,suspendorwithdrawthecertificateissuedorimpose
restrictionsonit,unlesscompliancewiththoserequirementsisensuredby
appropriatecorrectiveactiontakenbytheproviderofthesystemwithinan
appropriatedeadlinesetbythenotifiedbody.Thenotifiedbodyshallgive
reasonsforitsdecision.

--- Page 115 ---
Anappealprocedureagainstdecisionsofthenotifiedbodies,includingon
conformitycertificatesissued,shallbeavailable.
Article45
Informationobligationsofnotifiedbodies
1.Notifiedbodiesshallinformthenotifyingauthorityofthefollowing:
(a)anyUniontechnicaldocumentationassessmentcertificates,anysupplementsto
thosecertificates,andanyqualitymanagementsystemapprovalsissuedin
accordancewiththerequirementsofAnnexVII;
(b)anyrefusal,restriction,suspensionorwithdrawalofaUniontechnical
documentationassessmentcertificateoraqualitymanagementsystemapproval
issuedinaccordancewiththerequirementsofAnnexVII;
(c)anycircumstancesaffectingthescopeoforconditionsfornotification;
(d)anyrequestforinformationwhichtheyhavereceivedfrommarketsurveillance
authoritiesregardingconformityassessmentactivities;
(e)onrequest,conformityassessmentactivitiesperformedwithinthescopeoftheir
notificationandanyotheractivityperformed,includingcross-borderactivitiesand
subcontracting.
2.Eachnotifiedbodyshallinformtheothernotifiedbodiesof:
(a)qualitymanagementsystemapprovalswhichithasrefused,suspendedor
withdrawn,and,uponrequest,ofqualitysystemapprovalswhichithasissued;
(b)Uniontechnicaldocumentationassessmentcertificatesoranysupplementsthereto
whichithasrefused,withdrawn,suspendedorotherwiserestricted,and,upon
request,ofthecertificatesand/orsupplementstheretowhichithasissued.
3.Eachnotifiedbodyshallprovidetheothernotifiedbodiescarryingout
similarconformityassessmentactivitiescoveringthesametypesofAI
systemswithrelevantinformationonissuesrelatingtonegativeand,on
request,positiveconformityassessmentresults.
4.Notifiedbodiesshallsafeguardtheconfidentialityoftheinformation
thattheyobtain,inaccordancewithArticle78.
Article46
Derogationfromconformityassessmentprocedure
1.BywayofderogationfromArticle43anduponadulyjustifiedrequest,
anymarketsurveillanceauthoritymayauthorisetheplacingonthemarket
ortheputtingintoserviceofspecifichigh-riskAIsystemswithinthe
territoryoftheMemberStateconcerned,forexceptionalreasonsofpublic
securityortheprotectionoflifeandhealthofpersons,environmental

--- Page 116 ---
protectionortheprotectionofkeyindustrialandinfrastructuralassets.That
authorisationshallbeforalimitedperiodwhilethenecessaryconformity
assessmentproceduresarebeingcarriedout,takingintoaccountthe
exceptionalreasonsjustifyingthederogation.Thecompletionofthose
proceduresshallbeundertakenwithoutunduedelay.
2.Inadulyjustifiedsituationofurgencyforexceptionalreasonsofpublic
securityorinthecaseofspecific,substantialandimminentthreattothelife
orphysicalsafetyofnaturalpersons,law-enforcementauthoritiesorcivil
protectionauthoritiesmayputaspecifichigh-riskAIsystemintoservice
withouttheauthorisationreferredtoinparagraph1,providedthatsuch
authorisationisrequestedduringoraftertheusewithoutunduedelay.Ifthe
authorisationreferredtoinparagraph1isrefused,theuseofthehigh-risk
AIsystemshallbestoppedwithimmediateeffectandalltheresultsand
outputsofsuchuseshallbeimmediatelydiscarded.
3.Theauthorisationreferredtoinparagraph1shallbeissuedonlyifthe
marketsurveillanceauthorityconcludesthatthehigh-riskAIsystem
complieswiththerequirementsofSection2.Themarketsurveillance
authorityshallinformtheCommissionandtheotherMemberStatesofany
authorisationissuedpursuanttoparagraphs1and2.Thisobligationshall
notcoversensitiveoperationaldatainrelationtotheactivitiesoflaw-
enforcementauthorities.
4.Where,within15calendardaysofreceiptoftheinformationreferredto
inparagraph3,noobjectionhasbeenraisedbyeitheraMemberStateorthe
Commissioninrespectofanauthorisationissuedbyamarketsurveillance
authorityofaMemberStateinaccordancewithparagraph1,that
authorisationshallbedeemedjustified.
5.Where,within15calendardaysofreceiptofthenotificationreferredto
inparagraph3,objectionsareraisedbyaMemberStateagainstan
authorisationissuedbyamarketsurveillanceauthorityofanotherMember
State,orwheretheCommissionconsiderstheauthorisationtobecontraryto
Unionlaw,ortheconclusionoftheMemberStatesregardingthe
complianceofthesystemasreferredtoinparagraph3tobeunfounded,the
Commissionshall,withoutdelay,enterintoconsultationswiththerelevant
MemberState.Theoperatorsconcernedshallbeconsultedandhavethe
possibilitytopresenttheirviews.Havingregardthereto,theCommission
shalldecidewhethertheauthorisationisjustified.TheCommissionshall
addressitsdecisiontotheMemberStateconcernedandtotherelevant
operators.
6.WheretheCommissionconsiderstheauthorisationunjustified,itshall
bewithdrawnbythemarketsurveillanceauthorityoftheMemberState
concerned.

--- Page 117 ---
7.Forhigh-riskAIsystemsrelatedtoproductscoveredbyUnion
harmonisationlegislationlistedinSectionAofAnnexI,onlythe
derogationsfromtheconformityassessmentestablishedinthatUnion
harmonisationlegislationshallapply.
Article47
EUdeclarationofconformity
1.Theprovidershalldrawupawrittenmachinereadable,physicalor
electronicallysignedEUdeclarationofconformityforeachhigh-riskAI
system,andkeepitatthedisposalofthenationalcompetentauthoritiesfor
10yearsafterthehigh-riskAIsystemhasbeenplacedonthemarketorput
intoservice.TheEUdeclarationofconformityshallidentifythehigh-risk
AIsystemforwhichithasbeendrawnup.AcopyoftheEUdeclarationof
conformityshallbesubmittedtotherelevantnationalcompetentauthorities
uponrequest.
2.TheEUdeclarationofconformityshallstatethatthehigh-riskAIsystem
concernedmeetstherequirementssetoutinSection2.TheEUdeclaration
ofconformityshallcontaintheinformationsetoutinAnnexV,andshallbe
translatedintoalanguagethatcanbeeasilyunderstoodbythenational
competentauthoritiesoftheMemberStatesinwhichthehigh-riskAI
systemisplacedonthemarketormadeavailable.
3.Wherehigh-riskAIsystemsaresubjecttootherUnionharmonisation
legislationwhichalsorequiresanEUdeclarationofconformity,asingleEU
declarationofconformityshallbedrawnupinrespectofallUnionlaw
applicabletothehigh-riskAIsystem.Thedeclarationshallcontainallthe
informationrequiredtoidentifytheUnionharmonisationlegislationto
whichthedeclarationrelates.
4.BydrawinguptheEUdeclarationofconformity,theprovidershall
assumeresponsibilityforcompliancewiththerequirementssetoutin
Section2.TheprovidershallkeeptheEUdeclarationofconformityup-to-
dateasappropriate.
5.TheCommissionisempoweredtoadoptdelegatedactsinaccordance
withArticle97inordertoamendAnnexVbyupdatingthecontentofthe
EUdeclarationofconformitysetoutinthatAnnex,inordertointroduce
elementsthatbecomenecessaryinlightoftechnicalprogress.
Article48
CEmarking

--- Page 118 ---
1.TheCEmarkingshallbesubjecttothegeneralprinciplessetoutin
Article30ofRegulation(EC)No765/2008.
2.Forhigh-riskAIsystemsprovideddigitally,adigitalCEmarkingshall
beused,onlyifitcaneasilybeaccessedviatheinterfacefromwhichthat
systemisaccessedorviaaneasilyaccessiblemachine-readablecodeor
otherelectronicmeans.
3.TheCEmarkingshallbeaffixedvisibly,legiblyandindeliblyforhigh-
riskAIsystems.Wherethatisnotpossibleornotwarrantedonaccountof
thenatureofthehigh-riskAIsystem,itshallbeaffixedtothepackagingor
totheaccompanyingdocumentation,asappropriate.
4.Whereapplicable,theCEmarkingshallbefollowedbythe
identificationnumberofthenotifiedbodyresponsiblefortheconformity
assessmentproceduressetoutinArticle43.Theidentificationnumberof
thenotifiedbodyshallbeaffixedbythebodyitselfor,underitsinstructions,
bytheproviderorbytheprovider’sauthorisedrepresentative.The
identificationnumbershallalsobeindicatedinanypromotionalmaterial
whichmentionsthatthehigh-riskAIsystemfulfilstherequirementsforCE
marking.
5.Wherehigh-riskAIsystemsaresubjecttootherUnionlawwhichalso
providesfortheaffixingoftheCEmarking,theCEmarkingshallindicate
thatthehigh-riskAIsystemalsofulfiltherequirementsofthatotherlaw.
Article49
Registration
1.Beforeplacingonthemarketorputtingintoserviceahigh-riskAI
systemlistedinAnnexIII,withtheexceptionofhigh-riskAIsystems
referredtoinpoint2ofAnnexIII,theprovideror,whereapplicable,the
authorisedrepresentativeshallregisterthemselvesandtheirsysteminthe
EUdatabasereferredtoinArticle71.
2.BeforeplacingonthemarketorputtingintoserviceanAIsystemfor
whichtheproviderhasconcludedthatitisnothigh-riskaccordingto
Article6(3),thatprovideror,whereapplicable,theauthorisedrepresentative
shallregisterthemselvesandthatsystemintheEUdatabasereferredtoin
Article71.
3.Beforeputtingintoserviceorusingahigh-riskAIsystemlistedin
AnnexIII,withtheexceptionofhigh-riskAIsystemslistedinpoint2of
AnnexIII,deployersthatarepublicauthorities,Unioninstitutions,bodies,
officesoragenciesorpersonsactingontheirbehalfshallregisterthemselves,
selectthesystemandregisteritsuseintheEUdatabasereferredtoin
Article71.

--- Page 119 ---
4.Forhigh-riskAIsystemsreferredtoinpoints1,6and7ofAnnexIII,in
theareasoflawenforcement,migration,asylumandbordercontrol
management,theregistrationreferredtoinparagraphs1,2and3ofthis
Articleshallbeinasecurenon-publicsectionoftheEUdatabasereferredto
inArticle71andshallincludeonlythefollowinginformation,asapplicable,
referredtoin:
(a)SectionA,points1to10,ofAnnexVIII,withtheexceptionofpoints6,8and9;
(b)SectionB,points1to5,andpoints8and9ofAnnexVIII;
(c)SectionC,points1to3,ofAnnexVIII;
(d)points1,2,3and5,ofAnnexIX.
OnlytheCommissionandnationalauthoritiesreferredtoinArticle74(8)
shallhaveaccesstotherespectiverestrictedsectionsoftheEUdatabase
listedinthefirstsubparagraphofthisparagraph.
5.High-riskAIsystemsreferredtoinpoint2ofAnnexIIIshallbe
registeredatnationallevel.
CHAPTERIV
TRANSPARENCYOBLIGATIONSFORPROVIDERSAND
DEPLOYERSOFCERTAINAISYSTEMS
Article50
TransparencyobligationsforprovidersanddeployersofcertainAI
systems
1.ProvidersshallensurethatAIsystemsintendedtointeractdirectlywith
naturalpersonsaredesignedanddevelopedinsuchawaythatthenatural
personsconcernedareinformedthattheyareinteractingwithanAIsystem,
unlessthisisobviousfromthepointofviewofanaturalpersonwhois
reasonablywell-informed,observantandcircumspect,takingintoaccount
thecircumstancesandthecontextofuse.Thisobligationshallnotapplyto
AIsystemsauthorisedbylawtodetect,prevent,investigateorprosecute
criminaloffences,subjecttoappropriatesafeguardsfortherightsand
freedomsofthirdparties,unlessthosesystemsareavailableforthepublicto
reportacriminaloffence.
2.ProvidersofAIsystems,includinggeneral-purposeAIsystems,
generatingsyntheticaudio,image,videoortextcontent,shallensurethatthe
outputsoftheAIsystemaremarkedinamachine-readableformatand
detectableasartificiallygeneratedormanipulated.Providersshallensure
theirtechnicalsolutionsareeffective,interoperable,robustandreliableas

--- Page 120 ---
farasthisistechnicallyfeasible,takingintoaccountthespecificitiesand
limitationsofvarioustypesofcontent,thecostsofimplementationandthe
generallyacknowledgedstateoftheart,asmaybereflectedinrelevant
technicalstandards.ThisobligationshallnotapplytotheextenttheAI
systemsperformanassistivefunctionforstandardeditingordonot
substantiallyaltertheinputdataprovidedbythedeployerorthesemantics
thereof,orwhereauthorisedbylawtodetect,prevent,investigateor
prosecutecriminaloffences.
3.Deployersofanemotionrecognitionsystemorabiometric
categorisationsystemshallinformthenaturalpersonsexposedtheretoofthe
operationofthesystem,andshallprocessthepersonaldatainaccordance
withRegulations(EU)2016/679and(EU)2018/1725andDirective(EU)
2016/680,asapplicable.ThisobligationshallnotapplytoAIsystemsused
forbiometriccategorisationandemotionrecognition,whicharepermitted
bylawtodetect,preventorinvestigatecriminaloffences,subjectto
appropriatesafeguardsfortherightsandfreedomsofthirdparties,andin
accordancewithUnionlaw.
4.DeployersofanAIsystemthatgeneratesormanipulatesimage,audioor
videocontentconstitutingadeepfake,shalldisclosethatthecontenthas
beenartificiallygeneratedormanipulated.Thisobligationshallnotapply
wheretheuseisauthorisedbylawtodetect,prevent,investigateor
prosecutecriminaloffence.Wherethecontentformspartofanevidently
artistic,creative,satirical,fictionaloranalogousworkorprogramme,the
transparencyobligationssetoutinthisparagrapharelimitedtodisclosureof
theexistenceofsuchgeneratedormanipulatedcontentinanappropriate
mannerthatdoesnothamperthedisplayorenjoymentofthework.
DeployersofanAIsystemthatgeneratesormanipulatestextwhichis
publishedwiththepurposeofinformingthepubliconmattersofpublic
interestshalldisclosethatthetexthasbeenartificiallygeneratedor
manipulated.Thisobligationshallnotapplywheretheuseisauthorisedby
lawtodetect,prevent,investigateorprosecutecriminaloffencesorwhere
theAI-generatedcontenthasundergoneaprocessofhumanreviewor
editorialcontrolandwhereanaturalorlegalpersonholdseditorial
responsibilityforthepublicationofthecontent.
5.Theinformationreferredtoinparagraphs1to4shallbeprovidedtothe
naturalpersonsconcernedinaclearanddistinguishablemanneratthelatest
atthetimeofthefirstinteractionorexposure.Theinformationshall
conformtotheapplicableaccessibilityrequirements.
6.Paragraphs1to4shallnotaffecttherequirementsandobligationsset
outinChapterIII,andshallbewithoutprejudicetoothertransparency
obligationslaiddowninUnionornationallawfordeployersofAIsystems.

--- Page 121 ---
7.TheAIOfficeshallencourageandfacilitatethedrawingupofcodesof
practiceatUnionleveltofacilitatetheeffectiveimplementationofthe
obligationsregardingthedetectionandlabellingofartificiallygeneratedor
manipulatedcontent.TheCommissionmayadoptimplementingactsto
approvethosecodesofpracticeinaccordancewiththeprocedurelaiddown
inArticle56(6).Ifitdeemsthecodeisnotadequate,theCommissionmay
adoptanimplementingactspecifyingcommonrulesfortheimplementation
ofthoseobligationsinaccordancewiththeexaminationprocedurelaid
downinArticle98(2).
CHAPTERV
GENERAL-PURPOSEAIMODELS
SECTION1
Classificationrules
Article51
Classificationofgeneral-purposeAImodelsasgeneral-purposeAI
modelswithsystemicrisk
1.Ageneral-purposeAImodelshallbeclassifiedasageneral-purposeAI
modelwithsystemicriskifitmeetsanyofthefollowingconditions:
(a)ithashighimpactcapabilitiesevaluatedonthebasisofappropriatetechnicaltools
andmethodologies,includingindicatorsandbenchmarks;
(b)basedonadecisionoftheCommission,exofficioorfollowingaqualifiedalert
fromthescientificpanel,ithascapabilitiesoranimpactequivalenttothosesetout
inpoint(a)havingregardtothecriteriasetoutinAnnexXIII.
2.Ageneral-purposeAImodelshallbepresumedtohavehighimpact
capabilitiespursuanttoparagraph1,point(a),whenthecumulativeamount
ofcomputationusedforitstrainingmeasuredinfloatingpointoperationsis
greaterthan1025.
3.TheCommissionshalladoptdelegatedactsinaccordancewith
Article97toamendthethresholdslistedinparagraphs1and2ofthis
Article,aswellastosupplementbenchmarksandindicatorsinlightof
evolvingtechnologicaldevelopments,suchasalgorithmicimprovementsor
increasedhardwareefficiency,whennecessary,forthesethresholdsto
reflectthestateoftheart.
Article52

--- Page 122 ---
Procedure
1.Whereageneral-purposeAImodelmeetstheconditionreferredtoin
Article51(1),point(a),therelevantprovidershallnotifytheCommission
withoutdelayandinanyeventwithintwoweeksafterthatrequirementis
metoritbecomesknownthatitwillbemet.Thatnotificationshallinclude
theinformationnecessarytodemonstratethattherelevantrequirementhas
beenmet.IftheCommissionbecomesawareofageneral-purposeAImodel
presentingsystemicrisksofwhichithasnotbeennotified,itmaydecideto
designateitasamodelwithsystemicrisk.
2.Theproviderofageneral-purposeAImodelthatmeetsthecondition
referredtoinArticle51(1),point(a),maypresent,withitsnotification,
sufficientlysubstantiatedargumentstodemonstratethat,exceptionally,
althoughitmeetsthatrequirement,thegeneral-purposeAImodeldoesnot
present,duetoitsspecificcharacteristics,systemicrisksandtherefore
shouldnotbeclassifiedasageneral-purposeAImodelwithsystemicrisk.
3.WheretheCommissionconcludesthattheargumentssubmittedpursuant
toparagraph2arenotsufficientlysubstantiatedandtherelevantprovider
wasnotabletodemonstratethatthegeneral-purposeAImodeldoesnot
present,duetoitsspecificcharacteristics,systemicrisks,itshallrejectthose
arguments,andthegeneral-purposeAImodelshallbeconsideredtobe
ageneral-purposeAImodelwithsystemicrisk.
4.TheCommissionmaydesignateageneral-purposeAImodelas
presentingsystemicrisks,exofficioorfollowingaqualifiedalertfromthe
scientificpanelpursuanttoArticle90(1),point(a),onthebasisofcriteria
setoutinAnnexXIII.
TheCommissionisempoweredtoadoptdelegatedactsinaccordancewith
Article97inordertoamendAnnexXIIIbyspecifyingandupdatingthe
criteriasetoutinthatAnnex.
5.Uponareasonedrequestofaproviderwhosemodelhasbeendesignated
asageneral-purposeAImodelwithsystemicriskpursuanttoparagraph4,
theCommissionshalltaketherequestintoaccountandmaydecideto
reassesswhetherthegeneral-purposeAImodelcanstillbeconsideredto
presentsystemicrisksonthebasisofthecriteriasetoutinAnnexXIII.Such
arequestshallcontainobjective,detailedandnewreasonsthathavearisen
sincethedesignationdecision.Providersmayrequestreassessmentatthe
earliestsixmonthsafterthedesignationdecision.WheretheCommission,
followingitsreassessment,decidestomaintainthedesignationasageneral-
purposeAImodelwithsystemicrisk,providersmayrequestreassessmentat
theearliestsixmonthsafterthatdecision.
6.TheCommissionshallensurethatalistofgeneral-purposeAImodels
withsystemicriskispublishedandshallkeepthatlistuptodate,without

--- Page 123 ---
prejudicetotheneedtoobserveandprotectintellectualpropertyrightsand
confidentialbusinessinformationortradesecretsinaccordancewithUnion
andnationallaw.
SECTION2
Obligationsforprovidersofgeneral-purposeAImodels
Article53
Obligationsforprovidersofgeneral-purposeAImodels
1.Providersofgeneral-purposeAImodelsshall:
(a)drawupandkeepup-to-datethetechnicaldocumentationofthemodel,including
itstrainingandtestingprocessandtheresultsofitsevaluation,whichshallcontain,
ataminimum,theinformationsetoutinAnnexXIforthepurposeofprovidingit,
uponrequest,totheAIOfficeandthenationalcompetentauthorities;
(b)drawup,keepup-to-dateandmakeavailableinformationanddocumentationto
providersofAIsystemswhointendtointegratethegeneral-purposeAImodelinto
theirAIsystems.Withoutprejudicetotheneedtoobserveandprotectintellectual
propertyrightsandconfidentialbusinessinformationortradesecretsinaccordance
withUnionandnationallaw,theinformationanddocumentationshall:
(i)enableprovidersofAIsystemstohaveagoodunderstandingofthecapabilities
andlimitationsofthegeneral-purposeAImodelandtocomplywiththeir
obligationspursuanttothisRegulation;and
(ii)contain,ataminimum,theelementssetoutinAnnexXII;
(c)putinplaceapolicytocomplywithUnionlawoncopyrightandrelatedrights,and
inparticulartoidentifyandcomplywith,includingthroughstate-of-the-art
technologies,areservationofrightsexpressedpursuanttoArticle4(3)of
Directive(EU)2019/790;
(d)drawupandmakepubliclyavailableasufficientlydetailedsummaryaboutthe
contentusedfortrainingofthegeneral-purposeAImodel,accordingtoatemplate
providedbytheAIOffice.
2.Theobligationssetoutinparagraph1,points(a)and(b),shallnotapply
toprovidersofAImodelsthatarereleasedunderafreeandopen-source
licencethatallowsfortheaccess,usage,modification,anddistributionof
themodel,andwhoseparameters,includingtheweights,theinformationon
themodelarchitecture,andtheinformationonmodelusage,aremade
publiclyavailable.Thisexceptionshallnotapplytogeneral-purposeAI
modelswithsystemicrisks.
3.Providersofgeneral-purposeAImodelsshallcooperateasnecessary
withtheCommissionandthenationalcompetentauthoritiesintheexercise
oftheircompetencesandpowerspursuanttothisRegulation.

--- Page 124 ---
4.Providersofgeneral-purposeAImodelsmayrelyoncodesofpractice
withinthemeaningofArticle56todemonstratecompliancewiththe
obligationssetoutinparagraph1ofthisArticle,untilaharmonisedstandard
ispublished.CompliancewithEuropeanharmonisedstandardsgrants
providersthepresumptionofconformitytotheextentthatthosestandards
coverthoseobligations.Providersofgeneral-purposeAImodelswhodonot
adheretoanapprovedcodeofpracticeordonotcomplywithaEuropean
harmonisedstandardshalldemonstratealternativeadequatemeansof
complianceforassessmentbytheCommission.
5.ForthepurposeoffacilitatingcompliancewithAnnexXI,inparticular
points2(d)and(e)thereof,theCommissionisempoweredtoadopt
delegatedactsinaccordancewithArticle97todetailmeasurementand
calculationmethodologieswithaviewtoallowingforcomparableand
verifiabledocumentation.
6.TheCommissionisempoweredtoadoptdelegatedactsinaccordance
withArticle97(2)toamendAnnexesXIandXIIinlightofevolving
technologicaldevelopments.
7.AnyinformationordocumentationobtainedpursuanttothisArticle,
includingtradesecrets,shallbetreatedinaccordancewiththe
confidentialityobligationssetoutinArticle78.
Article54
Authorisedrepresentativesofprovidersofgeneral-purposeAImodels
1.Priortoplacingageneral-purposeAImodelontheUnionmarket,
providersestablishedinthirdcountriesshall,bywrittenmandate,appointan
authorisedrepresentativewhichisestablishedintheUnion.
2.Theprovidershallenableitsauthorisedrepresentativetoperformthe
tasksspecifiedinthemandatereceivedfromtheprovider.
3.Theauthorisedrepresentativeshallperformthetasksspecifiedinthe
mandatereceivedfromtheprovider.Itshallprovideacopyofthemandate
totheAIOfficeuponrequest,inoneoftheofficiallanguagesofthe
institutionsoftheUnion.ForthepurposesofthisRegulation,themandate
shallempowertheauthorisedrepresentativetocarryoutthefollowingtasks:
(a)verifythatthetechnicaldocumentationspecifiedinAnnexXIhasbeendrawnup
andallobligationsreferredtoinArticle53and,whereapplicable,Article55have
beenfulfilledbytheprovider;
(b)keepacopyofthetechnicaldocumentationspecifiedinAnnexXIatthedisposal
oftheAIOfficeandnationalcompetentauthorities,foraperiodof10yearsafter
thegeneral-purposeAImodelhasbeenplacedonthemarket,andthecontact
detailsoftheproviderthatappointedtheauthorisedrepresentative;

--- Page 125 ---
(c)providetheAIOffice,uponareasonedrequest,withalltheinformationand
documentation,includingthatreferredtoinpoint(b),necessarytodemonstrate
compliancewiththeobligationsinthisChapter;
(d)cooperatewiththeAIOfficeandcompetentauthorities,uponareasonedrequest,
inanyactiontheytakeinrelationtothegeneral-purposeAImodel,includingwhen
themodelisintegratedintoAIsystemsplacedonthemarketorputintoservicein
theUnion.
4.Themandateshallempowertheauthorisedrepresentativetobe
addressed,inadditiontoorinsteadoftheprovider,bytheAIOfficeorthe
competentauthorities,onallissuesrelatedtoensuringcompliancewiththis
Regulation.
5.Theauthorisedrepresentativeshallterminatethemandateifitconsiders
orhasreasontoconsidertheprovidertobeactingcontrarytoitsobligations
pursuanttothisRegulation.Insuchacase,itshallalsoimmediatelyinform
theAIOfficeabouttheterminationofthemandateandthereasonstherefor.
6.TheobligationsetoutinthisArticleshallnotapplytoprovidersof
general-purposeAImodelsthatarereleasedunderafreeandopen-source
licencethatallowsfortheaccess,usage,modification,anddistributionof
themodel,andwhoseparameters,includingtheweights,theinformationon
themodelarchitecture,andtheinformationonmodelusage,aremade
publiclyavailable,unlessthegeneral-purposeAImodelspresentsystemic
risks.
SECTION3
Obligationsofprovidersofgeneral-purposeAImodelswithsystemicrisk
Article55
Obligationsofprovidersofgeneral-purposeAImodelswithsystemic
risk
1.InadditiontotheobligationslistedinArticles53and54,providersof
general-purposeAImodelswithsystemicriskshall:
(a)performmodelevaluationinaccordancewithstandardisedprotocolsandtools
reflectingthestateoftheart,includingconductinganddocumentingadversarial
testingofthemodelwithaviewtoidentifyingandmitigatingsystemicrisks;
(b)assessandmitigatepossiblesystemicrisksatUnionlevel,includingtheirsources,
thatmaystemfromthedevelopment,theplacingonthemarket,ortheuseof
general-purposeAImodelswithsystemicrisk;
(c)keeptrackof,document,andreport,withoutunduedelay,totheAIOfficeand,as
appropriate,tonationalcompetentauthorities,relevantinformationaboutserious

--- Page 126 ---
incidentsandpossiblecorrectivemeasurestoaddressthem;
(d)ensureanadequatelevelofcybersecurityprotectionforthegeneral-purposeAI
modelwithsystemicriskandthephysicalinfrastructureofthemodel.
2.Providersofgeneral-purposeAImodelswithsystemicriskmayrelyon
codesofpracticewithinthemeaningofArticle56todemonstrate
compliancewiththeobligationssetoutinparagraph1ofthisArticle,until
aharmonisedstandardispublished.CompliancewithEuropeanharmonised
standardsgrantsprovidersthepresumptionofconformitytotheextentthat
thosestandardscoverthoseobligations.Providersofgeneral-purposeAI
modelswithsystemicriskswhodonotadheretoanapprovedcodeof
practiceordonotcomplywithaEuropeanharmonisedstandardshall
demonstratealternativeadequatemeansofcomplianceforassessmentbythe
Commission.
3.AnyinformationordocumentationobtainedpursuanttothisArticle,
includingtradesecrets,shallbetreatedinaccordancewiththe
confidentialityobligationssetoutinArticle78.
SECTION4
Codesofpractice
Article56
Codesofpractice
1.TheAIOfficeshallencourageandfacilitatethedrawingupofcodesof
practiceatUnionlevelinordertocontributetotheproperapplicationofthis
Regulation,takingintoaccountinternationalapproaches.
2.TheAIOfficeandtheBoardshallaimtoensurethatthecodesof
practicecoveratleasttheobligationsprovidedforinArticles53and55,
includingthefollowingissues:
(a)themeanstoensurethattheinformationreferredtoinArticle53(1),points(a)
and(b),iskeptuptodateinlightofmarketandtechnologicaldevelopments;
(b)theadequatelevelofdetailforthesummaryaboutthecontentusedfortraining;
(c)theidentificationofthetypeandnatureofthesystemicrisksatUnionlevel,
includingtheirsources,whereappropriate;
(d)themeasures,proceduresandmodalitiesfortheassessmentandmanagementofthe
systemicrisksatUnionlevel,includingthedocumentationthereof,whichshallbe
proportionatetotherisks,takeintoconsiderationtheirseverityandprobabilityand
takeintoaccountthespecificchallengesoftacklingthoserisksinlightofthe
possiblewaysinwhichsuchrisksmayemergeandmaterialisealongtheAIvalue
chain.

--- Page 127 ---
3.TheAIOfficemayinviteallprovidersofgeneral-purposeAImodels,as
wellasrelevantnationalcompetentauthorities,toparticipateinthedrawing-
upofcodesofpractice.Civilsocietyorganisations,industry,academiaand
otherrelevantstakeholders,suchasdownstreamprovidersandindependent
experts,maysupporttheprocess.
4.TheAIOfficeandtheBoardshallaimtoensurethatthecodesof
practiceclearlysetouttheirspecificobjectivesandcontaincommitmentsor
measures,includingkeyperformanceindicatorsasappropriate,toensurethe
achievementofthoseobjectives,andthattheytakedueaccountoftheneeds
andinterestsofallinterestedparties,includingaffectedpersons,atUnion
level.
5.TheAIOfficeshallaimtoensurethatparticipantstothecodesof
practicereportregularlytotheAIOfficeontheimplementationofthe
commitmentsandthemeasurestakenandtheiroutcomes,includingas
measuredagainstthekeyperformanceindicatorsasappropriate.Key
performanceindicatorsandreportingcommitmentsshallreflectdifferences
insizeandcapacitybetweenvariousparticipants.
6.TheAIOfficeandtheBoardshallregularlymonitorandevaluatethe
achievementoftheobjectivesofthecodesofpracticebytheparticipants
andtheircontributiontotheproperapplicationofthisRegulation.TheAI
OfficeandtheBoardshallassesswhetherthecodesofpracticecoverthe
obligationsprovidedforinArticles53and55,andshallregularlymonitor
andevaluatetheachievementoftheirobjectives.Theyshallpublishtheir
assessmentoftheadequacyofthecodesofpractice.
TheCommissionmay,bywayofanimplementingact,approveacodeof
practiceandgiveitageneralvaliditywithintheUnion.Thatimplementing
actshallbeadoptedinaccordancewiththeexaminationprocedurereferred
toinArticle98(2).
7.TheAIOfficemayinviteallprovidersofgeneral-purposeAImodelsto
adheretothecodesofpractice.Forprovidersofgeneral-purposeAImodels
notpresentingsystemicrisksthisadherencemaybelimitedtothe
obligationsprovidedforinArticle53,unlesstheydeclareexplicitlytheir
interesttojointhefullcode.
8.TheAIOfficeshall,asappropriate,alsoencourageandfacilitatethe
reviewandadaptationofthecodesofpractice,inparticularinlightof
emergingstandards.TheAIOfficeshallassistintheassessmentofavailable
standards.
9.Codesofpracticeshallbereadyatthelatestby2May2025.TheAI
Officeshalltakethenecessarysteps,includinginvitingproviderspursuant
toparagraph7.

--- Page 128 ---
If,by2August2025,acodeofpracticecannotbefinalised,oriftheAI
Officedeemsitisnotadequatefollowingitsassessmentunderparagraph6
ofthisArticle,theCommissionmayprovide,bymeansofimplementing
acts,commonrulesfortheimplementationoftheobligationsprovidedforin
Articles53and55,includingtheissuessetoutinparagraph2ofthisArticle.
Thoseimplementingactsshallbeadoptedinaccordancewiththe
examinationprocedurereferredtoinArticle98(2).
CHAPTERVI
MEASURESINSUPPORTOFINNOVATION
Article57
AIregulatorysandboxes
1.MemberStatesshallensurethattheircompetentauthoritiesestablishat
leastoneAIregulatorysandboxatnationallevel,whichshallbeoperational
by2August2026.Thatsandboxmayalsobeestablishedjointlywiththe
competentauthoritiesofotherMemberStates.TheCommissionmay
providetechnicalsupport,adviceandtoolsfortheestablishmentand
operationofAIregulatorysandboxes.
Theobligationunderthefirstsubparagraphmayalsobefulfilledby
participatinginanexistingsandboxinsofarasthatparticipationprovides
anequivalentlevelofnationalcoveragefortheparticipatingMemberStates.
2.AdditionalAIregulatorysandboxesatregionalorlocallevel,or
establishedjointlywiththecompetentauthoritiesofotherMemberStates
mayalsobeestablished.
3.TheEuropeanDataProtectionSupervisormayalsoestablishanAI
regulatorysandboxforUnioninstitutions,bodies,officesandagencies,and
mayexercisetherolesandthetasksofnationalcompetentauthoritiesin
accordancewiththisChapter.
4.MemberStatesshallensurethatthecompetentauthoritiesreferredtoin
paragraphs1and2allocatesufficientresourcestocomplywiththisArticle
effectivelyandinatimelymanner.Whereappropriate,nationalcompetent
authoritiesshallcooperatewithotherrelevantauthorities,andmayallowfor
theinvolvementofotheractorswithintheAIecosystem.ThisArticleshall
notaffectotherregulatorysandboxesestablishedunderUnionornational
law.MemberStatesshallensureanappropriatelevelofcooperation
betweentheauthoritiessupervisingthoseothersandboxesandthenational
competentauthorities.

--- Page 129 ---
5.AIregulatorysandboxesestablishedunderparagraph1shallprovidefor
acontrolledenvironmentthatfostersinnovationandfacilitatesthe
development,training,testingandvalidationofinnovativeAIsystemsfor
alimitedtimebeforetheirbeingplacedonthemarketorputintoservice
pursuanttoaspecificsandboxplanagreedbetweentheprovidersor
prospectiveprovidersandthecompetentauthority.Suchsandboxesmay
includetestinginrealworldconditionssupervisedtherein.
6.Competentauthoritiesshallprovide,asappropriate,guidance,
supervisionandsupportwithintheAIregulatorysandboxwithaviewto
identifyingrisks,inparticulartofundamentalrights,healthandsafety,
testing,mitigationmeasures,andtheireffectivenessinrelationtothe
obligationsandrequirementsofthisRegulationand,whererelevant,other
Unionandnationallawsupervisedwithinthesandbox.
7.Competentauthoritiesshallprovideprovidersandprospectiveproviders
participatingintheAIregulatorysandboxwithguidanceonregulatory
expectationsandhowtofulfiltherequirementsandobligationssetoutin
thisRegulation.
UponrequestoftheproviderorprospectiveprovideroftheAIsystem,the
competentauthorityshallprovideawrittenproofoftheactivities
successfullycarriedoutinthesandbox.Thecompetentauthorityshallalso
provideanexitreportdetailingtheactivitiescarriedoutinthesandboxand
therelatedresultsandlearningoutcomes.Providersmayusesuch
documentationtodemonstratetheircompliancewiththisRegulation
throughtheconformityassessmentprocessorrelevantmarketsurveillance
activities.Inthisregard,theexitreportsandthewrittenproofprovidedby
thenationalcompetentauthorityshallbetakenpositivelyintoaccountby
marketsurveillanceauthoritiesandnotifiedbodies,withaviewto
acceleratingconformityassessmentprocedurestoareasonableextent.
8.SubjecttotheconfidentialityprovisionsinArticle78,andwiththe
agreementoftheproviderorprospectiveprovider,theCommissionandthe
Boardshallbeauthorisedtoaccesstheexitreportsandshalltaketheminto
account,asappropriate,whenexercisingtheirtasksunderthisRegulation.If
boththeproviderorprospectiveproviderandthenationalcompetent
authorityexplicitlyagree,theexitreportmaybemadepubliclyavailable
throughthesingleinformationplatformreferredtointhisArticle.
9.TheestablishmentofAIregulatorysandboxesshallaimtocontributeto
thefollowingobjectives:
(a)improvinglegalcertaintytoachieveregulatorycompliancewiththisRegulationor,
whererelevant,otherapplicableUnionandnationallaw;
(b)supportingthesharingofbestpracticesthroughcooperationwiththeauthorities
involvedintheAIregulatorysandbox;

--- Page 130 ---
(c)fosteringinnovationandcompetitivenessandfacilitatingthedevelopmentofanAI
ecosystem;
(d)contributingtoevidence-basedregulatorylearning;
(e)facilitatingandacceleratingaccesstotheUnionmarketforAIsystems,in
particularwhenprovidedbySMEs,includingstart-ups.
10.Nationalcompetentauthoritiesshallensurethat,totheextentthe
innovativeAIsystemsinvolvetheprocessingofpersonaldataorotherwise
fallunderthesupervisoryremitofothernationalauthoritiesorcompetent
authoritiesprovidingorsupportingaccesstodata,thenationaldata
protectionauthoritiesandthoseothernationalorcompetentauthoritiesare
associatedwiththeoperationoftheAIregulatorysandboxandinvolvedin
thesupervisionofthoseaspectstotheextentoftheirrespectivetasksand
powers.
11.TheAIregulatorysandboxesshallnotaffectthesupervisoryor
correctivepowersofthecompetentauthoritiessupervisingthesandboxes,
includingatregionalorlocallevel.Anysignificantriskstohealthandsafety
andfundamentalrightsidentifiedduringthedevelopmentandtestingof
suchAIsystemsshallresultinanadequatemitigation.Nationalcompetent
authoritiesshallhavethepowertotemporarilyorpermanentlysuspendthe
testingprocess,ortheparticipationinthesandboxifnoeffectivemitigation
ispossible,andshallinformtheAIOfficeofsuchdecision.National
competentauthoritiesshallexercisetheirsupervisorypowerswithinthe
limitsoftherelevantlaw,usingtheirdiscretionarypowerswhen
implementinglegalprovisionsinrespectofaspecificAIregulatorysandbox
project,withtheobjectiveofsupportinginnovationinAIintheUnion.
12.ProvidersandprospectiveprovidersparticipatingintheAIregulatory
sandboxshallremainliableunderapplicableUnionandnationalliability
lawforanydamageinflictedonthirdpartiesasaresultofthe
experimentationtakingplaceinthesandbox.However,providedthatthe
prospectiveprovidersobservethespecificplanandthetermsandconditions
fortheirparticipationandfollowingoodfaiththeguidancegivenbythe
nationalcompetentauthority,noadministrativefinesshallbeimposedby
theauthoritiesforinfringementsofthisRegulation.Whereothercompetent
authoritiesresponsibleforotherUnionandnationallawwereactively
involvedinthesupervisionoftheAIsysteminthesandboxandprovided
guidanceforcompliance,noadministrativefinesshallbeimposedregarding
thatlaw.
13.TheAIregulatorysandboxesshallbedesignedandimplementedin
suchawaythat,whererelevant,theyfacilitatecross-bordercooperation
betweennationalcompetentauthorities.

--- Page 131 ---
14.Nationalcompetentauthoritiesshallcoordinatetheiractivitiesand
cooperatewithintheframeworkoftheBoard.
15.NationalcompetentauthoritiesshallinformtheAIOfficeandthe
Boardoftheestablishmentofasandbox,andmayaskthemforsupportand
guidance.TheAIOfficeshallmakepubliclyavailablealistofplannedand
existingsandboxesandkeepituptodateinordertoencouragemore
interactionintheAIregulatorysandboxesandcross-bordercooperation.
16.NationalcompetentauthoritiesshallsubmitannualreportstotheAI
OfficeandtotheBoard,fromoneyearaftertheestablishmentoftheAI
regulatorysandboxandeveryyearthereafteruntilitstermination,and
afinalreport.Thosereportsshallprovideinformationontheprogressand
resultsoftheimplementationofthosesandboxes,includingbestpractices,
incidents,lessonslearntandrecommendationsontheirsetupand,where
relevant,ontheapplicationandpossiblerevisionofthisRegulation,
includingitsdelegatedandimplementingacts,andontheapplicationof
otherUnionlawsupervisedbythecompetentauthoritieswithinthesandbox.
Thenationalcompetentauthoritiesshallmakethoseannualreportsor
abstractsthereofavailabletothepublic,online.TheCommissionshall,
whereappropriate,taketheannualreportsintoaccountwhenexercisingits
tasksunderthisRegulation.
17.TheCommissionshalldevelopasingleanddedicatedinterface
containingallrelevantinformationrelatedtoAIregulatorysandboxesto
allowstakeholderstointeractwithAIregulatorysandboxesandtoraise
enquirieswithcompetentauthorities,andtoseeknon-bindingguidanceon
theconformityofinnovativeproducts,services,businessmodelsembedding
AItechnologies,inaccordancewithArticle62(1),point(c).The
Commissionshallproactivelycoordinatewithnationalcompetent
authorities,whererelevant.
Article58
Detailedarrangementsfor,andfunctioningof,AIregulatorysandboxes
1.InordertoavoidfragmentationacrosstheUnion,theCommissionshall
adoptimplementingactsspecifyingthedetailedarrangementsforthe
establishment,development,implementation,operationandsupervisionof
theAIregulatorysandboxes.Theimplementingactsshallincludecommon
principlesonthefollowingissues:
(a)eligibilityandselectioncriteriaforparticipationintheAIregulatorysandbox;
(b)proceduresfortheapplication,participation,monitoring,exitingfromand
terminationoftheAIregulatorysandbox,includingthesandboxplanandtheexit
report;

--- Page 132 ---
(c)thetermsandconditionsapplicabletotheparticipants.
Thoseimplementingactsshallbeadoptedinaccordancewiththe
examinationprocedurereferredtoinArticle98(2).
2.Theimplementingactsreferredtoinparagraph1shallensure:
(a)thatAIregulatorysandboxesareopentoanyapplyingproviderorprospective
providerofanAIsystemwhofulfilseligibilityandselectioncriteria,whichshall
betransparentandfair,andthatnationalcompetentauthoritiesinformapplicantsof
theirdecisionwithinthreemonthsoftheapplication;
(b)thatAIregulatorysandboxesallowbroadandequalaccessandkeepupwith
demandforparticipation;providersandprospectiveprovidersmayalsosubmit
applicationsinpartnershipswithdeployersandotherrelevantthirdparties;
(c)thatthedetailedarrangementsfor,andconditionsconcerningAIregulatory
sandboxessupport,tothebestextentpossible,flexibilityfornationalcompetent
authoritiestoestablishandoperatetheirAIregulatorysandboxes;
(d)thataccesstotheAIregulatorysandboxesisfreeofchargeforSMEs,including
start-ups,withoutprejudicetoexceptionalcoststhatnationalcompetentauthorities
mayrecoverinafairandproportionatemanner;
(e)thattheyfacilitateprovidersandprospectiveproviders,bymeansofthelearning
outcomesoftheAIregulatorysandboxes,incomplyingwithconformity
assessmentobligationsunderthisRegulationandthevoluntaryapplicationofthe
codesofconductreferredtoinArticle95;
(f)thatAIregulatorysandboxesfacilitatetheinvolvementofotherrelevantactors
withintheAIecosystem,suchasnotifiedbodiesandstandardisationorganisations,
SMEs,includingstart-ups,enterprises,innovators,testingandexperimentation
facilities,researchandexperimentationlabsandEuropeanDigitalInnovationHubs,
centresofexcellence,individualresearchers,inordertoallowandfacilitate
cooperationwiththepublicandprivatesectors;
(g)thatprocedures,processesandadministrativerequirementsforapplication,
selection,participationandexitingtheAIregulatorysandboxaresimple,easily
intelligible,andclearlycommunicatedinordertofacilitatetheparticipationof
SMEs,includingstart-ups,withlimitedlegalandadministrativecapacitiesandare
streamlinedacrosstheUnion,inordertoavoidfragmentationandthatparticipation
inanAIregulatorysandboxestablishedbyaMemberState,orbytheEuropean
DataProtectionSupervisorismutuallyanduniformlyrecognisedandcarriesthe
samelegaleffectsacrosstheUnion;
(h)thatparticipationintheAIregulatorysandboxislimitedtoaperiodthatis
appropriatetothecomplexityandscaleoftheprojectandthatmaybeextendedby
thenationalcompetentauthority;
(i)thatAIregulatorysandboxesfacilitatethedevelopmentoftoolsandinfrastructure
fortesting,benchmarking,assessingandexplainingdimensionsofAIsystems
relevantforregulatorylearning,suchasaccuracy,robustnessandcybersecurity,as
wellasmeasurestomitigateriskstofundamentalrightsandsocietyatlarge.

--- Page 133 ---
3.ProspectiveprovidersintheAIregulatorysandboxes,inparticular
SMEsandstart-ups,shallbedirected,whererelevant,topre-deployment
servicessuchasguidanceontheimplementationofthisRegulation,toother
value-addingservicessuchashelpwithstandardisationdocumentsand
certification,testingandexperimentationfacilities,EuropeanDigital
InnovationHubsandcentresofexcellence.
4.Wherenationalcompetentauthoritiesconsiderauthorisingtestinginreal
worldconditionssupervisedwithintheframeworkofanAIregulatory
sandboxtobeestablishedunderthisArticle,theyshallspecificallyagreethe
termsandconditionsofsuchtestingand,inparticular,theappropriate
safeguardswiththeparticipants,withaviewtoprotectingfundamental
rights,healthandsafety.Whereappropriate,theyshallcooperatewithother
nationalcompetentauthoritieswithaviewtoensuringconsistentpractices
acrosstheUnion.
Article59
FurtherprocessingofpersonaldatafordevelopingcertainAIsystems
inthepublicinterestintheAIregulatorysandbox
1.IntheAIregulatorysandbox,personaldatalawfullycollectedforother
purposesmaybeprocessedsolelyforthepurposeofdeveloping,training
andtestingcertainAIsystemsinthesandboxwhenallofthefollowing
conditionsaremet:
(a)AIsystemsshallbedevelopedforsafeguardingsubstantialpublicinterestby
apublicauthorityoranothernaturalorlegalpersonandinoneormoreofthe
followingareas:
(i)publicsafetyandpublichealth,includingdiseasedetection,diagnosis
prevention,controlandtreatmentandimprovementofhealthcaresystems;
(ii)ahighlevelofprotectionandimprovementofthequalityoftheenvironment,
protectionofbiodiversity,protectionagainstpollution,greentransition
measures,climatechangemitigationandadaptationmeasures;
(iii) energysustainability;
(iv)safetyandresilienceoftransportsystemsandmobility,criticalinfrastructure
andnetworks;
(v)efficiencyandqualityofpublicadministrationandpublicservices;
(b)thedataprocessedarenecessaryforcomplyingwithoneormoreofthe
requirementsreferredtoinChapterIII,Section2wherethoserequirementscannot
effectivelybefulfilledbyprocessinganonymised,syntheticorothernon-personal
data;
(c)thereareeffectivemonitoringmechanismstoidentifyifanyhighriskstotherights
andfreedomsofthedatasubjects,asreferredtoinArticle35ofRegulation

--- Page 134 ---
(EU)2016/679andinArticle39ofRegulation(EU)2018/1725,mayariseduring
thesandboxexperimentation,aswellasresponsemechanismstopromptlymitigate
thoserisksand,wherenecessary,stoptheprocessing;
(d)anypersonaldatatobeprocessedinthecontextofthesandboxarein
afunctionallyseparate,isolatedandprotecteddataprocessingenvironmentunder
thecontroloftheprospectiveproviderandonlyauthorisedpersonshaveaccessto
thosedata;
(e)providerscanfurthersharetheoriginallycollecteddataonlyinaccordancewith
Uniondataprotectionlaw;anypersonaldatacreatedinthesandboxcannotbe
sharedoutsidethesandbox;
(f)anyprocessingofpersonaldatainthecontextofthesandboxneitherleadsto
measuresordecisionsaffectingthedatasubjectsnordoesitaffecttheapplication
oftheirrightslaiddowninUnionlawontheprotectionofpersonaldata;
(g)anypersonaldataprocessedinthecontextofthesandboxareprotectedbymeans
ofappropriatetechnicalandorganisationalmeasuresanddeletedoncethe
participationinthesandboxhasterminatedorthepersonaldatahasreachedthe
endofitsretentionperiod;
(h)thelogsoftheprocessingofpersonaldatainthecontextofthesandboxarekept
forthedurationoftheparticipationinthesandbox,unlessprovidedotherwiseby
Unionornationallaw;
(i)acompleteanddetaileddescriptionoftheprocessandrationalebehindthetraining,
testingandvalidationoftheAIsystemiskepttogetherwiththetestingresultsas
partofthetechnicaldocumentationreferredtoinAnnexIV;
(j)ashortsummaryoftheAIprojectdevelopedinthesandbox,itsobjectivesand
expectedresultsispublishedonthewebsiteofthecompetentauthorities;this
obligationshallnotcoversensitiveoperationaldatainrelationtotheactivitiesof
lawenforcement,bordercontrol,immigrationorasylumauthorities.
2.Forthepurposesoftheprevention,investigation,detectionor
prosecutionofcriminaloffencesortheexecutionofcriminalpenalties,
includingsafeguardingagainstandpreventingthreatstopublicsecurity,
underthecontrolandresponsibilityoflawenforcementauthorities,the
processingofpersonaldatainAIregulatorysandboxesshallbebasedon
aspecificUnionornationallawandsubjecttothesamecumulative
conditionsasreferredtoinparagraph1.
3.Paragraph1iswithoutprejudicetoUnionornationallawwhich
excludesprocessingofpersonaldataforotherpurposesthanthoseexplicitly
mentionedinthatlaw,aswellastoUnionornationallawlayingdownthe
basisfortheprocessingofpersonaldatawhichisnecessaryforthepurpose
ofdeveloping,testingortrainingofinnovativeAIsystemsoranyotherlegal
basis,incompliancewithUnionlawontheprotectionofpersonaldata.
Article60

--- Page 135 ---
Testingofhigh-riskAIsystemsinrealworldconditionsoutsideAI
regulatorysandboxes
1.Testingofhigh-riskAIsystemsinrealworldconditionsoutsideAI
regulatorysandboxesmaybeconductedbyprovidersorprospective
providersofhigh-riskAIsystemslistedinAnnexIII,inaccordancewith
thisArticleandthereal-worldtestingplanreferredtointhisArticle,without
prejudicetotheprohibitionsunderArticle5.
TheCommissionshall,bymeansofimplementingacts,specifythedetailed
elementsofthereal-worldtestingplan.Thoseimplementingactsshallbe
adoptedinaccordancewiththeexaminationprocedurereferredtoin
Article98(2).
ThisparagraphshallbewithoutprejudicetoUnionornationallawonthe
testinginrealworldconditionsofhigh-riskAIsystemsrelatedtoproducts
coveredbyUnionharmonisationlegislationlistedinAnnexI.
2.Providersorprospectiveprovidersmayconducttestingofhigh-riskAI
systemsreferredtoinAnnexIIIinrealworldconditionsatanytimebefore
theplacingonthemarketortheputtingintoserviceoftheAIsystemon
theirownorinpartnershipwithoneormoredeployersorprospective
deployers.
3.Thetestingofhigh-riskAIsystemsinrealworldconditionsunderthis
Articleshallbewithoutprejudicetoanyethicalreviewthatisrequiredby
Unionornationallaw.
4.Providersorprospectiveprovidersmayconductthetestinginrealworld
conditionsonlywhereallofthefollowingconditionsaremet:
(a)theproviderorprospectiveproviderhasdrawnupareal-worldtestingplanand
submittedittothemarketsurveillanceauthorityintheMemberStatewherethe
testinginrealworldconditionsistobeconducted;
(b)themarketsurveillanceauthorityintheMemberStatewherethetestinginreal
worldconditionsistobeconductedhasapprovedthetestinginrealworld
conditionsandthereal-worldtestingplan;wherethemarketsurveillanceauthority
hasnotprovidedananswerwithin30days,thetestinginrealworldconditionsand
thereal-worldtestingplanshallbeunderstoodtohavebeenapproved;where
nationallawdoesnotprovideforatacitapproval,thetestinginrealworld
conditionsshallremainsubjecttoanauthorisation;
(c)theproviderorprospectiveprovider,withtheexceptionofprovidersorprospective
providersofhigh-riskAIsystemsreferredtoinpoints1,6and7ofAnnexIIIin
theareasoflawenforcement,migration,asylumandbordercontrolmanagement,
andhigh-riskAIsystemsreferredtoinpoint2ofAnnexIIIhasregisteredthe
testinginrealworldconditionsinaccordancewithArticle71(4)withaUnion-wide
uniquesingleidentificationnumberandwiththeinformationspecifiedin
AnnexIX;theproviderorprospectiveproviderofhigh-riskAIsystemsreferredto
inpoints1,6and7ofAnnexIIIintheareasoflawenforcement,migration,

--- Page 136 ---
asylumandbordercontrolmanagement,hasregisteredthetestinginreal-world
conditionsinthesecurenon-publicsectionoftheEUdatabaseaccordingto
Article49(4),point(d),withaUnion-wideuniquesingleidentificationnumberand
withtheinformationspecifiedtherein;theproviderorprospectiveproviderof
high-riskAIsystemsreferredtoinpoint2ofAnnexIIIhasregisteredthetestingin
real-worldconditionsinaccordancewithArticle49(5);
(d)theproviderorprospectiveproviderconductingthetestinginrealworldconditions
isestablishedintheUnionorhasappointedalegalrepresentativewhois
establishedintheUnion;
(e)datacollectedandprocessedforthepurposeofthetestinginrealworldconditions
shallbetransferredtothirdcountriesonlyprovidedthatappropriateandapplicable
safeguardsunderUnionlawareimplemented;
(f)thetestinginrealworldconditionsdoesnotlastlongerthannecessarytoachieveits
objectivesandinanycasenotlongerthansixmonths,whichmaybeextendedfor
anadditionalperiodofsixmonths,subjecttopriornotificationbytheprovideror
prospectiveprovidertothemarketsurveillanceauthority,accompaniedbyan
explanationoftheneedforsuchanextension;
(g)thesubjectsofthetestinginrealworldconditionswhoarepersonsbelongingto
vulnerablegroupsduetotheirageordisability,areappropriatelyprotected;
(h)whereaproviderorprospectiveproviderorganisesthetestinginrealworld
conditionsincooperationwithoneormoredeployersorprospectivedeployers,the
latterhavebeeninformedofallaspectsofthetestingthatarerelevanttotheir
decisiontoparticipate,andgiventherelevantinstructionsforuseoftheAIsystem
referredtoinArticle13;theproviderorprospectiveproviderandthedeployeror
prospectivedeployershallconcludeanagreementspecifyingtheirrolesand
responsibilitieswithaviewtoensuringcompliancewiththeprovisionsfortesting
inrealworldconditionsunderthisRegulationandunderotherapplicableUnion
andnationallaw;
(i)thesubjectsofthetestinginrealworldconditionshavegiveninformedconsentin
accordancewithArticle61,orinthecaseoflawenforcement,wheretheseekingof
informedconsentwouldpreventtheAIsystemfrombeingtested,thetestingitself
andtheoutcomeofthetestingintherealworldconditionsshallnothaveany
negativeeffectonthesubjects,andtheirpersonaldatashallbedeletedafterthetest
isperformed;
(j)thetestinginrealworldconditionsiseffectivelyoverseenbytheprovideror
prospectiveprovider,aswellasbydeployersorprospectivedeployersthrough
personswhoaresuitablyqualifiedintherelevantfieldandhavethenecessary
capacity,trainingandauthoritytoperformtheirtasks;
(k)thepredictions,recommendationsordecisionsoftheAIsystemcanbeeffectively
reversedanddisregarded.
5.Anysubjectsofthetestinginrealworldconditions,ortheirlegally
designatedrepresentative,asappropriate,may,withoutanyresulting
detrimentandwithouthavingtoprovideanyjustification,withdrawfrom
thetestingatanytimebyrevokingtheirinformedconsentandmayrequest

--- Page 137 ---
theimmediateandpermanentdeletionoftheirpersonaldata.The
withdrawaloftheinformedconsentshallnotaffecttheactivitiesalready
carriedout.
6.InaccordancewithArticle75,MemberStatesshallconferontheir
marketsurveillanceauthoritiesthepowersofrequiringprovidersand
prospectiveproviderstoprovideinformation,ofcarryingoutunannounced
remoteoron-siteinspections,andofperformingchecksontheconductof
thetestinginrealworldconditionsandtherelatedhigh-riskAIsystems.
Marketsurveillanceauthoritiesshallusethosepowerstoensurethesafe
developmentoftestinginrealworldconditions.
7.Anyseriousincidentidentifiedinthecourseofthetestinginrealworld
conditionsshallbereportedtothenationalmarketsurveillanceauthorityin
accordancewithArticle73.Theproviderorprospectiveprovidershalladopt
immediatemitigationmeasuresor,failingthat,shallsuspendthetestingin
realworldconditionsuntilsuchmitigationtakesplace,orotherwise
terminateit.Theproviderorprospectiveprovidershallestablishaprocedure
forthepromptrecalloftheAIsystemuponsuchterminationofthetesting
inrealworldconditions.
8.Providersorprospectiveprovidersshallnotifythenationalmarket
surveillanceauthorityintheMemberStatewherethetestinginrealworld
conditionsistobeconductedofthesuspensionorterminationofthetesting
inrealworldconditionsandofthefinaloutcomes.
9.Theproviderorprospectiveprovidershallbeliableunderapplicable
Unionandnationalliabilitylawforanydamagecausedinthecourseoftheir
testinginrealworldconditions.
Article61
Informedconsenttoparticipateintestinginrealworldconditions
outsideAIregulatorysandboxes
1.ForthepurposeoftestinginrealworldconditionsunderArticle60,
freely-giveninformedconsentshallbeobtainedfromthesubjectsoftesting
priortotheirparticipationinsuchtestingandaftertheirhavingbeenduly
informedwithconcise,clear,relevant,andunderstandableinformation
regarding:
(a)thenatureandobjectivesofthetestinginrealworldconditionsandthepossible
inconveniencethatmaybelinkedtotheirparticipation;
(b)theconditionsunderwhichthetestinginrealworldconditionsistobeconducted,
includingtheexpecteddurationofthesubjectorsubjects’participation;
(c)theirrights,andtheguaranteesregardingtheirparticipation,inparticulartheirright
torefusetoparticipatein,andtherighttowithdrawfrom,testinginrealworld

--- Page 138 ---
conditionsatanytimewithoutanyresultingdetrimentandwithouthavingto
provideanyjustification;
(d)thearrangementsforrequestingthereversalorthedisregardingofthepredictions,
recommendationsordecisionsoftheAIsystem;
(e)theUnion-wideuniquesingleidentificationnumberofthetestinginrealworld
conditionsinaccordancewithArticle60(4)point(c),andthecontactdetailsofthe
provideroritslegalrepresentativefromwhomfurtherinformationcanbeobtained.
2.Theinformedconsentshallbedatedanddocumentedandacopyshall
begiventothesubjectsoftestingortheirlegalrepresentative.
Article62
Measuresforprovidersanddeployers,inparticularSMEs,including
start-ups
1.MemberStatesshallundertakethefollowingactions:
(a)provideSMEs,includingstart-ups,havingaregisteredofficeorabranchinthe
Union,withpriorityaccesstotheAIregulatorysandboxes,totheextentthatthey
fulfiltheeligibilityconditionsandselectioncriteria;thepriorityaccessshallnot
precludeotherSMEs,includingstart-ups,otherthanthosereferredtointhis
paragraphfromaccesstotheAIregulatorysandbox,providedthattheyalsofulfil
theeligibilityconditionsandselectioncriteria;
(b)organisespecificawarenessraisingandtrainingactivitiesontheapplicationofthis
RegulationtailoredtotheneedsofSMEsincludingstart-ups,deployersand,as
appropriate,localpublicauthorities;
(c)utiliseexistingdedicatedchannelsandwhereappropriate,establishnewonesfor
communicationwithSMEsincludingstart-ups,deployers,otherinnovatorsand,as
appropriate,localpublicauthoritiestoprovideadviceandrespondtoqueriesabout
theimplementationofthisRegulation,includingasregardsparticipationinAI
regulatorysandboxes;
(d)facilitatetheparticipationofSMEsandotherrelevantstakeholdersinthe
standardisationdevelopmentprocess.
2.ThespecificinterestsandneedsoftheSMEproviders,includingstart-
ups,shallbetakenintoaccountwhensettingthefeesforconformity
assessmentunderArticle43,reducingthosefeesproportionatelytotheir
size,marketsizeandotherrelevantindicators.
3.TheAIOfficeshallundertakethefollowingactions:
(a)providestandardisedtemplatesforareascoveredbythisRegulation,asspecified
bytheBoardinitsrequest;
(b)developandmaintainasingleinformationplatformprovidingeasytouse
informationinrelationtothisRegulationforalloperatorsacrosstheUnion;
(c)organiseappropriatecommunicationcampaignstoraiseawarenessaboutthe

--- Page 139 ---
obligationsarisingfromthisRegulation;
(d)evaluateandpromotetheconvergenceofbestpracticesinpublicprocurement
proceduresinrelationtoAIsystems.
Article63
Derogationsforspecificoperators
1.MicroenterpriseswithinthemeaningofRecommendation2003/361/EC
maycomplywithcertainelementsofthequalitymanagementsystem
requiredbyArticle17ofthisRegulationinasimplifiedmanner,provided
thattheydonothavepartnerenterprisesorlinkedenterpriseswithinthe
meaningofthatRecommendation.Forthatpurpose,theCommissionshall
developguidelinesontheelementsofthequalitymanagementsystemwhich
maybecompliedwithinasimplifiedmannerconsideringtheneedsof
microenterprises,withoutaffectingthelevelofprotectionortheneedfor
compliancewiththerequirementsinrespectofhigh-riskAIsystems.
2.Paragraph1ofthisArticleshallnotbeinterpretedasexemptingthose
operatorsfromfulfillinganyotherrequirementsorobligationslaiddownin
thisRegulation,includingthoseestablishedinArticles9,10,11,12,13,14,
15,72and73.
CHAPTERVII
GOVERNANCE
SECTION1
GovernanceatUnionlevel
Article64
AIOffice
1.TheCommissionshalldevelopUnionexpertiseandcapabilitiesinthe
fieldofAIthroughtheAIOffice.
2.MemberStatesshallfacilitatethetasksentrustedtotheAIOffice,as
reflectedinthisRegulation.
Article65
EstablishmentandstructureoftheEuropeanArtificialIntelligence
Board

--- Page 140 ---
1.AEuropeanArtificialIntelligenceBoard(the‘Board’)ishereby
established.
2.TheBoardshallbecomposedofonerepresentativeperMemberState.
TheEuropeanDataProtectionSupervisorshallparticipateasobserver.The
AIOfficeshallalsoattendtheBoard’smeetings,withouttakingpartinthe
votes.OthernationalandUnionauthorities,bodiesorexpertsmaybe
invitedtothemeetingsbytheBoardonacasebycasebasis,wherethe
issuesdiscussedareofrelevanceforthem.
3.EachrepresentativeshallbedesignatedbytheirMemberStatefor
aperiodofthreeyears,renewableonce.
4.MemberStatesshallensurethattheirrepresentativesontheBoard:
(a)havetherelevantcompetencesandpowersintheirMemberStatesoasto
contributeactivelytotheachievementoftheBoard’stasksreferredtoin
Article66;
(b)aredesignatedasasinglecontactpointvis-à-vistheBoardand,whereappropriate,
takingintoaccountMemberStates’needs,asasinglecontactpointfor
stakeholders;
(c)areempoweredtofacilitateconsistencyandcoordinationbetweennational
competentauthoritiesintheirMemberStateasregardstheimplementationofthis
Regulation,includingthroughthecollectionofrelevantdataandinformationfor
thepurposeoffulfillingtheirtasksontheBoard.
5.ThedesignatedrepresentativesoftheMemberStatesshalladoptthe
Board’srulesofprocedurebyatwo-thirdsmajority.Therulesofprocedure
shall,inparticular,laydownproceduresfortheselectionprocess,the
durationofthemandateof,andspecificationsofthetasksof,theChair,
detailedarrangementsforvoting,andtheorganisationoftheBoard’s
activitiesandthoseofitssub-groups.
6.TheBoardshallestablishtwostandingsub-groupstoprovideaplatform
forcooperationandexchangeamongmarketsurveillanceauthoritiesand
notifyingauthoritiesaboutissuesrelatedtomarketsurveillanceandnotified
bodiesrespectively.
Thestandingsub-groupformarketsurveillanceshouldactasthe
administrativecooperationgroup(ADCO)forthisRegulationwithinthe
meaningofArticle30ofRegulation(EU)2019/1020.
TheBoardmayestablishotherstandingortemporarysub-groupsas
appropriateforthepurposeofexaminingspecificissues.Whereappropriate,
representativesoftheadvisoryforumreferredtoinArticle67maybe
invitedtosuchsub-groupsortospecificmeetingsofthosesubgroupsas
observers.

--- Page 141 ---
7.TheBoardshallbeorganisedandoperatedsoastosafeguardthe
objectivityandimpartialityofitsactivities.
8.TheBoardshallbechairedbyoneoftherepresentativesoftheMember
States.TheAIOfficeshallprovidethesecretariatfortheBoard,convenethe
meetingsuponrequestoftheChair,andpreparetheagendainaccordance
withthetasksoftheBoardpursuanttothisRegulationanditsrulesof
procedure.
Article66
TasksoftheBoard
TheBoardshalladviseandassisttheCommissionandtheMemberStatesin
ordertofacilitatetheconsistentandeffectiveapplicationofthisRegulation.
Tothatend,theBoardmayinparticular:
(a)contributetothecoordinationamongnationalcompetentauthoritiesresponsiblefor
theapplicationofthisRegulationand,incooperationwithandsubjecttothe
agreementofthemarketsurveillanceauthoritiesconcerned,supportjointactivities
ofmarketsurveillanceauthoritiesreferredtoinArticle74(11);
(b)collectandsharetechnicalandregulatoryexpertiseandbestpracticesamong
MemberStates;
(c)provideadviceontheimplementationofthisRegulation,inparticularasregards
theenforcementofrulesongeneral-purposeAImodels;
(d)contributetotheharmonisationofadministrativepracticesintheMemberStates,
includinginrelationtothederogationfromtheconformityassessmentprocedures
referredtoinArticle46,thefunctioningofAIregulatorysandboxes,andtestingin
realworldconditionsreferredtoinArticles57,59and60;
(e)attherequestoftheCommissionoronitsowninitiative,issuerecommendations
andwrittenopinionsonanyrelevantmattersrelatedtotheimplementationofthis
Regulationandtoitsconsistentandeffectiveapplication,including:
(i)onthedevelopmentandapplicationofcodesofconductandcodesofpractice
pursuanttothisRegulation,aswellasoftheCommission’sguidelines;
(ii)theevaluationandreviewofthisRegulationpursuanttoArticle112,including
asregardstheseriousincidentreportsreferredtoinArticle73,andthe
functioningoftheEUdatabasereferredtoinArticle71,thepreparationofthe
delegatedorimplementingacts,andasregardspossiblealignmentsofthis
RegulationwiththeUnionharmonisationlegislationlistedinAnnexI;
(iii)ontechnicalspecificationsorexistingstandardsregardingtherequirementsset
outinChapterIII,Section2;
(iv)ontheuseofharmonisedstandardsorcommonspecificationsreferredtoin
Articles40and41;
(v)trends,suchasEuropeanglobalcompetitivenessinAI,theuptakeofAIinthe

--- Page 142 ---
Union,andthedevelopmentofdigitalskills;
(vi)trendsontheevolvingtypologyofAIvaluechains,inparticularonthe
resultingimplicationsintermsofaccountability;
(vii)onthepotentialneedforamendmenttoAnnexIIIinaccordancewithArticle7,
andonthepotentialneedforpossiblerevisionofArticle5pursuantto
Article112,takingintoaccountrelevantavailableevidenceandthelatest
developmentsintechnology;
(f)supporttheCommissioninpromotingAIliteracy,publicawarenessand
understandingofthebenefits,risks,safeguardsandrightsandobligationsin
relationtotheuseofAIsystems;
(g)facilitatethedevelopmentofcommoncriteriaandasharedunderstandingamong
marketoperatorsandcompetentauthoritiesoftherelevantconceptsprovidedforin
thisRegulation,includingbycontributingtothedevelopmentofbenchmarks;
(h)cooperate,asappropriate,withotherUnioninstitutions,bodies,officesand
agencies,aswellasrelevantUnionexpertgroupsandnetworks,inparticularinthe
fieldsofproductsafety,cybersecurity,competition,digitalandmediaservices,
financialservices,consumerprotection,dataandfundamentalrightsprotection;
(i)contributetoeffectivecooperationwiththecompetentauthoritiesofthirdcountries
andwithinternationalorganisations;
(j)assistnationalcompetentauthoritiesandtheCommissionindevelopingthe
organisationalandtechnicalexpertiserequiredfortheimplementationofthis
Regulation,includingbycontributingtotheassessmentoftrainingneedsforstaff
ofMemberStatesinvolvedinimplementingthisRegulation;
(k)assisttheAIOfficeinsupportingnationalcompetentauthoritiesinthe
establishmentanddevelopmentofAIregulatorysandboxes,andfacilitate
cooperationandinformation-sharingamongAIregulatorysandboxes;
(l)contributeto,andproviderelevantadviceon,thedevelopmentofguidance
documents;
(m)advisetheCommissioninrelationtointernationalmattersonAI;
(n)provideopinionstotheCommissiononthequalifiedalertsregardinggeneral-
purposeAImodels;
(o)receiveopinionsbytheMemberStatesonqualifiedalertsregardinggeneral-
purposeAImodels,andonnationalexperiencesandpracticesonthemonitoring
andenforcementofAIsystems,inparticularsystemsintegratingthegeneral-
purposeAImodels.
Article67
Advisoryforum
1.Anadvisoryforumshallbeestablishedtoprovidetechnicalexpertise
andadvisetheBoardandtheCommission,andtocontributetotheirtasks
underthisRegulation.

--- Page 143 ---
2.Themembershipoftheadvisoryforumshallrepresentabalanced
selectionofstakeholders,includingindustry,start-ups,SMEs,civilsociety
andacademia.Themembershipoftheadvisoryforumshallbebalanced
withregardtocommercialandnon-commercialinterestsand,withinthe
categoryofcommercialinterests,withregardtoSMEsandother
undertakings.
3.TheCommissionshallappointthemembersoftheadvisoryforum,in
accordancewiththecriteriasetoutinparagraph2,fromamongst
stakeholderswithrecognisedexpertiseinthefieldofAI.
4.Thetermofofficeofthemembersoftheadvisoryforumshallbetwo
years,whichmaybeextendedbyuptonomorethanfouryears.
5.TheFundamentalRightsAgency,ENISA,theEuropeanCommitteefor
Standardization(CEN),theEuropeanCommitteeforElectrotechnical
Standardization(CENELEC),andtheEuropeanTelecommunications
StandardsInstitute(ETSI)shallbepermanentmembersoftheadvisory
forum.
6.Theadvisoryforumshalldrawupitsrulesofprocedure.Itshallelect
twoco-chairsfromamongitsmembers,inaccordancewithcriteriasetoutin
paragraph2.Thetermofofficeoftheco-chairsshallbetwoyears,
renewableonce.
7.Theadvisoryforumshallholdmeetingsatleasttwiceayear.The
advisoryforummayinviteexpertsandotherstakeholderstoitsmeetings.
8.Theadvisoryforummayprepareopinions,recommendationsandwritten
contributionsattherequestoftheBoardortheCommission.
9.Theadvisoryforummayestablishstandingortemporarysub-groupsas
appropriateforthepurposeofexaminingspecificquestionsrelatedtothe
objectivesofthisRegulation.
10.Theadvisoryforumshallprepareanannualreportonitsactivities.That
reportshallbemadepubliclyavailable.
Article68
Scientificpanelofindependentexperts
1.TheCommissionshall,bymeansofanimplementingact,make
provisionsontheestablishmentofascientificpanelofindependentexperts
(the‘scientificpanel’)intendedtosupporttheenforcementactivitiesunder
thisRegulation.Thatimplementingactshallbeadoptedinaccordancewith
theexaminationprocedurereferredtoinArticle98(2).

--- Page 144 ---
2.ThescientificpanelshallconsistofexpertsselectedbytheCommission
onthebasisofup-to-datescientificortechnicalexpertiseinthefieldofAI
necessaryforthetaskssetoutinparagraph3,andshallbeableto
demonstratemeetingallofthefollowingconditions:
(a)havingparticularexpertiseandcompetenceandscientificortechnicalexpertisein
thefieldofAI;
(b)independencefromanyproviderofAIsystemsorgeneral-purposeAImodels;
(c)anabilitytocarryoutactivitiesdiligently,accuratelyandobjectively.
TheCommission,inconsultationwiththeBoard,shalldeterminethe
numberofexpertsonthepanelinaccordancewiththerequiredneedsand
shallensurefairgenderandgeographicalrepresentation.
3.ThescientificpanelshalladviseandsupporttheAIOffice,inparticular
withregardtothefollowingtasks:
(a)supportingtheimplementationandenforcementofthisRegulationasregards
general-purposeAImodelsandsystems,inparticularby:
(i)alertingtheAIOfficeofpossiblesystemicrisksatUnionlevelofgeneral-
purposeAImodels,inaccordancewithArticle90;
(ii)contributingtothedevelopmentoftoolsandmethodologiesforevaluating
capabilitiesofgeneral-purposeAImodelsandsystems,includingthrough
benchmarks;
(iii)providingadviceontheclassificationofgeneral-purposeAImodelswith
systemicrisk;
(iv)providingadviceontheclassificationofvariousgeneral-purposeAImodels
andsystems;
(v)contributingtothedevelopmentoftoolsandtemplates;
(b)supportingtheworkofmarketsurveillanceauthorities,attheirrequest;
(c)supportingcross-bordermarketsurveillanceactivitiesasreferredtoin
Article74(11),withoutprejudicetothepowersofmarketsurveillanceauthorities;
(d)supportingtheAIOfficeincarryingoutitsdutiesinthecontextoftheUnion
safeguardprocedurepursuanttoArticle81.
4.Theexpertsonthescientificpanelshallperformtheirtaskswith
impartialityandobjectivity,andshallensuretheconfidentialityof
informationanddataobtainedincarryingouttheirtasksandactivities.They
shallneitherseeknortakeinstructionsfromanyonewhenexercisingtheir
tasksunderparagraph3.Eachexpertshalldrawupadeclarationofinterests,
whichshallbemadepubliclyavailable.TheAIOfficeshallestablish
systemsandprocedurestoactivelymanageandpreventpotentialconflicts
ofinterest.

--- Page 145 ---
5.Theimplementingactreferredtoinparagraph1shallincludeprovisions
ontheconditions,proceduresanddetailedarrangementsforthescientific
panelanditsmemberstoissuealerts,andtorequesttheassistanceoftheAI
Officefortheperformanceofthetasksofthescientificpanel.
Article69
AccesstothepoolofexpertsbytheMemberStates
1.MemberStatesmaycalluponexpertsofthescientificpaneltosupport
theirenforcementactivitiesunderthisRegulation.
2.TheMemberStatesmayberequiredtopayfeesfortheadviceand
supportprovidedbytheexperts.Thestructureandtheleveloffeesaswell
asthescaleandstructureofrecoverablecostsshallbesetoutinthe
implementingactreferredtoinArticle68(1),takingintoaccountthe
objectivesoftheadequateimplementationofthisRegulation,cost-
effectivenessandthenecessityofensuringeffectiveaccesstoexpertsforall
MemberStates.
3.TheCommissionshallfacilitatetimelyaccesstotheexpertsbythe
MemberStates,asneeded,andensurethatthecombinationofsupport
activitiescarriedoutbyUnionAItestingsupportpursuanttoArticle84and
expertspursuanttothisArticleisefficientlyorganisedandprovidesthebest
possibleaddedvalue.
SECTION2
Nationalcompetentauthorities
Article70
Designationofnationalcompetentauthoritiesandsinglepointsof
contact
1.EachMemberStateshallestablishordesignateasnationalcompetent
authoritiesatleastonenotifyingauthorityandatleastonemarket
surveillanceauthorityforthepurposesofthisRegulation.Thosenational
competentauthoritiesshallexercisetheirpowersindependently,impartially
andwithoutbiassoastosafeguardtheobjectivityoftheiractivitiesand
tasks,andtoensuretheapplicationandimplementationofthisRegulation.
Themembersofthoseauthoritiesshallrefrainfromanyactionincompatible
withtheirduties.Providedthatthoseprinciplesareobserved,suchactivities
andtasksmaybeperformedbyoneormoredesignatedauthorities,in
accordancewiththeorganisationalneedsoftheMemberState.

--- Page 146 ---
2.MemberStatesshallcommunicatetotheCommissiontheidentityofthe
notifyingauthoritiesandthemarketsurveillanceauthoritiesandthetasksof
thoseauthorities,aswellasanysubsequentchangesthereto.MemberStates
shallmakepubliclyavailableinformationonhowcompetentauthoritiesand
singlepointsofcontactcanbecontacted,throughelectroniccommunication
meansby2August2025.MemberStatesshalldesignateamarket
surveillanceauthoritytoactasthesinglepointofcontactforthisRegulation,
andshallnotifytheCommissionoftheidentityofthesinglepointofcontact.
TheCommissionshallmakealistofthesinglepointsofcontactpublicly
available.
3.MemberStatesshallensurethattheirnationalcompetentauthoritiesare
providedwithadequatetechnical,financialandhumanresources,andwith
infrastructuretofulfiltheirtaskseffectivelyunderthisRegulation.In
particular,thenationalcompetentauthoritiesshallhaveasufficientnumber
ofpersonnelpermanentlyavailablewhosecompetencesandexpertiseshall
includeanin-depthunderstandingofAItechnologies,dataanddata
computing,personaldataprotection,cybersecurity,fundamentalrights,
healthandsafetyrisksandknowledgeofexistingstandardsandlegal
requirements.MemberStatesshallassessand,ifnecessary,update
competenceandresourcerequirementsreferredtointhisparagraphonan
annualbasis.
4.Nationalcompetentauthoritiesshalltakeappropriatemeasurestoensure
anadequatelevelofcybersecurity.
5.Whenperformingtheirtasks,thenationalcompetentauthoritiesshallact
inaccordancewiththeconfidentialityobligationssetoutinArticle78.
6.By2August2025,andonceeverytwoyearsthereafter,MemberStates
shallreporttotheCommissiononthestatusofthefinancialandhuman
resourcesofthenationalcompetentauthorities,withanassessmentoftheir
adequacy.TheCommissionshalltransmitthatinformationtotheBoardfor
discussionandpossiblerecommendations.
7.TheCommissionshallfacilitatetheexchangeofexperiencebetween
nationalcompetentauthorities.
8.Nationalcompetentauthoritiesmayprovideguidanceandadviceonthe
implementationofthisRegulation,inparticulartoSMEsincludingstart-ups,
takingintoaccounttheguidanceandadviceoftheBoardandthe
Commission,asappropriate.Whenevernationalcompetentauthorities
intendtoprovideguidanceandadvicewithregardtoanAIsysteminareas
coveredbyotherUnionlaw,thenationalcompetentauthoritiesunderthat
Unionlawshallbeconsulted,asappropriate.

--- Page 147 ---
9.WhereUnioninstitutions,bodies,officesoragenciesfallwithinthe
scopeofthisRegulation,theEuropeanDataProtectionSupervisorshallact
asthecompetentauthorityfortheirsupervision.
CHAPTERVIII
EUDATABASEFORHIGH-RISKAISYSTEMS
Article71
EUdatabaseforhigh-riskAIsystemslistedinAnnexIII
1.TheCommissionshall,incollaborationwiththeMemberStates,setup
andmaintainanEUdatabasecontaininginformationreferredtoin
paragraphs2and3ofthisArticleconcerninghigh-riskAIsystemsreferred
toinArticle6(2)whichareregisteredinaccordancewithArticles49and60
andAIsystemsthatarenotconsideredashigh-riskpursuanttoArticle6(3)
andwhichareregisteredinaccordancewithArticle6(4)andArticle49.
Whensettingthefunctionalspecificationsofsuchdatabase,theCommission
shallconsulttherelevantexperts,andwhenupdatingthefunctional
specificationsofsuchdatabase,theCommissionshallconsulttheBoard.
2.ThedatalistedinSectionsAandBofAnnexVIIIshallbeenteredinto
theEUdatabasebytheprovideror,whereapplicable,bytheauthorised
representative.
3.ThedatalistedinSectionCofAnnexVIIIshallbeenteredintotheEU
databasebythedeployerwhois,orwhoactsonbehalfof,apublicauthority,
agencyorbody,inaccordancewithArticle49(3)and(4).
4.WiththeexceptionofthesectionreferredtoinArticle49(4)and
Article60(4),point(c),theinformationcontainedintheEUdatabase
registeredinaccordancewithArticle49shallbeaccessibleandpublicly
availableinauser-friendlymanner.Theinformationshouldbeeasily
navigableandmachine-readable.Theinformationregisteredinaccordance
withArticle60shallbeaccessibleonlytomarketsurveillanceauthorities
andtheCommission,unlesstheprospectiveproviderorproviderhasgiven
consentforalsomakingtheinformationaccessiblethepublic.
5.TheEUdatabaseshallcontainpersonaldataonlyinsofarasnecessary
forcollectingandprocessinginformationinaccordancewiththisRegulation.
Thatinformationshallincludethenamesandcontactdetailsofnatural
personswhoareresponsibleforregisteringthesystemandhavethelegal
authoritytorepresenttheproviderorthedeployer,asapplicable.
6.TheCommissionshallbethecontrolleroftheEUdatabase.Itshall
makeavailabletoproviders,prospectiveprovidersanddeployersadequate

--- Page 148 ---
technicalandadministrativesupport.TheEUdatabaseshallcomplywiththe
applicableaccessibilityrequirements.
CHAPTERIX
POST-MARKETMONITORING,INFORMATIONSHARINGAND
MARKETSURVEILLANCE
SECTION1
Post-marketmonitoring
Article72
Post-marketmonitoringbyprovidersandpost-marketmonitoringplan
forhigh-riskAIsystems
1.Providersshallestablishanddocumentapost-marketmonitoringsystem
inamannerthatisproportionatetothenatureoftheAItechnologiesandthe
risksofthehigh-riskAIsystem.
2.Thepost-marketmonitoringsystemshallactivelyandsystematically
collect,documentandanalyserelevantdatawhichmaybeprovidedby
deployersorwhichmaybecollectedthroughothersourcesonthe
performanceofhigh-riskAIsystemsthroughouttheirlifetime,andwhich
allowtheprovidertoevaluatethecontinuouscomplianceofAIsystemswith
therequirementssetoutinChapterIII,Section2.Whererelevant,post-
marketmonitoringshallincludeananalysisoftheinteractionwithotherAI
systems.Thisobligationshallnotcoversensitiveoperationaldataof
deployerswhicharelaw-enforcementauthorities.
3.Thepost-marketmonitoringsystemshallbebasedonapost-market
monitoringplan.Thepost-marketmonitoringplanshallbepartofthe
technicaldocumentationreferredtoinAnnexIV.TheCommissionshall
adoptanimplementingactlayingdowndetailedprovisionsestablishing
atemplateforthepost-marketmonitoringplanandthelistofelementstobe
includedintheplanby2February2026.Thatimplementingactshallbe
adoptedinaccordancewiththeexaminationprocedurereferredtoin
Article98(2).
4.Forhigh-riskAIsystemscoveredbytheUnionharmonisationlegislation
listedinSectionAofAnnexI,whereapost-marketmonitoringsystemand
planarealreadyestablishedunderthatlegislation,inordertoensure
consistency,avoidduplicationsandminimiseadditionalburdens,providers
shallhaveachoiceofintegrating,asappropriate,thenecessaryelements
describedinparagraphs1,2and3usingthetemplatereferredinparagraph3

--- Page 149 ---
intosystemsandplansalreadyexistingunderthatlegislation,providedthat
itachievesanequivalentlevelofprotection.
Thefirstsubparagraphofthisparagraphshallalsoapplytohigh-riskAI
systemsreferredtoinpoint5ofAnnexIIIplacedonthemarketorputinto
servicebyfinancialinstitutionsthataresubjecttorequirementsunderUnion
financialserviceslawregardingtheirinternalgovernance,arrangementsor
processes.
SECTION2
Sharingofinformationonseriousincidents
Article73
Reportingofseriousincidents
1.Providersofhigh-riskAIsystemsplacedontheUnionmarketshall
reportanyseriousincidenttothemarketsurveillanceauthoritiesofthe
MemberStateswherethatincidentoccurred.
2.Thereportreferredtoinparagraph1shallbemadeimmediatelyafterthe
providerhasestablishedacausallinkbetweentheAIsystemandtheserious
incidentorthereasonablelikelihoodofsuchalink,and,inanyevent,not
laterthan15daysaftertheprovideror,whereapplicable,thedeployer,
becomesawareoftheseriousincident.
Theperiodforthereportingreferredtointhefirstsubparagraphshalltake
accountoftheseverityoftheseriousincident.
3.Notwithstandingparagraph2ofthisArticle,intheeventofawidespread
infringementoraseriousincidentasdefinedinArticle3,point(49)(b),the
reportreferredtoinparagraph1ofthisArticleshallbeprovided
immediately,andnotlaterthantwodaysaftertheprovideror,where
applicable,thedeployerbecomesawareofthatincident.
4.Notwithstandingparagraph2,intheeventofthedeathofaperson,the
reportshallbeprovidedimmediatelyaftertheproviderorthedeployerhas
established,orassoonasitsuspects,acausalrelationshipbetweenthehigh-
riskAIsystemandtheseriousincident,butnotlaterthan10daysafterthe
dateonwhichtheprovideror,whereapplicable,thedeployerbecomes
awareoftheseriousincident.
5.Wherenecessarytoensuretimelyreporting,theprovideror,where
applicable,thedeployer,maysubmitaninitialreportthatisincomplete,
followedbyacompletereport.

--- Page 150 ---
6.Followingthereportingofaseriousincidentpursuanttoparagraph1,
theprovidershall,withoutdelay,performthenecessaryinvestigationsin
relationtotheseriousincidentandtheAIsystemconcerned.Thisshall
includeariskassessmentoftheincident,andcorrectiveaction.
Theprovidershallcooperatewiththecompetentauthorities,andwhere
relevantwiththenotifiedbodyconcerned,duringtheinvestigationsreferred
tointhefirstsubparagraph,andshallnotperformanyinvestigationwhich
involvesalteringtheAIsystemconcernedinawaywhichmayaffectany
subsequentevaluationofthecausesoftheincident,priortoinformingthe
competentauthoritiesofsuchaction.
7.Uponreceivinganotificationrelatedtoaseriousincidentreferredtoin
Article3,point(49)(c),therelevantmarketsurveillanceauthorityshall
informthenationalpublicauthoritiesorbodiesreferredtoinArticle77(1).
TheCommissionshalldevelopdedicatedguidancetofacilitatecompliance
withtheobligationssetoutinparagraph1ofthisArticle.Thatguidance
shallbeissuedby2August2025,andshallbeassessedregularly.
8.Themarketsurveillanceauthorityshalltakeappropriatemeasures,as
providedforinArticle19ofRegulation(EU)2019/1020,withinsevendays
fromthedateitreceivedthenotificationreferredtoinparagraph1ofthis
Article,andshallfollowthenotificationproceduresasprovidedinthat
Regulation.
9.Forhigh-riskAIsystemsreferredtoinAnnexIIIthatareplacedonthe
marketorputintoservicebyprovidersthataresubjecttoUnionlegislative
instrumentslayingdownreportingobligationsequivalenttothosesetoutin
thisRegulation,thenotificationofseriousincidentsshallbelimitedtothose
referredtoinArticle3,point(49)(c).
10.Forhigh-riskAIsystemswhicharesafetycomponentsofdevices,or
arethemselvesdevices,coveredbyRegulations(EU)2017/745and(EU)
2017/746,thenotificationofseriousincidentsshallbelimitedtothose
referredtoinArticle3,point(49)(c)ofthisRegulation,andshallbemadeto
thenationalcompetentauthoritychosenforthatpurposebytheMember
Stateswheretheincidentoccurred.
11.Nationalcompetentauthoritiesshallimmediatelynotifythe
Commissionofanyseriousincident,whetherornottheyhavetakenaction
onit,inaccordancewithArticle20ofRegulation(EU)2019/1020.
SECTION3
Enforcement

--- Page 151 ---
Article74
MarketsurveillanceandcontrolofAIsystemsintheUnionmarket
1.Regulation(EU)2019/1020shallapplytoAIsystemscoveredbythis
Regulation.ForthepurposesoftheeffectiveenforcementofthisRegulation:
(a)anyreferencetoaneconomicoperatorunderRegulation(EU)2019/1020shallbe
understoodasincludingalloperatorsidentifiedinArticle2(1)ofthisRegulation;
(b)anyreferencetoaproductunderRegulation(EU)2019/1020shallbeunderstood
asincludingallAIsystemsfallingwithinthescopeofthisRegulation.
2.AspartoftheirreportingobligationsunderArticle34(4)ofRegulation
(EU)2019/1020,themarketsurveillanceauthoritiesshallreportannuallyto
theCommissionandrelevantnationalcompetitionauthoritiesany
informationidentifiedinthecourseofmarketsurveillanceactivitiesthat
maybeofpotentialinterestfortheapplicationofUnionlawoncompetition
rules.TheyshallalsoannuallyreporttotheCommissionabouttheuseof
prohibitedpracticesthatoccurredduringthatyearandaboutthemeasures
taken.
3.Forhigh-riskAIsystemsrelatedtoproductscoveredbytheUnion
harmonisationlegislationlistedinSectionAofAnnexI,themarket
surveillanceauthorityforthepurposesofthisRegulationshallbethe
authorityresponsibleformarketsurveillanceactivitiesdesignatedunder
thoselegalacts.
Byderogationfromthefirstsubparagraph,andinappropriatecircumstances,
MemberStatesmaydesignateanotherrelevantauthoritytoactasamarket
surveillanceauthority,providedtheyensurecoordinationwiththerelevant
sectoralmarketsurveillanceauthoritiesresponsiblefortheenforcementof
theUnionharmonisationlegislationlistedinAnnexI.
4.TheproceduresreferredtoinArticles79to83ofthisRegulationshall
notapplytoAIsystemsrelatedtoproductscoveredbytheUnion
harmonisationlegislationlistedinsectionAofAnnexI,wheresuchlegal
actsalreadyprovideforproceduresensuringanequivalentlevelof
protectionandhavingthesameobjective.Insuchcases,therelevantsectoral
proceduresshallapplyinstead.
5.Withoutprejudicetothepowersofmarketsurveillanceauthoritiesunder
Article14ofRegulation(EU)2019/1020,forthepurposeofensuringthe
effectiveenforcementofthisRegulation,marketsurveillanceauthorities
mayexercisethepowersreferredtoinArticle14(4),points(d)and(j),of
thatRegulationremotely,asappropriate.
6.Forhigh-riskAIsystemsplacedonthemarket,putintoservice,orused
byfinancialinstitutionsregulatedbyUnionfinancialserviceslaw,the
marketsurveillanceauthorityforthepurposesofthisRegulationshallbethe

--- Page 152 ---
relevantnationalauthorityresponsibleforthefinancialsupervisionofthose
institutionsunderthatlegislationinsofarastheplacingonthemarket,
puttingintoservice,ortheuseoftheAIsystemisindirectconnectionwith
theprovisionofthosefinancialservices.
7.Bywayofderogationfromparagraph6,inappropriatecircumstances,
andprovidedthatcoordinationisensured,anotherrelevantauthoritymaybe
identifiedbytheMemberStateasmarketsurveillanceauthorityforthe
purposesofthisRegulation.
Nationalmarketsurveillanceauthoritiessupervisingregulatedcredit
institutionsregulatedunderDirective2013/36/EU,whichareparticipating
intheSingleSupervisoryMechanismestablishedbyRegulation(EU)
No1024/2013,shouldreport,withoutdelay,totheEuropeanCentralBank
anyinformationidentifiedinthecourseoftheirmarketsurveillance
activitiesthatmaybeofpotentialinterestfortheprudentialsupervisory
tasksoftheEuropeanCentralBankspecifiedinthatRegulation.
8.Forhigh-riskAIsystemslistedinpoint1ofAnnexIIItothisRegulation,
insofarasthesystemsareusedforlawenforcementpurposes,border
managementandjusticeanddemocracy,andforhigh-riskAIsystemslisted
inpoints6,7and8ofAnnexIIItothisRegulation,MemberStatesshall
designateasmarketsurveillanceauthoritiesforthepurposesofthis
Regulationeitherthecompetentdataprotectionsupervisoryauthorities
underRegulation(EU)2016/679orDirective(EU)2016/680,oranyother
authoritydesignatedpursuanttothesameconditionslaiddownin
Articles41to44ofDirective(EU)2016/680.Marketsurveillanceactivities
shallinnowayaffecttheindependenceofjudicialauthorities,orotherwise
interferewiththeiractivitieswhenactingintheirjudicialcapacity.
9.WhereUnioninstitutions,bodies,officesoragenciesfallwithinthe
scopeofthisRegulation,theEuropeanDataProtectionSupervisorshallact
astheirmarketsurveillanceauthority,exceptinrelationtotheCourtof
JusticeoftheEuropeanUnionactinginitsjudicialcapacity.
10.MemberStatesshallfacilitatecoordinationbetweenmarket
surveillanceauthoritiesdesignatedunderthisRegulationandotherrelevant
nationalauthoritiesorbodieswhichsupervisetheapplicationofUnion
harmonisationlegislationlistedinAnnexI,orinotherUnionlaw,that
mightberelevantforthehigh-riskAIsystemsreferredtoinAnnexIII.
11.MarketsurveillanceauthoritiesandtheCommissionshallbeableto
proposejointactivities,includingjointinvestigations,tobeconductedby
eithermarketsurveillanceauthoritiesormarketsurveillanceauthorities
jointlywiththeCommission,thathavetheaimofpromotingcompliance,
identifyingnon-compliance,raisingawarenessorprovidingguidancein
relationtothisRegulationwithrespecttospecificcategoriesofhigh-riskAI

--- Page 153 ---
systemsthatarefoundtopresentaseriousriskacrosstwoormoreMember
StatesinaccordancewithArticle9ofRegulation(EU)2019/1020.TheAI
Officeshallprovidecoordinationsupportforjointinvestigations.
12.WithoutprejudicetothepowersprovidedforunderRegulation(EU)
2019/1020,andwhererelevantandlimitedtowhatisnecessarytofulfil
theirtasks,themarketsurveillanceauthoritiesshallbegrantedfullaccessby
providerstothedocumentationaswellasthetraining,validationandtesting
datasetsusedforthedevelopmentofhigh-riskAIsystems,including,where
appropriateandsubjecttosecuritysafeguards,throughapplication
programminginterfaces(API)orotherrelevanttechnicalmeansandtools
enablingremoteaccess.
13.Marketsurveillanceauthoritiesshallbegrantedaccesstothesource
codeofthehigh-riskAIsystemuponareasonedrequestandonlywhenboth
ofthefollowingconditionsarefulfilled:
(a)accesstosourcecodeisnecessarytoassesstheconformityofahigh-riskAIsystem
withtherequirementssetoutinChapterIII,Section2;and
(b)testingorauditingproceduresandverificationsbasedonthedataand
documentationprovidedbytheproviderhavebeenexhaustedorproved
insufficient.
14.Anyinformationordocumentationobtainedbymarketsurveillance
authoritiesshallbetreatedinaccordancewiththeconfidentialityobligations
setoutinArticle78.
Article75
Mutualassistance,marketsurveillanceandcontrolofgeneral-purpose
AIsystems
1.WhereanAIsystemisbasedonageneral-purposeAImodel,andthe
modelandthesystemaredevelopedbythesameprovider,theAIOffice
shallhavepowerstomonitorandsupervisecomplianceofthatAIsystem
withobligationsunderthisRegulation.Tocarryoutitsmonitoringand
supervisiontasks,theAIOfficeshallhaveallthepowersofamarket
surveillanceauthorityprovidedforinthisSectionandRegulation(EU)
2019/1020.
2.Wheretherelevantmarketsurveillanceauthoritieshavesufficientreason
toconsidergeneral-purposeAIsystemsthatcanbeuseddirectlyby
deployersforatleastonepurposethatisclassifiedashigh-riskpursuantto
thisRegulationtobenon-compliantwiththerequirementslaiddowninthis
Regulation,theyshallcooperatewiththeAIOfficetocarryoutcompliance
evaluations,andshallinformtheBoardandothermarketsurveillance
authoritiesaccordingly.

--- Page 154 ---
3.Whereamarketsurveillanceauthorityisunabletoconcludeits
investigationofthehigh-riskAIsystembecauseofitsinabilitytoaccess
certaininformationrelatedtothegeneral-purposeAImodeldespitehaving
madeallappropriateeffortstoobtainthatinformation,itmaysubmit
areasonedrequesttotheAIOffice,bywhichaccesstothatinformation
shallbeenforced.Inthatcase,theAIOfficeshallsupplytotheapplicant
authoritywithoutdelay,andinanyeventwithin30days,anyinformation
thattheAIOfficeconsiderstoberelevantinordertoestablishwhether
ahigh-riskAIsystemisnon-compliant.Marketsurveillanceauthoritiesshall
safeguardtheconfidentialityoftheinformationthattheyobtainin
accordancewithArticle78ofthisRegulation.Theprocedureprovidedfor
inChapterVIofRegulation(EU)2019/1020shallapplymutatismutandis.
Article76
Supervisionoftestinginrealworldconditionsbymarketsurveillance
authorities
1.Marketsurveillanceauthoritiesshallhavecompetencesandpowersto
ensurethattestinginrealworldconditionsisinaccordancewiththis
Regulation.
2.WheretestinginrealworldconditionsisconductedforAIsystemsthat
aresupervisedwithinanAIregulatorysandboxunderArticle58,themarket
surveillanceauthoritiesshallverifythecompliancewithArticle60aspartof
theirsupervisoryrolefortheAIregulatorysandbox.Thoseauthoritiesmay,
asappropriate,allowthetestinginrealworldconditionstobeconductedby
theproviderorprospectiveprovider,inderogationfromtheconditionsset
outinArticle60(4),points(f)and(g).
3.Whereamarketsurveillanceauthorityhasbeeninformedbythe
prospectiveprovider,theprovideroranythirdpartyofaseriousincidentor
hasothergroundsforconsideringthattheconditionssetoutinArticles60
and61arenotmet,itmaytakeeitherofthefollowingdecisionsonits
territory,asappropriate:
(a)tosuspendorterminatethetestinginrealworldconditions;
(b)torequiretheproviderorprospectiveproviderandthedeployerorprospective
deployertomodifyanyaspectofthetestinginrealworldconditions.
4.Whereamarketsurveillanceauthorityhastakenadecisionreferredtoin
paragraph3ofthisArticle,orhasissuedanobjectionwithinthemeaningof
Article60(4),point(b),thedecisionortheobjectionshallindicatethe
groundsthereforandhowtheproviderorprospectiveprovidercanchallenge
thedecisionorobjection.

--- Page 155 ---
5.Whereapplicable,whereamarketsurveillanceauthorityhastaken
adecisionreferredtoinparagraph3,itshallcommunicatethegrounds
therefortothemarketsurveillanceauthoritiesofotherMemberStatesin
whichtheAIsystemhasbeentestedinaccordancewiththetestingplan.
Article77
Powersofauthoritiesprotectingfundamentalrights
1.Nationalpublicauthoritiesorbodieswhichsuperviseorenforcethe
respectofobligationsunderUnionlawprotectingfundamentalrights,
includingtherighttonon-discrimination,inrelationtotheuseofhigh-risk
AIsystemsreferredtoinAnnexIIIshallhavethepowertorequestand
accessanydocumentationcreatedormaintainedunderthisRegulationin
accessiblelanguageandformatwhenaccesstothatdocumentationis
necessaryforeffectivelyfulfillingtheirmandateswithinthelimitsoftheir
jurisdiction.Therelevantpublicauthorityorbodyshallinformthemarket
surveillanceauthorityoftheMemberStateconcernedofanysuchrequest.
2.By2November2024,eachMemberStateshallidentifythepublic
authoritiesorbodiesreferredtoinparagraph1andmakealistofthem
publiclyavailable.MemberStatesshallnotifythelisttotheCommission
andtotheotherMemberStates,andshallkeepthelistuptodate.
3.Wherethedocumentationreferredtoinparagraph1isinsufficientto
ascertainwhetheraninfringementofobligationsunderUnionlawprotecting
fundamentalrightshasoccurred,thepublicauthorityorbodyreferredtoin
paragraph1maymakeareasonedrequesttothemarketsurveillance
authority,toorganisetestingofthehigh-riskAIsystemthroughtechnical
means.Themarketsurveillanceauthorityshallorganisethetestingwiththe
closeinvolvementoftherequestingpublicauthorityorbodywithin
areasonabletimefollowingtherequest.
4.Anyinformationordocumentationobtainedbythenationalpublic
authoritiesorbodiesreferredtoinparagraph1ofthisArticlepursuantto
thisArticleshallbetreatedinaccordancewiththeconfidentiality
obligationssetoutinArticle78.
Article78
Confidentiality
1.TheCommission,marketsurveillanceauthoritiesandnotifiedbodies
andanyothernaturalorlegalpersoninvolvedintheapplicationofthis
Regulationshall,inaccordancewithUnionornationallaw,respectthe
confidentialityofinformationanddataobtainedincarryingouttheirtasks
andactivitiesinsuchamannerastoprotect,inparticular:

--- Page 156 ---
(a)theintellectualpropertyrightsandconfidentialbusinessinformationortrade
secretsofanaturalorlegalperson,includingsourcecode,exceptinthecases
referredtoinArticle5ofDirective(EU)2016/943oftheEuropeanParliamentand
oftheCouncil(57);
(b)theeffectiveimplementationofthisRegulation,inparticularforthepurposesof
inspections,investigationsoraudits;
(c)publicandnationalsecurityinterests;
(d)theconductofcriminaloradministrativeproceedings;
(e)informationclassifiedpursuanttoUnionornationallaw.
2.TheauthoritiesinvolvedintheapplicationofthisRegulationpursuantto
paragraph1shallrequestonlydatathatisstrictlynecessaryforthe
assessmentoftheriskposedbyAIsystemsandfortheexerciseoftheir
powersinaccordancewiththisRegulationandwithRegulation(EU)
2019/1020.Theyshallputinplaceadequateandeffectivecybersecurity
measurestoprotectthesecurityandconfidentialityoftheinformationand
dataobtained,andshalldeletethedatacollectedassoonasitisnolonger
neededforthepurposeforwhichitwasobtained,inaccordancewith
applicableUnionornationallaw.
3.Withoutprejudicetoparagraphs1and2,informationexchangedon
aconfidentialbasisbetweenthenationalcompetentauthoritiesorbetween
nationalcompetentauthoritiesandtheCommissionshallnotbedisclosed
withoutpriorconsultationoftheoriginatingnationalcompetentauthority
andthedeployerwhenhigh-riskAIsystemsreferredtoinpoint1,6or7of
AnnexIIIareusedbylawenforcement,bordercontrol,immigrationor
asylumauthoritiesandwhensuchdisclosurewouldjeopardisepublicand
nationalsecurityinterests.Thisexchangeofinformationshallnotcover
sensitiveoperationaldatainrelationtotheactivitiesoflawenforcement,
bordercontrol,immigrationorasylumauthorities.
Whenthelawenforcement,immigrationorasylumauthoritiesareproviders
ofhigh-riskAIsystemsreferredtoinpoint1,6or7ofAnnexIII,the
technicaldocumentationreferredtoinAnnexIVshallremainwithinthe
premisesofthoseauthorities.Thoseauthoritiesshallensurethatthemarket
surveillanceauthoritiesreferredtoinArticle74(8)and(9),asapplicable,
can,uponrequest,immediatelyaccessthedocumentationorobtainacopy
thereof.Onlystaffofthemarketsurveillanceauthorityholdingthe
appropriatelevelofsecurityclearanceshallbeallowedtoaccessthat
documentationoranycopythereof.
4.Paragraphs1,2and3shallnotaffecttherightsorobligationsofthe
Commission,MemberStatesandtheirrelevantauthorities,aswellasthose
ofnotifiedbodies,withregardtotheexchangeofinformationandthe
disseminationofwarnings,includinginthecontextofcross-border

--- Page 157 ---
cooperation,norshalltheyaffecttheobligationsofthepartiesconcernedto
provideinformationundercriminallawoftheMemberStates.
5.TheCommissionandMemberStatesmayexchange,wherenecessary
andinaccordancewithrelevantprovisionsofinternationalandtrade
agreements,confidentialinformationwithregulatoryauthoritiesofthird
countrieswithwhichtheyhaveconcludedbilateralormultilateral
confidentialityarrangementsguaranteeinganadequatelevelof
confidentiality.
Article79
ProcedureatnationallevelfordealingwithAIsystemspresenting
arisk
1.AIsystemspresentingariskshallbeunderstoodasa‘productpresenting
arisk’asdefinedinArticle3,point19ofRegulation(EU)2019/1020,
insofarastheypresentriskstothehealthorsafety,ortofundamentalrights,
ofpersons.
2.WherethemarketsurveillanceauthorityofaMemberStatehas
sufficientreasontoconsideranAIsystemtopresentariskasreferredtoin
paragraph1ofthisArticle,itshallcarryoutanevaluationoftheAIsystem
concernedinrespectofitscompliancewithalltherequirementsand
obligationslaiddowninthisRegulation.Particularattentionshallbegiven
toAIsystemspresentingarisktovulnerablegroups.Whererisksto
fundamentalrightsareidentified,themarketsurveillanceauthorityshall
alsoinformandfullycooperatewiththerelevantnationalpublicauthorities
orbodiesreferredtoinArticle77(1).Therelevantoperatorsshallcooperate
asnecessarywiththemarketsurveillanceauthorityandwiththeother
nationalpublicauthoritiesorbodiesreferredtoinArticle77(1).
Where,inthecourseofthatevaluation,themarketsurveillanceauthorityor,
whereapplicablethemarketsurveillanceauthorityincooperationwiththe
nationalpublicauthorityreferredtoinArticle77(1),findsthattheAI
systemdoesnotcomplywiththerequirementsandobligationslaiddownin
thisRegulation,itshallwithoutunduedelayrequiretherelevantoperatorto
takeallappropriatecorrectiveactionstobringtheAIsysteminto
compliance,towithdrawtheAIsystemfromthemarket,ortorecallit
withinaperiodthemarketsurveillanceauthoritymayprescribe,andinany
eventwithintheshorterof15workingdays,orasprovidedforinthe
relevantUnionharmonisationlegislation.
Themarketsurveillanceauthorityshallinformtherelevantnotifiedbody
accordingly.Article18ofRegulation(EU)2019/1020shallapplytothe
measuresreferredtointhesecondsubparagraphofthisparagraph.

--- Page 158 ---
3.Wherethemarketsurveillanceauthorityconsidersthatthenon-
complianceisnotrestrictedtoitsnationalterritory,itshallinformthe
CommissionandtheotherMemberStateswithoutunduedelayoftheresults
oftheevaluationandoftheactionswhichithasrequiredtheoperatortotake.
4.Theoperatorshallensurethatallappropriatecorrectiveactionistakenin
respectofalltheAIsystemsconcernedthatithasmadeavailableonthe
Unionmarket.
5.WheretheoperatorofanAIsystemdoesnottakeadequatecorrective
actionwithintheperiodreferredtoinparagraph2,themarketsurveillance
authorityshalltakeallappropriateprovisionalmeasurestoprohibitor
restricttheAIsystem’sbeingmadeavailableonitsnationalmarketorput
intoservice,towithdrawtheproductorthestandaloneAIsystemfromthat
marketortorecallit.Thatauthorityshallwithoutunduedelaynotifythe
CommissionandtheotherMemberStatesofthosemeasures.
6.Thenotificationreferredtoinparagraph5shallincludeallavailable
details,inparticulartheinformationnecessaryfortheidentificationofthe
non-compliantAIsystem,theoriginoftheAIsystemandthesupplychain,
thenatureofthenon-complianceallegedandtheriskinvolved,thenature
anddurationofthenationalmeasurestakenandtheargumentsputforward
bytherelevantoperator.Inparticular,themarketsurveillanceauthorities
shallindicatewhetherthenon-complianceisduetooneormoreofthe
following:
(a)non-compliancewiththeprohibitionoftheAIpracticesreferredtoinArticle5;
(b)afailureofahigh-riskAIsystemtomeetrequirementssetoutinChapterIII,
Section2;
(c)shortcomingsintheharmonisedstandardsorcommonspecificationsreferredtoin
Articles40and41conferringapresumptionofconformity;
(d)non-compliancewithArticle50.
7.Themarketsurveillanceauthoritiesotherthanthemarketsurveillance
authorityoftheMemberStateinitiatingtheprocedureshall,withoutundue
delay,informtheCommissionandtheotherMemberStatesofanymeasures
adoptedandofanyadditionalinformationattheirdisposalrelatingtothe
non-complianceoftheAIsystemconcerned,and,intheeventof
disagreementwiththenotifiednationalmeasure,oftheirobjections.
8.Where,withinthreemonthsofreceiptofthenotificationreferredtoin
paragraph5ofthisArticle,noobjectionhasbeenraisedbyeitheramarket
surveillanceauthorityofaMemberStateorbytheCommissioninrespectof
aprovisionalmeasuretakenbyamarketsurveillanceauthorityofanother
MemberState,thatmeasureshallbedeemedjustified.Thisshallbewithout
prejudicetotheproceduralrightsoftheconcernedoperatorinaccordance

--- Page 159 ---
withArticle18ofRegulation(EU)2019/1020.Thethree-monthperiod
referredtointhisparagraphshallbereducedto30daysintheeventofnon-
compliancewiththeprohibitionoftheAIpracticesreferredtoinArticle5
ofthisRegulation.
9.Themarketsurveillanceauthoritiesshallensurethatappropriate
restrictivemeasuresaretakeninrespectoftheproductortheAIsystem
concerned,suchaswithdrawaloftheproductortheAIsystemfromtheir
market,withoutunduedelay.
Article80
ProcedurefordealingwithAIsystemsclassifiedbytheproviderasnon-
high-riskinapplicationofAnnexIII
1.Whereamarketsurveillanceauthorityhassufficientreasontoconsider
thatanAIsystemclassifiedbytheproviderasnon-high-riskpursuantto
Article6(3)isindeedhigh-risk,themarketsurveillanceauthorityshallcarry
outanevaluationoftheAIsystemconcernedinrespectofitsclassification
asahigh-riskAIsystembasedontheconditionssetoutinArticle6(3)and
theCommissionguidelines.
2.Where,inthecourseofthatevaluation,themarketsurveillanceauthority
findsthattheAIsystemconcernedishigh-risk,itshallwithoutunduedelay
requiretherelevantprovidertotakeallnecessaryactionstobringtheAI
systemintocompliancewiththerequirementsandobligationslaiddownin
thisRegulation,aswellastakeappropriatecorrectiveactionwithinaperiod
themarketsurveillanceauthoritymayprescribe.
3.WherethemarketsurveillanceauthorityconsidersthattheuseoftheAI
systemconcernedisnotrestrictedtoitsnationalterritory,itshallinformthe
CommissionandtheotherMemberStateswithoutunduedelayoftheresults
oftheevaluationandoftheactionswhichithasrequiredtheproviderto
take.
4.Theprovidershallensurethatallnecessaryactionistakentobringthe
AIsystemintocompliancewiththerequirementsandobligationslaiddown
inthisRegulation.WheretheproviderofanAIsystemconcerneddoesnot
bringtheAIsystemintocompliancewiththoserequirementsand
obligationswithintheperiodreferredtoinparagraph2ofthisArticle,the
providershallbesubjecttofinesinaccordancewithArticle99.
5.Theprovidershallensurethatallappropriatecorrectiveactionistaken
inrespectofalltheAIsystemsconcernedthatithasmadeavailableonthe
Unionmarket.

--- Page 160 ---
6.WheretheprovideroftheAIsystemconcerneddoesnottakeadequate
correctiveactionwithintheperiodreferredtoinparagraph2ofthisArticle,
Article79(5)to(9)shallapply.
7.Where,inthecourseoftheevaluationpursuanttoparagraph1ofthis
Article,themarketsurveillanceauthorityestablishesthattheAIsystemwas
misclassifiedbytheproviderasnon-high-riskinordertocircumventthe
applicationofrequirementsinChapterIII,Section2,theprovidershallbe
subjecttofinesinaccordancewithArticle99.
8.InexercisingtheirpowertomonitortheapplicationofthisArticle,and
inaccordancewithArticle11ofRegulation(EU)2019/1020,market
surveillanceauthoritiesmayperformappropriatechecks,takingintoaccount
inparticularinformationstoredintheEUdatabasereferredtoinArticle71
ofthisRegulation.
Article81
Unionsafeguardprocedure
1.Where,withinthreemonthsofreceiptofthenotificationreferredtoin
Article79(5),orwithin30daysinthecaseofnon-compliancewiththe
prohibitionoftheAIpracticesreferredtoinArticle5,objectionsareraised
bythemarketsurveillanceauthorityofaMemberStatetoameasuretaken
byanothermarketsurveillanceauthority,orwheretheCommission
considersthemeasuretobecontrarytoUnionlaw,theCommissionshall
withoutunduedelayenterintoconsultationwiththemarketsurveillance
authorityoftherelevantMemberStateandtheoperatororoperators,and
shallevaluatethenationalmeasure.Onthebasisoftheresultsofthat
evaluation,theCommissionshall,withinsixmonths,orwithin60daysin
thecaseofnon-compliancewiththeprohibitionoftheAIpracticesreferred
toinArticle5,startingfromthenotificationreferredtoinArticle79(5),
decidewhetherthenationalmeasureisjustifiedandshallnotifyitsdecision
tothemarketsurveillanceauthorityoftheMemberStateconcerned.The
Commissionshallalsoinformallothermarketsurveillanceauthoritiesofits
decision.
2.WheretheCommissionconsidersthemeasuretakenbytherelevant
MemberStatetobejustified,allMemberStatesshallensurethattheytake
appropriaterestrictivemeasuresinrespectoftheAIsystemconcerned,such
asrequiringthewithdrawaloftheAIsystemfromtheirmarketwithout
unduedelay,andshallinformtheCommissionaccordingly.Wherethe
Commissionconsidersthenationalmeasuretobeunjustified,theMember
Stateconcernedshallwithdrawthemeasureandshallinformthe
Commissionaccordingly.

--- Page 161 ---
3.Wherethenationalmeasureisconsideredjustifiedandthenon-
complianceoftheAIsystemisattributedtoshortcomingsintheharmonised
standardsorcommonspecificationsreferredtoinArticles40and41ofthis
Regulation,theCommissionshallapplytheprocedureprovidedforin
Article11ofRegulation(EU)No1025/2012.
Article82
CompliantAIsystemswhichpresentarisk
1.Where,havingperformedanevaluationunderArticle79,after
consultingtherelevantnationalpublicauthorityreferredtoinArticle77(1),
themarketsurveillanceauthorityofaMemberStatefindsthatalthough
ahigh-riskAIsystemcomplieswiththisRegulation,itneverthelesspresents
arisktothehealthorsafetyofpersons,tofundamentalrights,ortoother
aspectsofpublicinterestprotection,itshallrequiretherelevantoperatorto
takeallappropriatemeasurestoensurethattheAIsystemconcerned,when
placedonthemarketorputintoservice,nolongerpresentsthatriskwithout
unduedelay,withinaperioditmayprescribe.
2.Theproviderorotherrelevantoperatorshallensurethatcorrective
actionistakeninrespectofalltheAIsystemsconcernedthatithasmade
availableontheUnionmarketwithinthetimelineprescribedbythemarket
surveillanceauthorityoftheMemberStatereferredtoinparagraph1.
3.TheMemberStatesshallimmediatelyinformtheCommissionandthe
otherMemberStatesofafindingunderparagraph1.Thatinformationshall
includeallavailabledetails,inparticularthedatanecessaryforthe
identificationoftheAIsystemconcerned,theoriginandthesupplychainof
theAIsystem,thenatureoftheriskinvolvedandthenatureanddurationof
thenationalmeasurestaken.
4.TheCommissionshallwithoutunduedelayenterintoconsultationwith
theMemberStatesconcernedandtherelevantoperators,andshallevaluate
thenationalmeasurestaken.Onthebasisoftheresultsofthatevaluation,
theCommissionshalldecidewhetherthemeasureisjustifiedand,where
necessary,proposeotherappropriatemeasures.
5.TheCommissionshallimmediatelycommunicateitsdecisiontothe
MemberStatesconcernedandtotherelevantoperators.Itshallalsoinform
theotherMemberStates.
Article83
Formalnon-compliance

--- Page 162 ---
1.WherethemarketsurveillanceauthorityofaMemberStatemakesone
ofthefollowingfindings,itshallrequiretherelevantprovidertoputanend
tothenon-complianceconcerned,withinaperioditmayprescribe:
(a)theCEmarkinghasbeenaffixedinviolationofArticle48;
(b)theCEmarkinghasnotbeenaffixed;
(c)theEUdeclarationofconformityreferredtoinArticle47hasnotbeendrawnup;
(d)theEUdeclarationofconformityreferredtoinArticle47hasnotbeendrawnup
correctly;
(e)theregistrationintheEUdatabasereferredtoinArticle71hasnotbeencarried
out;
(f)whereapplicable,noauthorisedrepresentativehasbeenappointed;
(g)technicaldocumentationisnotavailable.
2.Wherethenon-compliancereferredtoinparagraph1persists,the
marketsurveillanceauthorityoftheMemberStateconcernedshalltake
appropriateandproportionatemeasurestorestrictorprohibitthehigh-risk
AIsystembeingmadeavailableonthemarketortoensurethatitisrecalled
orwithdrawnfromthemarketwithoutdelay.
Article84
UnionAItestingsupportstructures
1.TheCommissionshalldesignateoneormoreUnionAItestingsupport
structurestoperformthetaskslistedunderArticle21(6)ofRegulation(EU)
2019/1020intheareaofAI.
2.Withoutprejudicetothetasksreferredtoinparagraph1,UnionAI
testingsupportstructuresshallalsoprovideindependenttechnicalor
scientificadviceattherequestoftheBoard,theCommission,orofmarket
surveillanceauthorities.
SECTION4
Remedies
Article85
Righttolodgeacomplaintwithamarketsurveillanceauthority
Withoutprejudicetootheradministrativeorjudicialremedies,anynatural
orlegalpersonhavinggroundstoconsiderthattherehasbeenan

--- Page 163 ---
infringementoftheprovisionsofthisRegulationmaysubmitcomplaintsto
therelevantmarketsurveillanceauthority.
InaccordancewithRegulation(EU)2019/1020,suchcomplaintsshallbe
takenintoaccountforthepurposeofconductingmarketsurveillance
activities,andshallbehandledinlinewiththededicatedprocedures
establishedthereforbythemarketsurveillanceauthorities.
Article86
Righttoexplanationofindividualdecision-making
1.Anyaffectedpersonsubjecttoadecisionwhichistakenbythedeployer
onthebasisoftheoutputfromahigh-riskAIsystemlistedinAnnexIII,
withtheexceptionofsystemslistedunderpoint2thereof,andwhich
produceslegaleffectsorsimilarlysignificantlyaffectsthatpersoninaway
thattheyconsidertohaveanadverseimpactontheirhealth,safetyor
fundamentalrightsshallhavetherighttoobtainfromthedeployerclearand
meaningfulexplanationsoftheroleoftheAIsysteminthedecision-making
procedureandthemainelementsofthedecisiontaken.
2.Paragraph1shallnotapplytotheuseofAIsystemsforwhich
exceptionsfrom,orrestrictionsto,theobligationunderthatparagraph
followfromUnionornationallawincompliancewithUnionlaw.
3.ThisArticleshallapplyonlytotheextentthattherightreferredtoin
paragraph1isnototherwiseprovidedforunderUnionlaw.
Article87
Reportingofinfringementsandprotectionofreportingpersons
Directive(EU)2019/1937shallapplytothereportingofinfringementsof
thisRegulationandtheprotectionofpersonsreportingsuchinfringements.
SECTION5
Supervision,investigation,enforcementandmonitoringinrespectof
providersofgeneral-purposeAImodels
Article88
Enforcementoftheobligationsofprovidersofgeneral-purposeAI
models
1.TheCommissionshallhaveexclusivepowerstosuperviseandenforce
ChapterV,takingintoaccounttheproceduralguaranteesunderArticle94.

--- Page 164 ---
TheCommissionshallentrusttheimplementationofthesetaskstotheAI
Office,withoutprejudicetothepowersoforganisationoftheCommission
andthedivisionofcompetencesbetweenMemberStatesandtheUnion
basedontheTreaties.
2.WithoutprejudicetoArticle75(3),marketsurveillanceauthoritiesmay
requesttheCommissiontoexercisethepowerslaiddowninthisSection,
wherethatisnecessaryandproportionatetoassistwiththefulfilmentof
theirtasksunderthisRegulation.
Article89
Monitoringactions
1.ForthepurposeofcarryingoutthetasksassignedtoitunderthisSection,
theAIOfficemaytakethenecessaryactionstomonitortheeffective
implementationandcompliancewiththisRegulationbyprovidersof
general-purposeAImodels,includingtheiradherencetoapprovedcodesof
practice.
2.Downstreamprovidersshallhavetherighttolodgeacomplaintalleging
aninfringementofthisRegulation.Acomplaintshallbedulyreasonedand
indicateatleast:
(a)thepointofcontactoftheproviderofthegeneral-purposeAImodelconcerned;
(b)adescriptionoftherelevantfacts,theprovisionsofthisRegulationconcerned,and
thereasonwhythedownstreamproviderconsidersthattheproviderofthegeneral-
purposeAImodelconcernedinfringedthisRegulation;
(c)anyotherinformationthatthedownstreamproviderthatsenttherequestconsiders
relevant,including,whereappropriate,informationgatheredonitsowninitiative.
Article90
Alertsofsystemicrisksbythescientificpanel
1.ThescientificpanelmayprovideaqualifiedalerttotheAIOfficewhere
ithasreasontosuspectthat:
(a)ageneral-purposeAImodelposesconcreteidentifiableriskatUnionlevel;or
(b)ageneral-purposeAImodelmeetstheconditionsreferredtoinArticle51.
2.Uponsuchqualifiedalert,theCommission,throughtheAIOfficeand
afterhavinginformedtheBoard,mayexercisethepowerslaiddowninthis
Sectionforthepurposeofassessingthematter.TheAIOfficeshallinform
theBoardofanymeasureaccordingtoArticles91to94.
3.Aqualifiedalertshallbedulyreasonedandindicateatleast:

--- Page 165 ---
(a)thepointofcontactoftheproviderofthegeneral-purposeAImodelwithsystemic
riskconcerned;
(b)adescriptionoftherelevantfactsandthereasonsforthealertbythescientific
panel;
(c)anyotherinformationthatthescientificpanelconsiderstoberelevant,including,
whereappropriate,informationgatheredonitsowninitiative.
Article91
Powertorequestdocumentationandinformation
1.TheCommissionmayrequesttheproviderofthegeneral-purposeAI
modelconcernedtoprovidethedocumentationdrawnupbytheproviderin
accordancewithArticles53and55,oranyadditionalinformationthatis
necessaryforthepurposeofassessingcomplianceoftheproviderwiththis
Regulation.
2.Beforesendingtherequestforinformation,theAIOfficemayinitiate
astructureddialoguewiththeproviderofthegeneral-purposeAImodel.
3.Uponadulysubstantiatedrequestfromthescientificpanel,the
Commissionmayissuearequestforinformationtoaproviderofageneral-
purposeAImodel,wheretheaccesstoinformationisnecessaryand
proportionateforthefulfilmentofthetasksofthescientificpanelunder
Article68(2).
4.Therequestforinformationshallstatethelegalbasisandthepurposeof
therequest,specifywhatinformationisrequired,setaperiodwithinwhich
theinformationistobeprovided,andindicatethefinesprovidedforin
Article101forsupplyingincorrect,incompleteormisleadinginformation.
5.Theproviderofthegeneral-purposeAImodelconcerned,orits
representativeshallsupplytheinformationrequested.Inthecaseoflegal
persons,companiesorfirms,orwheretheproviderhasnolegalpersonality,
thepersonsauthorisedtorepresentthembylaworbytheirstatutes,shall
supplytheinformationrequestedonbehalfoftheproviderofthegeneral-
purposeAImodelconcerned.Lawyersdulyauthorisedtoactmaysupply
informationonbehalfoftheirclients.Theclientsshallneverthelessremain
fullyresponsibleiftheinformationsuppliedisincomplete,incorrector
misleading.
Article92
Powertoconductevaluations

--- Page 166 ---
1.TheAIOffice,afterconsultingtheBoard,mayconductevaluationsof
thegeneral-purposeAImodelconcerned:
(a)toassesscomplianceoftheproviderwithobligationsunderthisRegulation,where
theinformationgatheredpursuanttoArticle91isinsufficient;or
(b)toinvestigatesystemicrisksatUnionlevelofgeneral-purposeAImodelswith
systemicrisk,inparticularfollowingaqualifiedalertfromthescientificpanelin
accordancewithArticle90(1),point(a).
2.TheCommissionmaydecidetoappointindependentexpertstocarryout
evaluationsonitsbehalf,includingfromthescientificpanelestablished
pursuanttoArticle68.Independentexpertsappointedforthistaskshall
meetthecriteriaoutlinedinArticle68(2).
3.Forthepurposesofparagraph1,theCommissionmayrequestaccessto
thegeneral-purposeAImodelconcernedthroughAPIsorfurther
appropriatetechnicalmeansandtools,includingsourcecode.
4.Therequestforaccessshallstatethelegalbasis,thepurposeandreasons
oftherequestandsettheperiodwithinwhichtheaccessistobeprovided,
andthefinesprovidedforinArticle101forfailuretoprovideaccess.
5.Theprovidersofthegeneral-purposeAImodelconcernedorits
representativeshallsupplytheinformationrequested.Inthecaseoflegal
persons,companiesorfirms,orwheretheproviderhasnolegalpersonality,
thepersonsauthorisedtorepresentthembylaworbytheirstatutes,shall
providetheaccessrequestedonbehalfoftheproviderofthegeneral-
purposeAImodelconcerned.
6.TheCommissionshalladoptimplementingactssettingoutthedetailed
arrangementsandtheconditionsfortheevaluations,includingthedetailed
arrangementsforinvolvingindependentexperts,andtheprocedureforthe
selectionthereof.Thoseimplementingactsshallbeadoptedinaccordance
withtheexaminationprocedurereferredtoinArticle98(2).
7.Priortorequestingaccesstothegeneral-purposeAImodelconcerned,
theAIOfficemayinitiateastructureddialoguewiththeproviderofthe
general-purposeAImodeltogathermoreinformationontheinternaltesting
ofthemodel,internalsafeguardsforpreventingsystemicrisks,andother
internalproceduresandmeasurestheproviderhastakentomitigatesuch
risks.
Article93
Powertorequestmeasures
1.Wherenecessaryandappropriate,theCommissionmayrequest
providersto:

--- Page 167 ---
(a)takeappropriatemeasurestocomplywiththeobligationssetoutinArticles53
and54;
(b)implementmitigationmeasures,wheretheevaluationcarriedoutinaccordance
withArticle92hasgivenrisetoseriousandsubstantiatedconcernofasystemic
riskatUnionlevel;
(c)restrictthemakingavailableonthemarket,withdraworrecallthemodel.
2.Beforeameasureisrequested,theAIOfficemayinitiateastructured
dialoguewiththeproviderofthegeneral-purposeAImodel.
3.If,duringthestructureddialoguereferredtoinparagraph2,theprovider
ofthegeneral-purposeAImodelwithsystemicriskofferscommitmentsto
implementmitigationmeasurestoaddressasystemicriskatUnionlevel,the
Commissionmay,bydecision,makethosecommitmentsbindingand
declarethattherearenofurthergroundsforaction.
Article94
Proceduralrightsofeconomicoperatorsofthegeneral-purposeAI
model
Article18ofRegulation(EU)2019/1020shallapplymutatismutandistothe
providersofthegeneral-purposeAImodel,withoutprejudicetomore
specificproceduralrightsprovidedforinthisRegulation.
CHAPTERX
CODESOFCONDUCTANDGUIDELINES
Article95
Codesofconductforvoluntaryapplicationofspecificrequirements
1.TheAIOfficeandtheMemberStatesshallencourageandfacilitatethe
drawingupofcodesofconduct,includingrelatedgovernancemechanisms,
intendedtofosterthevoluntaryapplicationtoAIsystems,otherthanhigh-
riskAIsystems,ofsomeoralloftherequirementssetoutinChapterIII,
Section2takingintoaccounttheavailabletechnicalsolutionsandindustry
bestpracticesallowingfortheapplicationofsuchrequirements.
2.TheAIOfficeandtheMemberStatesshallfacilitatethedrawingupof
codesofconductconcerningthevoluntaryapplication,includingby
deployers,ofspecificrequirementstoallAIsystems,onthebasisofclear
objectivesandkeyperformanceindicatorstomeasuretheachievementof
thoseobjectives,includingelementssuchas,butnotlimitedto:

--- Page 168 ---
(a)applicableelementsprovidedforinUnionethicalguidelinesfortrustworthyAI;
(b)assessingandminimisingtheimpactofAIsystemsonenvironmental
sustainability,includingasregardsenergy-efficientprogrammingandtechniques
fortheefficientdesign,traininganduseofAI;
(c)promotingAIliteracy,inparticularthatofpersonsdealingwiththedevelopment,
operationanduseofAI;
(d)facilitatinganinclusiveanddiversedesignofAIsystems,includingthroughthe
establishmentofinclusiveanddiversedevelopmentteamsandthepromotionof
stakeholders’participationinthatprocess;
(e)assessingandpreventingthenegativeimpactofAIsystemsonvulnerablepersons
orgroupsofvulnerablepersons,includingasregardsaccessibilityforpersonswith
adisability,aswellasongenderequality.
3.Codesofconductmaybedrawnupbyindividualprovidersordeployers
ofAIsystemsorbyorganisationsrepresentingthemorbyboth,including
withtheinvolvementofanyinterestedstakeholdersandtheirrepresentative
organisations,includingcivilsocietyorganisationsandacademia.Codesof
conductmaycoveroneormoreAIsystemstakingintoaccountthe
similarityoftheintendedpurposeoftherelevantsystems.
4.TheAIOfficeandtheMemberStatesshalltakeintoaccountthespecific
interestsandneedsofSMEs,includingstart-ups,whenencouragingand
facilitatingthedrawingupofcodesofconduct.
Article96
GuidelinesfromtheCommissionontheimplementationofthis
Regulation
1.TheCommissionshalldevelopguidelinesonthepractical
implementationofthisRegulation,andinparticularon:
(a)theapplicationoftherequirementsandobligationsreferredtoinArticles8to15
andinArticle25;
(b)theprohibitedpracticesreferredtoinArticle5;
(c)thepracticalimplementationoftheprovisionsrelatedtosubstantialmodification;
(d)thepracticalimplementationoftransparencyobligationslaiddowninArticle50;
(e)detailedinformationontherelationshipofthisRegulationwiththeUnion
harmonisationlegislationlistedinAnnexI,aswellaswithotherrelevantUnion
law,includingasregardsconsistencyintheirenforcement;
(f)theapplicationofthedefinitionofanAIsystemassetoutinArticle3,point(1).

--- Page 169 ---
Whenissuingsuchguidelines,theCommissionshallpayparticularattention
totheneedsofSMEsincludingstart-ups,oflocalpublicauthoritiesandof
thesectorsmostlikelytobeaffectedbythisRegulation.
Theguidelinesreferredtointhefirstsubparagraphofthisparagraphshall
takedueaccountofthegenerallyacknowledgedstateoftheartonAI,as
wellasofrelevantharmonisedstandardsandcommonspecificationsthatare
referredtoinArticles40and41,orofthoseharmonisedstandardsor
technicalspecificationsthataresetoutpursuanttoUnionharmonisationlaw.
2.AttherequestoftheMemberStatesortheAIOffice,oronitsown
initiative,theCommissionshallupdateguidelinespreviouslyadoptedwhen
deemednecessary.
CHAPTERXI
DELEGATIONOFPOWERANDCOMMITTEEPROCEDURE
Article97
Exerciseofthedelegation
1.ThepowertoadoptdelegatedactsisconferredontheCommission
subjecttotheconditionslaiddowninthisArticle.
2.ThepowertoadoptdelegatedactsreferredtoinArticle6(6)and(7),
Article7(1)and(3),Article11(3),Article43(5)and(6),Article47(5),
Article51(3),Article52(4)andArticle53(5)and(6)shallbeconferredon
theCommissionforaperiodoffiveyearsfrom1August2024.The
Commissionshalldrawupareportinrespectofthedelegationofpowernot
laterthanninemonthsbeforetheendofthefive-yearperiod.Thedelegation
ofpowershallbetacitlyextendedforperiodsofanidenticalduration,unless
theEuropeanParliamentortheCouncilopposessuchextensionnotlater
thanthreemonthsbeforetheendofeachperiod.
3.ThedelegationofpowerreferredtoinArticle6(6)and(7),Article7(1)
and(3),Article11(3),Article43(5)and(6),Article47(5),Article51(3),
Article52(4)andArticle53(5)and(6)mayberevokedatanytimebythe
EuropeanParliamentorbytheCouncil.Adecisionofrevocationshallput
anendtothedelegationofpowerspecifiedinthatdecision.Itshalltake
effectthedayfollowingthatofitspublicationintheOfficialJournalofthe
EuropeanUnionoratalaterdatespecifiedtherein.Itshallnotaffectthe
validityofanydelegatedactsalreadyinforce.
4.Beforeadoptingadelegatedact,theCommissionshallconsultexperts
designatedbyeachMemberStateinaccordancewiththeprincipleslaid

--- Page 170 ---
downintheInterinstitutionalAgreementof13April2016onBetterLaw-
Making.
5.Assoonasitadoptsadelegatedact,theCommissionshallnotifyit
simultaneouslytotheEuropeanParliamentandtotheCouncil.
6.AnydelegatedactadoptedpursuanttoArticle6(6)or(7),Article7(1)or
(3),Article11(3),Article43(5)or(6),Article47(5),Article51(3),
Article52(4)orArticle53(5)or(6)shallenterintoforceonlyifno
objectionhasbeenexpressedbyeithertheEuropeanParliamentorthe
Councilwithinaperiodofthreemonthsofnotificationofthatacttothe
EuropeanParliamentandtheCouncilorif,beforetheexpiryofthatperiod,
theEuropeanParliamentandtheCouncilhavebothinformedthe
Commissionthattheywillnotobject.Thatperiodshallbeextendedbythree
monthsattheinitiativeoftheEuropeanParliamentoroftheCouncil.
Article98
Committeeprocedure
1.TheCommissionshallbeassistedbyacommittee.Thatcommitteeshall
beacommitteewithinthemeaningofRegulation(EU)No182/2011.
2.Wherereferenceismadetothisparagraph,Article5ofRegulation(EU)
No182/2011shallapply.
CHAPTERXII
PENALTIES
Article99
Penalties
1.InaccordancewiththetermsandconditionslaiddowninthisRegulation,
MemberStatesshalllaydowntherulesonpenaltiesandotherenforcement
measures,whichmayalsoincludewarningsandnon-monetarymeasures,
applicabletoinfringementsofthisRegulationbyoperators,andshalltake
allmeasuresnecessarytoensurethattheyareproperlyandeffectively
implemented,therebytakingintoaccounttheguidelinesissuedbythe
CommissionpursuanttoArticle96.Thepenaltiesprovidedforshallbe
effective,proportionateanddissuasive.Theyshalltakeintoaccountthe
interestsofSMEs,includingstart-ups,andtheireconomicviability.
2.TheMemberStatesshall,withoutdelayandatthelatestbythedateof
entryintoapplication,notifytheCommissionoftherulesonpenaltiesand

--- Page 171 ---
ofotherenforcementmeasuresreferredtoinparagraph1,andshallnotifyit,
withoutdelay,ofanysubsequentamendmenttothem.
3.Non-compliancewiththeprohibitionoftheAIpracticesreferredtoin
Article5shallbesubjecttoadministrativefinesofuptoEUR35000000or,
iftheoffenderisanundertaking,upto7%ofitstotalworldwideannual
turnoverfortheprecedingfinancialyear,whicheverishigher.
4.Non-compliancewithanyofthefollowingprovisionsrelatedto
operatorsornotifiedbodies,otherthanthoselaiddowninArticles5,shall
besubjecttoadministrativefinesofuptoEUR15000000or,ifthe
offenderisanundertaking,upto3%ofitstotalworldwideannualturnover
fortheprecedingfinancialyear,whicheverishigher:
(a)obligationsofproviderspursuanttoArticle16;
(b)obligationsofauthorisedrepresentativespursuanttoArticle22;
(c)obligationsofimporterspursuanttoArticle23;
(d)obligationsofdistributorspursuanttoArticle24;
(e)obligationsofdeployerspursuanttoArticle26;
(f)requirementsandobligationsofnotifiedbodiespursuanttoArticle31,
Article33(1),(3)and(4)orArticle34;
(g)transparencyobligationsforprovidersanddeployerspursuanttoArticle50.
5.Thesupplyofincorrect,incompleteormisleadinginformationto
notifiedbodiesornationalcompetentauthoritiesinreplytoarequestshall
besubjecttoadministrativefinesofuptoEUR7500000or,iftheoffender
isanundertaking,upto1%ofitstotalworldwideannualturnoverforthe
precedingfinancialyear,whicheverishigher.
6.InthecaseofSMEs,includingstart-ups,eachfinereferredtointhis
Articleshallbeuptothepercentagesoramountreferredtoinparagraphs3,
4and5,whicheverthereofislower.
7.Whendecidingwhethertoimposeanadministrativefineandwhen
decidingontheamountoftheadministrativefineineachindividualcase,all
relevantcircumstancesofthespecificsituationshallbetakenintoaccount
and,asappropriate,regardshallbegiventothefollowing:
(a)thenature,gravityanddurationoftheinfringementandofitsconsequences,taking
intoaccountthepurposeoftheAIsystem,aswellas,whereappropriate,the
numberofaffectedpersonsandthelevelofdamagesufferedbythem;
(b)whetheradministrativefineshavealreadybeenappliedbyothermarket
surveillanceauthoritiestothesameoperatorforthesameinfringement;
(c)whetheradministrativefineshavealreadybeenappliedbyotherauthoritiestothe
sameoperatorforinfringementsofotherUnionornationallaw,whensuch
infringementsresultfromthesameactivityoromissionconstitutingarelevant

--- Page 172 ---
infringementofthisRegulation;
(d)thesize,theannualturnoverandmarketshareoftheoperatorcommittingthe
infringement;
(e)anyotheraggravatingormitigatingfactorapplicabletothecircumstancesofthe
case,suchasfinancialbenefitsgained,orlossesavoided,directlyorindirectly,
fromtheinfringement;
(f)thedegreeofcooperationwiththenationalcompetentauthorities,inorderto
remedytheinfringementandmitigatethepossibleadverseeffectsofthe
infringement;
(g)thedegreeofresponsibilityoftheoperatortakingintoaccountthetechnicaland
organisationalmeasuresimplementedbyit;
(h)themannerinwhichtheinfringementbecameknowntothenationalcompetent
authorities,inparticularwhether,andifsotowhatextent,theoperatornotifiedthe
infringement;
(i)theintentionalornegligentcharacteroftheinfringement;
(j)anyactiontakenbytheoperatortomitigatetheharmsufferedbytheaffected
persons.
8.EachMemberStateshalllaydownrulesontowhatextent
administrativefinesmaybeimposedonpublicauthoritiesandbodies
establishedinthatMemberState.
9.DependingonthelegalsystemoftheMemberStates,theruleson
administrativefinesmaybeappliedinsuchamannerthatthefinesare
imposedbycompetentnationalcourtsorbyotherbodies,asapplicablein
thoseMemberStates.TheapplicationofsuchrulesinthoseMemberStates
shallhaveanequivalenteffect.
10.TheexerciseofpowersunderthisArticleshallbesubjectto
appropriateproceduralsafeguardsinaccordancewithUnionandnational
law,includingeffectivejudicialremediesanddueprocess.
11.MemberStatesshall,onanannualbasis,reporttotheCommission
abouttheadministrativefinestheyhaveissuedduringthatyear,in
accordancewiththisArticle,andaboutanyrelatedlitigationorjudicial
proceedings.
Article100
AdministrativefinesonUnioninstitutions,bodies,officesandagencies
1.TheEuropeanDataProtectionSupervisormayimposeadministrative
finesonUnioninstitutions,bodies,officesandagenciesfallingwithinthe
scopeofthisRegulation.Whendecidingwhethertoimposean
administrativefineandwhendecidingontheamountoftheadministrative

--- Page 173 ---
fineineachindividualcase,allrelevantcircumstancesofthespecific
situationshallbetakenintoaccountanddueregardshallbegiventothe
following:
(a)thenature,gravityanddurationoftheinfringementandofitsconsequences,taking
intoaccountthepurposeoftheAIsystemconcerned,aswellas,whereappropriate,
thenumberofaffectedpersonsandthelevelofdamagesufferedbythem;
(b)thedegreeofresponsibilityoftheUnioninstitution,body,officeoragency,taking
intoaccounttechnicalandorganisationalmeasuresimplementedbythem;
(c)anyactiontakenbytheUnioninstitution,body,officeoragencytomitigatethe
damagesufferedbyaffectedpersons;
(d)thedegreeofcooperationwiththeEuropeanDataProtectionSupervisorinorderto
remedytheinfringementandmitigatethepossibleadverseeffectsofthe
infringement,includingcompliancewithanyofthemeasurespreviouslyordered
bytheEuropeanDataProtectionSupervisoragainsttheUnioninstitution,body,
officeoragencyconcernedwithregardtothesamesubjectmatter;
(e)anysimilarpreviousinfringementsbytheUnioninstitution,body,officeor
agency;
(f)themannerinwhichtheinfringementbecameknowntotheEuropeanData
ProtectionSupervisor,inparticularwhether,andifsotowhatextent,theUnion
institution,body,officeoragencynotifiedtheinfringement;
(g)theannualbudgetoftheUnioninstitution,body,officeoragency.
2.Non-compliancewiththeprohibitionoftheAIpracticesreferredtoin
Article5shallbesubjecttoadministrativefinesofuptoEUR1500000.
3.Thenon-complianceoftheAIsystemwithanyrequirementsor
obligationsunderthisRegulation,otherthanthoselaiddowninArticle5,
shallbesubjecttoadministrativefinesofuptoEUR750000.
4.BeforetakingdecisionspursuanttothisArticle,theEuropeanData
ProtectionSupervisorshallgivetheUnioninstitution,body,officeor
agencywhichisthesubjectoftheproceedingsconductedbytheEuropean
DataProtectionSupervisortheopportunityofbeingheardonthematter
regardingthepossibleinfringement.TheEuropeanDataProtection
Supervisorshallbasehisorherdecisionsonlyonelementsand
circumstancesonwhichthepartiesconcernedhavebeenabletocomment.
Complainants,ifany,shallbeassociatedcloselywiththeproceedings.
5.Therightsofdefenceofthepartiesconcernedshallbefullyrespectedin
theproceedings.TheyshallbeentitledtohaveaccesstotheEuropeanData
ProtectionSupervisor’sfile,subjecttothelegitimateinterestofindividuals
orundertakingsintheprotectionoftheirpersonaldataorbusinesssecrets.

--- Page 174 ---
6.FundscollectedbyimpositionoffinesinthisArticleshallcontributeto
thegeneralbudgetoftheUnion.Thefinesshallnotaffecttheeffective
operationoftheUnioninstitution,body,officeoragencyfined.
7.TheEuropeanDataProtectionSupervisorshall,onanannualbasis,
notifytheCommissionoftheadministrativefinesithasimposedpursuantto
thisArticleandofanylitigationorjudicialproceedingsithasinitiated.
Article101
Finesforprovidersofgeneral-purposeAImodels
1.TheCommissionmayimposeonprovidersofgeneral-purposeAI
modelsfinesnotexceeding3%oftheirannualtotalworldwideturnoverin
theprecedingfinancialyearorEUR15000000,whicheverishigher.,when
theCommissionfindsthattheproviderintentionallyornegligently:
(a)infringedtherelevantprovisionsofthisRegulation;
(b)failedtocomplywitharequestforadocumentorforinformationpursuantto
Article91,orsuppliedincorrect,incompleteormisleadinginformation;
(c)failedtocomplywithameasurerequestedunderArticle93;
(d)failedtomakeavailabletotheCommissionaccesstothegeneral-purposeAImodel
orgeneral-purposeAImodelwithsystemicriskwithaviewtoconductingan
evaluationpursuanttoArticle92.
Infixingtheamountofthefineorperiodicpenaltypayment,regardshallbe
hadtothenature,gravityanddurationoftheinfringement,takingdue
accountoftheprinciplesofproportionalityandappropriateness.The
Commissionshallalsointoaccountcommitmentsmadeinaccordancewith
Article93(3)ormadeinrelevantcodesofpracticeinaccordancewith
Article56.
2.Beforeadoptingthedecisionpursuanttoparagraph1,theCommission
shallcommunicateitspreliminaryfindingstotheproviderofthegeneral-
purposeAImodelandgiveitanopportunitytobeheard.
3.FinesimposedinaccordancewiththisArticleshallbeeffective,
proportionateanddissuasive.
4.InformationonfinesimposedunderthisArticleshallalsobe
communicatedtotheBoardasappropriate.
5.TheCourtofJusticeoftheEuropeanUnionshallhaveunlimited
jurisdictiontoreviewdecisionsoftheCommissionfixingafineunderthis
Article.Itmaycancel,reduceorincreasethefineimposed.
6.TheCommissionshalladoptimplementingactscontainingdetailed
arrangementsandproceduralsafeguardsforproceedingsinviewofthe

--- Page 175 ---
possibleadoptionofdecisionspursuanttoparagraph1ofthisArticle.Those
implementingactsshallbeadoptedinaccordancewiththeexamination
procedurereferredtoinArticle98(2).
CHAPTERXIII
FINALPROVISIONS
Article102
AmendmenttoRegulation(EC)No300/2008
InArticle4(3)ofRegulation(EC)No300/2008,thefollowingsubparagraph
isadded:
‘Whenadoptingdetailedmeasuresrelatedtotechnicalspecificationsand
proceduresforapprovalanduseofsecurityequipmentconcerningArtificial
IntelligencesystemswithinthemeaningofRegulation(EU)2024/1689of
theEuropeanParliamentandoftheCouncil(*),therequirementssetoutin
ChapterIII,Section2,ofthatRegulationshallbetakenintoaccount.
Article103
AmendmenttoRegulation(EU)No167/2013
InArticle17(5)ofRegulation(EU)No167/2013,thefollowing
subparagraphisadded:
‘Whenadoptingdelegatedactspursuanttothefirstsubparagraphconcerning
artificialintelligencesystemswhicharesafetycomponentswithinthe
meaningofRegulation(EU)2024/1689oftheEuropeanParliamentandof
theCouncil(*),therequirementssetoutinChapterIII,Section2,ofthat
Regulationshallbetakenintoaccount.
Article104
AmendmenttoRegulation(EU)No168/2013
InArticle22(5)ofRegulation(EU)No168/2013,thefollowing
subparagraphisadded:
‘Whenadoptingdelegatedactspursuanttothefirstsubparagraphconcerning
ArtificialIntelligencesystemswhicharesafetycomponentswithinthe
meaningofRegulation(EU)2024/1689oftheEuropeanParliamentandof
theCouncil(*),therequirementssetoutinChapterIII,Section2,ofthat
Regulationshallbetakenintoaccount.

--- Page 176 ---
Article105
AmendmenttoDirective2014/90/EU
InArticle8ofDirective2014/90/EU,thefollowingparagraphisadded:
‘5.ForArtificialIntelligencesystemswhicharesafetycomponentswithin
themeaningofRegulation(EU)2024/1689oftheEuropeanParliamentand
oftheCouncil(*),whencarryingoutitsactivitiespursuanttoparagraph1
andwhenadoptingtechnicalspecificationsandtestingstandardsin
accordancewithparagraphs2and3,theCommissionshalltakeintoaccount
therequirementssetoutinChapterIII,Section2,ofthatRegulation.
Article106
AmendmenttoDirective(EU)2016/797
InArticle5ofDirective(EU)2016/797,thefollowingparagraphisadded:
‘12.Whenadoptingdelegatedactspursuanttoparagraph1and
implementingactspursuanttoparagraph11concerningArtificial
Intelligencesystemswhicharesafetycomponentswithinthemeaningof
Regulation(EU)2024/1689oftheEuropeanParliamentandofthe
Council(*),therequirementssetoutinChapterIII,Section2,ofthat
Regulationshallbetakenintoaccount.
Article107
AmendmenttoRegulation(EU)2018/858
InArticle5ofRegulation(EU)2018/858thefollowingparagraphisadded:
‘4.Whenadoptingdelegatedactspursuanttoparagraph3concerning
ArtificialIntelligencesystemswhicharesafetycomponentswithinthe
meaningofRegulation(EU)2024/1689oftheEuropeanParliamentandof
theCouncil(*),therequirementssetoutinChapterIII,Section2,ofthat
Regulationshallbetakenintoaccount.
Article108
AmendmentstoRegulation(EU)2018/1139
Regulation(EU)2018/1139isamendedasfollows:
(1)inArticle17,thefollowingparagraphisadded:
‘3.Withoutprejudicetoparagraph2,whenadoptingimplementingactspursuant
toparagraph1concerningArtificialIntelligencesystemswhicharesafety
componentswithinthemeaningofRegulation(EU)2024/1689oftheEuropean
ParliamentandoftheCouncil(*),therequirementssetoutinChapterIII,

--- Page 177 ---
Section2,ofthatRegulationshallbetakenintoaccount.
(*)Regulation(EU)2024/1689oftheEuropeanParliamentandoftheCouncilof13June2024layingdownharmonised
rulesonartificialintelligenceandamendingRegulations(EC)No300/2008,(EU)No167/2013,(EU)No168/2013,(EU)
2018/858,(EU)2018/1139and(EU)2019/2144andDirectives2014/90/EU,(EU)2016/797and(EU)2020/1828(Artificial
IntelligenceAct)(OJL,2024/1689,12.7.2024,ELI:http://data.europa.eu/eli/reg/2024/1689/oj).’;"
(2)inArticle19,thefollowingparagraphisadded:
‘4.Whenadoptingdelegatedactspursuanttoparagraphs1and2concerning
ArtificialIntelligencesystemswhicharesafetycomponentswithinthemeaningof
Regulation(EU)2024/1689,therequirementssetoutinChapterIII,Section2,of
thatRegulationshallbetakenintoaccount.’
;
(3)inArticle43,thefollowingparagraphisadded:
‘4.Whenadoptingimplementingactspursuanttoparagraph1concerning
ArtificialIntelligencesystemswhicharesafetycomponentswithinthemeaningof
Regulation(EU)2024/1689,therequirementssetoutinChapterIII,Section2,of
thatRegulationshallbetakenintoaccount.’
;
(4)inArticle47,thefollowingparagraphisadded:
‘3.Whenadoptingdelegatedactspursuanttoparagraphs1and2concerning
ArtificialIntelligencesystemswhicharesafetycomponentswithinthemeaningof
Regulation(EU)2024/1689,therequirementssetoutinChapterIII,Section2,of
thatRegulationshallbetakenintoaccount.’
;
(5)inArticle57,thefollowingsubparagraphisadded:
‘WhenadoptingthoseimplementingactsconcerningArtificialIntelligencesystems
whicharesafetycomponentswithinthemeaningofRegulation(EU)2024/1689,
therequirementssetoutinChapterIII,Section2,ofthatRegulationshallbetaken
intoaccount.’
;
(6)inArticle58,thefollowingparagraphisadded:
‘3.Whenadoptingdelegatedactspursuanttoparagraphs1and2concerning
ArtificialIntelligencesystemswhicharesafetycomponentswithinthemeaningof
Regulation(EU)2024/1689,therequirementssetoutinChapterIII,Section2,of
thatRegulationshallbetakenintoaccount.’.
Article109
AmendmenttoRegulation(EU)2019/2144
InArticle11ofRegulation(EU)2019/2144,thefollowingparagraphis
added:

--- Page 178 ---
‘3.Whenadoptingtheimplementingactspursuanttoparagraph2,
concerningartificialintelligencesystemswhicharesafetycomponents
withinthemeaningofRegulation(EU)2024/1689oftheEuropean
ParliamentandoftheCouncil(*),therequirementssetoutinChapterIII,
Section2,ofthatRegulationshallbetakenintoaccount.
Article110
AmendmenttoDirective(EU)2020/1828
InAnnexItoDirective(EU)2020/1828oftheEuropeanParliamentandof
theCouncil(58),thefollowingpointisadded:
‘(68)Regulation(EU)2024/1689oftheEuropeanParliamentandoftheCouncilof
13June2024layingdownharmonisedrulesonartificialintelligenceand
amendingRegulations(EC)No300/2008,(EU)No167/2013,(EU)
No168/2013,(EU)2018/858,(EU)2018/1139and(EU)2019/2144and
Directives2014/90/EU,(EU)2016/797and(EU)2020/1828(Artificial
Intelligence Act) (OJL, 2024/1689, 12.7.2024,
ELI:http://data.europa.eu/eli/reg/2024/1689/oj).’.
Article111
AIsystemsalreadyplacedonthemarketorputintoserviceand
general-purposeAImodelsalreadyplacedonthemarked
1.WithoutprejudicetotheapplicationofArticle5asreferredtoin
Article113(3),point(a),AIsystemswhicharecomponentsofthelarge-
scaleITsystemsestablishedbythelegalactslistedinAnnexXthathave
beenplacedonthemarketorputintoservicebefore2August2027shallbe
broughtintocompliancewiththisRegulationby31December2030.
TherequirementslaiddowninthisRegulationshallbetakenintoaccountin
theevaluationofeachlarge-scaleITsystemestablishedbythelegalacts
listedinAnnexXtobeundertakenasprovidedforinthoselegalactsand
wherethoselegalactsarereplacedoramended.
2.WithoutprejudicetotheapplicationofArticle5asreferredtoin
Article113(3),point(a),thisRegulationshallapplytooperatorsofhigh-risk
AIsystems,otherthanthesystemsreferredtoinparagraph1ofthisArticle,
thathavebeenplacedonthemarketorputintoservicebefore2August
2026,onlyif,asfromthatdate,thosesystemsaresubjecttosignificant
changesintheirdesigns.Inanycase,theprovidersanddeployersofhigh-
riskAIsystemsintendedtobeusedbypublicauthoritiesshalltakethe
necessarystepstocomplywiththerequirementsandobligationsofthis
Regulationby2August2030.

--- Page 179 ---
3.Providersofgeneral-purposeAImodelsthathavebeenplacedonthe
marketbefore2August2025shalltakethenecessarystepsinorderto
complywiththeobligationslaiddowninthisRegulationby2August2027.
Article112
Evaluationandreview
1.TheCommissionshallassesstheneedforamendmentofthelistsetout
inAnnexIIIandofthelistofprohibitedAIpracticeslaiddowninArticle5,
onceayearfollowingtheentryintoforceofthisRegulation,anduntilthe
endoftheperiodofthedelegationofpowerlaiddowninArticle97.The
CommissionshallsubmitthefindingsofthatassessmenttotheEuropean
ParliamentandtheCouncil.
2.By2August2028andeveryfouryearsthereafter,theCommissionshall
evaluateandreporttotheEuropeanParliamentandtotheCouncilonthe
following:
(a)theneedforamendmentsextendingexistingareaheadingsoraddingnewarea
headingsinAnnexIII;
(b)amendmentstothelistofAIsystemsrequiringadditionaltransparencymeasuresin
Article50;
(c)amendmentsenhancingtheeffectivenessofthesupervisionandgovernance
system.
3.By2August2029andeveryfouryearsthereafter,theCommissionshall
submitareportontheevaluationandreviewofthisRegulationtothe
EuropeanParliamentandtotheCouncil.Thereportshallincludean
assessmentwithregardtothestructureofenforcementandthepossibleneed
foraUnionagencytoresolveanyidentifiedshortcomings.Onthebasisof
thefindings,thatreportshall,whereappropriate,beaccompaniedby
aproposalforamendmentofthisRegulation.Thereportsshallbemade
public.
4.Thereportsreferredtoinparagraph2shallpayspecificattentiontothe
following:
(a)thestatusofthefinancial,technicalandhumanresourcesofthenationalcompetent
authoritiesinordertoeffectivelyperformthetasksassignedtothemunder
thisRegulation;
(b)thestateofpenalties,inparticularadministrativefinesasreferredtoin
Article99(1),appliedbyMemberStatesforinfringementsofthisRegulation;
(c)adoptedharmonisedstandardsandcommonspecificationsdevelopedtosupport
thisRegulation;
(d)thenumberofundertakingsthatenterthemarketaftertheentryintoapplicationof

--- Page 180 ---
thisRegulation,andhowmanyofthemareSMEs.
5.By2August2028,theCommissionshallevaluatethefunctioningofthe
AIOffice,whethertheAIOfficehasbeengivensufficientpowersand
competencestofulfilitstasks,andwhetheritwouldberelevantandneeded
fortheproperimplementationandenforcementofthisRegulationto
upgradetheAIOfficeanditsenforcementcompetencesandtoincreaseits
resources.TheCommissionshallsubmitareportonitsevaluationtothe
EuropeanParliamentandtotheCouncil.
6.By2August2028andeveryfouryearsthereafter,theCommissionshall
submitareportonthereviewoftheprogressonthedevelopmentof
standardisationdeliverablesontheenergy-efficientdevelopmentofgeneral-
purposeAImodels,andassestheneedforfurthermeasuresoractions,
includingbindingmeasuresoractions.Thereportshallbesubmittedtothe
EuropeanParliamentandtotheCouncil,anditshallbemadepublic.
7.By2August2028andeverythreeyearsthereafter,theCommission
shallevaluatetheimpactandeffectivenessofvoluntarycodesofconductto
fostertheapplicationoftherequirementssetoutinChapterIII,Section2for
AIsystemsotherthanhigh-riskAIsystemsandpossiblyotheradditional
requirementsforAIsystemsotherthanhigh-riskAIsystems,includingas
regardsenvironmentalsustainability.
8.Forthepurposesofparagraphs1to7,theBoard,theMemberStatesand
nationalcompetentauthoritiesshallprovidetheCommissionwith
informationuponitsrequestandwithoutunduedelay.
9.Incarryingouttheevaluationsandreviewsreferredtoinparagraphs1to
7,theCommissionshalltakeintoaccountthepositionsandfindingsofthe
Board,oftheEuropeanParliament,oftheCouncil,andofotherrelevant
bodiesorsources.
10.TheCommissionshall,ifnecessary,submitappropriateproposalsto
amendthisRegulation,inparticulartakingintoaccountdevelopmentsin
technology,theeffectofAIsystemsonhealthandsafety,andon
fundamentalrights,andinlightofthestateofprogressintheinformation
society.
11.Toguidetheevaluationsandreviewsreferredtoinparagraphs1to7of
thisArticle,theAIOfficeshallundertaketodevelopanobjectiveand
participativemethodologyfortheevaluationofrisklevelsbasedonthe
criteriaoutlinedintherelevantArticlesandtheinclusionofnewsystemsin:
(a)thelistsetoutinAnnexIII,includingtheextensionofexistingareaheadingsorthe
additionofnewareaheadingsinthatAnnex;
(b)thelistofprohibitedpracticessetoutinArticle5;and
(c)thelistofAIsystemsrequiringadditionaltransparencymeasurespursuant

--- Page 181 ---
toArticle50.
12.AnyamendmenttothisRegulationpursuanttoparagraph10,or
relevantdelegatedorimplementingacts,whichconcernssectoralUnion
harmonisationlegislationlistedinSectionBofAnnexIshalltakeinto
accounttheregulatoryspecificitiesofeachsector,andtheexisting
governance,conformityassessmentandenforcementmechanismsand
authoritiesestablishedtherein.
13.By2August2031,theCommissionshallcarryoutanassessmentofthe
enforcementofthisRegulationandshallreportonittotheEuropean
Parliament,theCouncilandtheEuropeanEconomicandSocialCommittee,
takingintoaccountthefirstyearsofapplicationofthisRegulation.Onthe
basisofthefindings,thatreportshall,whereappropriate,beaccompanied
byaproposalforamendmentofthisRegulationwithregardtothestructure
ofenforcementandtheneedforaUnionagencytoresolveanyidentified
shortcomings.
Article113
Entryintoforceandapplication
ThisRegulationshallenterintoforceonthetwentiethdayfollowingthatof
itspublicationintheOfficialJournaloftheEuropeanUnion.
Itshallapplyfrom2August2026.
However:
(a)ChaptersIandIIshallapplyfrom2February2025;
(b)ChapterIIISection4,ChapterV,ChapterVIIandChapterXIIandArticle78shall
applyfrom2August2025,withtheexceptionofArticle101;
(c)Article6(1)andthecorrespondingobligationsinthisRegulationshallapplyfrom
2August2027.
ThisRegulationshallbebindinginitsentiretyand
directlyapplicableinallMemberStates.
DoneatBrussels,13June2024.
FortheEuropeanParliament
ThePresident
R.METSOLA
FortheCouncil
ThePresident
M.MICHEL

--- Page 182 ---
(1)OJC517,22.12.2021,p.56.
(2)OJC115,11.3.2022,p.5.
(3)OJC97,28.2.2022,p.60.
(4)PositionoftheEuropeanParliamentof13March2024(notyetpublishedintheOfficialJournal)anddecisionoftheCouncil
of21May2024.
(5)EuropeanCouncil,SpecialmeetingoftheEuropeanCouncil(1and2October2020)—Conclusions,EUCO13/20,2020,
p.6.
(6)EuropeanParliamentresolutionof20October2020withrecommendationstotheCommissiononaframeworkofethical
aspectsofartificialintelligence,roboticsandrelatedtechnologies,2020/2012(INL).
(7)Regulation(EC)No765/2008oftheEuropeanParliamentandoftheCouncilof9July2008settingouttherequirementsfor
accreditationandrepealingRegulation(EEC)No339/93(OJL218,13.8.2008,p.30).
(8)DecisionNo768/2008/ECoftheEuropeanParliamentandoftheCouncilof9July2008onacommonframeworkforthe
marketingofproducts,andrepealingCouncilDecision93/465/EEC(OJL218,13.8.2008,p.82).
(9)Regulation(EU)2019/1020oftheEuropeanParliamentandoftheCouncilof20June2019onmarketsurveillanceand
complianceofproductsandamendingDirective2004/42/ECandRegulations(EC)No765/2008and(EU)No305/2011(OJ
L169,25.6.2019,p.1).
(10)CouncilDirective85/374/EECof25July1985ontheapproximationofthelaws,regulationsandadministrativeprovisions
oftheMemberStatesconcerningliabilityfordefectiveproducts(OJL210,7.8.1985,p.29).
(11)Regulation(EU)2016/679oftheEuropeanParliamentandoftheCouncilof27April2016ontheprotectionofnatural
personswithregardtotheprocessingofpersonaldataandonthefreemovementofsuchdata,andrepealingDirective95/46/EC
(GeneralDataProtectionRegulation)(OJL119,4.5.2016,p.1).
(12)Regulation(EU)2018/1725oftheEuropeanParliamentandoftheCouncilof23October2018ontheprotectionofnatural
personswithregardtotheprocessingofpersonaldatabytheUnioninstitutions,bodies,officesandagenciesandonthefree
movementofsuchdata,andrepealingRegulation(EC)No45/2001andDecisionNo1247/2002/EC(OJL295,21.11.2018,
p.39).
(13)Directive(EU)2016/680oftheEuropeanParliamentandoftheCouncilof27April2016ontheprotectionofnatural
personswithregardtotheprocessingofpersonaldatabycompetentauthoritiesforthepurposesoftheprevention,investigation,
detectionorprosecutionofcriminaloffencesortheexecutionofcriminalpenalties,andonthefreemovementofsuchdata,and
repealingCouncilFrameworkDecision2008/977/JHA(OJL119,4.5.2016,p.89).
(14)Directive2002/58/ECoftheEuropeanParliamentandoftheCouncilof12July2002concerningtheprocessingofpersonal
dataandtheprotectionofprivacyintheelectroniccommunicationssector(Directiveonprivacyandelectroniccommunications)
(OJL201,31.7.2002,p.37).
(15)Regulation(EU)2022/2065oftheEuropeanParliamentandoftheCouncilof19October2022onaSingleMarketFor
DigitalServicesandamendingDirective2000/31/EC(DigitalServicesAct)(OJL277,27.10.2022,p.1).
(16)Directive(EU)2019/882oftheEuropeanParliamentandoftheCouncilof17April2019ontheaccessibilityrequirements
forproductsandservices(OJL151,7.6.2019,p.70).
(17)Directive2005/29/ECoftheEuropeanParliamentandoftheCouncilof11May2005concerningunfairbusiness-to-
consumercommercialpracticesintheinternalmarketandamendingCouncilDirective84/450/EEC,Directives97/7/EC,
98/27/ECand2002/65/ECoftheEuropeanParliamentandoftheCouncilandRegulation(EC)No2006/2004oftheEuropean
ParliamentandoftheCouncil(‘UnfairCommercialPracticesDirective’)(OJL149,11.6.2005,p.22).
(18)CouncilFrameworkDecision2002/584/JHAof13June2002ontheEuropeanarrestwarrantandthesurrenderprocedures
betweenMemberStates(OJL190,18.7.2002,p.1).

--- Page 183 ---
(19)Directive(EU)2022/2557oftheEuropeanParliamentandoftheCouncilof14December2022ontheresilienceofcritical
entitiesandrepealingCouncilDirective2008/114/EC(OJL333,27.12.2022,p.164).
(20)OJC247,29.6.2022,p.1.
(21)Regulation(EU)2017/745oftheEuropeanParliamentandoftheCouncilof5April2017onmedicaldevices,amending
Directive2001/83/EC,Regulation(EC)No178/2002andRegulation(EC)No1223/2009andrepealingCouncilDirectives
90/385/EECand93/42/EEC(OJL117,5.5.2017,p.1).
(22)Regulation(EU)2017/746oftheEuropeanParliamentandoftheCouncilof5April2017oninvitrodiagnosticmedical
devicesandrepealingDirective98/79/ECandCommissionDecision2010/227/EU(OJL117,5.5.2017,p.176).
(23)Directive2006/42/ECoftheEuropeanParliamentandoftheCouncilof17May2006onmachinery,andamendingDirective
95/16/EC(OJL157,9.6.2006,p.24).
(24)Regulation(EC)No300/2008oftheEuropeanParliamentandoftheCouncilof11March2008oncommonrulesinthefield
ofcivilaviationsecurityandrepealingRegulation(EC)No2320/2002(OJL97,9.4.2008,p.72).
(25)Regulation(EU)No167/2013oftheEuropeanParliamentandoftheCouncilof5February2013ontheapprovalandmarket
surveillanceofagriculturalandforestryvehicles(OJL60,2.3.2013,p.1).
(26)Regulation(EU)No168/2013oftheEuropeanParliamentandoftheCouncilof15January2013ontheapprovalandmarket
surveillanceoftwo-orthree-wheelvehiclesandquadricycles(OJL60,2.3.2013,p.52).
(27)Directive2014/90/EUoftheEuropeanParliamentandoftheCouncilof23July2014onmarineequipmentandrepealing
CouncilDirective96/98/EC(OJL257,28.8.2014,p.146).
(28)Directive(EU)2016/797oftheEuropeanParliamentandoftheCouncilof11May2016ontheinteroperabilityoftherail
systemwithintheEuropeanUnion(OJL138,26.5.2016,p.44).
(29)Regulation(EU)2018/858oftheEuropeanParliamentandoftheCouncilof30May2018ontheapprovalandmarket
surveillanceofmotorvehiclesandtheirtrailers,andofsystems,componentsandseparatetechnicalunitsintendedforsuch
vehicles,amendingRegulations(EC)No715/2007and(EC)No595/2009andrepealingDirective2007/46/EC(OJL151,
14.6.2018,p.1).
(30)Regulation(EU)2018/1139oftheEuropeanParliamentandoftheCouncilof4July2018oncommonrulesinthefieldof
civilaviationandestablishingaEuropeanUnionAviationSafetyAgency,andamendingRegulations(EC)No2111/2005,(EC)
No1008/2008,(EU)No996/2010,(EU)No376/2014andDirectives2014/30/EUand2014/53/EUoftheEuropeanParliament
andoftheCouncil,andrepealingRegulations(EC)No552/2004and(EC)No216/2008oftheEuropeanParliamentandofthe
CouncilandCouncilRegulation(EEC)No3922/91(OJL212,22.8.2018,p.1).
(31)Regulation(EU)2019/2144oftheEuropeanParliamentandoftheCouncilof27November2019ontype-approval
requirementsformotorvehiclesandtheirtrailers,andsystems,componentsandseparatetechnicalunitsintendedforsuch
vehicles,asregardstheirgeneralsafetyandtheprotectionofvehicleoccupantsandvulnerableroadusers,amendingRegulation
(EU)2018/858oftheEuropeanParliamentandoftheCouncilandrepealingRegulations(EC)No78/2009,(EC)No79/2009
and(EC)No661/2009oftheEuropeanParliamentandoftheCouncilandCommissionRegulations(EC)No631/2009,(EU)
No406/2010,(EU)No672/2010,(EU)No1003/2010,(EU)No1005/2010,(EU)No1008/2010,(EU)No1009/2010,(EU)
No19/2011,(EU)No109/2011,(EU)No458/2011,(EU)No65/2012,(EU)No130/2012,(EU)No347/2012,
(EU)No351/2012,(EU)No1230/2012and(EU)2015/166(OJL325,16.12.2019,p.1).
(32)Regulation(EC)No810/2009oftheEuropeanParliamentandoftheCouncilof13July2009establishingaCommunity
CodeonVisas(VisaCode)(OJL243,15.9.2009,p.1).
(33)Directive2013/32/EUoftheEuropeanParliamentandoftheCouncilof26June2013oncommonproceduresforgranting
andwithdrawinginternationalprotection(OJL180,29.6.2013,p.60).
(34)Regulation(EU)2024/900oftheEuropeanparliamentandoftheCouncilof13March2024onthetransparencyand
targetingofpoliticaladvertising(OJL,2024/900,20.3.2024,ELI:http://data.europa.eu/eli/reg/2024/900/oj).
(35)Directive2014/31/EUoftheEuropeanParliamentandoftheCouncilof26February2014ontheharmonisationofthelaws
oftheMemberStatesrelatingtothemakingavailableonthemarketofnon-automaticweighinginstruments(OJL96,29.3.2014,
p.107).

--- Page 184 ---
(36)Directive2014/32/EUoftheEuropeanParliamentandoftheCouncilof26February2014ontheharmonisationofthelaws
oftheMemberStatesrelatingtothemakingavailableonthemarketofmeasuringinstruments(OJL96,29.3.2014,p.149).
(37)Regulation(EU)2019/881oftheEuropeanParliamentandoftheCouncilof17April2019onENISA(theEuropeanUnion
AgencyforCybersecurity)andoninformationandcommunicationstechnologycybersecuritycertificationandrepealing
Regulation(EU)No526/2013(CybersecurityAct)(OJL151,7.6.2019,p.15).
(38)Directive(EU)2016/2102oftheEuropeanParliamentandoftheCouncilof26October2016ontheaccessibilityofthe
websitesandmobileapplicationsofpublicsectorbodies(OJL327,2.12.2016,p.1).
(39)Directive2002/14/ECoftheEuropeanParliamentandoftheCouncilof11March2002establishingageneralframeworkfor
informingandconsultingemployeesintheEuropeanCommunity(OJL80,23.3.2002,p.29).
(40)Directive(EU)2019/790oftheEuropeanParliamentandoftheCouncilof17April2019oncopyrightandrelatedrightsin
theDigitalSingleMarketandamendingDirectives96/9/ECand2001/29/EC(OJL130,17.5.2019,p.92).
(41)Regulation(EU)No1025/2012oftheEuropeanParliamentandoftheCouncilof25October2012onEuropean
standardisation,amendingCouncilDirectives89/686/EECand93/15/EECandDirectives94/9/EC,94/25/EC,95/16/EC,
97/23/EC,98/34/EC,2004/22/EC,2007/23/EC,2009/23/ECand2009/105/ECoftheEuropeanParliamentandoftheCouncil
andrepealingCouncilDecision87/95/EECandDecisionNo1673/2006/ECoftheEuropeanParliamentandoftheCouncil(OJ
L316,14.11.2012,p.12).
(42)Regulation(EU)2022/868oftheEuropeanParliamentandoftheCouncilof30May2022onEuropeandatagovernanceand
amendingRegulation(EU)2018/1724(DataGovernanceAct)(OJL152,3.6.2022,p.1).
(43)Regulation(EU)2023/2854oftheEuropeanParliamentandoftheCouncilof13December2023onharmonisedruleson
fairaccesstoanduseofdataandamendingRegulation(EU)2017/2394andDirective(EU)2020/1828(DataAct)(OJL,
2023/2854,22.12.2023,ELI:http://data.europa.eu/eli/reg/2023/2854/oj).
(44)CommissionRecommendationof6May2003concerningthedefinitionofmicro,smallandmedium-sizedenterprises(OJ
L124,20.5.2003,p.36).
(45)CommissionDecisionof24.1.2024establishingtheEuropeanArtificialIntelligenceOfficeC(2024)390.
(46)Regulation(EU)No575/2013oftheEuropeanParliamentandoftheCouncilof26June2013onprudentialrequirementsfor
creditinstitutionsandinvestmentfirmsandamendingRegulation(EU)No648/2012(OJL176,27.6.2013,p.1).
(47)Directive2008/48/ECoftheEuropeanParliamentandoftheCouncilof23April2008oncreditagreementsforconsumers
andrepealingCouncilDirective87/102/EEC(OJL133,22.5.2008,p.66).
(48)Directive2009/138/ECoftheEuropeanParliamentandoftheCouncilof25November2009onthetaking-upandpursuitof
thebusinessofInsuranceandReinsurance(SolvencyII)(OJL335,17.12.2009,p.1).
(49)Directive2013/36/EUoftheEuropeanParliamentandoftheCouncilof26June2013onaccesstotheactivityofcredit
institutionsandtheprudentialsupervisionofcreditinstitutionsandinvestmentfirms,amendingDirective2002/87/ECand
repealingDirectives2006/48/ECand2006/49/EC(OJL176,27.6.2013,p.338).
(50)Directive2014/17/EUoftheEuropeanParliamentandoftheCouncilof4February2014oncreditagreementsfor
consumersrelatingtoresidentialimmovablepropertyandamendingDirectives2008/48/ECand2013/36/EUandRegulation(EU)
No1093/2010(OJL60,28.2.2014,p.34).
(51)Directive(EU)2016/97oftheEuropeanParliamentandoftheCouncilof20January2016oninsurancedistribution(OJ
L26,2.2.2016,p.19).
(52)CouncilRegulation(EU)No1024/2013of15October2013conferringspecifictasksontheEuropeanCentralBank
concerningpoliciesrelatingtotheprudentialsupervisionofcreditinstitutions(OJL287,29.10.2013,p.63).
(53)Regulation(EU)2023/988oftheEuropeanParliamentandoftheCouncilof10May2023ongeneralproductsafety,
amendingRegulation(EU)No1025/2012oftheEuropeanParliamentandoftheCouncilandDirective(EU)2020/1828ofthe
EuropeanParliamentandtheCouncil,andrepealingDirective2001/95/ECoftheEuropeanParliamentandoftheCounciland
CouncilDirective87/357/EEC(OJL135,23.5.2023,p.1).

--- Page 185 ---
(54)Directive(EU)2019/1937oftheEuropeanParliamentandoftheCouncilof23October2019ontheprotectionofpersons
whoreportbreachesofUnionlaw(OJL305,26.11.2019,p.17).
(55)OJL123,12.5.2016,p.1.
(56)Regulation(EU)No182/2011oftheEuropeanParliamentandoftheCouncilof16February2011layingdowntherulesand
generalprinciplesconcerningmechanismsforcontrolbyMemberStatesoftheCommission’sexerciseofimplementingpowers
(OJL55,28.2.2011,p.13).
(57)Directive(EU)2016/943oftheEuropeanParliamentandoftheCouncilof8June2016ontheprotectionofundisclosed
know-howandbusinessinformation(tradesecrets)againsttheirunlawfulacquisition,useanddisclosure(OJL157,15.6.2016,
p.1).
(58)Directive(EU)2020/1828oftheEuropeanParliamentandoftheCouncilof25November2020onrepresentativeactionsfor
theprotectionofthecollectiveinterestsofconsumersandrepealingDirective2009/22/EC(OJL409,4.12.2020,p.1).
ANNEXI
ListofUnionharmonisationlegislation
SectionA.ListofUnionharmonisationlegislationbasedontheNew
LegislativeFramework
1.Directive2006/42/ECoftheEuropeanParliamentandoftheCouncilof17May2006
onmachinery,andamendingDirective95/16/EC(OJL157,9.6.2006,p.24);
2.Directive2009/48/ECoftheEuropeanParliamentandoftheCouncilof18June2009
onthesafetyoftoys(OJL170,30.6.2009,p.1);
3.Directive2013/53/EUoftheEuropeanParliamentandoftheCouncilof20November
2013onrecreationalcraftandpersonalwatercraftandrepealingDirective94/25/EC
(OJL354,28.12.2013,p.90);
4.Directive2014/33/EUoftheEuropeanParliamentandoftheCouncilof26February
2014ontheharmonisationofthelawsoftheMemberStatesrelatingtoliftsandsafety
componentsforlifts(OJL96,29.3.2014,p.251);
5.Directive2014/34/EUoftheEuropeanParliamentandoftheCouncilof26February
2014ontheharmonisationofthelawsoftheMemberStatesrelatingtoequipmentand
protectivesystemsintendedforuseinpotentiallyexplosiveatmospheres(OJL96,
29.3.2014,p.309);
6.Directive2014/53/EUoftheEuropeanParliamentandoftheCouncilof16April2014
ontheharmonisationofthelawsoftheMemberStatesrelatingtothemakingavailable
onthemarketofradioequipmentandrepealingDirective1999/5/EC(OJL153,
22.5.2014,p.62);
7.Directive2014/68/EUoftheEuropeanParliamentandoftheCouncilof15May2014
ontheharmonisationofthelawsoftheMemberStatesrelatingtothemakingavailable
onthemarketofpressureequipment(OJL189,27.6.2014,p.164);

--- Page 186 ---
8.Regulation(EU)2016/424oftheEuropeanParliamentandoftheCouncilof9March
2016oncablewayinstallationsandrepealingDirective2000/9/EC(OJL81,
31.3.2016,p.1);
9.Regulation(EU)2016/425oftheEuropeanParliamentandoftheCouncilof9March
2016onpersonalprotectiveequipmentandrepealingCouncilDirective89/686/EEC
(OJL81,31.3.2016,p.51);
10.Regulation(EU)2016/426oftheEuropeanParliamentandoftheCouncilof9March
2016onappliancesburninggaseousfuelsandrepealingDirective2009/142/EC(OJ
L81,31.3.2016,p.99);
11.Regulation(EU)2017/745oftheEuropeanParliamentandoftheCouncilof5April
2017onmedicaldevices,amendingDirective2001/83/EC,Regulation(EC)
No178/2002andRegulation(EC)No1223/2009andrepealingCouncilDirectives
90/385/EECand93/42/EEC(OJL117,5.5.2017,p.1);
12.Regulation(EU)2017/746oftheEuropeanParliamentandoftheCouncilof5April
2017oninvitrodiagnosticmedicaldevicesandrepealingDirective98/79/ECand
CommissionDecision2010/227/EU(OJL117,5.5.2017,p.176).
SectionB.ListofotherUnionharmonisationlegislation
13.Regulation(EC)No300/2008oftheEuropeanParliamentandoftheCouncil
of11March2008oncommonrulesinthefieldofcivilaviationsecurityand
repealingRegulation(EC)No2320/2002(OJL97,9.4.2008,p.72);
14.Regulation(EU)No168/2013oftheEuropeanParliamentandoftheCouncil
of15January2013ontheapprovalandmarketsurveillanceoftwo-orthree-wheel
vehiclesandquadricycles(OJL60,2.3.2013,p.52);
15.Regulation(EU)No167/2013oftheEuropeanParliamentandoftheCouncil
of5February2013ontheapprovalandmarketsurveillanceofagriculturaland
forestryvehicles(OJL60,2.3.2013,p.1);
16.Directive2014/90/EUoftheEuropeanParliamentandoftheCouncilof23July2014
onmarineequipmentandrepealingCouncilDirective96/98/EC(OJL257,
28.8.2014,p.146);
17.Directive(EU)2016/797oftheEuropeanParliamentandoftheCouncilof11May
2016ontheinteroperabilityoftherailsystemwithintheEuropeanUnion(OJL138,
26.5.2016,p.44);
18.Regulation(EU)2018/858oftheEuropeanParliamentandoftheCouncilof30May
2018ontheapprovalandmarketsurveillanceofmotorvehiclesandtheirtrailers,
andofsystems,componentsandseparatetechnicalunitsintendedforsuchvehicles,
amendingRegulations(EC)No715/2007and(EC)No595/2009andrepealing
Directive2007/46/EC(OJL151,14.6.2018,p.1);
19.Regulation(EU)2019/2144oftheEuropeanParliamentandoftheCouncil

--- Page 187 ---
of27November2019ontype-approvalrequirementsformotorvehiclesandtheir
trailers,andsystems,componentsandseparatetechnicalunitsintendedforsuch
vehicles,asregardstheirgeneralsafetyandtheprotectionofvehicleoccupantsand
vulnerableroadusers,amendingRegulation(EU)2018/858oftheEuropean
ParliamentandoftheCouncilandrepealingRegulations(EC)No78/2009,(EC)
No79/2009and(EC)No661/2009oftheEuropeanParliamentandoftheCouncil
andCommissionRegulations(EC)No631/2009,(EU)No406/2010,(EU)
No672/2010,(EU)No1003/2010,(EU)No1005/2010,(EU)No1008/2010,(EU)
No1009/2010,(EU)No19/2011,(EU)No109/2011,(EU)No458/2011,(EU)
No65/2012,(EU)No130/2012,(EU)No347/2012,(EU)No351/2012,(EU)
No1230/2012and(EU)2015/166(OJL325,16.12.2019,p.1);
20.Regulation(EU)2018/1139oftheEuropeanParliamentandoftheCouncilof4July
2018oncommonrulesinthefieldofcivilaviationandestablishingaEuropean
UnionAviationSafetyAgency,andamendingRegulations(EC)No2111/2005,(EC)
No1008/2008,(EU)No996/2010,(EU)No376/2014andDirectives2014/30/EU
and2014/53/EUoftheEuropeanParliamentandoftheCouncil,andrepealing
Regulations(EC)No552/2004and(EC)No216/2008oftheEuropeanParliament
andoftheCouncilandCouncilRegulation(EEC)No3922/91(OJL212,22.8.2018,
p.1),insofarasthedesign,productionandplacingonthemarketofaircrafts
referredtoinArticle2(1),points(a)and(b)thereof,whereitconcernsunmanned
aircraftandtheirengines,propellers,partsandequipmenttocontrolthemremotely,
areconcerned.
ANNEXII
ListofcriminaloffencesreferredtoinArticle5(1),firstsubparagraph,
point(h)(iii)
CriminaloffencesreferredtoinArticle5(1),firstsubparagraph,point
(h)(iii):
— terrorism,
—traffickinginhumanbeings,
—sexualexploitationofchildren,andchildpornography,
—illicittraffickinginnarcoticdrugsorpsychotropicsubstances,
—illicittraffickinginweapons,munitionsorexplosives,
—murder,grievousbodilyinjury,
—illicittradeinhumanorgansortissue,
—illicittraffickinginnuclearorradioactivematerials,
—kidnapping,illegalrestraintorhostage-taking,

--- Page 188 ---
—crimeswithinthejurisdictionoftheInternationalCriminalCourt,
—unlawfulseizureofaircraftorships,
— rape,
— environmentalcrime,
—organisedorarmedrobbery,
— sabotage,
—participationinacriminalorganisationinvolvedinoneormoreoftheoffences
listedabove.
ANNEXIII
High-riskAIsystemsreferredtoinArticle6(2)
High-riskAIsystemspursuanttoArticle6(2)aretheAIsystemslistedin
anyofthefollowingareas:
1.Biometrics,insofarastheiruseispermittedunderrelevantUnionornationallaw:
(a)remotebiometricidentificationsystems.
ThisshallnotincludeAIsystemsintendedtobeusedforbiometricverification
thesolepurposeofwhichistoconfirmthataspecificnaturalpersonistheperson
heorsheclaimstobe;
(b)AIsystemsintendedtobeusedforbiometriccategorisation,accordingto
sensitiveorprotectedattributesorcharacteristicsbasedontheinferenceofthose
attributesorcharacteristics;
(c)AIsystemsintendedtobeusedforemotionrecognition.
2.Criticalinfrastructure:AIsystemsintendedtobeusedassafetycomponentsinthe
managementandoperationofcriticaldigitalinfrastructure,roadtraffic,orinthe
supplyofwater,gas,heatingorelectricity.
3.Educationandvocationaltraining:
(a)AIsystemsintendedtobeusedtodetermineaccessoradmissionortoassign
naturalpersonstoeducationalandvocationaltraininginstitutionsatalllevels;
(b)AIsystemsintendedtobeusedtoevaluatelearningoutcomes,includingwhen
thoseoutcomesareusedtosteerthelearningprocessofnaturalpersonsin
educationalandvocationaltraininginstitutionsatalllevels;
(c)AIsystemsintendedtobeusedforthepurposeofassessingtheappropriatelevel
ofeducationthatanindividualwillreceiveorwillbeabletoaccess,inthe
contextoforwithineducationalandvocationaltraininginstitutionsatalllevels;
(d)AIsystemsintendedtobeusedformonitoringanddetectingprohibited
behaviourofstudentsduringtestsinthecontextoforwithineducationaland

--- Page 189 ---
vocationaltraininginstitutionsatalllevels.
4.Employment,workers’managementandaccesstoself-employment:
(a)AIsystemsintendedtobeusedfortherecruitmentorselectionofnatural
persons,inparticulartoplacetargetedjobadvertisements,toanalyseandfilter
jobapplications,andtoevaluatecandidates;
(b)AIsystemsintendedtobeusedtomakedecisionsaffectingtermsofwork-related
relationships,thepromotionorterminationofwork-relatedcontractual
relationships,toallocatetasksbasedonindividualbehaviourorpersonaltraitsor
characteristicsortomonitorandevaluatetheperformanceandbehaviourof
personsinsuchrelationships.
5.Accesstoandenjoymentofessentialprivateservicesandessentialpublicservices
andbenefits:
(a)AIsystemsintendedtobeusedbypublicauthoritiesoronbehalfofpublic
authoritiestoevaluatetheeligibilityofnaturalpersonsforessentialpublic
assistancebenefitsandservices,includinghealthcareservices,aswellastogrant,
reduce,revoke,orreclaimsuchbenefitsandservices;
(b)AIsystemsintendedtobeusedtoevaluatethecreditworthinessofnatural
personsorestablishtheircreditscore,withtheexceptionofAIsystemsusedfor
thepurposeofdetectingfinancialfraud;
(c)AIsystemsintendedtobeusedforriskassessmentandpricinginrelationto
naturalpersonsinthecaseoflifeandhealthinsurance;
(d)AIsystemsintendedtoevaluateandclassifyemergencycallsbynaturalpersons
ortobeusedtodispatch,ortoestablishpriorityinthedispatchingof,emergency
firstresponseservices,includingbypolice,firefightersandmedicalaid,aswell
asofemergencyhealthcarepatienttriagesystems.
6.Lawenforcement,insofarastheiruseispermittedunderrelevantUnionornational
law:
(a)AIsystemsintendedtobeusedbyoronbehalfoflawenforcementauthorities,or
byUnioninstitutions,bodies,officesoragenciesinsupportoflawenforcement
authoritiesorontheirbehalftoassesstheriskofanaturalpersonbecomingthe
victimofcriminaloffences;
(b)AIsystemsintendedtobeusedbyoronbehalfoflawenforcementauthoritiesor
byUnioninstitutions,bodies,officesoragenciesinsupportoflawenforcement
authoritiesaspolygraphsorsimilartools;
(c)AIsystemsintendedtobeusedbyoronbehalfoflawenforcementauthorities,or
byUnioninstitutions,bodies,officesoragencies,insupportoflawenforcement
authoritiestoevaluatethereliabilityofevidenceinthecourseoftheinvestigation
orprosecutionofcriminaloffences;
(d)AIsystemsintendedtobeusedbylawenforcementauthoritiesorontheirbehalf
orbyUnioninstitutions,bodies,officesoragenciesinsupportoflaw
enforcementauthoritiesforassessingtheriskofanaturalpersonoffendingorre-
offendingnotsolelyonthebasisoftheprofilingofnaturalpersonsasreferredto
inArticle3(4)ofDirective(EU)2016/680,ortoassesspersonalitytraitsand

--- Page 190 ---
characteristicsorpastcriminalbehaviourofnaturalpersonsorgroups;
(e)AIsystemsintendedtobeusedbyoronbehalfoflawenforcementauthoritiesor
byUnioninstitutions,bodies,officesoragenciesinsupportoflawenforcement
authoritiesfortheprofilingofnaturalpersonsasreferredtoinArticle3(4)of
Directive(EU)2016/680inthecourseofthedetection,investigationor
prosecutionofcriminaloffences.
7.Migration,asylumandbordercontrolmanagement,insofarastheiruseis
permittedunderrelevantUnionornationallaw:
(a)AIsystemsintendedtobeusedbyoronbehalfofcompetentpublicauthoritiesor
byUnioninstitutions,bodies,officesoragenciesaspolygraphsorsimilartools;
(b)AIsystemsintendedtobeusedbyoronbehalfofcompetentpublicauthoritiesor
byUnioninstitutions,bodies,officesoragenciestoassessarisk,including
asecurityrisk,ariskofirregularmigration,orahealthrisk,posedbyanatural
personwhointendstoenterorwhohasenteredintotheterritoryofaMember
State;
(c)AIsystemsintendedtobeusedbyoronbehalfofcompetentpublicauthoritiesor
byUnioninstitutions,bodies,officesoragenciestoassistcompetentpublic
authoritiesfortheexaminationofapplicationsforasylum,visaorresidence
permitsandforassociatedcomplaintswithregardtotheeligibilityofthenatural
personsapplyingforastatus,includingrelatedassessmentsofthereliabilityof
evidence;
(d)AIsystemsintendedtobeusedbyoronbehalfofcompetentpublicauthorities,
orbyUnioninstitutions,bodies,officesoragencies,inthecontextofmigration,
asylumorbordercontrolmanagement,forthepurposeofdetecting,recognising
oridentifyingnaturalpersons,withtheexceptionoftheverificationoftravel
documents.
8.Administrationofjusticeanddemocraticprocesses:
(a)AIsystemsintendedtobeusedbyajudicialauthorityorontheirbehalftoassist
ajudicialauthorityinresearchingandinterpretingfactsandthelawandin
applyingthelawtoaconcretesetoffacts,ortobeusedinasimilarwayin
alternativedisputeresolution;
(b)AIsystemsintendedtobeusedforinfluencingtheoutcomeofanelectionor
referendumorthevotingbehaviourofnaturalpersonsintheexerciseoftheir
voteinelectionsorreferenda.ThisdoesnotincludeAIsystemstotheoutputof
whichnaturalpersonsarenotdirectlyexposed,suchastoolsusedtoorganise,
optimiseorstructurepoliticalcampaignsfromanadministrativeorlogistical
pointofview.
ANNEXIV
TechnicaldocumentationreferredtoinArticle11(1)

--- Page 191 ---
ThetechnicaldocumentationreferredtoinArticle11(1)shallcontainat
leastthefollowinginformation,asapplicabletotherelevantAIsystem:
1.AgeneraldescriptionoftheAIsystemincluding:
(a)itsintendedpurpose,thenameoftheproviderandtheversionofthesystem
reflectingitsrelationtopreviousversions;
(b)howtheAIsysteminteractswith,orcanbeusedtointeractwith,hardwareor
software,includingwithotherAIsystems,thatarenotpartoftheAIsystem
itself,whereapplicable;
(c)theversionsofrelevantsoftwareorfirmware,andanyrequirementsrelatedto
versionupdates;
(d)thedescriptionofalltheformsinwhichtheAIsystemisplacedonthemarketor
putintoservice,suchassoftwarepackagesembeddedintohardware,downloads,
orAPIs;
(e)thedescriptionofthehardwareonwhichtheAIsystemisintendedtorun;
(f)wheretheAIsystemisacomponentofproducts,photographsorillustrations
showingexternalfeatures,themarkingandinternallayoutofthoseproducts;
(g)abasicdescriptionoftheuser-interfaceprovidedtothedeployer;
(h)instructionsforuseforthedeployer,andabasicdescriptionoftheuser-interface
providedtothedeployer,whereapplicable;
2.AdetaileddescriptionoftheelementsoftheAIsystemandoftheprocessforits
development,including:
(a)themethodsandstepsperformedforthedevelopmentoftheAIsystem,
including,whererelevant,recoursetopre-trainedsystemsortoolsprovidedby
thirdpartiesandhowthosewereused,integratedormodifiedbytheprovider;
(b)thedesignspecificationsofthesystem,namelythegenerallogicoftheAIsystem
andofthealgorithms;thekeydesignchoicesincludingtherationaleand
assumptionsmade,includingwithregardtopersonsorgroupsofpersonsin
respectofwho,thesystemisintendedtobeused;themainclassificationchoices;
whatthesystemisdesignedtooptimisefor,andtherelevanceofthedifferent
parameters;thedescriptionoftheexpectedoutputandoutputqualityofthe
system;thedecisionsaboutanypossibletrade-offmaderegardingthetechnical
solutionsadoptedtocomplywiththerequirementssetoutinChapterIII,
Section2;
(c)thedescriptionofthesystemarchitectureexplaininghowsoftwarecomponents
buildonorfeedintoeachotherandintegrateintotheoverallprocessing;the
computationalresourcesusedtodevelop,train,testandvalidatetheAIsystem;
(d)whererelevant,thedatarequirementsintermsofdatasheetsdescribingthe
trainingmethodologiesandtechniquesandthetrainingdatasetsused,including
ageneraldescriptionofthesedatasets,informationabouttheirprovenance,
scopeandmaincharacteristics;howthedatawasobtainedandselected;labelling
procedures(e.g.forsupervisedlearning),datacleaningmethodologies(e.g.
outliersdetection);

--- Page 192 ---
(e)assessmentofthehumanoversightmeasuresneededinaccordancewith
Article14,includinganassessmentofthetechnicalmeasuresneededtofacilitate
theinterpretationoftheoutputsofAIsystemsbythedeployers,inaccordance
withArticle13(3),point(d);
(f)whereapplicable,adetaileddescriptionofpre-determinedchangestotheAI
systemanditsperformance,togetherwithalltherelevantinformationrelatedto
thetechnicalsolutionsadoptedtoensurecontinuouscomplianceoftheAIsystem
withtherelevantrequirementssetoutinChapterIII,Section2;
(g)thevalidationandtestingproceduresused,includinginformationaboutthe
validationandtestingdatausedandtheirmaincharacteristics;metricsusedto
measureaccuracy,robustnessandcompliancewithotherrelevantrequirements
setoutinChapterIII,Section2,aswellaspotentiallydiscriminatoryimpacts;
testlogsandalltestreportsdatedandsignedbytheresponsiblepersons,
includingwithregardtopre-determinedchangesasreferredtounderpoint(f);
(h)cybersecuritymeasuresputinplace;
3.Detailedinformationaboutthemonitoring,functioningandcontroloftheAI
system,inparticularwithregardto:itscapabilitiesandlimitationsinperformance,
includingthedegreesofaccuracyforspecificpersonsorgroupsofpersonson
whichthesystemisintendedtobeusedandtheoverallexpectedlevelofaccuracy
inrelationtoitsintendedpurpose;theforeseeableunintendedoutcomesandsources
ofriskstohealthandsafety,fundamentalrightsanddiscriminationinviewofthe
intendedpurposeoftheAIsystem;thehumanoversightmeasuresneededin
accordancewithArticle14,includingthetechnicalmeasuresputinplaceto
facilitatetheinterpretationoftheoutputsofAIsystemsbythedeployers;
specificationsoninputdata,asappropriate;
4.AdescriptionoftheappropriatenessoftheperformancemetricsforthespecificAI
system;
5.AdetaileddescriptionoftheriskmanagementsysteminaccordancewithArticle9;
6.Adescriptionofrelevantchangesmadebytheprovidertothesystemthroughits
lifecycle;
7.Alistoftheharmonisedstandardsappliedinfullorinpartthereferencesofwhich
havebeenpublishedintheOfficialJournaloftheEuropeanUnion;wherenosuch
harmonisedstandardshavebeenapplied,adetaileddescriptionofthesolutions
adoptedtomeettherequirementssetoutinChapterIII,Section2,includingalistof
otherrelevantstandardsandtechnicalspecificationsapplied;
8.AcopyoftheEUdeclarationofconformityreferredtoinArticle47;
9.AdetaileddescriptionofthesysteminplacetoevaluatetheAIsystemperformance
inthepost-marketphaseinaccordancewithArticle72,includingthepost-market
monitoringplanreferredtoinArticle72(3).
ANNEXV

--- Page 193 ---
EUdeclarationofconformity
TheEUdeclarationofconformityreferredtoinArticle47,shallcontainall
ofthefollowinginformation:
1.AIsystemnameandtypeandanyadditionalunambiguousreferenceallowingthe
identificationandtraceabilityoftheAIsystem;
2.Thenameandaddressoftheprovideror,whereapplicable,oftheirauthorised
representative;
3.AstatementthattheEUdeclarationofconformityreferredtoinArticle47isissued
underthesoleresponsibilityoftheprovider;
4.AstatementthattheAIsystemisinconformitywiththisRegulationand,if
applicable,withanyotherrelevantUnionlawthatprovidesfortheissuingoftheEU
declarationofconformityreferredtoinArticle47;
5.WhereanAIsysteminvolvestheprocessingofpersonaldata,astatementthatthat
AIsystemcomplieswithRegulations(EU)2016/679and(EU)2018/1725and
Directive(EU)2016/680;
6.Referencestoanyrelevantharmonisedstandardsusedoranyothercommon
specificationinrelationtowhichconformityisdeclared;
7.Whereapplicable,thenameandidentificationnumberofthenotifiedbody,
adescriptionoftheconformityassessmentprocedureperformed,andidentification
ofthecertificateissued;
8.Theplaceanddateofissueofthedeclaration,thenameandfunctionoftheperson
whosignedit,aswellasanindicationfor,oronbehalfofwhom,thatpersonsigned,
asignature.
ANNEXVI
Conformityassessmentprocedurebasedoninternalcontrol
1.
Theconformityassessmentprocedurebasedoninternalcontrolisthe
conformityassessmentprocedurebasedonpoints2,3and4.
2.
Theproviderverifiesthattheestablishedqualitymanagementsystemisin
compliancewiththerequirementsofArticle17.
3.

--- Page 194 ---
Theproviderexaminestheinformationcontainedinthetechnical
documentationinordertoassessthecomplianceoftheAIsystemwiththe
relevantessentialrequirementssetoutinChapterIII,Section2.
4.
TheprovideralsoverifiesthatthedesignanddevelopmentprocessoftheAI
systemanditspost-marketmonitoringasreferredtoinArticle72is
consistentwiththetechnicaldocumentation.
ANNEXVII
Conformitybasedonanassessmentofthequalitymanagementsystem
andanassessmentofthetechnicaldocumentation
1.Introduction
Conformitybasedonanassessmentofthequalitymanagementsystemand
anassessmentofthetechnicaldocumentationistheconformityassessment
procedurebasedonpoints2to5.
2.Overview
Theapprovedqualitymanagementsystemforthedesign,developmentand
testingofAIsystemspursuanttoArticle17shallbeexaminedinaccordance
withpoint3andshallbesubjecttosurveillanceasspecifiedinpoint5.The
technicaldocumentationoftheAIsystemshallbeexaminedinaccordance
withpoint4.
3.Qualitymanagementsystem
3.1.Theapplicationoftheprovidershallinclude:
(a)thenameandaddressoftheproviderand,iftheapplicationislodgedbyan
authorisedrepresentative,alsotheirnameandaddress;
(b)thelistofAIsystemscoveredunderthesamequalitymanagementsystem;
(c)thetechnicaldocumentationforeachAIsystemcoveredunderthesamequality
managementsystem;
(d)thedocumentationconcerningthequalitymanagementsystemwhichshall
coveralltheaspectslistedunderArticle17;
(e)adescriptionoftheproceduresinplacetoensurethatthequalitymanagement

--- Page 195 ---
systemremainsadequateandeffective;
(f)awrittendeclarationthatthesameapplicationhasnotbeenlodgedwithany
othernotifiedbody.
3.2.Thequalitymanagementsystemshallbeassessedbythenotifiedbody,whichshall
determinewhetheritsatisfiestherequirementsreferredtoinArticle17.
Thedecisionshallbenotifiedtotheprovideroritsauthorisedrepresentative.
Thenotificationshallcontaintheconclusionsoftheassessmentofthequality
managementsystemandthereasonedassessmentdecision.
3.3.Thequalitymanagementsystemasapprovedshallcontinuetobeimplementedand
maintainedbytheprovidersothatitremainsadequateandefficient.
3.4.AnyintendedchangetotheapprovedqualitymanagementsystemorthelistofAI
systemscoveredbythelattershallbebroughttotheattentionofthenotifiedbodyby
theprovider.
Theproposedchangesshallbeexaminedbythenotifiedbody,whichshalldecide
whetherthemodifiedqualitymanagementsystemcontinuestosatisfythe
requirementsreferredtoinpoint3.2orwhetherareassessmentisnecessary.
Thenotifiedbodyshallnotifytheproviderofitsdecision.Thenotificationshall
containtheconclusionsoftheexaminationofthechangesandthereasoned
assessmentdecision.
4.Controlofthetechnicaldocumentation.
4.1.Inadditiontotheapplicationreferredtoinpoint3,anapplicationwithanotified
bodyoftheirchoiceshallbelodgedbytheproviderfortheassessmentofthe
technicaldocumentationrelatingtotheAIsystemwhichtheproviderintendsto
placeonthemarketorputintoserviceandwhichiscoveredbythequality
managementsystemreferredtounderpoint3.
4.2.Theapplicationshallinclude:
(a)thenameandaddressoftheprovider;
(b)awrittendeclarationthatthesameapplicationhasnotbeenlodgedwithany
othernotifiedbody;
(c)thetechnicaldocumentationreferredtoinAnnexIV.
4.3.Thetechnicaldocumentationshallbeexaminedbythenotifiedbody.Where
relevant,andlimitedtowhatisnecessarytofulfilitstasks,thenotifiedbodyshallbe
grantedfullaccesstothetraining,validation,andtestingdatasetsused,including,
whereappropriateandsubjecttosecuritysafeguards,throughAPIorotherrelevant
technicalmeansandtoolsenablingremoteaccess.
4.4.Inexaminingthetechnicaldocumentation,thenotifiedbodymayrequirethatthe
providersupplyfurtherevidenceorcarryoutfurthertestssoastoenableaproper
assessmentoftheconformityoftheAIsystemwiththerequirementssetoutin
ChapterIII,Section2.Wherethenotifiedbodyisnotsatisfiedwiththetestscarried
outbytheprovider,thenotifiedbodyshallitselfdirectlycarryoutadequatetests,as

--- Page 196 ---
appropriate.
4.5.Wherenecessarytoassesstheconformityofthehigh-riskAIsystemwiththe
requirementssetoutinChapterIII,Section2,afterallotherreasonablemeansto
verifyconformityhavebeenexhaustedandhaveproventobeinsufficient,andupon
areasonedrequest,thenotifiedbodyshallalsobegrantedaccesstothetrainingand
trainedmodelsoftheAIsystem,includingitsrelevantparameters.Suchaccessshall
besubjecttoexistingUnionlawontheprotectionofintellectualpropertyandtrade
secrets.
4.6.Thedecisionofthenotifiedbodyshallbenotifiedtotheprovideroritsauthorised
representative.Thenotificationshallcontaintheconclusionsoftheassessmentof
thetechnicaldocumentationandthereasonedassessmentdecision.
WheretheAIsystemisinconformitywiththerequirementssetoutinChapterIII,
Section2,thenotifiedbodyshallissueaUniontechnicaldocumentation
assessmentcertificate.Thecertificateshallindicatethenameandaddressofthe
provider,theconclusionsoftheexamination,theconditions(ifany)forits
validityandthedatanecessaryfortheidentificationoftheAIsystem.
Thecertificateanditsannexesshallcontainallrelevantinformationtoallowthe
conformityoftheAIsystemtobeevaluated,andtoallowforcontroloftheAI
systemwhileinuse,whereapplicable.
WheretheAIsystemisnotinconformitywiththerequirementssetoutin
ChapterIII,Section2,thenotifiedbodyshallrefusetoissueaUniontechnical
documentationassessmentcertificateandshallinformtheapplicantaccordingly,
givingdetailedreasonsforitsrefusal.
WheretheAIsystemdoesnotmeettherequirementrelatingtothedatausedto
trainit,re-trainingoftheAIsystemwillbeneededpriortotheapplicationfor
anewconformityassessment.Inthiscase,thereasonedassessmentdecisionof
thenotifiedbodyrefusingtoissuetheUniontechnicaldocumentationassessment
certificateshallcontainspecificconsiderationsonthequalitydatausedtotrainthe
AIsystem,inparticularonthereasonsfornon-compliance.
4.7.AnychangetotheAIsystemthatcouldaffectthecomplianceoftheAIsystemwith
therequirementsoritsintendedpurposeshallbeassessedbythenotifiedbody
whichissuedtheUniontechnicaldocumentationassessmentcertificate.The
providershallinformsuchnotifiedbodyofitsintentiontointroduceanyofthe
abovementionedchanges,orifitotherwisebecomesawareoftheoccurrenceofsuch
changes.Theintendedchangesshallbeassessedbythenotifiedbody,whichshall
decidewhetherthosechangesrequireanewconformityassessmentinaccordance
withArticle43(4)orwhethertheycouldbeaddressedbymeansofasupplementto
theUniontechnicaldocumentationassessmentcertificate.Inthelattercase,the
notifiedbodyshallassessthechanges,notifytheproviderofitsdecisionand,where
thechangesareapproved,issuetotheproviderasupplementtotheUniontechnical
documentationassessmentcertificate.
5.Surveillanceoftheapprovedqualitymanagementsystem.

--- Page 197 ---
5.1.ThepurposeofthesurveillancecarriedoutbythenotifiedbodyreferredtoinPoint
3istomakesurethattheproviderdulycomplieswiththetermsandconditionsof
theapprovedqualitymanagementsystem.
5.2.Forassessmentpurposes,theprovidershallallowthenotifiedbodytoaccessthe
premiseswherethedesign,development,testingoftheAIsystemsistakingplace.
Theprovidershallfurthersharewiththenotifiedbodyallnecessaryinformation.
5.3.Thenotifiedbodyshallcarryoutperiodicauditstomakesurethattheprovider
maintainsandappliesthequalitymanagementsystemandshallprovidetheprovider
withanauditreport.Inthecontextofthoseaudits,thenotifiedbodymaycarryout
additionaltestsoftheAIsystemsforwhichaUniontechnicaldocumentation
assessmentcertificatewasissued.
ANNEXVIII
Informationtobesubmittedupontheregistrationofhigh-riskAI
systemsinaccordancewithArticle49
SectionA—Informationtobesubmittedbyprovidersofhigh-riskAI
systemsinaccordancewithArticle49(1)
Thefollowinginformationshallbeprovidedandthereafterkeptuptodate
withregardtohigh-riskAIsystemstoberegisteredinaccordancewith
Article49(1):
1.Thename,addressandcontactdetailsoftheprovider;
2.Wheresubmissionofinformationiscarriedoutbyanotherpersononbehalfofthe
provider,thename,addressandcontactdetailsofthatperson;
3.Thename,addressandcontactdetailsoftheauthorisedrepresentative,where
applicable;
4.TheAIsystemtradenameandanyadditionalunambiguousreferenceallowingthe
identificationandtraceabilityoftheAIsystem;
5.AdescriptionoftheintendedpurposeoftheAIsystemandofthecomponentsand
functionssupportedthroughthisAIsystem;
6.Abasicandconcisedescriptionoftheinformationusedbythesystem(data,inputs)
anditsoperatinglogic;
7.ThestatusoftheAIsystem(onthemarket,orinservice;nolongerplacedonthe
market/inservice,recalled);
8.Thetype,numberandexpirydateofthecertificateissuedbythenotifiedbodyand
thenameoridentificationnumberofthatnotifiedbody,whereapplicable;
9.Ascannedcopyofthecertificatereferredtoinpoint8,whereapplicable;
10.AnyMemberStatesinwhichtheAIsystemhasbeenplacedonthemarket,put

--- Page 198 ---
intoserviceormadeavailableintheUnion;
11.AcopyoftheEUdeclarationofconformityreferredtoinArticle47;
12.Electronicinstructionsforuse;thisinformationshallnotbeprovidedforhigh-risk
AIsystemsintheareasoflawenforcementormigration,asylumandborder
controlmanagementreferredtoinAnnexIII,points1,6and7;
13.AURLforadditionalinformation(optional).
SectionB—Informationtobesubmittedbyprovidersofhigh-riskAI
systemsinaccordancewithArticle49(2)
Thefollowinginformationshallbeprovidedandthereafterkeptuptodate
withregardtoAIsystemstoberegisteredinaccordancewithArticle49(2):
1.Thename,addressandcontactdetailsoftheprovider;
2.Wheresubmissionofinformationiscarriedoutbyanotherpersononbehalfofthe
provider,thename,addressandcontactdetailsofthatperson;
3.Thename,addressandcontactdetailsoftheauthorisedrepresentative,where
applicable;
4.TheAIsystemtradenameandanyadditionalunambiguousreferenceallowingthe
identificationandtraceabilityoftheAIsystem;
5.AdescriptionoftheintendedpurposeoftheAIsystem;
6.TheconditionorconditionsunderArticle6(3)basedonwhichtheAIsystemis
consideredtobenot-high-risk;
7.AshortsummaryofthegroundsonwhichtheAIsystemisconsideredtobenot-
high-riskinapplicationoftheprocedureunderArticle6(3);
8.ThestatusoftheAIsystem(onthemarket,orinservice;nolongerplacedonthe
market/inservice,recalled);
9.AnyMemberStatesinwhichtheAIsystemhasbeenplacedonthemarket,putinto
serviceormadeavailableintheUnion.
SectionC—Informationtobesubmittedbydeployersofhigh-riskAI
systemsinaccordancewithArticle49(3)
Thefollowinginformationshallbeprovidedandthereafterkeptuptodate
withregardtohigh-riskAIsystemstoberegisteredinaccordancewith
Article49(3):
1.Thename,addressandcontactdetailsofthedeployer;
2.Thename,addressandcontactdetailsofthepersonsubmittinginformationon
behalfofthedeployer;
3.TheURLoftheentryoftheAIsystemintheEUdatabasebyitsprovider;
4.Asummaryofthefindingsofthefundamentalrightsimpactassessmentconducted

--- Page 199 ---
inaccordancewithArticle27;
5.Asummaryofthedataprotectionimpactassessmentcarriedoutinaccordancewith
Article35ofRegulation(EU)2016/679orArticle27ofDirective(EU)2016/680as
specifiedinArticle26(8)ofthisRegulation,whereapplicable.
ANNEXIX
Informationtobesubmittedupontheregistrationofhigh-riskAI
systemslistedinAnnexIIIinrelationtotestinginrealworldconditions
inaccordancewithArticle60
Thefollowinginformationshallbeprovidedandthereafterkeptuptodate
withregardtotestinginrealworldconditionstoberegisteredinaccordance
withArticle60:
1.AUnion-wideuniquesingleidentificationnumberofthetestinginrealworld
conditions;
2.Thenameandcontactdetailsoftheproviderorprospectiveproviderandofthe
deployersinvolvedinthetestinginrealworldconditions;
3.AbriefdescriptionoftheAIsystem,itsintendedpurpose,andotherinformation
necessaryfortheidentificationofthesystem;
4.Asummaryofthemaincharacteristicsoftheplanfortestinginrealworld
conditions;
5.Informationonthesuspensionorterminationofthetestinginrealworldconditions.
ANNEXX
Unionlegislativeactsonlarge-scaleITsystemsintheareaofFreedom,
SecurityandJustice
1.SchengenInformationSystem
(a)Regulation(EU)2018/1860oftheEuropeanParliamentandoftheCouncil
of28November2018ontheuseoftheSchengenInformationSystemforthe
returnofillegallystayingthird-countrynationals(OJL312,7.12.2018,p.1).
(b)Regulation(EU)2018/1861oftheEuropeanParliamentandoftheCouncil
of28November2018ontheestablishment,operationanduseoftheSchengen
InformationSystem(SIS)inthefieldofborderchecks,andamendingthe
ConventionimplementingtheSchengenAgreement,andamendingandrepealing
Regulation(EC)No1987/2006(OJL312,7.12.2018,p.14).
(c)Regulation(EU)2018/1862oftheEuropeanParliamentandoftheCouncil

--- Page 200 ---
of28November2018ontheestablishment,operationanduseoftheSchengen
InformationSystem(SIS)inthefieldofpolicecooperationandjudicial
cooperationincriminalmatters,amendingandrepealingCouncilDecision
2007/533/JHA,andrepealingRegulation(EC)No1986/2006oftheEuropean
ParliamentandoftheCouncilandCommissionDecision2010/261/EU(OJL312,
7.12.2018,p.56).
2.VisaInformationSystem
(a)Regulation(EU)2021/1133oftheEuropeanParliamentandoftheCouncil
of7July2021amendingRegulations(EU)No603/2013,(EU)2016/794,
(EU)2018/1862,(EU)2019/816and(EU)2019/818asregardstheestablishment
oftheconditionsforaccessingotherEUinformationsystemsforthepurposesof
theVisaInformationSystem(OJL248,13.7.2021,p.1).
(b)Regulation(EU)2021/1134oftheEuropeanParliamentandoftheCouncil
of7July2021amendingRegulations(EC)No767/2008,(EC)No810/2009,
(EU)2016/399,(EU)2017/2226,(EU)2018/1240,(EU)2018/1860,
(EU)2018/1861,(EU)2019/817and(EU)2019/1896oftheEuropeanParliament
andoftheCouncilandrepealingCouncilDecisions2004/512/ECand
2008/633/JHA,forthepurposeofreformingtheVisaInformationSystem(OJ
L248,13.7.2021,p.11).
3.Eurodac
Regulation(EU)2024/1358oftheEuropeanParliamentandoftheCouncil
of14May2024ontheestablishmentof‘Eurodac’forthecomparisonof
biometricdatainordertoeffectivelyapplyRegulations(EU)2024/1315and
(EU)2024/1350oftheEuropeanParliamentandoftheCouncilandCouncil
Directive2001/55/ECandtoidentifyillegallystayingthird-country
nationalsandstatelesspersonsandonrequestsforthecomparisonwith
EurodacdatabyMemberStates’lawenforcementauthoritiesandEuropol
forlawenforcementpurposes,amendingRegulations(EU)2018/1240and
(EU)2019/818oftheEuropeanParliamentandoftheCouncilandrepealing
Regulation(EU)No603/2013oftheEuropeanParliamentandofthe
Council (OJL, 2024/1358, 22.5.2024,
ELI:http://data.europa.eu/eli/reg/2024/1358/oj).
4.Entry/ExitSystem
Regulation(EU)2017/2226oftheEuropeanParliamentandoftheCouncil
of30November2017establishinganEntry/ExitSystem(EES)toregister
entryandexitdataandrefusalofentrydataofthird-countrynationals
crossingtheexternalbordersoftheMemberStatesanddeterminingthe
conditionsforaccesstotheEESforlawenforcementpurposes,and
amendingtheConventionimplementingtheSchengenAgreementand
Regulations(EC)No767/2008and(EU)No1077/2011(OJL327,
9.12.2017,p.20).

--- Page 201 ---
5.EuropeanTravelInformationandAuthorisationSystem
(a)Regulation(EU)2018/1240oftheEuropeanParliamentandoftheCouncil
of12September2018establishingaEuropeanTravelInformationand
AuthorisationSystem(ETIAS)andamendingRegulations(EU)No1077/2011,
(EU)No515/2014,(EU)2016/399,(EU)2016/1624and(EU)2017/2226(OJ
L236,19.9.2018,p.1).
(b)Regulation(EU)2018/1241oftheEuropeanParliamentandoftheCouncil
of12September2018amendingRegulation(EU)2016/794forthepurposeof
establishingaEuropeanTravelInformationandAuthorisationSystem(ETIAS)
(OJL236,19.9.2018,p.72).
6.EuropeanCriminalRecordsInformationSystemonthird-country
nationalsandstatelesspersons
Regulation(EU)2019/816oftheEuropeanParliamentandoftheCouncilof
17April2019establishingacentralisedsystemfortheidentificationof
MemberStatesholdingconvictioninformationonthird-countrynationals
andstatelesspersons(ECRIS-TCN)tosupplementtheEuropeanCriminal
RecordsInformationSystemandamendingRegulation(EU)2018/1726(OJ
L135,22.5.2019,p.1).
7.Interoperability
(a)Regulation(EU)2019/817oftheEuropeanParliamentandoftheCouncil
of20May2019onestablishingaframeworkforinteroperabilitybetweenEU
informationsystemsinthefieldofbordersandvisaandamendingRegulations
(EC)No767/2008,(EU)2016/399,(EU)2017/2226,(EU)2018/1240,
(EU)2018/1726and(EU)2018/1861oftheEuropeanParliamentandofthe
CouncilandCouncilDecisions2004/512/ECand2008/633/JHA(OJL135,
22.5.2019,p.27).
(b)Regulation(EU)2019/818oftheEuropeanParliamentandoftheCouncil
of20May2019onestablishingaframeworkforinteroperabilitybetweenEU
informationsystemsinthefieldofpoliceandjudicialcooperation,asylumand
migrationandamendingRegulations(EU)2018/1726,(EU)2018/1862and
(EU)2019/816(OJL135,22.5.2019,p.85).
ANNEXXI
TechnicaldocumentationreferredtoinArticle53(1),point(a)—
technicaldocumentationforprovidersofgeneral-purposeAImodels
Section1

--- Page 202 ---
Informationtobeprovidedbyallprovidersofgeneral-purposeAI
models
ThetechnicaldocumentationreferredtoinArticle53(1),point(a)shall
containatleastthefollowinginformationasappropriatetothesizeandrisk
profileofthemodel:
1.Ageneraldescriptionofthegeneral-purposeAImodelincluding:
(a)thetasksthatthemodelisintendedtoperformandthetypeandnatureofAI
systemsinwhichitcanbeintegrated;
(b)theacceptableusepoliciesapplicable;
(c)thedateofreleaseandmethodsofdistribution;
(d)thearchitectureandnumberofparameters;
(e)themodality(e.g.text,image)andformatofinputsandoutputs;
(f) thelicence.
2.Adetaileddescriptionoftheelementsofthemodelreferredtoinpoint1,and
relevantinformationoftheprocessforthedevelopment,includingthefollowing
elements:
(a)thetechnicalmeans(e.g.instructionsofuse,infrastructure,tools)requiredforthe
general-purposeAImodeltobeintegratedinAIsystems;
(b)thedesignspecificationsofthemodelandtrainingprocess,includingtraining
methodologiesandtechniques,thekeydesignchoicesincludingtherationaleand
assumptionsmade;whatthemodelisdesignedtooptimiseforandtherelevance
ofthedifferentparameters,asapplicable;
(c)informationonthedatausedfortraining,testingandvalidation,where
applicable,includingthetypeandprovenanceofdataandcurationmethodologies
(e.g.cleaning,filtering,etc.),thenumberofdatapoints,theirscopeandmain
characteristics;howthedatawasobtainedandselectedaswellasallother
measurestodetecttheunsuitabilityofdatasourcesandmethodstodetect
identifiablebiases,whereapplicable;
(d)thecomputationalresourcesusedtotrainthemodel(e.g.numberoffloating
pointoperations),trainingtime,andotherrelevantdetailsrelatedtothetraining;
(e)knownorestimatedenergyconsumptionofthemodel.
Withregardtopoint(e),wheretheenergyconsumptionofthemodelisunknown,
theenergyconsumptionmaybebasedoninformationaboutcomputational
resourcesused.
Section2
Additionalinformationtobeprovidedbyprovidersofgeneral-purpose
AImodelswithsystemicrisk

--- Page 203 ---
1.Adetaileddescriptionoftheevaluationstrategies,includingevaluationresults,onthe
basisofavailablepublicevaluationprotocolsandtoolsorotherwiseofotherevaluation
methodologies.Evaluationstrategiesshallincludeevaluationcriteria,metricsandthe
methodologyontheidentificationoflimitations.
2.Whereapplicable,adetaileddescriptionofthemeasuresputinplaceforthepurpose
ofconductinginternaland/orexternaladversarialtesting(e.g.redteaming),model
adaptations,includingalignmentandfine-tuning.
3.Whereapplicable,adetaileddescriptionofthesystemarchitectureexplaininghow
softwarecomponentsbuildorfeedintoeachotherandintegrateintotheoverall
processing.
ANNEXXII
TransparencyinformationreferredtoinArticle53(1),point(b)—
technicaldocumentationforprovidersofgeneral-purposeAImodelsto
downstreamprovidersthatintegratethemodelintotheirAIsystem
TheinformationreferredtoinArticle53(1),point(b)shallcontainatleast
thefollowing:
1.Ageneraldescriptionofthegeneral-purposeAImodelincluding:
(a)thetasksthatthemodelisintendedtoperformandthetypeandnatureofAI
systemsintowhichitcanbeintegrated;
(b)theacceptableusepoliciesapplicable;
(c)thedateofreleaseandmethodsofdistribution;
(d)howthemodelinteracts,orcanbeusedtointeract,withhardwareorsoftware
thatisnotpartofthemodelitself,whereapplicable;
(e)theversionsofrelevantsoftwarerelatedtotheuseofthegeneral-purposeAI
model,whereapplicable;
(f)thearchitectureandnumberofparameters;
(g)themodality(e.g.text,image)andformatofinputsandoutputs;
(h)thelicenceforthemodel.
2.Adescriptionoftheelementsofthemodelandoftheprocessforitsdevelopment,
including:
(a)thetechnicalmeans(e.g.instructionsforuse,infrastructure,tools)requiredfor
thegeneral-purposeAImodeltobeintegratedintoAIsystems;
(b)themodality(e.g.text,image,etc.)andformatoftheinputsandoutputsandtheir
maximumsize(e.g.contextwindowlength,etc.);
(c)informationonthedatausedfortraining,testingandvalidation,where
applicable,includingthetypeandprovenanceofdataandcuration

--- Page 204 ---
methodologies.
ANNEXXIII
Criteriaforthedesignationofgeneral-purposeAImodelswithsystemic
riskreferredtoinArticle51
Forthepurposeofdeterminingthatageneral-purposeAImodelhas
capabilitiesoranimpactequivalenttothosesetoutinArticle51(1),point
(a),theCommissionshalltakeintoaccountthefollowingcriteria:
(a)thenumberofparametersofthemodel;
(b)thequalityorsizeofthedataset,forexamplemeasuredthroughtokens;
(c)theamountofcomputationusedfortrainingthemodel,measuredinfloatingpoint
operationsorindicatedbyacombinationofothervariablessuchasestimatedcost
oftraining,estimatedtimerequiredforthetraining,orestimatedenergy
consumptionforthetraining;
(d)theinputandoutputmodalitiesofthemodel,suchastexttotext(largelanguage
models),texttoimage,multi-modality,andthestateoftheartthresholdsfor
determininghigh-impactcapabilitiesforeachmodality,andthespecifictypeof
inputsandoutputs(e.g.biologicalsequences);
(e)thebenchmarksandevaluationsofcapabilitiesofthemodel,includingconsidering
thenumberoftaskswithoutadditionaltraining,adaptabilitytolearnnew,distinct
tasks,itslevelofautonomyandscalability,thetoolsithasaccessto;
(f)whetherithasahighimpactontheinternalmarketduetoitsreach,whichshallbe
presumedwhenithasbeenmadeavailabletoatleast10000registeredbusiness
usersestablishedintheUnion;
(g)thenumberofregisteredend-users.
ELI:http://data.europa.eu/eli/reg/2024/1689/oj
ISSN1977-0677(electronicedition)