{"_id": "686ae826383c6b855905e79d", "title": "NATIONAL STRATEGY FOR ARTIFICIAL INTELLIGENCE", "source": "https://www.niti.gov.in/sites/default/files/2023-03/National-Strategy-for-Artificial-Intelligence.pdf", "text": "NITI Aayog\n\n## NATIONAL STRATEGY FOR ARTIFICIAL INTELLIGENCE #AIFORALL\n\nThis page has been intentionally left blank\n\n## Acknowledgments\n\nIn writing this Report, Arnab Kumar, Punit Shukla, Aalekh Sharan and Tanay Mahindru of NITI Aayog have made valuable contributions.\n\nInputs were also provided by Dr. Avik Sarkar, Dr. Ashish Nayan and Kartikeya Asthana of NITI Aayog.\n\nThe valuable contributions of Mr. P. Anandan and his team from Wadhwani Institute for AI, Dr. Manish Gupta of Videoken, Prof. Ramesh Raskar of MIT Media Labs, nVIDIA, Intel, IBM, NASSCOM, McKinsey and Accenture are also thankfully acknowledged. Special contribution of Accenture in the production of this report is also acknowledged.\n\nAnna Roy Advisor (Industry) NITI Aayog\n\n## Contents\n\n5\n\n7\n\n12\n\n16\n\n18\n\n24\n\n24\n\n30\n\n35\n\n39\n\n41\n\n46\n\n48\n\n50\n\n64\n\n71\n\n85\n\n91\n\n96\n\n| INTRODUCTION                                          |   5 |\n|-------------------------------------------------------|-----|\n| EXECUTIVE SUMMARY                                     |   7 |\n| WHAT IS ARTIFICIAL INTELLIGENCE?                      |  12 |\n| GLOBAL DEVELOPMENTS IN ARTIFICIAL INTELLIGENCE        |  16 |\n| ARTIFICIAL INTELLIGENCE AND INDIA                     |  18 |\n| FOCUS AREAS FOR AI INTERVENTION                       |  24 |\n| Healthcare                                            |  24 |\n| Agriculture                                           |  30 |\n| Education                                             |  35 |\n| Smart Cities and Infrastructure                       |  39 |\n| Smart Mobility and Transportation                     |  41 |\n| KEY CHALLENGES TO ADOPTION OF AI IN INDIA             |  46 |\n| WAY FORWARD TO HARNESS THE POWER OF AI                |  48 |\n| RESEARCH                                              |  50 |\n| SKILLING FOR THE AI AGE                               |  64 |\n| ACCELERATING ADOPTION                                 |  71 |\n| ETHICS, PRIVACY, SECURITY AND ARTIFICIAL INTELLIGENCE |  85 |\n| ACTIONS FOR THE GOVERNMENT                            |  91 |\n| APPENDIX I: ARTIFICIAL INTELLIGENCE EXPLAINED         |  96 |\n| APPENDIX II: GLOBAL COUNTRY STRATEGY REVIEW           | 100 |\n| APPENDIX III: DATA ECOSYSTEM                          | 110 |\n\n## Introduction\n\n## #AIforAll: Technology Leadership for Inclusive Growth\n\nArtificial  Intelligence  (AI)  is  poised  to  disrupt  our  world. With  intelligent  machines  enabling  high-level cognitive processes like thinking, perceiving, learning, problem solving and decision making, coupled with advances in data collection and aggregation, analytics and computer processing power, AI presents opportunities to complement and supplement human intelligence and enrich the way people live and work.\n\nIndia, being the fastest growing economy with the second largest population in the world, has a significant stake in the AI revolution. Recognising AI's potential to transform economies and the need for India to strategise its approach, Hon'ble Finance Minister, in his budget speech for 2018 - 2019, mandated NITI Aayog to establish the National Program on AI, with a view to guiding the research and development in new and emerging technologies. In pursuance of the above, NITI Aayog has adopted a three-pronged approach - undertaking exploratory proof-of-concept AI projects in  various areas, crafting  a national strategy  for  building  a  vibrant  AI  ecosystem  in  India  and  collaborating  with  various  experts  and stakeholders. Since the start of this year, NITI Aayog has partnered with several leading AI technology players to implement AI projects in critical areas such as agriculture and health. Learnings from these projects, under various stages of implementation, as well as our engagement with some of the leading institutions and experts have given a better perspective to our task of crafting the national strategy for AI, which is the focus of this discussion paper.\n\nThis strategy document is premised on the proposition that India, given its strengths and characteristics, has the potential to position itself among leaders on the global AI map - with a unique brand of #AIforAll . The approach in this paper focuses on how India can leverage the transformative technologies to ensure social and inclusive growth in line with the development philosophy of the government. In addition, India should strive to replicate these solutions in other similarly placed developing countries.\n\n#AIforAll will aim at enhancing and empowering human capabilities to address the challenges of access, affordability, shortage and inconsistency of skilled expertise; effective implementation of AI initiatives to evolve scalable solutions for emerging economies; and endeavors to tackle some of the global challenges from AI's perspective, be it application, research, development, technology, or responsible AI. #AIforAll will focus on harnessing collaborations and partnerships, and aspires to ensure prosperity for all. Thus, #AIforAll means technology leadership in AI for achieving the greater good.\n\nWhile evolving the national strategy for AI, the underlying thrust was to identify applications with maximum social impact, a willingness to learn from the best of the world when it comes to the recent technology advancements in AI, and leveraging approaches that democratize access to and further development of AI.\n\nFrom an applications perspective, the  approach  is  to  identify  sectors  that  may  have  the  potential  of greatest externalities while adopting AI solutions, and hence require the government to play a leading role in developing the implementation roadmap for AI. For example, the agriculture sector in India, which forms the bedrock of India's economy, needs multi-layered technology infusion and coordination amongst several stakeholders. Efforts from private sector may neither be financially  optimal nor efficient on a standalone basis, and hence sustained government intervention to tackle the existing challenges and constraints is needed. Hence, India's approach to implementation of AI has to be guided by optimisation of social goods, rather than maximisation of topline growth.\n\nFrom a technology perspective, the strategy is to maximise the late-movers' advantage. Acknowledging that  India  is  some  distance  away  from  consistently  delivering  home  grown  pioneering  technology solutions in AI, adapting and innovating the technology for India's unique needs and opportunities would help it in leap frogging, while simultaneously building the foundational R&amp;D capability aimed at ensuring competitiveness in the long run.\n\nSolving  for  India,  given  the  complexity  and  multi-dimensional  aspects  of  most  of  our  economic  and societal challenges, can easily be extended to the rest of the emerging and developing economies. An integral part of India's strategy for AI involves tackling common and complex global challenges that can be solved through technology intervention, and India's scale and opportunity landscape provides the ideal test-bed to ensure sustainable and scalable solutions.\n\nThe  purpose  of  this  paper  is  to  lay  the  ground  work  for  evolving  the  National  Strategy  for  Artificial Intelligence.  While  this  paper  includes  several  recommendations,  some  of  which  may  be  deemed disruptive,  specifics  (e.g.  execution  and  financial  implications)  have  been  consciously  avoided,  since wider consultations and consensus building is needed to refine these recommendations. This document is intended to serve as an 'essential pre-read' in building a truly transformative approach in pursuit of #AIforAll.\n\nAmitabh Kant\n\nCEO, NITI Aayog\n\n## Executive Summary\n\n## India's Approach to Leadership in AI\n\nAI refers to the ability of machines to perform cognitive tasks like thinking, perceiving, learning, problem solving and decision making. Initially conceived as a technology that could mimic human intelligence, AI has evolved  in  ways  that  far  exceed  its  original  conception. With  incredible  advances  made  in  data collection, processing and computation power, intelligent systems can now be deployed to take over a variety  of  tasks,  enable  connectivity  and  enhance  productivity.  As  AI's  capabilities  have  dramatically expanded, so have its utility in a growing number of fields.\n\nThe  truly  transformative  nature  of  the  technology,  yet  the  nascent  stage  of  its  adoption  worldwide, provides India with an opportunity to define its own brand of AI leadership. #AIforAll - the brand proposed for India implies inclusive technology leadership, where the full potential of AI is realised in pursuance of the  country's  unique  needs  and  aspirations.  The  strategy  should  strive  to  leverage  AI  for  economic growth, social development and inclusive growth, and finally as a 'Garage' for emerging and developing economies.\n\nWhile AI has the potential to provide large incremental value to a wide range of sectors, adoption till date has been driven primarily from a commercial perspective. Technology disruptions like AI are once-in-ageneration phenomenon, and hence large-scale adoption strategies, especially national strategies, need to strike a balance between narrow definitions of financial impact and the greater good. NITI Aayog has decided to focus on five sectors that are envisioned to benefit the most from AI in solving societal needs:\n\n- a) Healthcare: increased access and affordability of quality healthcare,\n- b) Agriculture: enhanced farmers' income, increased farm productivity and reduction of wastage,\n- c) Education: improved access and quality of education,\n- d) Smart Cities and Infrastructure: efficient and connectivity for the burgeoning urban population, and\n- e) Smart Mobility and Transportation: smarter and safer modes of transportation and better traffic and congestion problems.\n\nTo truly reap the benefits of deploying AI at scale, the report identifies the following barriers that need to be addressed in order to achieve the goals of #AIforAll:\n\n- a) Lack of broad based expertise in research and application of AI,\n- b) Absence of enabling data ecosystems - access to intelligent data,\n- c) High resource cost and low awareness for adoption of AI,\n- d) Privacy and security, including a lack of formal regulations around anonymisation of data, and\n- e) Absence of collaborative approach to adoption and application of AI.\n\nSuperior  research  capabilities  have  been  the  cornerstone  of  leadership  aspirations  in  emerging technologies and effectively realising the growth potential requires expertise in both core and applied research. Despite indications of recent positive efforts in this aspect of technology, AI research in India is still in its infancy and requires large scale concerted and collaborative interventions.\n\nThe paper proposes a two-tiered structure to address India's AI research aspirations:\n\n- a) Centre of Research Excellence (CORE) focused on developing better understanding of existing core research and pushing technology frontiers through creation of new knowledge;\n- b) International Centers of Transformational AI (ICTAI) with a mandate of developing and deploying application-based  research.  Private  sector  collaboration  is  envisioned  to  be  a  key  aspect  of ICTAIs.\n\nThe research capabilities are proposed to be complemented by an umbrella organisation responsible for providing  direction  to  research  efforts  through  analysis  of  socio-economic  indicators,  studying  global advancements,  and  encouraging  international  collaboration.  Pursuing  ' moonshot  research  projects ' through specialised teams, development of a dedicated supranational agency to channel research in solving big, audacious problems of AI - 'CERN for AI', and developing common computing and other related infrastructure for AI are other key components research suggested.\n\nAs  technology  increasingly  disrupts  the  nature  of  jobs  and  shifts  the  benchmarks  of  technological aptitude, skilling and reskilling of workforce forms an integral part of our approach to adopting AI. There is an emergent need for reskilling the existing workforce and developing future talent in accordance with the changing needs of the job market. This could be done via the adoption of decentralised teaching mechanisms working in collaboration with the private sector and educational  institutions to prescribe certification with value. Furthermore, promotion of job creation in new areas, like data annotation needs to  be  identified  and  promoted,  as these  would have  the potential  of absorbing  a large  portion  of the workforce that may find itself redundant due to increasing automation.\n\nAdoption of AI across the value chain viz. startups, private sector, PSUs and government entities, will truly  unlock  the  potential  by  creating  a  virtuous  cycle  of  supply  and  demand.  The  barriers  to  AI development and deployment can effectively be addressed by adopting the marketplace model - one that enables market discovery of not only the price but also of different approaches that are best suited to achieve the desired results. A three-pronged, formal marketplace could be created focusing on data collection and aggregation, data annotation and deployable models. There could be a common platform called the National AI Marketplace (NAIM).\n\nFurthermore, for accelerated adoption of a highly collaborative technology like AI, the government has to play the critical role of a catalyst in supporting partnerships, providing access to infrastructure, fostering innovation  through  research  and  creating  the  demand  by  seeking  solutions  for  addressing  various governmental needs.\n\nAs AI-based solutions  permeate the  way  we  live  and  do  business,  questions  on  ethics,  privacy  and security will also emerge. Most discussions on ethical considerations of AI are a derivation of the FAT framework (Fairness, Accountability and Transparency). A consortium of Ethics Councils at each Centre of  Research Excellence can be set up and it would be expected that all COREs adhere to standard practice while developing AI technology and products.\n\nData is one of the primary drivers of AI solutions, and thus appropriate handling of data, ensuring privacy and security is of prime importance. Challenges include data usage without consent, risk of identification of  individuals  through  data,  data  selection  bias  and  the  resulting  discrimination  of  AI  models,  and asymmetry  in  data  aggregation.  The  paper  suggests  establishing  data  protection  frameworks  and sectorial regulatory frameworks, and promotion of adoption of international standards.\n\nIn order for India to ride the AI innovation wave, a robust intellectual property framework is required. Despite a number of government initiatives in strengthening the IP regime, challenges remain, especially in respect of applying stringent and narrowly focused patent laws to AI applications - given the unique nature of AI solution development. The importance of data to development of useful models is one such example. To tackle these issues, establishment of IP facilitation centers to help bridge the gap between practitioners and AI developers, and adequate training of IP granting authorities, judiciary and tribunals is suggested.\n\nThe AI strategy is aimed at primarily guiding an inevitable wave of change for quicker and better impact. The AI ecosystem is rapidly evolving and taking societies into uncharted territory. For now, we can begin to ask some of the big questions that each society must answer for itself: are we ready to manage data ethically?  How  do  we  bridge  the  digital  divide?  Which  innovations  are  worthy  of  public  funds  and\n\npartnerships?  Bringing  these  questions  into  the  open  is  the  most  important  step  in  ensuring  that  AI advances create a better society.\n\nThere has been tremendous activity concerning AI policy in different countries over the past couple of years. Governments in USA, UK, France, Japan and China have released their policy and strategy papers relating to AI. In order to establish a leadership role, it is important for India to take the plunge and start by releasing a Strategy Paper to initiate the roll out of an ambitious programme that would ensure for India its rightful place in this transformational era.\n\nThis page has been intentionally left blank\n\n## CONTEXT\n\n## What is Artificial Intelligence?\n\n## A technical primer\n\nAI might just be the single largest technology revolution of our live times, with the potential to disrupt almost all aspects of human existence. Andrew Ng, Co-founder of Coursera and formerly head of Baidu AI Group / Google Brain, compares the transformational impact of AI to that of electricity 100 years back. With many industries aggressively investing in cognitive and AI solutions, global investments are forecast to achieve a compound annual growth rate (CAGR) of 50.1% to reach USD57.6 billion in 2021 1 .\n\nAI is not a new phenomenon, with much of its theoretical and technological underpinning developed over the past 70 years by computer scientists such as Alan Turing, Marvin Minsky and John McCarthy. AI has already existed to some degree in many industries and governments. Now, thanks to virtually unlimited computing power and the decreasing costs of data storage, we are on the cusp of the exponential age of AI as organisations learn to unlock the value trapped in vast volumes of data.\n\nAI is a constellation of technologies that enable machines to act with higher levels of intelligence and emulate  the  human  capabilities  of  sense,  comprehend  and  act.  Thus,  computer  vision  and  audio processing can actively perceive the world around them by acquiring and processing images, sound and speech. The natural language processing and inference engines can enable AI systems to analyse and understand the information collected. An AI system can also take action through technologies such as expert  systems  and  inference  engines  or  undertake  actions  in  the  physical  world.  These  human capabilities  are  augmented  by  the  ability  to  learn  from  experience  and  keep  adapting  over  time.  AI systems are finding ever-wider application to supplement these capabilities across enterprises as they grow in sophistication.\n\nIrrespective of the type of AI being used, however, every application begins with large amounts of training data. In the past, this kind of performance was driven by rules-based data analytics programs, statistical regressions, and early 'expert systems.' But the explosion of powerful deep neural networks now gives AI something a mere program doesn't have: the ability to do the unexpected.\n\n1 Worldwide Semi-annual Cognitive Artificial Intelligence Systems Spending Guide from International Data Corp. (IDC), 2017\n\nSource:\n\nAccenture\n\nSource:\n\nAccenture\n\nFigure 1: What is Artificial Intelligence\n\nEmerging Al technologies\n\nAI technology has experienced a checkered history of waves of optimism followed by disappointment and periods of inertia, dubbed as ' AI winters '. Each previous breakthrough has only ever partly lived up to the hype it generated, and none has managed to kick-start the technology into the mainstream.\n\nThe big change today is that we are in an unprecedented period of technology innovation across so many different fields that gives us the belief that the ' AI Spring ' has not only arrived but is here to stay. Key developments responsible for this optimism are:\n\n- a) Unlimited access to computing power : The worldwide public cloud services market is projected to grow 21.4% in 2018 to total USD186.4 billion, up from USD153.5 billion in 2017, according to Gartner, Inc. The access is amplified by rapid increase in computational power.\n- b) Huge fall in cost of storing data : We are in an age where the hard drive cost per gigabyte of data has been falling exponentially, to the extent that we are approaching near zero marginal cost for storing data (down from USD500,000 a gigabyte in 1980 to 2 cents a gigabyte in 2017).\n- c) Explosion in data that is digitised : As per IDC forecasts, by 2025, the global data sphere will grow to 163 zettabytes (that is a trillion gigabytes) 2 , or ten times the 16.1ZB of data generated in 2016. As Barry Smyth, Professor of Computer science at University College Dublin, says: \"Data is to AI  what  food  is  to  humans.\"  So,  in  a  more  digital  world,  the  exponential  growth  of  data  is constantly feeding AI improvements.\n\nConsider,  for  example,  the  vastly  increased  processing  power  that  comes  from  using  Graphics Processing  Units  (GPUs)  in  place  of  Central  Processing  Units  (CPUs).  Google,  in  May  2017, announced that its Tensor Processing Unit (TPU) delivered 30-80 times higher performance-per-watt than contemporary CPUs and GPUs. When you add the decreasing cost of storage to the mix, plus the exponential growth in data volumes, together with the emergence of open source platforms and frameworks, you have got a uniquely potent combination of technologies and capabilities. It all adds up to a very powerful foundation to give AI its critical mass for mainstream adoption.\n\n## Box 1: Machine Learning and Deep Learning\n\nMachine Learning, a term coined by Artur Samuel in 1959, meant 'the ability to learn  without  being explicitly programmed.' Machine Learning involves the use of algorithms to parse data and learn from it, and making a determination or prediction as a result. Instead of hand coding software libraries with welldefined specific instructions for a particular task, the machine gets 'trained' using large amounts of data and algorithms, and in turn gains the capability to perform specific tasks.\n\n'Deep Learning is a technique for implementing Machine Learning. Deep Learning was inspired by the structure  and  function  of  the  brain,  specifically  the  interconnecting  of  many  neurons.  Artificial  Neural Networks (ANNs) are algorithms that are based on the biological structure of the brain. In ANNs, there are  'neurons'  which have discrete layers and connections to other 'neurons'. Each layer picks out a specific feature to learn. It's this layering that gives deep learning its name, depth is created by using multiple layers as opposed to a single layer 3 .'\n\nFigure 3: AI, ML and Deep Learning\n\nSource:\n\nnVIDIA\n\n2 Data Age 2025: 'The Evolution of Data to Life-Critical whitepaper by International Data Corporation, 2017'\n\n3 Medium.com: 'The Difference Between Artificial Intelligence, Machine Learning, and Deep Learning'\n\nSource:\n\nAccenture\n\nFor a detailed analysis of major types of Machine Learning, algorithms and use cases, please refer to Appendix I: Artificial Intelligence Explained.\n\nAI gets categorised in different ways and it may be useful to understand the various categories, their rationale and the implications.\n\n- a) Weak AI vs. Strong AI : Weak AI describes \"simulated\" thinking. That is, a system which appears to behave intelligently, but doesn't have any kind of consciousness about what it's doing. For example, a chatbot might appear to hold a natural conversation, but it has no sense of who it is or why it's talking to you. Strong AI describes \"actual\" thinking. That is, behaving intelligently, thinking as human does, with a conscious, subjective mind. For example, when two humans converse, they most likely know exactly who they are, what they're doing, and why.\n- b) Narrow AI vs. General AI :  Narrow AI describes an AI that is limited to a single task or a set number of tasks. For example, the capabilities of IBM's Deep Blue, the chess playing computer that beat world champion Gary Kasparov in 1997, were limited to playing chess. It wouldn't have been able to win a game of tic-tac-toe - or even know how to play. General AI describes an AI which can be used to complete a wide range of tasks in a wide range of environments. As such, it's much closer to human intelligence.\n- c) Superintelligence: The term \"superintelligence\" is often used to refer to general and strong AI at the point at which it surpasses human intelligence, if it ever does.\n\nWhile  big  strides  have  been  made  in  Artificial  Narrow  Intelligence  -  algorithms  that  can  process documents, drive vehicles or beat champion chess players, no one has yet claimed the first production or development of General AI. The weight of expert opinion is that we are a long way off the emergence of General AI.\n\n## Global Developments in Artificial Intelligence\n\n## Benchmarking select countries\n\nCountries  around  the  world  are  becoming  increasingly  aware  of  the  potential  economic  and  social benefits of developing and applying AI. For example, China and U.K. estimate that 26% and 10% of their GDPs respectively in 2030 will be sourced from AI-related activities and businesses. There has been tremendous activity concerning AI policy positions and the development of an AI ecosystem in different countries over the last 18 to 24 months - the US published its AI report in December 2016; France published the AI strategy in January 2017 followed by a detailed policy document in March 2018; Japan released a document in March 2017; China published the AI strategy in July 2017; and U.K. released its industrial strategy in November 2017.\n\nInfrastructural supply side interventions have been planned by various countries for creating a larger ecosystem of AI development. Creation of 'data trusts', rolling out of digital connectivity infrastructure such as 5G / full fiber networks, common supercomputing facilities, fiscal incentives and creation of open source software  libraries  are  some  of  the  focus  areas  of  various  governments  as  committed  in  their strategy papers.\n\nIn the area of core research in AI and related technologies, universities and research institutions from the US, China and Japan have led the publication volume on AI research topics between 2010 and 2016. Universities in USA, primarily Carnegie Mellon University, Massachusetts Institute of Technology and Stanford, took an early lead in AI research by offering new courses, establishing research facilities and instituting  industry  partnerships.  Off  late,  Chinese  universities,  especially  Peking  and  Tsinghua Universities have caught on to the race by utilising large scale public funding and extensive research partnerships with private companies.\n\nFor  building  the  future  workforce  for  AI,  countries  are  also  significantly  increasing  the  allocation  of resources  for  Science,  Technology,  Engineering  and  Maths  (STEM)  talent  development  through investment in universities, mandating new courses (e.g., AI and law), and offering schemes to retrain people. For instance, U.K. has planned to build over 1,000 government supported PhD researchers by 2025 and set up a Turing fellowship to support an initial cohort of AI fellows while China has launched a five-year university program to train at least 500 teachers and 5,000 students working on AI technologies.\n\nGovernance structures for enabling all the above mandates vary across countries. Many countries have instituted dedicated public offices such as Ministry of AI (UAE), and Office of AI and AI Council (U.K.) while China and Japan have allowed existing ministries to take up AI implementation in their sectoral areas. Not just national governments, but even local city governments have become increasingly aware about the importance and potential of AI and have committed public investments.\n\nNational governments have significantly increased public funding for AI through commitments such as increasing the R&amp;D spend, setting up industrial and investment funds in AI startups, investing in network and infrastructure and AI-related public procurements. China, USA, France and Japan have committed significant public spending for AI technology development and adoption.\n\nThese countries are also leveraging different combinations of public-private-academia to develop and promote  AI.  Development  of  technology  parks,  and  connecting  large  corporations  with  startups  and\n\nforming 'national teams' with large private players to undertake fundamental and applied research are some of the public-private partnership approaches various national governments have espoused.\n\nAI technology development and applications are evolving rapidly with major implications for economies and societies. A study by EY and NASCCOM found that by 2022, around 46% of the workforce will be engaged in  entirely  new  jobs  that  do  not  exist  today,  or  will  be  deployed  in  jobs  that  have  radically changed skillsets 4 . If some countries decide to wait for a few years to establish an AI strategy and put in place the foundations for developing the AI ecosystem, it seems unlikely that they would be able to attain and match up to the current momentum in the rapidly changing socio-economic environment. Therefore, the need of the hour is to develop a policy framework that will help set up a vibrant AI ecosystem in India.\n\nA detailed study of various country strategies for AI is placed in the Appendix II: Global Country Strategy Review .\n\n4 Future of Jobs in India: A 2022 Perspective, 2017\n\n## Artificial Intelligence and India\n\n## Identifying priority areas for India's efforts in Artificial Intelligence\n\nA national AI strategy needs to be premised on a framework which is adapted to India's unique needs and aspirations, while at the same time, is capable of achieving the country's full potential of leveraging AI developments. Such a framework could be seen as an aggregation of the following three distinct, yet inter-related components:\n\n- a) Opportunity : the economic impact of AI for India\n- b) AI for Greater Good : social development and inclusive growth\n- c) AI  Garage  for  40%  of  the  world :  solution  provider  of  choice  for  the  emerging  and  developing economies (ex-China) across the globe\n\n## Opportunity: the economic impact of Artificial Intelligence for India\n\nAI is emerging as a new factor of production, augmenting the traditional factors of production viz. labor, capital and innovation and technological changes captured in total factor productivity. AI has the potential to overcome the physical limitations of capital and labour, and open up new sources of value and growth. From an economic impact perspective,  AI  has  the  potential  to  drive  growth  through enabling: (a)  intelligent  automation  i.e.  ability  to  automate complex physical world tasks that require adaptability and agility across industries, (b) labour and capital augmentation: enabling humans to focus on parts of their role that  add  the  most  value,  complementing  human capabilities and improving capital efficiency, and (c)\n\ninnovation diffusion i.e. propelling innovations as it diffuses through the economy. AI innovations in one sector will have positive consequences in another, as industry sectors are interdependent based on value chain. Economic value is expected to be created from the new goods, services and innovations that AI will enable.\n\nAccenture, in its recent AI research reports 5 , provides a framework for evaluating the economic impact of AI for select G20 countries and estimates AI to boost India's annual growth rate by 1.3 percentage points by 2035.\n\n5 Rewire for Growth: Accelerating India's Economic Growth with Artificial Intelligence, Accenture\n\nSource: Accenture\n\nFigure 5: Unlocking innovation through AI\n\n## AI for Greater Good: social development and inclusive growth\n\nBeyond just the headline numbers of economic impact, a disruptive technology such as AI needs to be seen from the perspective of the transformative impact it could have on the greater good - improving the quality  of  life  and  access  of  choice  to  a  large  section  of  the  country.  In  that  sense,  the  recent advancements in AI seem to be custom-made for the unique opportunities and challenges that India faces. Increased access to quality health facilities (including addressing the locational access barriers), inclusive financial growth for large sections of population that have hitherto been excluded from formal financial products, providing real-time advisory to farmers and help address unforeseen factors towards increasing  productivity,  building  smart  and  efficient  cities  and  infrastructure  to  meet  the  demands  of rapidly urbanising population are some of the examples that can be most effectively solved through the non-incremental advantages that a technology such as AI can provide.\n\n## AI Garage for 40% of the world\n\nIn addition to providing unique opportunities, India provides a perfect ' playground ' for enterprises and institutions  globally  to  develop  scalable solutions  which can be easily  implemented  in the rest of the developing and emerging economies. Simply put, Solve for India means solve for 40% or more of the world. An advanced AI based solution for early diagnosis of tuberculosis (one of the top-10 causes of deaths worldwide), for example, could easily be rolled out to countries in South East Asia or Africa, once developed  and  refined  in  India.  Beyond  healthcare,  AI  technologies  in  the  other  sectors  including agriculture, education and mobility are set to transform the world. The commonality of issues with regard to the above sectors across developing countries provides the ideal use case of developing AI solutions that could be adapted for multiple markets. Hence, AI technologies suited for the Indian agricultural sector could  easily  be  customised  for  other  developing  nations  based  on  their  local  climatic  conditions. Education continues to be a major concern in almost all developing countries. AI technologies that are capable of imparting quality education to India's linguistically diverse population could prove very useful in other developing nations.\n\nAnother aspect of India's potential as a leader in AI is it proven track record in technology solution provider of choice. Solved in India (or more accurately, solved by Indian IT companies) could be the model going forward for Artificial Intelligence as a Service (AIaaS). Indian IT companies have been pioneers in bringing technology products and developments as solutions across the globe. As AI matures and generalised applications become common place, its advantage India when it comes to large scale implementation. Furthermore, India's competence in IT combined with opportunities, such as interoperability between\n\nmultiple languages, provides the much needed impetus for finding scalable solutions for problems that have global implications, such as NLP.\n\nArtificial  Intelligence  has  the  potential  to  provide  large  incremental  value  to  a  wide  range  of  sectors globally, and is expected to be the key source of competitive advantage for firms.\n\n- a) Healthcare : Application of AI in healthcare can help address issues of high barriers to access to healthcare facilities, particularly in rural areas that suffer from poor connectivity and limited supply of healthcare professionals. This can be achieved through implementation of use cases such as AI  driven  diagnostics,  personalised  treatment,  early  identification  of  potential  pandemics,  and imaging diagnostics, among others.\n- b) Agriculture : AI holds the promise of driving a food revolution and meeting the increased demand for food (global need to produce 50% more food and cater to an additional 2 billion people by 2050 as compared to today). It also has the potential to address challenges such as inadequate demand prediction, lack of assured irrigation, and overuse / misuse of pesticides and fertilisers. Some use cases include improvement in crop yield through real time advisory, advanced detection of pest attacks, and prediction of crop prices to inform sowing practices.\n- c) Smart  Mobility,  including  Transports  and  Logistics :  Potential  use  cases  in  this  domain  include autonomous fleets for ride sharing, semi-autonomous features such as driver assist, and predictive engine monitoring and maintenance. Other areas that AI can impact include autonomous trucking and delivery, and improved traffic management.\n- d) Retail : The retail sector has been one of the early adopters of AI solutions, with applications such as improving user experience by providing personalised suggestions, preference-based browsing and  image-based  product  search.  Other  use  cases  include  customer  demand  anticipation, improved inventory management, and efficient delivery management.\n- e) Manufacturing :  Manufacturing industry  is expected to be one of the biggest beneficiaries of AI based solutions, thus enabling 'Factory  of the Future' through flexible and adaptable technical systems to automate processes and machinery to respond to unfamiliar or unexpected situations by making smart decisions. Impact areas include engineering (AI for R&amp;D efforts), supply chain management  (demand  forecasting),  production  (AI  can  achieve  cost  reduction  and  increase efficiency), maintenance  (predictive maintenance  and  increased  asset  utilisation), quality assurance (e.g. vision systems with machine learning algorithms to identify defects and deviations in product features), and in-plant logistics and warehousing.\n- f) Energy : Potential use cases in the energy sector include energy system modelling and forecasting to decrease unpredictability and increase efficiency in power balancing and usage. In renewable energy systems, AI can enable storage of energy through intelligent grids enabled by smart meters, and also improve the reliability and affordability of photovoltaic energy. Similar to the manufacturing sector, AI may also be deployed for predictive maintenance of grid infrastructure.\n- g) Smart Cities : Integration of AI in newly developed smart cities and infrastructure could also help meet the demands of a rapidly urbanising population and providing them with enhanced quality of life. Potential use cases include traffic control to reduce congestion and enhanced security through improved  crowd management.\n- h) Education and Skilling : AI can potentially solve for quality and access issues observed in the Indian education sector. Potential use cases include augmenting and enhancing the learning experience through personalised learning, automating and expediting administrative tasks, and predicting the need for student intervention to reduce dropouts or recommend vocational training.\n\nSource:\n\nMcKinsey\n\nGlobal\n\nInstitute AI\n\nadoption and use survey\n\nAdoption of AI by various sectors have been influenced by, among other factors, technical and regulatory challenges, but commercial implications has been the biggest determinant. While technical feasibility, availability of structured data, regulatory barriers, privacy considerations, ethical issues, preference for human relationship have all played their roles in determining the readiness of a sector for large scale AI adoption; compelling business use cases (e.g. improved efficiency, accuracy, speed, forecasting and accurate decision making) that lead to direct impact on revenue and profitability have been the biggest driver for companies to pursue accelerated adoption of AI. As illustrated in McKinsey Global Institute's AI adoption and use survey, sectors leading the AI adoption today also intend to grow their investment in AI the most, thus further reinforcing the varying degrees of AI adoption across sectors.\n\nFigure 6: Current AI adoption and future AI investments by sector\n\n## Future Al demand trajectory'\n\n- Based on the midpoint of the range selected by the survey respondent\n- Results are weighted by fim size.See Appendix B f\u0153 an explanation of the weighting methodology.\n\nIt comes as no surprise that Banking and Financial Services sector has been one of the leading sectors globally  when  it  comes  to  AI  adoption,  and  India  has  also  seen  a  steep  increase  in  AI  based implementation in recent times. Existing and potential use of Artificial Intelligence in this sector include improved  customer  interaction  through  personalised  engagement,  virtual  customer  assistance,  and chatbots; improved processes through deployment of intelligent automation in rule based back-office operations; development of credit scores through analysis of bank history or social media data; and fraud analytics  for  proactive  monitoring  and  prevention  of  various  instances  of  fraud,  money  laundering, malpractice, and the prediction of potential risks. AI in this sector has also been employed in wealth management viz. robo-advisory, algorithmic trading and automated transactions.\n\nSimilarly, manufacturing sector, primarily automotive and assembly, has been one of the first sectors to implement advanced robotics at scale. The manufacturing sector in India hasn't been far behind, as reflected in a recent study by BCG, where India was ranked 3 rd  in the world in AI implementation in\n\nmanufacturing, ahead of nations such as Germany, with 19% of companies in the sector already using AI to a significant extent 6 .\n\nThese trends have also been reflected in the nature of investment in research in India, with private sector initiatives  such  as  the  Robert  Bosch  Centre  for  Data  Science  and  Artificial  Intelligence  (RBC-DSAI), choosing  to  focus  their  efforts  in  applied  research  on  sectors  such  as  manufacturing  analytics  and financial analytics.\n\nFigure 6 also reveals that sectors like Healthcare and Education have quite a lot of ground to cover as far  as  AI  adoption  is  concerned.  Healthcare,  despite  being  one  of  the  hottest  areas  of  AI  startup investments  ( Appendix  IV:  What  Do  the  Markets  Say ),  is  tricky,  especially  in  the  Indian  context. Agriculture doesn't even feature in the analysis above. Another analysis by McKinsey Global Institute indicates that potential value of AI for agriculture was in the bottom tercile of 19 sectors evaluated 7 , and could be a possible explanation for diminished private sector led AI adoption in agriculture. In sectors such as these, externalities from adoption of AI far outweigh the economic returns realised by private initiatives, and hence the role of government becomes pivotal in ensuring large scale AI intervention.\n\nNITI Aayog has evaluated various sectors that will be impacted by AI and has taken a conscious decision to focus on a select set of sectors where only private sector led initiatives will not lead to achieving desired societal outcomes. In addition to Healthcare and Agriculture, focus sectors include Education (preparing tomorrow's  generation  to  leverage  the  global  AI  revolution  to  India's  advantage),  Smart  Cities  and Infrastructure (solving for India's rapidly urbanising population) and Smart Mobility and Transportation (solving for challenges congestion, pollution, high rates of road accidents leading to economic inefficiency and enormous human cost).\n\nAn unrelated but interesting paradigm for AI application is the 'AI + X' approach. Despite its vast potential, the capabilities of AI today are limited to tasks for which it has been specifically trained, and are still many years from achieving human like consciousness. AI today should thus be regarded as an enhancement, or enabler of increased efficiency in previously existing processes, rather than capable of a complete overhaul  of  traditional  tasks.  Deployment  can  be  viewed  through  the  paradigm  of  'take  an  existing process, and add AI' or 'AI + X'; where 'X' can range from tasks such as driving a car, where AI can provide incremental value through improved routing and energy management, to act of sowing seeds, where AI can help inform decision making and improve productivity.\n\nSimilar to the effects of electricity, AI can increasingly be seen as an intelligent, additive utility that can be deployed at will, but remain largely invisible to the tasks performer. This vision is perhaps best put by author Kevin Kelley:\n\n' There is almost nothing we can think of that cannot be made new, different, or more valuable by infusing it with some extra IQ. In fact, the business plans for the next 10,000 startups are easy to forecast: Take X and add AI ' .\n\nIn applying this paradigm to the development of a national strategy, it is thus important to consider the challenges faced by individual sectors, or various manifestations of 'X' to best identify the incremental value  that  AI  can  provide.  The  paradigm  also  cements  the  need  for  collaboration  with  sectorial stakeholders in the application of the technology. The paradigm provides a useful framework to analyse what is possible in terms of technology intervention today.\n\n6 BCG 'AI in the Factory of the Future'\n\n7 McKinsey Global Institute 'Notes From The AI Frontier: Insights From Hundreds Of Use Cases'\n\n## AND ENABLERS\n\nSource: PwC Analysis, World Bank data (2017)\n\n## Focus areas for AI intervention\n\n## Sectoral deep dives\n\n## Healthcare\n\nHealthcare is one of the most dynamic, yet challenging, sectors in India,  and is expected to grow to USD280 billion by 2020, at a CAGR of upwards of 16%, from the current ~USD100 billion 8 .\n\nYet, it faces major challenges of quality, accessibility and affordability for a large section of the population:\n\n- a) Shortage  of  qualified  healthcare  professionals  and  services  like  qualified  doctors,  nurses, technicians  and  infrastructure :  as  evidenced  in  0.76  doctors  and  2.09  nurses  per  1,000 population  (as  compared  to  WHO  recommendations  of  1  doctor  and  2.5  nurses  per  1,000 population  respectively)  and  1.3  hospital  beds  per  1,000  population  as  compared  to  WHO recommended 3.5 hospital beds per 1,000 population 9 .\n- b)  N on-uniform accessibility to healthcare across the country with physical access continuing to be the major barrier to both preventive and curative health services, and glaring disparity between rural and urban India.\n\nFigure 7: Accessibility of Healthcare across India\n\nWith most of the private facilities concentrated in and around tier 1 and tier 2 cities, patients have to travel substantial distances for basic and advanced healthcare services. (Box 2: What TMH's Cancer heat map tells us about the availability of healthcare in India?)\n\nThe problem is further accentuated by lack of consistent quality in healthcare across India, most of the services provided is individual driven rather than institution driven, and less than 2% of hospitals in India are accredited.\n\n## Box 2: What TMH's Cancer heat map tells us about the availability of healthcare in India?\n\nTata Memorial Hospital, one of the leading cancer hospitals in India, registered more than 67,000 new registrations for cancer treatment in 2015. While the hospital is located in Mumbai, less than 23% of the new patients were geographically based in Maharashtra, with a whopping 21.7% of patients traveling from the states of UP, Bihar, Jharkhand and West Bengal to TMH.\n\nFigure 8 : Geographic location of TMH cancer patients\n\nThat these patients had to travel more than 1,800 km, on an average, to avail cancer treatment is an unfortunate tale of lack of access to quality healthcare. In addition to battling a potentially life threatening disease, the patients are saddled by the stress and financial implications of traveling long way away from home. While the data is not available to such an effect, it wouldn't be surprising to find that most of these patients choose to travel to TMH when cancer has developed to an advanced stage, thus further reducing the chances of successful cure and treatment.\n\nCredit\n\n: Tata Memorial Centre\n\n- c) Affordability remains  a  problem  with  private  expenditure  accounting  for  ~70%  of  healthcare expenses, of which ~62% is out-of-pocket expenditure, probably one of the highest in the world. Significant portion of hospital costs in both rural (~47%) and urban India (~31%) are financed by loans and sale of assets. Poor and marginalised are hit the most, and as per the Government estimates,  a  sizeable  part  of  the  population  (~63  million)  are  faced  with  poverty  every  year because of their healthcare expenditure 10 .\n- d) Reactive approach to essential healthcare largely due to lack of awareness, access to services and behavioral factors implies that majority of patients approach a hospital / physician only when a disease has reached an advanced stage, thus increasing the cost of care and reducing the chances of recovery.\n\nThe  Government  of  India  has  been  making  a  series  of  large  scale  interventions  to  address  India's healthcare challenges, viz. transformation of 1.5 lakh Health and Wellness Centers, developing district hospitals  to  cater  to  long-term  care  for  non-communicable  diseases,  Ayushman  Bharat  Mission, promoting e-Health etc.\n\n## Box 3: Government of India's push for Universal Healthcare Coverage\n\nThe  Government  of  India,  through  its  recent  policy  interventions,  has  shown  a  bold  commitment  to achieve  Universal  Health  Coverage  and  increased  access  to  comprehensive  primary  health  care. Through  the  Ayushman  Bharat  programme  announced  in  Union  Budget  2018,  probably  the  world's largest government funded health care programme, the Government of India has embarked on a path breaking journey to ensure the affordability and accessibility of healthcare in India. The Ayushman Bharat - National Health Protection Mission (AB - NHPM) aims to provide insurance cover of INR 5 lakh per family per year for secondary and tertiary care hospitalisation. Ayushman Bharat is targeted at more than 10 crore families (approximately 50 crore beneficiaries / ~40% of India's population) belonging to the poor and vulnerable sections based on the SECC database, and doesn't impose any limitations on family size or age limit for the beneficiaries to avail benefits. The benefits package covers most medical and surgical conditions with minimal exclusions, covers pre and post hospitalisation expenses, and covers all preexisting conditions from day one - thus simplifying availing requisite healthcare by the beneficiaries. The benefits of the Mission will be available at public hospitals as well as empaneled private health care facilities.\n\nThe Union Budget 2018 also included a commitment of ~INR1,200 crore for Health and Wellness Centres (HWC), which will lay the foundation for  India's health system as envisioned in the National Health Policy 2017. These HWCs, to be set up by transforming 1.5 lakh Health Sub Centres from 2018 to 2022, are aimed  at  shifting  primary  healthcare  from  selective  (reproductive  and  child  health  /  few  infectious diseases)  to  comprehensive  (including  screening  and  management  of  NCDs;  screening  and  basic management of mental health ailments; care for common ophthalmic and ENT problems; basic dental health care; geriatric and palliative health care, and trauma care and emergency care). NCDs account for ~60% of mortality in India, 55% of which is premature. NCDs are predominantly chronic conditions and impact the poor most adversely, given the high costs of treatment involved. Prevention and early detection are therefore of the essence in reducing the disease burden attributable to these conditions as well as ensuring long-term follow-up and management of symptoms for patients. The HWCs, under the new implementation plan, will provide 12 basic healthcare services, expanding from the current package of 6 services. Crucially, these centres will provide preventive services to improve healthy behaviours for\n\n10 National Health Policy 2015 Draft\n\nfamily health and control the incidence of communicable and non-communicable diseases among the population  covered  by  HWCs.  A  key  component  of  HWCs  will  be  universal  screening  for  NCDs. Screening for five NCDs and associated risk factors has been prioritised given the high burden of disease associated with them. These include  hypertension, diabetes, as well as  three common cancers - oral, breast and cervical. Screening for other conditions such as Chronic Obstructive Disease will be added subsequently.  The  HWCs  will  be  operated  by  a  mid-level  health  service  provider,    auxiliary  nurse midwives, accredited social health activists and a male health worker responsible for comprehensive primary health care services for a population of about 5,000.\n\n## Figure 9 : Features of HWC\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\nCare in pregnancy and child-birth\n\nNeonatal, infant health care services\n\nChildhood and adolescent healthcare\n\nFamily planning / reproductive healthcare\n\nCommunicable diseases (TB, Malaria etc.)\n\nScreening, prevention and control of NCDs\n\nEquipped with consulting spaces and wellness rooms\n\nCommon ophthalmic and ENT care\n\nOut-patient care for acute simple illnesses /  ailments\n\nBasic oral healthcare\n\nManageable emergency medical services\n\nScreening / management of mental health ailments\n\n7\n\n8\n\n9\n\n10\n\n11\n\n12\n\nElderly and palliative health care services\n\nHub and spoke model for connecting HWCs with PHCs\n\nTelemedicine facilities and point of care diagnostics\n\nDrug storage and dispensation, waiting area for 30+ people\n\nThe NHPM and HWC, in unison, are aimed at holistically addressing the health needs of the population, including health promotion and disease prevention as well as the delivery of primary, secondary and tertiary services.\n\nIn addition, the government aims at leveraging technology to improve healthcare facilities through the:\n\n- a) the National eHealth Authority (NeHA) which will strategise eHealth adoption, define  standards and a framework for the health sector, put in place  electronic health exchanges for interoperability,\n- b) the Integrated Health Information Program (IHIP) to provide EHR to all citizens of India and provide interoperability to existing EHR/EMRs,\n- c) the Electronic Health Record Standards for India\n\nDespite  the  obvious  economic  potential,  the  healthcare  sector  in  India  remains  multi-layered  and complex, and is ripe for disruption from emerging technologies at multiple levels. It is probably the most intuitive  and  obvious  use  case  primed  for  intervention  by  AI  driven  solutions,  as  evidenced  by  the increasing activity from large corporates and startups alike in developing AI focused healthcare solutions. Adoption of AI for healthcare applications is expected to see an exponential increase in next few years. The healthcare market globally driven by AI is expected to register an explosive CAGR of 40% through\n\nComprehensive primary health care through HWCs\n\nRobust IT\n\nsystem, MLHP\n\nand payment reforms\n\nExpansion to 12 basic services, integration with AYUSH, health promotion\n\nSource: PWC, 'No longer science fiction, AI and robotics are transforming healthcare'\n\n2021, and what was a USD600 million market in 2014 is expected to reach USD6.6 billion by 2021 11 . The increased advances in technology, and interest and activity from innovators, provides opportunity for India to solve some of its long existing challenges in providing appropriate healthcare to a large section of its population. AI combined with robotics and Internet of Medical Things (IoMT) could potentially be the new nervous system for healthcare, presenting solutions to address healthcare problems and helping the government in meeting the above objectives.\n\nFigure 10: Potential use cases of AI in Healthcare\n\nAI solutions can augment the scarce personnel and lab facilities; help overcome the barriers to access and solve the accessibility problem; through early detection, diagnostic, decision making and treatment, cater to a large part of India.\n\nCancer screening and treatment is an area where AI provides tremendous scope for targeted large scale interventions. India sees an incidence of more than 1 million new cases of cancer every year, and early detection and management can be crucial in an optimum cancer treatment regimen across the country. NITI  Aayog  is  in  an  advanced  stage  for  launching  a  programme  to  develop  a  national  repository  of annotated  and  curated  pathology  images.  Another  related  project  under  discussions  is  an  Imaging Biobank for Cancer.\n\n## Box 4: AI for India's cancer woes\n\nCancer screening and treatment is an area where AI provides tremendous scope for targeted large scale interventions. India sees an incidence of more than 1 million new cases of cancer every year, a number that  is  likely  to  increase  given  the  increasing  age  of  Indian  population  and  lifestyle  changes.  Early detection and management can be crucial in an optimum cancer treatment regimen across the country. Good quality pathology service is the essential building block of cancer care, which unfortunately is not easily available outside select Indian cities. For an annual incidence of more than 1 million new cancer diagnosis every year, India has barely 2,000 pathologists experienced in oncology, and less than 500\n\n11 Frost &amp; Sullivan, 'From $600 M to $6 Billion, Artificial Intelligence Systems Poised for Dramatic Market Expansion in Healthcare'\n\npathologists who could be considered an expert oncopathologist. Machine learning solutions aimed at assisting  a  general  pathologist  in  making  quality  diagnosis  can  very  well  plug  this  gap  in  providing essential  healthcare.  An  essential  pre-requisite  in  implementation  of  such  a  solution  is  availability  of quality annotated pathology datasets. NITI Aayog is in an advanced stage for launching a programme to develop a national repository of annotated and curated pathology images. The components of such a repository  include  a move towards 'Digital Pathology', which entails all glass slides generated being scanned  at  high  resolution  and  magnification,  followed  by  accurate,  precise  and  comprehensive annotation of the scanned images using various data sources &amp; levels of clinical &amp; pathological (gross pathology, histopathology and molecular) information available from day-to-day patient care.\n\nAnother related project under discussions is an Imaging Biobank for Cancer. Human cancers exhibit strong phenotypic differences that may be visualised noninvasively by expert radiologists (using imaging modalities). Recent literature suggests that certain image based features may correlate to molecular and clinical features like known mutations (KRAS, EGFR, etc.), receptor status, prognostic power, intra-tumor heterogeneity, gene expression patterns, etc. Reports have shown an association between radiographic imaging  phenotypes  and  tumor  stage,  metabolism,  hypoxia,  angiogenesis  and  the  underlying  gene and/or protein expression profiles. These correlations, if rigorously established, may have a huge clinical impact  as  imaging  is  routinely  used  in  clinical  practice.  Moreover,  this  provides  an  unprecedented opportunity  to  use  artificial  intelligence  to  improve  decision-support  in  cancer  treatment  at  low  cost especially  in  countries  like  India.  AI  based  Radiomics  is  an  emerging  field  that  refers  to  the comprehensive quantification of tumor phenotypes by applying a large number of quantitative imaging features.  It  has  resulted  in  improvement  to  existing  biomarker  signature  panels  by  adding  imaging features.\n\nCredit : Tata Memorial Centre for developing the concepts for Digital Pathology and Imaging Biobank\n\nNITI Aayog is working with Microsoft and Forus Health to roll out a technology for early detection of diabetic retinopathy as a pilot project. 3Nethra, developed by Forus Health, is a portable device that can screen for common eye problem. Integrating AI capabilities to this device using Microsoft's retinal imaging APIs  enables operators of 3Nethra device to get AI-powered insights even when they are working at eye checkup camps in remote areas with nil or intermittent connectivity to the cloud. The resultant technology solution also solves for quality issues with image capture and systems checks in place to evaluate the usability of the image captured.\n\nAI based healthcare solutions can also help in making healthcare services more proactive - moving from 'sick' care to true 'health' care, with emphasis on preventive techniques.\n\nSource: World Bank and UNSECOIHE Report on Water Footprint 2010\n\n## Agriculture\n\nWhile India has come a long way from being categorised as purely an agrarian economy, agriculture and allied sector still accounts for 49% of India's workforce, 16% of the country's gross domestic product (GDP) 12 , and ensures food security to roughly 1.3 billion people.\n\nAgriculture and allied sector is critical to India's growth story. To achieve and maintain an annual growth rate of 8 -10% for the Indian economy, agriculture sector must grow 4% or higher rate. The Government of India has recently prioritised Doubling Farmers' Income as a National Agenda ; putting considerable focus on supply chain perspectives in agriculture and market development in addition to productivity augmentation.\n\nDespite  making  impressive  progress  and  receiving  government  attention,  the  sector  continues  to  be dependent on unpredictable variables, has weak supply chain and low productivity.\n\nIndia  has  not  been  able  to  completely  remove  its  exploitative  dependence  on  resource  intensive agricultural practices. Degradation of land, reduction in soil fertility, increased dependence on inorganic fertilizers for higher production, rapidly dropping water tables and emerging pest resistance are some of the  several  manifestations  of  India's  unsustainable  agricultural  practices.  As  global  climate  becomes more vulnerable and unpredictable, dependence on unsustainable and resource intensive agriculture will only heighten the risks of food scarcity and agricultural distress.\n\nThe sector suffers from poor resource utilisation, with the production quantum and productivity still being quite low. For example, yield of cereals, comprising a major share of food grain production, in terms of magnitude  is  significantly  lower  than  that  of  China  and  the  USA.  Technology  adoption  and  efficient resource usage in these two countries are far higher, thus resulting in higher yields.\n\nSimilarly, use of water in agriculture continues to be high and sub-optimal. The practice of growing water intensive crops, and inefficient water management, makes India a net exporter of water and puts India's long run agronomic sustainability in question. Despite having just one-third of the gross cropped area under irrigation, agriculture consumes 89% of our extracted groundwater.\n\nFigure 11: Comparison of yield and water footprint\n\nAgrarian distress in India has increased over time due to a multiplicity of factors. Fluctuating agricultural growth rate, globalised value chains leading to variability in commodity prices, unpredictable changes in\n\n12 Economic Survey 2018\n\nSource: Doubling Farmers Income Committee Estimates monsoon rainfall over years and structurally inefficient domestic agricultural markets are just some of the reasons  for  income  variability  of  farmers.  Various  National  Sample  Survey  rounds  have  shown  the reduction in proportion of value share of crops to overall agricultural value from 78% to 69% since the Green Revolution 13 . Thus income disparity between a farmer and non-agricultural worker has increased over the years. 14\n\nFigure 12: Income disparity\n\nOn the market side, non-existent functional end-to-end agriculture value chains have caused the price realisation for farmers to remain low. Access to, and timely availability of services, across agricultural value chain at the farmers' end thus becomes a challenge. At present, there is no functional mechanism to track the capacity of storage facilities available to the farmer. Value chain is not integrated through its entire  length  -  procurement  to  market,  including  ICT,  and  banking  services.  The  following  figure effectively captures the present scenario.\n\nFigure 13: Agri-Commodity value chain in India\n\nSource: Accenture Research\n\nAI  will  have  significant  global  impact  on  agricultural  productivity  at  all  levels  of  the  value  chain. An estimate by Markets and Markets Research valued AI in agriculture to be USD432 million in 2016 and expects it to grow at the rate of 22.5% CAGR to be valued at USD2.6 billion by 2025 15 .\n\nAccording to CB Insights, agricultural tech startups have raised over USD800million in the last 5 years. Deals for startups using robotics and machine learning to solve problems in agriculture started gaining momentum in 2014, in line with the rising interest in AI across multiple industries like healthcare, finance, and commerce. From analysing millions of satellite images to finding healthy strains of plant microbiome, these startups have raised over USD500 million to bring AI and robotics to agriculture.\n\nGlobally, digital and AI technologies are helping solve pressing issues across the agriculture value chain. The relative role of each technology in creating impact is dependent on the nature of the work, and the issues at hand. India has ~30 million farmers who own smartphones, which is expected to grow 3 times by 2020 and 315 million rural Indians will be using internet by 2020 16 . An Accenture study says digital farming and connected farm services can impact 70 million Indian farmers in 2020, adding USD9 billion to farmer incomes . These are not futuristic scenarios, they are in play today, enabled by a vast digital ecosystem which includes traditional Original Equipment Manufacturers (OEM), software and services companies, cloud providers, open source platforms, startups, R&amp;D institutions and others. Future growth is interdependent on the close partnership among these players.\n\n## Figure 14: Ecosystem crucial for benefits of Precision Agriculture\n\nIn  2016,  approximately  50  Indian  agricultural,  technology  based  startups  ('AgTech')  raised  USD313 million 17 .  For the first time, this sector is seeing widespread participation by  startups. Intello Labs, for example, uses image-recognition software to monitor crops and predict farm yields. Aibono uses agridata science and AI to provide solutions to stabilise crop yields. Trithi Robotics uses drone technology to allow farmers to monitor crops in real time and provide precise analysis of their soil. SatSure, a startup\n\n15 MarketsAndMarkets\n\n16 Forbes.com 'For India's Farmers It's Agtech Startups, Not Government, That Is Key'\n\n17 Agfunder.com\n\nwith roots in India, uses ML techniques to assess images of farms and predict economic value of their future yield.\n\nUse of AI and related technologies have the potential to impact productivity and efficiency at all of the above stages of the agricultural value chain.\n\n- \uf0b7 Soil health monitoring and restoration: Image recognition and deep learning models have enabled distributed soil health monitoring without the need of laboratory testing infrastructure. AI solutions integrated with data signals from remote satellites, as well as local image capture in the farm, have made it possible for farmers to take immediate actions to restore soil health.\n\n## Box 5: Application for soil care\n\nBerlin-based agricultural tech startup PEAT has developed a deep learning application called Plantix that reportedly identifies potential defects and nutrient deficiencies in the soil. The analysis is conducted by software algorithms which correlate particular foliage patterns with certain soil defects, plant pests and diseases. The image recognition app identifies possible defects through images captured by the user's smartphone camera. Users are then provided with soil restoration techniques, tips and other possible solutions.\n\n- \uf0b7 Crop health monitoring and providing real time action advisories to farmers: The Indian agriculture sector is vulnerable to climate change due to being rain dependent. Varying weather patterns such as increase in temperature, changes in precipitation levels, and ground water density, can affect farmers especially in the rainfed areas of the country. AI can be used to predict advisories for sowing, pest  control,  input  control  can  help  in  ensuring  increased  income  and  providing  stability  for  the agricultural community. For example, many agronomic factors (such as vegetation health and soil moisture) can be monitored up to the farm level through remote sensing. Using remote sensed data, high  resolution  weather  data,  AI  technologies,  and  AI  platform,  it  is  possible  to  monitor  crops holistically and provide additional insights to the extension workers/farmers for their farms as &amp; when required.\n- \uf0b7 Increasing efficiency of farm mechanisation: Image classification tools combined with remote and local sensed data can bring a revolutionary change in utilisation and efficiency of farm machinery, in areas of weed removal, early disease identification, produce harvesting and grading. Horticultural practices require a lot of monitoring at all levels of plant growth and AI tools provide round the clock monitoring of these high value products.\n\n## Box 6: AI sowing app\n\nMicrosoft in collaboration with ICRISAT, developed an AI Sowing App powered by Microsoft Cortana Intelligence  Suite  including  Machine  Learning  and  Power  BI.  The  app  sends  sowing  advisories  to participating farmers on the optimal date to sow. The best part - the farmers don't need to install any sensors in their fields or incur any capital expenditure. All they needed was a feature phone capable of receiving text messages. The advisories contained essential information including the optimal sowing date, soil test based fertilizer application, farm yard manure application, seed treatment, optimum sowing depth, and more. In tandem with the app, a personalised village advisory dashboard provided important\n\ninsights into soil health, recommended fertilizer, and seven-day weather forecasts. In 2017, the program was expanded to touch more than 3,000 farmers across the states of Andhra Pradesh and Karnataka during the Kharif crop cycle (rainy season) for a host of crops including groundnut, ragi, maize, rice and cotton, among others. The increase in yield ranged from 10% to 30% across crops.\n\n## Box 7: AI for herbicide optimisation\n\nBlue River Technology has designed and integrated computer vision and machine learning technology that  enables  farmers  to  reduce  the  use  of  herbicides  by  spraying  only  where  weeds  are  present, optimising the use of inputs in farming - a key objective of precision agriculture.\n\n- \uf0b7 Increasing the share of price realisation to producers: Current low levels of price realisation to farmers (as  low  as  20%  in  fruits  and  vegetables 18 )  are  primarily  due  to  ineffective  price  discovery  and dissemination mechanisms, supply chain intermediary inefficiency and local regulations. Predictive analytics using AI tools can bring more accurate supply and demand information to farmers, thus reducing  information  asymmetry  between  farmers  and  intermediaries.  As  commodity  prices  are interlinked globally, big data analysis becomes imperative. Data from e-NAM, Agricultural Census (with data on over 138 million operational holdings), AGMARKET and over 110 million Soil Health Samples provide the volumes required for any predictive modelling.\n\n## Box 8: AI for Precision Farming\n\nNITI Aayog and IBM have partnered to develop a crop yield prediction model using AI to provide real time advisory to farmers. IBM's AI model for predictive insights to improve crop productivity, soil yield, control agricultural inputs and early warning on pest/disease outbreak will use data from remote sensing (ISRO), soil health cards, IMD's weather prediction and soil moisture/temperature, crop phenology etc. to give accurate prescriptions to farmers. The project is being implemented in 10 Aspirational Districts across the States of Assam, Bihar, Jharkhand, Madhya Pradesh, Maharashtra, Rajasthan and Uttar Pradesh.\n\n18 DFI Committee Report\n\n## Education\n\nAn  effective  education  sector has  the  ability  to transform  a  country  through  development  of  human resources and increased productivity. In the context of emerging countries particularly, levels of education and literacy of the population play an important role in development and overall transition to an advanced economy.\n\nIn  India,  the  importance  of  a  developed  education  sector  is  amplified  by  a  large  youth  population. Estimates indicate that currently over half the population of the country is below the age of 25. As the adoption of digital means of gathering data increases, it is important that these methods are effectively leveraged to deliver improved education and teaching.\n\nThe adoption of technology in education is improving, though not at the pace required. It is estimated that schools globally spent nearly USD160 billion on education technology, or 'EdTech', in 2016, and forecast spending to grow 17% annually through 2020. Private investment in educational technology, broadly defined as the use of computers or other technology to enhance teaching, grew 32% annually from 2011 through 2015, rising to USD4.5 billion globally. Adoption of new technologies is still lacking, however, often attributed to unwillingness of teachers and students to adopt technology.\n\nSchool education in India has seen substantial progress in recent decades, with efforts at both the Central and State levels, and substantive gains in enrolment have been achieved - Gross Enrolment Ratio (GER) is 97% at elementary level and 80% at secondary level, as per recent figures. However, low retention rates and poor learning outcomes mar the impact of gains in enrolment.\n\n- a) Low retention rates: Enrolment of children is of little use if children are not retained in the schooling system. Retention rate of 70.7% at elementary level indicates that one-third of enrolled children drop out before completing Class 8. Retention rate at secondary level is also poor at 57.4%. Low quality of education is one of the causes of poor retention.\n- b) Poor learning outcomes: There is increasing concern about the poor learning levels of children in school, and a new National Achievement Survey (NAS) was recently conducted in November 2017. Previous rounds of NAS results provide an insight into longitudinal performance over time - average performance of States / UTs on previous rounds showed that over 60% of Class 5 students scored below 50% across subjects; and for majority of the 31 States / UTs tested, performance significantly deteriorated in NAS Cycle-4 versus Cycle-3. Assessments from the perspective of basic foundational skills also indicate poor learning outcomes - in rural areas, only 47.8% of Class 5 children could read Class 2 level text and only 26% could do Class-5-level arithmetic.\n\nThe above scenario is a consequence of a complex interplay of factors that pose challenges to improving the quality of education:\n\n- a) Multi-grade  and  multi-level  classrooms: For  a  large  proportion  of  schools,  especially  in  small  or remote villages,  it  is  not  viable  to  have  separate  classrooms  and  teachers  for  different  grades  / classes.  Consequently,  the  teacher  is  faced  with  a  heterogenous  group  of  children  in  the  same classroom, with wide variations in their classes, ages, abilities and learning levels. This large variation poses a huge challenge to the teacher and is a common cause of poor teaching-learning, thus leading to poor learning outcomes.\n- c) Lack of interactive pedagogy and ineffective remedial instruction: Teaching-learning processes in most classrooms are highly rote-based and non-interactive. Remedial instruction, where conducted, typically lacks customisation to the child's learning level, abilities, and pace of learning.\n\n- d) Inadequate attention / action for likely drop-outs: Several children may be at risk of dropout due to various  factors,  such  as  inadequate  school  infrastructure,  poor  teachers,  poor  school  readiness, language barriers, large learning gaps with respect to grade level, family circumstances (e.g. migrant families), poor nutritional or health status, etc.\n- e) Large  teacher  vacancies  due  to  uneven  distribution  across  locations: Large  number  of  teacher vacancies are mostly not due to an overall shortage of teachers in a State - instead, they are due to uneven distribution across different geographical areas within the State. For instance, recent figures for  Uttar  Pradesh  revealed  1.74  lakh  teacher  vacancies  at  elementary  school  level,  but  a simultaneous surplus of 0.66 lakh teachers across the state.\n- f) Professional development courses / training do not cater to real needs and have poor coverage Existing  teacher  training  is  typically  a  generic  kind  of  an  exercise.  It  is  not  linked  to  the  specific weaknesses / requirements of a teacher - for instance, a teacher with poor arithmetic understanding requires corresponding training to clarify arithmetic concepts. Consequently, most teacher training exercises end up as wasted public expenditure, with little or no benefit to the teacher and her / his students. Similar issues exist with respect to training of other staff such as school headmasters/principals. The coverage of existing training programs is also extremely low, typically less than 20% annually.\n- g) Low adoption of existing technologies : A recent survey found that level of adoption of technology in schools is lacking, and can be largely attributed to lack of teacher training, despite provision of the ICT infrastructure. While 83% of the teachers surveyed use computers, the use is limited primarily to audio  /  visual  display,  or  student  practice.  A  meagre  41%  and  27%  use  technology  for  tracking student data and participating in forums respectively. This trend is even more pronounced in the low fee school segment surveyed 19 . Another trend observed is that trained teachers are much more likely to  use  technology  in  the  classroom.  88%  of  trained  teachers  reported  making  use  of  available computers as compared to only 53% of untrained teachers. Trained teachers were found to be nearly twice  as  likely  to  report  using  technology  for  communication  purposes  and  for  online  forum participation 20 .\n\nAccording  to  EdTechXGlobal,  EdTech  is  becoming  a  global  phenomenon,  and  as  distribution  and platforms scale internationally, the market is projected to grow at 17.0% per annum, to USD252 billion by 2020. India's digital learning market was valued at USD2 billion in 2016 and is projected to grow at a CAGR of 30%, reaching USD5.7 billion in 2020 as per estimates from Technopak.\n\nAs per Forbes, in 2017, across every market involved in EdTech, international funding reached a new record  of  USD9.52  billion,  and  813  different  EdTech  companies  received  fundings  last  year.  These EdTech investments mark a gain of 30% from 2016. VC interest in the education space continues to grow. For example, one of India's leading EdTech startups Byju's raised USD40 million from Tencent in July 2017, just four months after raising USD30 million from Belgium-based Verlinvest. Among Byju's other investors include Sequoia Capital and The Chan Zuckerberg Foundation.\n\nAI has the potential to bring about changes in the sector by supplementing pedagogy and establishing systems to inform and support decision making across stakeholders and administrative levels. However,\n\n19 Cross Square Foundation, Ed Tech Adoption Survey\n\n20 Economic Survey, 2016-17\n\nimplementation of AI must be preceded by efforts to digitise records of teacher performance, student performance, and curriculum. Several AI tools are being successfully used in other parts of the world, and they can be adapted to the Indian context to target specific challenges.\n\n- a) Adaptive learning tools for customised learning : While AI may not completely replace a teacher, it has the potential to greatly assist teachers in efficiently and effectively managing multi-level / multigrade  classrooms,  by  judging  learning  levels  of  individual  students,  and  allowing  automated development of customised educational content adapted to each child's class and learning level. Assessing time spent by a student on each part / page of the learning material, for example, would allow real-time feedback on student performance to help the teacher appropriately tailor her guidance to the child. This concept can be extended to automatic grading of tests, as well.\n- b) Intelligent and interactive tutoring systems : Intelligent Tutoring Systems can provide great benefit to students through delivery of learning materials adapted to the child's proficiency level, learning style, and pace of learning. In-built pop-up questions tailored to students, for example, can help increase interactivity, and catch student's attention and interest. It can also help in assessment of student's level of attention or comprehension to appropriately design remedial instruction. GradeGuardian, for example,  uses  predictive  models  and  visualisations  for  student  performance  with  an  interactive dashboard  showing  anticipated  effect  of  policy  changes.  Submission  includes  3  components packaged as a single web app - a Chatbot that inputs student information, an Advisor Console that shows students at risk, and a prediction module for policymakers.\n\n## Box 9: Creating 'smart content' for improved interactivity\n\nContent Technologies Inc. (CTI), an AI research and development company, develops AI that creates customised educational content. Using deep learning to absorb and analyse existing course materials, textbooks, and course curriculum, the technology creates custom learning materials, including textbooks, chapter summaries, and multiple-choice tests.\n\nA recent hackathon conducted by NITI Aayog also featured 'ReadEx', an android application that does real-time question generation using NLP, content recommendations, and flashcard creation.\n\n- c) Predictive tools to inform pre-emptive action for students predicted to drop out of school: Analysis of test results and attendance records using AI can be used to predict probable student activities and inform pre-emptive action.  For instance, in a recent preliminary experiment conducted in Andhra Pradesh, AI applications processed data on all students based on parameters such as gender, socioeconomic factors, academic performance, school infrastructure, teacher skills, etc., with the objective of helping the government identify students likely to drop out. Test results could inform suggestions to enroll students in vocational studies. Additionally, redressal mechanisms could be put in place to identify students whose performance can be improved by focus of existing schemes to their family.\n\n## Box 10: Microsoft is helping in predicting drop outs in Andhra Pradesh\n\nThe AP government is making concerted efforts to bring down the school dropout rate in the state. It has tied up with Microsoft to address this complex challenge. Based on specific parameters, such as gender, socio-economic  demographics,  academic  performance,  school  infrastructure  and  teacher  skills,  an application powered by Azure Machine Learning processes the data pertaining to all students to find predictive patterns.\n\nWith these data insights, the district education officials can intervene and help students who are most likely to drop out. A variety of programs and counselling sessions could be conducted for these students and their parents.\n\nThe Andhra Pradesh government, based on machine learning and analytics, has identified about 19,500 probable dropouts from government schools in Visakhapatnam district for the next academic year (201819).\n\n- d) Automated rationalisation of teachers: AI tools can be used to develop automated teacher posting and transfer systems, using analytics based on demand - supply gaps across schools in the State, candidate's prior postings, candidate preferences, etc. This would help in plugging of gaps in teacher distribution more effectively.\n- e) Customised professional development courses: To tackle issues of poorly designed professional development courses with poor coverage, adaptive AI tools can be used to design automated, customised professional development training content for the teacher based on their performance, identification of their knowledge and skill gaps. This could then be continuously adapted as teacher's skills and concepts improve.\n\n## Box 11: WriteToLearn by Pearson\n\nPearson's  WriteToLearn  software  uses  natural  language  processing  technology  to  give  students personalised feedback, hints, and tips to improve their writing skills. In describing his experience using WriteToLearn,  one  7th-grade  English  language  arts  teacher  said,  ' I  feel  it's  pretty  accurate.  \u2026  Is  it perfect? No. But when I reach that 67 th  essay, I'm not [really] accurate, either. As a team, [WriteToLearn and I]  are  pretty  good .'  Essay  grading technology cannot substitute for a teacher's ability to provide feedback and coaching on particular words and sentences: the software merely rates students' essays in  general  areas-  such  as  organisation,  idea  development,  and  style-and  then  provides  generic suggestions for improvement in these areas. But when teachers use the software as a first pass at grading and then interject their detailed feedback to address the improvement areas identified by the software, essay  grading  becomes  a  much  less  time-consuming  and  laborious  process.  The  net  result  is  that teachers  can  spend  less  time  grading  and  more  time  teaching,  while  also  giving  students  more opportunities to receive customised feedback on their writing.\n\n## Smart Cities and Infrastructure\n\nIndia is currently in the midst of a surge of urbanisation. While the percentage of the population living in urban areas was estimated to be 31% in 2011 21 , recent research on satellite data indicates that this figure is close 45% today 22 , and predicted to rise to up-to 60 percent by 2050 23 . Though seen as an important aspect  of  a  country's  economic  growth  and  a  major  step  in  the  overall  development  of  the  country, unplanned urbanisation presents challenges such as congestion, over pollution, high crime rates, poor living standards, and can potentially put a huge burden on the infrastructure and administrative needs of existing Indian cities.\n\nTo tackle these challenges, the Government of India has embarked on an ambitious initiative to set up Smart  Cities  across  India,  aimed  at  driving  economic  growth  and  improving  the  quality  of  life,  by harnessing IT solutions. As part of the Smart Cities Mission, 99 cities have been selected with expected investment  of  INR2.04  lakh  crores.  The  strategic  components  of  these  Smart  Cities  include  city improvement (retrofitting), city renewal (redevelopment) and city extension (greenfield development) in addition to a pan-city initiative in which smart solutions are applied covering large parts of the city. The Atal  Mission  for  Rejuvenation  and  Urban  Transformation  (AMRUT) is another  related  initiative  which targets improving the infrastructure of existing cities.\n\nSmart cities attempt to address the challenges of urbanisation through development of features based on IT solutions, some of which are listed below.\n\n- a) Poor urban planning 24 : Smart cities aim to solve challenges of inefficient land use, improper land use categorisation, area based development and lack of open spaces such as parks, playgrounds, and recreational spaces in order to enhance the quality of life of citizens, reduce the urban heat effect, and generally promote improved ecological balance.\n- b) Inefficient utility distribution : Through large scale deployment of smart meters in both electricity and water, smart cities being developed are trying to solve challenges such as low visibility on usage of utilities  such  as  electricity,  water,  and  waste  management.  This  is  also  targeted  to  help  address issues of leakages in electricity and water distribution, and improper disposal of waste, and have the potential to significantly reduce cost associate with administration and management.\n- c) Improved delivery of citizen services: In the domain of service delivery, smart cities aim to harness data to solve issues in low accountability and transparency. By using digital channels, they can help address  challenges  in  administration  of  offices,  and  long  wait  times.  Today,  poor  standards  of grievance redressal form another pressing issue that may be addressed by increasing adoption of technology based solutions.\n- d) Improving public safety: Cities in India today are hotbeds for a range of crimes. Smart cities aim to address the issues of increase in crime and increased risk of urban emergencies through improved city design and surveillance analytics.\n\nSome Smart Cities have already begun implementing these features through specific projects. Pune, for example, has launched The Pune Street Light Project to setup energy efficient street lights that can be remote controlled through a Supervisory Control and Data Acquisition (SCADA) systems. Surat has built a network of more than 600 surveillance cameras which will be expanded to all major locations in the\n\n21 Census 2011\n\n22 LiveMint: 'How much of India is actually urban?'\n\n23 LiveMint: '60% of India's population to live in cities by 2050: government'\n\n24 Smartcities.gov.in\n\ncity,  as  well  as  collaborated  with  Microsoft  to  develop  solutions  for  water  management  and  urban planning.\n\nDue to the large amount of data they can create, smart cities are especially amenable to application of AI, which can make sense of the data being generated, and transform it into predictive intelligence - thus transitioning from a smart city to an 'intelligent city'.\n\nHowever, the wide range of connected devices also gives rise to increased risks in cyber security, with harmful actors such as hackers now capable of affecting city scale infrastructure.\n\nSome use cases of AI that can augment the features of a smart city are listed below.\n\n- a) Smart  Parks  and  public  facilities :  Public  facilities  such  as  parks  and  other  spaces  contribute substantially to a city's liveability. Use of AI to monitor patronage and accordingly control associated systems such as pavement lighting, park maintenance and other operational conditions could lead to cost savings while also improving safety and accessibility.\n- b) Smart  Homes :  Smart  homes  concept  is  creating  buzz  with  AI  technologies  being  developed  to optimise  human  effort  in  performing  daily  activities.  Extending  this  concept  to  other  domestic applications such as smart rooftops, water saving applications optimising domestic water utilisation for different human activities etc.\n- c) AI  driven  service  delivery :  Implementation  of  AI  to  leverage  data  on  service  delivery  could  see application  such  as  predictive  service  delivery  on  the  basis  of  citizen  data,  rationalisation  of administrative personnel on the basis of predicted service demand and migration trend analysis, and AI based grievance redressal through chat-bots.\n- d) Crowd management: Use of AI in providing effective solutions in crowd management in recent times have been in vogue and given fruitful results in averting city-scale challenges such as managing mega footfall events, emergency and disasters. Accenture worked with the Singapore Government during  their  SG50  Celebrations  (50 th   anniversary  of  Singapore'  independence),  and  developed solution  aimed  at  predicting  crowd  behavior  and  potential  responses  to  incidents.  The  solution resulted in 85% accuracy in high crowd activity, crowd size estimation and object detection. Closer home, the  'Kumbh  Mela  Experiment'  is  aimed  at  predicting  crowd  behavior  and  possibility  of  a stampede.  Similar  Big  Data  and  AI  solutions  could  help  with  advance  prediction  and  response management.\n- e) Intelligent safety systems : AI technology could provide safety through smart command centres with sophisticated surveillance systems that could keep checks on people's movement, potential crime incidents, and general security of the residents. Social media intelligence platforms can provide aid to public safety by gathering information from social media  and predicting potential activities that could  disrupt  public  peace.  In  the  city  of  Surat,  the  crime  rate  has  declined  by  27%  after  the implementation of AI powered safety systems.\n- f) Cyber -attacks: Cyber-attacks seem to pose a great threat to our institutions and public systems, today. AI technologies possess the capability to detect vulnerabilities and take remedial measures to minimise exposure of secure online platforms containing highly sensitive data from being targeted by unscrupulous social elements.\n\n## Smart Mobility and Transportation\n\nMobility and transportation form the backbone of the modern economy due to their linkages with other sectors  and  importance  in  both  domestic  and  international  trades.  Today's  society  demands  a  high degree of mobility of various kinds, so as to enable efficient and safe transportation of both people and goods.  As  a  major  contributor  to  overall  emissions,  this  sector  must  also  be  sensitive  to  ideas  of environmental sustainability.\n\nIn India, majority of both passenger and freight traffic is carried through roads and railways. As of 2007 08, roads and railways accounted for almost 87% of total freight traffic in the country and almost 90% of total traffic as of 2011-12 25 . As the economy grows, it is expected that this reliance on these modes of transport shall continue unless there are major shifts in the policy initiatives in the area. The fact that these  modes of  transport  are  particularly  pollution  intensive  compared  to  shipping  and  air  transport, further increase the need to implement smart practices in their deployment.\n\nEven apart from issues in poor modal mix, the Indian transportation sector faces a variety of issues.\n\n- a) Congestion and road accidents: Despite having one of the most extensive transportation networks in the  world,  various  sub-sectors  sector  continues  to  be  underdeveloped  leading  to  economic inefficiency and enormous human cost. Congestion and its associated costs in India are continually on the rise. Statistics from Government of India and a study conducted by IIT Madras suggest the following growth patterns over the years, respectively.\n\nFigure 15: Total registered motor vehicles per 1,000 population\n\nFigure 16: Projected cost of congestion (USD million / year)\n\n- b) High number of traffic deaths: According to a PIB release by the Ministry of Road Transport and Highways (MORTH) in March 2017, the total number of road accidents in the country during 2015 was 501,423 which resulted to 146,133 fatalities. The National Highways (NHs) accounted for about 29.1% share of total road accidents and 35.0% of total fatalities. Although the existing NHs comprise approximately 1.9 % of total road network, they carry about 40% of total road traffic. According to MORTH statistics, there has been a steady increase in the number of on-road accidents over the years.\n- c) Lack  of  public  transportation  infrastructure: Public  transport  infrastructure  development  remains laggard in the overall discourse of transport policy design, either at national and regional levels, with focus  directed  towards  promoting  and  improving  private  car  and  associated  infrastructure.  The following statistics from MORTH indicates the modal share of public transport (buses) over the years which has seen, but minimal increase over the years.\n\nSource:\n\nMORTH\n\nFigure 17: Total numbers of public buses per 1,000 population\n\n- d) Assisted vehicle technologies : Autonomy is not economically viable in India currently as driver costs per kilometre is too low. However, investing in the suite of autonomous vehicle technologies and exporting such vehicles represents a significant economic opportunity for India and since the same technologies can play a large role in reducing fatalities and decreasing congestion, it would be wise for Indian manufactures to invest in research and development of the broader suite of technologies that are essential for assistive AI. These technologies can assist the driver by taking driving decisions which the system has a high degree of confidence in and alerting the driver in case it has a low degree  of  confidence  in  any  decision.  A  prime  example  of  such  productised,  assistive  AI  is  the advanced cruise control used in Tesla vehicles today. This can follow highway traffic and the curves in the road as well as start and stop in response to traffic. However, the moment the driver gives any input, the system is taken over by the driver. This hybrid approach is much safer than an unassisted human driving, without the potential drawbacks of having a completely autonomous system. There is another reason why India should not completely ignore assistive vehicle technology research, and it has to do with the development of new public infrastructure. Since we have only recently begun building a large share of the total requirement of greenfield infrastructure, we have the benefit of hindsight.\n- e) Need for sustainable transportation : The recent initiative of the Government of India for announcing development of 100 Smart Cities is aimed at addressing this anomaly and catalyse smart strategies for urban planning which promote sustainable land use design and multimodal integration. While new initiatives could take time to show realisable impact, the existing issues in urban mobility related to congestion, efficient traffic flow, movement of goods etc. can indeed be solved using AI technology. AI  can  power  multimodal  integration  by  assisting  with  scheduling  public  transportation  systems, improved accessibility to public transportation infrastructure based on users' choice behaviours, while also  suggesting  real-time  travel  mode  advisory  based  on  predicted  traffic  situation.  AI  enabled mobility solutions can ameliorate several of the challenges being faced by the Indian automotive and transportation sector.\n- f) Efficiencies  in  design  of  greenfield  infrastructure -  Autonomous-ready  traffic  will  have  significant impacts on greenfield road infrastructure design and consequently on greenfield city design. Lane size, lesser traffic congestion and reduced costs in upgradation of highway infrastructure are some of the externalities which will benefit the sector of assisted vehicle adoption.\n\nListed below are some of the major applications of AI on the mobility front beyond autonomous cars:\n\n- a) Autonomous trucking: Autonomous technology in trucking has the potential to transform the way we move goods today. AI can help increase safety and hauling efficiency through intelligent platooning, wherein trucks form platoons giving drivers the liberty to rest while the platoon keeps moving. Such a method also ensures optimal road-space utilisation, helping improve road infrastructure capacity.\n- b) Intelligent  Transportation  Systems: Through  the  use  of  an  intelligent  traffic  management  system including sensors, CCTV cameras, automatic number plate recognition cameras, speed detection cameras, signalised pedestrian crossings and stop line violation detection systems and the use of AI, real time dynamic decisions on traffic flows such as lane monitoring, access to exits, toll pricing, allocating right of way to public transport vehicles, enforcing traffic regulations through smart ticketing etc. can be made. Accident heat maps could be generated using accident data and driver behaviour at specific locations on the road network related to topology, road geometric design, speed limit etc. and suitable measures could be pre-emptively taken to prevent possible accidents. Also, AI could help to design sophisticated urban traffic control systems that can optimise signal timings at the intersection,  zonal  and  network  level,  while  also  facilitating  services  such  as  automatic  vehicle detection for extension of red/green phase or providing intermittent priority.\n- c) Travel route/flow optimisation: With access to traffic data at the network level, AI can help make smart predictions for public transport journeys by optimising total journey time including access time, waiting time  and  travel  time.  Considering  factors  such  as  accessibility  to  nearest  mode  of  travel,  most convenient access path based on local conditions and one's preferences, AI can revolutionise firstlast  mile  travel  which  could  change the  way  we  perceive public  transport journeys, today.  About private car usage, AI could utilise a range of traffic data sets and one's own preferences to make human-like decisions on route selection. With information on dynamic tolls and traffic flows on links, the  dependency on overhead Variable Messaging Systems (VMS) could be minimised, reducing substantial infrastructure costs. On the systemic level, AI can help predict flow of traffic at the network level and suggest alternative flow strategies in order to contain congestion, alleviating cities of this major issue.\n- d) AI for Railways: According to official figures, more than 500 train accidents occurred between 20122017, 53% of them due to derailment. Train operators can obtain situational intelligence through realtime operational data and analyse them in three different dimensions: spatial, temporal and nodal. Fleet management and asset maintenance including that of rolling stock are pertinent AI use cases. Recently, the Ministry of Railways, Govt. of India has decided to use AI to undertake remote condition monitoring using non-intrusive sensors for monitoring signals, track circuits, axle counters and their sub-systems of interlocking, power supply systems including the voltage and current levels, relays, timers.\n- e) Community Based Parking: The availability of parking is a major issue for Indian cities. AI can help optimise parking, likely by minimising vehicle downtime and maximising driving time. With the advent of electric vehicles, AI will be needed to mediate the complex vehicle grid interactions(VGI) as well as for charging optimisation. Parking guidance systems help drivers to find vacant parking spaces while they are using the road network and have approached close to their destination. Community\n\nbased parking using AI helps cars in traffic to collect data on vacant parking spaces, and allocates cars to spaces such that the demand is always met.\n\n## Box 12: Effect on R&amp;D\n\nGlobally, research on autonomous vehicle has spurred advances, especially in AI fields of computer vision and robotics. Due to the extremely high market potential, over the past two years, most of the large investments in AI have been made in the field of autonomous vehicle as it is widely tipped to be the first large scale commercial application of AI to be adopted.\n\nMoreover, due to the congestion and chaotic conditions of Indian traffic, AI algorithms trained on Indian driving data have the potential to be very robust.\n\nError rates of object classification have fallen from 28.5% to 2.5% since 2010 according to the Stanford AI index. Therefore, current techniques are mature enough to be used in Indian conditions. Also, within AI,  the  core  technologies  used have high transference potential. The same template used to identify objects on a road can be used to identify cancerous cells in a pathological image.\n\n## Key challenges to adoption of AI in India\n\nCommonality of problems mandate an integrated approach\n\nThe  preceding  analysis  of  focus  sectors  -  Healthcare,  Agriculture,  Education,  Smart  Cities  and Infrastructure, and Smart Mobility and Transport, highlight the potential of AI tools and technologies in transforming the sectors and state of Indian economy as a whole. The analysis, however, also detail a multitude of challenges that India needs to overcome to realise the full potential of a disruptive technology like AI.\n\nAdopting a narrow view and focusing on the challenges for a specific sector, the barriers to developing a robust set of AI applications may seem contextual and limited to that sector. Taking Healthcare sector as an example, enabling large scale adoption would require at least the following factors to be addressed:\n\n- a) absence of collaborative effort between various stakeholders: while India has adopted electronic health record (EHR) policy, sharing of data between various hospital chains still remains a work in  progress, since different hospital chains have adopted different interpretations of 'digitising records';\n- b) relevant data is unavailable and there is absence of robust open clinical data sets; and\n- c) concerns  on  privacy and  security of data, including lack of formal regulation  around anonymisation of data.\n\nHowever, analysing across the focus sectors, the challenges are concentrated across common themes of:\n\n- a) Lack of enabling data ecosystems\n- b) Low intensity of AI research\n- i. Core research in fundamental technologies\n- ii. Transforming core research into market applications\n- c) Inadequate availability of AI expertise, manpower and skilling opportunities\n- d) High resource cost and low awareness for adopting AI in business processes\n- e) Unclear privacy, security and ethical regulations\n- f) Unattractive Intellectual Property regime to incentivise research and adoption of AI\n\nThese  challenges,  while  by  no  means  exhaustive,  if  addressed  in  an  expeditious  manner  through concerted collaborative efforts by relevant stakeholders, with government playing a leading role, could lead to fundamental building blocks that form the core to India's march towards leadership in AI. The next section  of  the  paper  attempts  to  solve  some  of  these  challenge  through  specific  interventions  and recommendations. These recommendations have been formulated as fundamentally infrastructural in nature, and hence span across sectoral use cases.\n\n## Way Forward to Harness the Power of AI\n\n## Recommendations\n\nIndia's unique challenges and aspirations, combined with the advancement in AI, and a desire to assume leadership in this nascent technology means India's approach towards AI strategy has to be balanced for both local needs and greater good. The way forward for India in AI has to factor in our current strengths in AI, or a lack thereof, and thus requires large scale transformational interventions, primarily led by the government, with private sector providing able support.\n\nThis section lays down a set of recommendation to address the biggest challenges and opportunities for India in the field of AI. The preceding analysis of focus sectors lead us to the assertion that the efforts need to be concentrated across major themes of research, data democratisation, accelerating adoption and  reskilling  -  with  privacy,  security,  ethics  and  intellectual  property  rights  permeating  as  common denominators for all our recommended initiatives. These challenges, while by no means exhaustive, if addressed in an expeditious manner through concerted collaborative efforts by relevant stakeholders, with government playing a catalytic role, could lead to fundamental building blocks that can form the core to India's march towards achieving its goal of #AIforAll.\n\nIndia's capabilities in AI research are rather limited, both in quantity (distant 5 th  globally) and especially in quality (disappointing impact of research produced). The research community is rather confined to a handful of academic institutes, and relies on individual brilliance rather than institutional competence. Acerbating the problem is the fact that private sector's contribution to AI research has remained meagre. Despite some encouraging recent developments, viz. Government of Karnataka's intention to set up a Centre of Excellence in AI in partnership with NASSCOM, a lot of ground needs to be covered. The first set  of  recommendations  focus  on  turbocharging  both  core  and  applied  research.  In  addition,  two frameworks for solving some of AI's biggest research challenges through collaborative, market oriented approach have been proposed.\n\nThe new age of AI and related frontier technologies would disrupt the nature of jobs of tomorrow and the skills  required  to  realise  the  true  potential  of  these  transformative  technologies.  The  changes  and challenges anticipated for the workforce will come from both the demand and supply side: demand for capabilities for jobs that don't even exist today and diminished demand for some of the jobs that could be automated, supply of newly minted STEM graduates, a large portion of whom may struggle to be gainfully employed. Given our strength in advanced IT sector and the strength of favorable demographics, India may seem more equipped for workforce disruption that AI will bring, however our large numbers may soon turn from potential assets to liabilities if right structures are not put in place. Our next set of recommendations focus on reskilling of existing workforce and preparing students for developing applied set of skills for the changing world of technology.\n\nEarly  adoption  of  AI  -  be  it  the  research  community  building  technology  infrastructure,  the  startup community developing applications and corporations deploying solutions for their business needs, would be one of the key determinants in ensuring leadership in AI. Adoption of AI in India has remained rather limited, less than a quarter of firms in India are using AI in any form for their business processes and startup ecosystem in AI is virtually non-existent. Among the several impediments towards large scale\n\nadoption of AI in India, the primary ones include difficulty in access to data (more specifically, structured and  intelligent  data),  high  cost  and  low  availability  of  computing  infrastructure,  lack  of  collaborative approach  to  solving  for  AI  combined  with  low  awareness.  Our  recommendations  to  address  these challenges include developing large foundational annotated data sets to democratise data and multistakeholder marketplaces across the AI value chain (data, annotated data and AI models).\n\nOne of the key aspects of our ambition of #AIforAll includes responsible AI: ensuring adequate privacy, security and IP related concerns and balancing ethical considerations with need for innovation. Our final set of recommendations lay down the challenges and suggestion for addressing some of these not so straightforward implementational challenges of AI.\n\nThe recommendations in the following chapters are aimed at initiating an informed conversation on India's future roadmap for AI, and are descriptive rather than prescriptive by design. The paper should be seen as providing framework for developing National Strategy for Artificial Intelligence, and as such, we have consciously avoided providing specific funding targets and funding mechanisms, as these require broad based stakeholder consultations.\n\n## Research\n\n## Incentivising Core and Applied research in AI\n\nAdvanced research, both core and applied, provides the basis for commercialisation and utilisation of any emerging technology, more so for technologies like AI.\n\n## Where does India stand in Artificial Intelligence research?\n\nIndia has the necessary building blocks to develop a thriving AI research and development ecosystem, viz. availability of highly educated talent pool, world class educational institutes and an illustrious list of top notch IT companies dominating the global IT landscape. Despite these advantages India sees itself lagging considerably in producing world-class research and innovation in most technology fields, more so in AI.\n\nIndia produced a whopping 2.6 million 26 STEM graduates in 2016, second only to China and more than 4 times the graduates produced by USA, thus producing the requisite talent pool to drive innovation in emerging technologies. Disappointingly though, an overwhelming majority of this talent pool is focused on  routine  IT  development  and  not  so  much  on  research  and  innovation.  Exacerbating  the  problem further, a majority of the small population focused on research almost always prefers to pursue advance degrees (Masters or PhD degrees) to subsequently apply their expertise abroad.\n\nAn analysis of India's competence in core research in AI paints a somber picture. As per the Global AI Talent Report 2018, which crawled LinkedIn for its analysis, India only has 386 of a total of 22,000 PhDeducated  researchers  worldwide,  and  is  ranked  10 th   globally.  The  report  also  looks  at  leading  AI conferences globally for presenters who could be considered influential experts in their respective field of AI. On this metric, India was ranked 13 th  globally, with just 44 top-notch presenters. While these two approaches have their limitations and inherent biases, anecdotal evidence based on discussions with top researchers  reveals  that  serious  research  work  in  India  is  limited  to  less  than  50  researchers, concentrated mostly at institutes like IITs, IIITs and IISc.\n\nIn terms of the citable documents published in the field of AI from 2010 - 2016, India ranks a distant 5 th , far behind the likes of China and USA and just about edging ahead of Germany and France who have considerably smaller STEM population.\n\n26 World Economic Forum\n\nSource: Scimago Journal and Country Rank (SJR)\n\nSource: Scimago Journal and Country Rank (SJR)\n\nFigure 18: Citable documents in Artificial Intelligence (2010 - 2016)\n\nDiving deeper into these numbers, if we look at the country wise H-Index (a metric that quantifies a country's scientific productivity and scientific impact), India ranks a dismal 19 th  globally. In other words, while India may be producing research pieces in numbers, their utility has been rather limited.\n\nFigure 19: H Index for Artificial Intelligence (1996 - 2016)\n\nLooking at the research coming out of academic institutes, the numbers are heavily skewed in favour of top-15 institutes, that in total have contributed more than 42% of all research publications from 2001 2016 27 . IISc dominates the research publications, with 7.5% of all publications coming from this institute. For a country that has more than 750 universities and close to 40,000 colleges, this concentration of publication is a worrying sign.\n\nThe Indian IT services companies, the likes of TCS, Wipro and Infosys, have been the flag bearers of India's  competence  in  implementation  of  cutting  edge  technology  solutions,  yet  their  contribution  to research has been limited. Given that these IT giants have been working closely with businesses globally and anticipating the trends in emerging technologies, it wouldn't be unreasonable to expect a sizeable volume of research work coming out of these companies. Yet, looking at all the research publications from 2001 - 2016, only 14% of all publications have come from industry, with universities contributing 86% of all publications. Even this limited research publication universe by industry is dominated by Indian subsidiaries of international companies (~70%), with only one Indian company in top-10 (TCS) 28 .\n\n27 Neel Shah: 'Research trends of AI in India'\n\n28 Neel Shah: 'Research trends of AI in India'\n\n## Box 13: What India can learn from other economies in terms of AI Research\n\nThe US Government is estimated to have spent USD1.2 billion in non-classified research in 2016-18 and the Defence Advanced Research Projects Agency (DARPA) is seeking a budget of USD3.44 billion in fiscal  year  2019-20, an  increase of 8.5% compared with its request for fiscal 2018-19. However, US leadership in AI investment has largely been driven by the private sector. The world's leading companies in AI research in 2016 were Microsoft, Google and IBM, all US companies. According to CB Insights, based on 2017 figures, Amazon, Google and Microsoft dominate enterprise AI - again all US companies. It is estimated that more than half the world's unicorns are from the US. The digital ecosystems around the  hubs  of  Silicon  Valley,  Seattle,  Boston  and  New  York,  which  bring  together  talent  and  research capabilities from leading universities, private investment and cross-science / industry collaboration, can be considered to have played an important role in developing the US's AI capabilities.\n\nWhile still behind the US in terms of overall investment, China has clear ambitions to be at the same level as the US by 2020 and the world leader in AI by 2030, supported by a new development plan to create a USD150 billion domestic AI industry. Its plans to build a new AI industry include a national fund that supports  research,  from  the  most  basic  research  to  critical  AI  projects.  The  top  9  universities  have received  government  funding  to  each  establish  an  AI  school  and  the  remaining  32  to  include  an  AI programme as part of their curriculum. The Ministry of Industry and Information Technology is planning to put nearly USD950 million dollars per year into strategic AI projects for State Owned Enterprises and the public sector. In addition to state investment, the government is expected (at the time of writing) to publish Next Generation AI Development Guidelines immanently. The guidelines are expected to include a  clear  governance  structure,  with  allocation  of  responsibility  and  plans  for  research,  industry  and legislative action or each of 2020, 2025 and 2030.\n\nWhile  China's  approach  is  not  necessarily  replicable  in  other  parts  of  the  world,  there  are  two  key learnings from its programme:\n\n- \u00b7 Public sector investment, particularly in R&amp;D, helps drive private investment.\n- \u00b7 It has a plan with a governance structure and clear milestones. Having a plan instils confidence in inward investors. Based on interviews Accenture carried out with inward investors in the UK, there was consensus that the governments' public messaging had a significant impact on companies' confidence and therefore willingness to invest in a country.\n\nIn the UK, the universities of Cambridge and Oxford are considered centres of AI innovation; having already stimulated three startups that made major AI breakthroughs and later became prime acquisition targets.  Google  in  2014  bought  DeepMind,  Apple  in  2015  purchased  VocalIQ,  and  Microsoft  bought SwiftKey in 2016. This success is supported by funding from organisations like the Leverhulme Trust, which provides annual funding of GBP80 million for research. Other capabilities include The Alan Turing Institute: the national institute for data science. The Institute was established in 2015 by five founding universities (Cambridge, Edinburgh, Oxford, UCL and Warwick) and the UK Engineering and Physical Sciences Research Council. The Institute's researchers work across disciplines and look at theoretical development and application to real world problems. It was announced as the national centre for AI in November 2017 and six new universities will join the institute 2018.\n\nThe  German  Research  Centre  for  Artificial  Intelligence  (DFKI  -  Deutsches  Forschungszentrum  f\u00fcr K\u00fcnstliche Intelligenz) is one of the world's largest AI research institutes. It has facilities in the German cities of Kaiserslautern, Saarbr\u00fccken, Bremen and Berlin and is partnering with companies on application oriented basic research to develop product functions, prototypes and patentable solutions.\n\nThe EU's Robotics Public Private Partnership, launched in 2013, has seen the allocation of EUR700 million for research to 2020. This is coupled with private investment for an overall backing of EUR2.8 billion.\n\nIt  is  believed  to  be  the  biggest  civilian  research  programme  in  this  area  in  the  world  and  could  be considered instrumental in the strong presence of Europe among service robot manufacturers. Clearly, public-sector investment has paid-off.\n\nSource : Realising the economic and societal potential of responsible AI, Accenture\n\nThe research ecosystem in India has seen some green shoots in recent years. Encouraging is the fact that the number of papers published has jumped 10 fold in last 10 years, from 331 papers in 2006 to 3,301 papers in 2016 29 . IISc, almost all the IITs, some of the IIITs and central / state universities have increased their research efforts in various foundational and applied fields of AI. IIT Bombay and IIT Patna have entered into a joint research collaboration with industry to focus on the applied aspects of AI. The research,  focused  on  IT  services  and  social  good,  will  aim  to  provide  powerful  AI  insights  and recommendations  for  improved  productivity.  It  also  includes  software  analytics  -  building,  testing, managing and modernisation of applications, solving real-life social issues such as malnutrition, human trafficking and climate change through prediction and recommendation models using AI.\n\nAnother research group at IISc is working on the theory and application of reinforcement learning (RL), an aspect of machine learning used in optimisation problems. They are particularly interested in traffic handling-both the vehicular kind on our roads, as well as the digital kind in our wireless networks.\n\nFurthermore, there have been some encouraging efforts from both government and private sector in facilitating  top  quality  research  in  recent  times.  Government  of  Karnataka  is  setting  up  a  Centre  of Excellence  for  Data  Science  and  Artificial  Intelligence  in  partnership  with  NASSCOM.  Wadhwani Foundation has set up India's first research institute dedicated to developing AI solutions for social good in Mumbai in Feb 2018.\n\nHowever,  the  research  ecosystem  still  has  several  obvious  gaps.  The  Detailed  Project  Report  of Inter-Ministerial National Mission on Interdisciplinary Cyber Physical Systems has highlighted some of these as:\n\n- a) Lack of collaborative / interdisciplinary approach: research is mostly focused in silos in academic institutions\n- b) Lack of scale for experimental validation: due to various practical and financial reasons, university research is largely restricted to theoretical or laboratory scale. This needs to be augmented with pilot projects / large scale test beds / laboratories\n- c) Lack of facilities to support large scale experimental test beds: Large scale experimental test-beds are difficult to construct, maintain and operate, solely by academic institutions\n- d) Lack of connect with stakeholders and practitioners to convert outputs to outcomes: The views of the stakeholders in terms of what application problems to focus on will be of great importance to ensure practical applicability of the research. At the same time, this should be facilitated in a way which does not constraint/suffocate the academic researchers in order for them to make foundational advances. Involving 'technology translators' at an early stage, i.e. entrepreneurs/agencies/companies which can convert the research technologies to commercial products is needed.\n\n29 Scimago Journal and Country Rank (SJR)\n\n- e) Lack of large scale mission mode project management capabilities: Academic researchers usually work best individually (with a small team of students and research project staff). Current approaches to research and related facilities may not be suited for large scale experimental projects.\n\nWhile  the  numbers  point  to  a  small  yet  encouraging  base,  a  concerted  effort  is  needed  to  build  a comprehensive  research  focused  AI  strategy  for  India,  one  that  will  position  India  towards  global leadership in this emerging area of technology. What is evident though is that incremental changes would not suffice and there is need for transformational changes to boost research major push coming from the government.\n\n## Framework for promoting Artificial Intelligence Research in India\n\nThe  Detailed  Project  Report  of  Inter-Ministerial  National  Mission  on  Interdisciplinary  Cyber  Physical Systems (IM-ICPS) has suggested the following four-tier framework for promoting research focused on all aspects of technology life-cycle: research, technology deployment, translation and management:\n\n- a) ICON (International Centres of New Knowledge): focusing on creation of new knowledge through basic research,\n- b) CROSS  (Centre  for  Research  On  Sub-Systems): focusing  on  developing  and  integrating  core technologies developed at ICON layer and any other sources\n- c) CASTLE  (Center  for  Advanced  Studies,  Translational  research  and  Leadership): focusing  on development and deployment of application based research and\n- d) CETIT (Centre of Excellence in Technology Innovation and Transfer): focusing on commercialisation of technologies developed\n\nWhile the above structure has significant advantages, a far more simplified and agile approach is required to ensure seamless, targeted and accountable framework for promoting research. Hence the following two-tier integrated approach to boost both core and applied research in AI is proposed:\n\n- a) COREs (Centres of Research Excellence in Artificial Intelligence): COREs will focus on core research of AI, and will take on the mantle of executing the responsibilities of both ICON and CROSS as per the  IM-ICPS  framework.  Thus,  COREs  will  specialise  in  creating  new  knowledge  through  basic research and will source for fundamental knowledge / technologies that will be needed to keep India prepared  for  the  next  generation  of  technologies.  Furthermore,  COREs  will  also  emphasise  on development infrastructure tools for direct application of basic research, including development of new areas of AI architecture / platforms.\n- b) ICTAI (International Centre for Transformational Artificial Intelligence): ICTAIs will provide the ecosystem for application based technology development and deployment, and will take on the mantle of executing the responsibilities of both CASTLE and CETIT as per the IM-ICPS framework. This will be  an  industry-led  initiative  and  expected  to  take  on  the  top-level  challenges  identified  or  interministerial projects calling for AI based solutions. Furthermore, ICTAIs will also be responsible for delivering commercial technology, and taking ideas / concepts or prototypes and turning them into marketable products by way of proactive coordination, communication and interfacing for technology transfer to the industry.\n\n## Figure 20: Proposed integration of COREs and ICTAIs\n\nIn summary, COREs will be focused on core research, in evolving and new areas of AI, and will act as the  technology  feeders  for  ICTAIs  which  will  be  focused  on  creating  AI  based  applications  for,  and accelerating early adoption in, domains of societal importance.\n\nIn  addition,  an  umbrella  organisation  should  be  established  to  address  issues  relating  to  access  to finance, social sustainability and the global competitiveness of the technologies developed. This body, which shall be recognised as the Centre for Studies on Technological Sustainability (CSTS), could be established  on  the  lines  of  the  Campus  for  Research  Excellence  and  Technological  Enterprise (CREATE), Singapore program or Innovate UK. The major responsibilities of CSTS could be on the following lines:\n\n- a) to monitor the impact of the AI technologies developed at the consumer level through social indices and recommend necessary modifications for a better market penetration\n- b) to  study  the  financial  viability  of  the  AI  technologies  developed  such  that  it  caters  to  the  target consumer base, while proposing improved pricing models for a pan India reach\n- c) to study best practices on pricing models and social penetration of AI technologies across the world and recommend strategies to foster globally competitive technological development\n- d) to catalyse international collaborations for COREs and ICTAIs\n- e) to study the AI landscape in other nations and design strategies for customisation and deployment of developed AI technologies as per their specifications for a global impact\n- f) to  provide  a  knowledge  management  platform  for  AI  technologies  by  organising  international workshops  and  conferences,  promoting  the  confluence  of  thought  leaders,  practitioners  and authorities\n\n## Centres of Excellence for Artificial Intelligence\n\nCOREs for AI will focus on core research, in evolving and new areas of AI.\n\nTo start with, COREs could be established at IISc, ISI and top IITs and IIITs. Given that the research in AI  needs  to  be  multi-disciplinary,  linkages  need  to  be  established  with  premier  institutions  in  other disciplines viz. AIIMS for healthcare, TISS for arts and social science etc. Furthermore, these COREs should also act as a guide and mentor for other institutes researching in AI, in a hub-and-spoke model, to enable broad based development of AI research capabilities across India.\n\nThe COREs would have to build on both the short-term and the long-term capabilities of these research centers. In the short-term, given the paucity of quality faculty in India in AI, appropriate incentivisation mechanism  (which  could  be  a  combination  of  promise  of  topnotch  infrastructural  facilities  and remunerations  matching  international  standards)  to  bring  top-tier  international  faculty,  especially  the Indian diaspora, needs to be developed. Furthermore, the top Indian PhD aspirants, who would otherwise pursue  their  studies  from  top  universities  abroad,  will  need  to  be  retained  in  India,  again  through appropriate incentivisation mechanism. One possible way could be to institute National AI Fellowships.\n\nIn the long-term, successive PhD classes of these COREs can increase the faculty pool and work towards a sustainable operational model for COREs.\n\nPossible focus area for the COREs for AI could be:\n\n- a) Sensory AI (Computer Vision, IoT etc.),\n- b) Physical AI (Robotics, Industrial Automation etc.),\n- c) Cognitive AI (NLP, worker training etc.),\n- d) General AI,\n- e) High precision learning from small data sets,\n- f) Research on new algorithms (e.g. advance cryptography, security), data sets etc., and\n- g) Explainable AI\n\nAn application based model may be followed to selected COREs wherein an applicant institute would have to demonstrate a viability plan, in terms of faculty and other capabilities, before being anointed an CORE. A CORE can choose to work on one or multiple focus areas. The COREs will be encouraged to pursue  projects  across  other  COREs,  to  promote  linkages  and  cross-functional  technologies.  The financial component of COREs for AI, which could be to the tune of INR 50 crore - INR 100 crore per CORE, should also include large scale funding for specific projects.\n\n## International Centers for Transformational Artificial Intelligence\n\nInternational Centers for Transformational Artificial Intelligence (ICTAIs) are envisioned as institutions focused on creating AI based applications for, and accelerating early adoptions in, domains for societal importance. These applied research and development institutions should be set up with the elements of domain or industry 'pull' baked into their structure and operation. While core (or fundamental AI) research and teaching may not be seen as their priority areas, some flexibility might be built in the structure.\n\nFrom both funding and operational perspective, the ICTAIs are envisioned to be a truly public private partnership. A professionally managed society / section 8 company ('ICTAI Inc.') should be set up and trusted with the initial contribution from the government. The management team for ICTAI Inc. should comprise of suitable representation from the government, but should have a majority of independent private sector representation. The mandate for ICTAI Inc. would be to select the ICTAIs to fund and oversee their progress. In addition, ICTAIs may commission ' moonshot projects ' that may span across multiple ICTAIs or may need limited term independent project teams to be set up.\n\nICTAIs are expected to leverage the strength of AI technologies to solve for application in a specific focus sector areas. Suggested focus sector areas to begin with, as identified in this report, are Healthcare,\n\nAgriculture, Education, Smart Mobility and Transportation, Smart Cities and Infrastructure. ICTAI Inc. however should have the autonomy to decide on sectors to focus on and sequencing of sector selection. ICTAI Inc. should work proactively with private sector institutions to seek partnerships to set up the ICTAIs in priority domains.\n\nFurthermore, ICTAIs should have well-defined linkages with the COREs. As a technology  feeder for ICTAIs, COREs should be incentivised to commercialise their research at ICTAIs.\n\nThe key to success for the ICTAIs would be their leadership teams. The decision on which ICTAIs to invest  in  could  involve  believing  in  capability  and  the  vision  of  the  proposed  CEO  and  rest  of  the management team who have applied for ICTAI funding. Alternatively, ICTAI Inc. may also search and select a CEO and entrust her with running a particular ICTAI.\n\nThe initial funding for a ICTAI would constitute the seed funding (in the range of INR 200 crore - INR 500 crore per ICTAI) for first 5 years to cover the major operational expenses of the ICTAI, in addition to the physical  infrastructure  and  technology  /  computing  infrastructure.  The  seed  funding  should  be  a combination of funding from the government and private participation, preferably in equity/grant sharing mechanism. Corporates should be free to take a predetermined amount of ownership. One corporate should be partnered with for each ICTAI based on a ' challenge method '. The incentive for corporates to participate would arise from the following points that the government should endeavour to ensure:\n\n- a) Access to high quality training data\n- b) Computational and physical infrastructure\n- c) A  chance  for  staff  at  corporates  to  be  part  of  a  national  mission  and  work  on  challenging problems with a higher gestation period than traditional commercial problems\n- d) Ability to count expenditure incurred towards CSR\n- e) Boost  in  visibility  received  by  working  on  AI  for  social  good  directly  with  top  government institutions\n\nThe ICTAIs should raise additional funding  beyond this base funding,  through  philanthropic / private contributions,  preferably  in  equity  sharing  mechanism  as  well.  ICTAI  Inc.  may  also  award  further contributions to ICTAIs based on measures of success.\n\nEach ICTAI should have a Governance Board, comprising of industry leaders, academic luminaries and global  thought  leaders.  The  CEO  and  /  or  the  industry  partner  (if  one  is  there)  may  suggest  the Governance Board, which may be vetted and agreed by ICTAI Inc. An industry partner with sizeable contribution may have a reasonable say in selection of the Governance Board. The responsibilities of Governance  Board  will  be  akin  to  a  Board  of  Directors  /  Board  of  Governors  of  any  suitably  large successful corporation i.e. provide overall guidance and direction, and oversee the output for the ICTAI. While ICTAI Inc. may lay down the success criteria for ICTAIs in general, specific targets for each ICTAI should be decided between the Governance Board and leadership team of individual ICTAIs.\n\nThe ICTAIs should ideally be located close to top engineering institutes / close to large cities, so that attracting the best talent from across the world is plausible. ICTAIs should also seek to leverage the availability  of  students  /  research  scholars  from  the  engineering  institutes  close  to  them  for  specific projects etc. (through internships etc.) to build the talent pool for future. ICTAIs should aim to involve the successful  AI  researchers  /  practitioners  of  Indian  origin  from  across  the  world  in  either  full  time  or advisory capacity. If finances are a constraint for ICTAIs to attract the best talent, ICTAI Inc. may consider National AI Fellowships for the benefit of ICTAIs.\n\nPRAIRIE Institute, recently established by the French government in collaboration with academia and industry, is a good potential implementational model for CTAIs.\n\n## Box 14: The PRAIRIE Institute\n\nThe PRAIRIE Institute (PaRis Artificial Intelligence Research Institute) is a collaboration of industry and academia supported by the French government to create an institution which becomes an international benchmark in AI.\n\nThe  partners  (CNRS,  Inria  and  PSL  University,  together  with  Amazon,  Criteo,  Facebook,  Faurecia, Google, Microsoft, NAVER LABS, Nokia Bell Labs, PSA Group, SUEZ and Valeo) in PRAIRIE institute are pursuing three goals:\n\n- \u00b7 to  drive  progress  in  fundamental  knowledge  creation  in  AI  (AI)  freely  distributed  among  the international scientific community;\n- \u00b7 to take part in solving concrete problems with a major application-related impact;\n- \u00b7 to contribute to training in the field of AI.\n\nThe five-year objective is to bring together AI scientific and industrial leaders and make the PRAIRIE Institute a world leader in AI.\n\nThe aim of the PRAIRIE Institute is to act as a catalyst for exchanges between the academic and industrial worlds, to train new generations of researchers in AI and to play a role in leading and coordinating the community. Transfer and innovation will be among its duties, along with scientific progress. The work done will highlight an integrated approach to the two traditional branches of research:\n\n- \u00b7 upstream research, calling on partner facilities of excellence in France and abroad;\n- \u00b7 research focusing on companies and applications, drawing on industrial partners, who are often also world leaders in their fields.\n\nIntegration between research topics will facilitate synergy between the two branches of the PRAIRIE Institute and will enable researchers to make the transition easily from one to the other.\n\nAt an international level, the PRAIRIE Institute will draw on a network of partnerships with centres of AI excellence to promote exchanges and leverage impact. Collaborative agreements have already been signed with the Center for Data Science at NYU, the AI laboratory of UC Berkeley (BAIR), the Robotics institute at  Carnegie-Mellon  University  in  Pittsburgh, MILA in  Montr\u00e9al,  the Max  Planck  institute in T\u00fcbingen, the CIIRC (Czech Institute of Informatics, Robotics and Cybernetics) and the Turing Institute in London.\n\n## Common Compute Platform for CoEs / CTAIs\n\nFor COREs and ICTAIs to discharge their duties effectively, pooled cloud infrastructure for AI applications should be made available. All the COREs and ICTAIs should be connected to the National Knowledge Network (NKN) and from there via a very high-speed link to a pooled cloud computing environment. This approach will reduce infrastructural requirements due to pooling efficiencies and reduce operational and maintenance costs while keeping national data secure (Box 15: AIRAWAT)\n\n## Box 15: AIRAWAT (AI Research, Analytics and knoWledge Assimilation plaTform)\n\n## Scope\n\nAIRAWAT will be a cloud platform for Big Data Analytics and Assimilation, with a large, power-optimised AI Computing infrastructure using advanced AI processing. The proposed Infrastructure will be equipped with  facilities  for  world's  leading  machine  learning  including  deep  learning,  high  performance  high throughput  supercomputing,  infrastructure  to  store,  process,  simulate  and  analyse  big  data  sets  like images, video, text, sound, speech. AIRAWAT will support advancement of AI-based developments in image  recognition,  speech  recognition,  natural  language  processing  for  research,  development  and creation of varieties of new applications for the support of advancements in the fields of Agriculture &amp; Healthcare.\n\n## Infrastructure Requirements\n\n- 1. AI Infrastructure: High throughput processing supercomputing systems to train the machines learn the  data  sets  using  AI  deep  learning.  We  propose  to  set  up  a  100-AI  petaflop  computing Infrastructure, like the one as JAPAN's ABCI AI Supercomputing facility.\n- 2. Multi-tenant multi-user computing support through resource partitioning and provisioning, dynamic computing environment deployment, etc.\n- 3. Energy-saving, high Teraflops per Watt per U rack space designed computing systems with low TCO\n- 4. Deep Learning Software stack - Training and Inferencing development kit, frameworks, libraries, cloud management software and portal for data labelling, data analytics, data transfer &amp; data model exchanges\n- 5. Low latency High bandwidth network\n- 6. Mass Storage System to collect, store and share multi-petabytes of big data\n\n## Utilisation\n\nBig data Labelling, Annotating, Anonymisation, Analytics, Skills development, job creation, support R&amp;D, Academia,  startups,  entrepreneurs  and end  users  for  agriculture  &amp;  healthcare  advancements. intelligence.\n\nCredit\n\n: nVIDIA\n\n## Pursuing excellence in research in Artificial Intelligence\n\nTo achieve technology leadership in AI, India also needs  to pursue 'moonshot' projects - ambitious explorations that aim to push the technology frontier and that would require the pursuit of world class technology  development  and  leadership  in  applying  AI  technologies  to  solve  some  of  the  biggest challenges. A potential project could be tested on a twin criteria of whether it is (a) a new technology or scientific area that has emerged or gained traction and has the capability of solving, often in new ways, practical problems of importance, and (b) whether it addresses emerging user needs that existing and available technology solutions cannot address. An example could be development of advanced natural language processing (NLP) infrastructure for Indian languages, with features of sentiment and semantic analysis, or imaging biobank for early cancer detection.\n\nSome experts believe that such ambitious projects should be driven by the industry, since they have the requisite resources, technical expertise and are attuned to practical use cases; and should rarely be pushed forward by government initiatives. Google's advances in NLP, as underlined by Duplex, is one such  example  of  private  sector  led  innovation  that  pushes  the  realisable  boundaries  of  technology. However, the inherent risk and ambition of such projects does not necessarily lay themselves well to the functioning and methods of most corporations.\n\nICTAI Inc., the overall governing body for ICTAIs, could be the DARPA (see Box 16) equivalent of AI research in India. ICTAI Inc. should have the full autonomy on selecting the projects of importance and executing these projects, and should be trusted with a separate budget for pursuing such projects. Some of the key elements of execution include:\n\n- a) Projects  with  pre-defined  durations  and  tenures :  Although  ICTAIs  could  adopt  the  moonshot approach to select projects, the projects shall have pre-defined durations for efficient management, timely  realisation  of  research  deliverables  and  financial  sustainability.  The  type  of  project  could govern the timeline, for example a project that requires integration of existing AI technologies to solve a specific problem could have a shorter duration, whereas projects which would require a unique technological development could be allocated a timeline suitably.\n- b) Teams of contractors : Specialised teams of contractors who have proven credentials in advanced technological development shall be chosen to undertake the projects. Focus could be laid more on the qualitative impact of past research activity, and less on the size or global recognition.\n- c) Special emphasis on selecting the right project leaders : Project leaders with the right skill sets to lead projects of national importance shall be key to drive the research output of projects undertaken at ICTAIs. They shall be people with proven capabilities in applied research, and the acumen to deliver technology in the form most suitable for India and the developing world.\n- d) Independence :  Independence  to  select  projects,  design  timelines  and  deliverables  and  allocate budgets shall fall  within the ambit of the ICTAIs with no intervention of  any government agency. Selection  of  the  project  teams  based  on  credentials  while  collaborating  with  premier  research institutions  with  full  independence  shall  ensure  a  robust  technological  development  that  creates impact.\n- e) Fail fast model :  ICTAIs shall be given the autonomy to shut down projects and shift resources to other  operational  projects.   With  the  moonshot  approach  for  project  selection,  it  is  plausible  that certain research projects do not provide expected results in terms of efficiency, scalability or cost. In such  cases,  diverting  resources  to  other  operational  projects  with  higher  probability  of  research output delivery would ensure financial efficacy.\n\nProjects could be housed at one ICTAI, but could involve working across multiple ICTAIs and COREs.\n\nThe algorithms and data used in an AI powered application are key elements in ensuring operational success. Therefore, it is imperative that the Intellectual Property Regime in the context of AI be robust and enforceable for innovators to have the confidence that they will be able to make profits from and take credit for their work. This is essential for the promotion of innovation, entrepreneurship and core and applied research in the field of AI.\n\nHowever, IP in the context of AI has some key differences with IP in the context of generic computer programs or other content due to the way such algorithms are designed and trained with large datasets. The data fed to an AI algorithm during the training step is key to its success.  Keeping this and other issues in mind, the government may set up a task force, comprising jointly of Ministry of Corporate Affairs and DIPP to examine and issue appropriate modifications to the IP regulatory regime pertaining to AI.\n\n## Box 16: Defense Advanced Research Projects Agency\n\nPentagon's Defense Advanced Research Projects Agency (DARPA) was created in 1958 as response to increased US concerns that Soviet Union may have achieved technological superiority following its successful launch of Spuntnik. DARPA's founding mission was simple and nimble, 'to prevent and create strategic surprise'.\n\nFor the past 60 years, DARPA has been the beacon of scientific breakthroughs and radical innovations. Amongst its success stories include the internet, RISC computing; global positioning satellites; stealth technology; unmanned aerial vehicles, or 'drones. While originally created for US military, the agency has played a pivotal role in giving genesis to several multi-billion dollar industries.\n\nWhat  is  even  more  impressive  is  DARPA's  agility  and  swiftness  despite  a  small  team  and  modest budgetary allocations. DARPA's total support staff is only 120 strong, and its annual budget is only USD3 billion. DARPA accomplishes most of its programs through a 'specialised project' model - assembling project specific teams of experts from universities, industry, government and non-profit, with well-defined targets and tenures.\n\nThe three essential elements of DARPA are:\n\n- a) ambitious goals: the projects pursued by DARPA are designed to solve real-world problems or create new opportunities. The problems are such that they can't be solved without pursuing new frontiers or catalysing new developments. Urgent need for application underlines the problems.\n- b) temporary project teams: teams of world-class experts from industry and academia are assembled to work on well-defined projects of relatively short duration, led by accomplished technical managers. Given the intensity, sharp focus and reputation attached, these projects attract high caliber talent who achieve extraordinary levels of collaboration.\n- c) independence: DARPA has complete autonomy in selecting and running projects.\n\nSource: Harvard Business Review article 'Special Forces' Innovation: How DARPA Attacks Problems published October 2013\n\n## CERN for AI\n\nGary Marcus, Professor of Psychology at NYU, mooted the idea of a CERN for AI at the #AIforGood Summit in Geneva in June 2017. In an OpEd for the New York Times, Gary further elaborated on the idea:\n\n'I  look  with  envy  at  my  peers  in  high-energy  physics,  and  in  particular  at  CERN,  the  European Organisation for Nuclear Research, a huge, international collaboration, with thousands of scientists and billions of dollars of funding. They pursue ambitious, tightly defined projects (like using the Large Hadron Collider to discover the Higgs boson) and share their results with the world, rather than restricting them to a single country or corporation.'\n\n## Box 17: European Organisation for Nuclear Research aka CERN\n\nCERN, established  in  1954  by  12  founding  European  nations,  had  its  origins  in  establishing  a  truly international scientific collaboration to pursue world class research in particle physics. Among the biggest of the several achievements to come out of this remarkable collaboration, home to the world's biggest atom smasher (the Large Hadron Collider) include the development of World Wide Web and the discovery of the Higgs boson (the 'God Particle'), W and Z bosons, Antimatter etc.\n\nCERN's current 21 member states each contribute to the overall CERN budget (CHF1,240 million in 2013). Special contributions are made to specific projects, like Large Hardon Collider, by interested Host States and non-member states. The biggest chunk of CERN's budget is spent on the construction of its enormous scientific installations, most of which are too expensive for a single country to afford.\n\nThe current state of AI, which is focused on solutions to narrow applications, and grappling with questions around next phases of development, ethics, security and privacy may benefit from a global public AI research institution advancing the field for the good of humanity, the 'People's AI' 30 .\n\nTo achieve #AIforAll, which gives the mandate for inclusive AI for the world, the Government of India should take the lead in bringing together the relevant parties to create People's AI, the CERN for AI. India has a proven track record for leading projects with ambitions of greater good. India is already playing a leading role in climate leadership, with Hon'ble Prime Minister Narendra Modi vowing to go 'above and beyond' India's commitment on Paris Agreement on climate change. Similarly, India has been a pioneer in a sustained push for clean energy revolution by leading the International Solar Alliance, and setting an ambitious target of 100GW of installed solar  energy  capacity by 2022. With 20GW of installed solar capacity, India is well and truly on its way to achieving this target. With the Government of India's focus on inclusive growth which saw several transformational reforms in the last few years, India is poised and most suited to wear the mantle of leading the #AIforAll movement. Furthermore, India offers the best possible test bed and a plethora of use cases for building AI solutions fulfilling the inclusive AI criteria, be it in healthcare, education or agriculture.\n\nWhile  the  modalities  of  funding  and  mandate  for  this  #AIforAll  should  be  the  subject  of  further deliberations,  the  proposed  centre  should  ideally  be  funded  by  a  mix  of  government  funding  and contributions  from  large  companies  pursuing  AI  (GAFAM,  BATX  etc.).  Where  should  this  centre  be located? Nowhere and everywhere. While the CERN had the requirements of physical facilities such as the  Large  Hadron Collider,  #AIforAll  could  be  distributed  across  different  regions  and  countries.  The Government of India, through NITI Aayog, can be the coordinating agency for initial funding and setting up the requisite mandates and human and computing resources.\n\nThe mandates of the #AIforAll should include challenges of AI that are common to other countries and large corporations and startups alike, and the foundational components that could truly make AI inclusive and good for all. Suggestive technology topics could include:\n\n- a) General AI;\n- b) Opening the Black Box / Explainable AI;\n- c) Advanced anonymisation protocols for data security and privacy;\n\n30 Medium.com 'The People's AI: democratizing AI research and development'\n\n- d) Ethics in AI; and\n- e) AI approach to solving world's biggest problems in healthcare, education, urbanisation, agriculture etc.\n\nA start has been made by OpenAI, set up by the likes of Elon Musk and Sam Altman, with a mission to discover and enact the path to safe artificial general intelligence. Similarly, Declaration on Cooperation in Artificial Intelligence was signed by 25 states of European Union on 10 th  April 2018. What is needed though is a commitment and collaboration of truly international standards to develop and ensure #AIforAll.\n\n## Skilling for the AI age\n\n## Getting India ready for the AI wave\n\nHistory suggests how technology has disrupted the nature of jobs and the skills required to perform them, requiring the global workforce to continuously adapt. Advent of AI has accelerated this disruption to a pace that has not previously been seen, due to the wide range of capabilities it offers and speed at which it is developing.\n\nNASCCOM predicts that by 2022, a startling 46% of the Indian workforce will be engaged in entirely new jobs that do not exist today or jobs that have radically changed skill sets 31 . Some other sources estimate that demand for AI and machine learning specialists in India is expected to see a 60% rise by 2018 32 . In the data domain as well, an independent study estimated that India will face a demand-supply gap of 2,00,000 data analytics professionals by 2020.\n\nIn the IT-BPM sector, traditional software developer roles are set to transition to roles such as computer vision engineers, Robotic Process Automation (RPA) engineers and cloud architects, among others. At the same time, completely new job roles such as language processing specialists and 3D modelling engineers are set to arise as the technologies are increasingly adopted and deployed 33 . With AI, such transition would move beyond the IT sector and affect sectors such as education, health, agriculture, finance etc, requiring the underlying skill sets.\n\n31 Future of Jobs in India: A 2022 Perspective, 2017\n\n32 KellyOCG, India\n\n33 Future of Jobs in India: A 2022 Perspective, 2017\n\nSource: Reworking the Revolution, Accenture\n\n## Source:\n\nFuture of Jobs in India: A 2022 Perspective, 2017\n\nFigure 21: Transition in jobs and skill sets\n\nThe demand for new-age jobs is accelerating in India, and can be attributed to three major factors 34 , viz. increased adoption of technology; shift in market demographics and de-acceleration of globalisation.\n\nFigure 22: Impact of primary forces on jobs in 2022\n\nAs technology adoption increases across sectors, so will the demand for skills required to implement them.  India's  growing  middle  class  and  millennial  demographic  form  a  major  part  of  the  market  for technology enabled products. As the size of these demographics increases, so will the demand for these products, and thus the workforce that can enable their creation. Increased globalisation played a major part in the creation of jobs in the services sector. However, as the permeation of automation increases,\n\n34 Future of Jobs in India: A 2022 Perspective, 2017\n\nSource:\n\nNASSCOM,\n\nICRIER,\n\nMcKinsey analysis\n\nand protectionism among previous markets for these services becomes predominant, it is important to recognise that these jobs will see a large overhaul.\n\nIndia may appear to be relatively well positioned to take advantage of the AI disruption by virtue of its advanced IT sector and large youth demographic potential to establish itself as the future hub for AI related activities. However, given the poor availability of qualified faculty and researchers, this advantage could fast transform into a liability without urgent government interventions towards promoting access to such skills. This is a critical component of AI development, and should be a national priority.\n\nChanging nature of the global service sector, uncertain impact of automation in manufacturing, and poor infrastructure can pose a challenge to the task of enabling up-skilling or re-skilling.\n\nShifts in the outsourcing needs of developed economies have the potential to impact India dramatically. As multinational companies move toward 'in-shoring' or 'no-shoring' due to development of automation technology  and  increasingly  protectionist  measures  globally,  it  is  of  critical  importance  that  the outsourcing industry (which currently accounts for roughly 15% of India's total labour force) adapts to these changing needs accordingly.\n\nAs indicated below, automation could affect even traditional sectors in a variety of ways. Agriculture is predicted to see a net decrease in jobs due to automation, while the job opportunities in the construction sector are predicted to improve significantly. These large scale shifts in employment depend largely on the  nature  of  technology  being  developed  as  well  as  deployed,  and  are  very  hard  to  predict  for  any informed policy intervention.\n\nSource:\n\nMcKinsey, Jobs Lost, Jobs Gained: Workforce Transitions in a Time of Automation\n\nFigure 24: Impact of automation\n\nMultiple studies have underlined the lack of employment readiness of STEM graduates, thus highlighting the poor standard of education in engineering colleges in India. As per some estimates, almost 80% of engineering graduates are unemployable on graduation. Low availability of specialised faculty; lack of flexibility  in  curriculum  revisions  in  engineering  and  computer  science  courses  to  keep  up  with  rapid advancements in technology; and low levels of interdisciplinary research in AI related fields to facilitate an AI education for non-computer science engineering (and vice versa), are just some of the factors that have led to this scenario.\n\nAt the school level as well, poor outcomes in Maths and reading are particularly troubling, since these subjects form the foundation of knowledge required to move to an AI related education, and later jobs in the domain.\n\n## Recommendations\n\nFor addressing issues relating to skilling, a two-pronged approach is warranted, one set of interventions aimed at the workforce and the second for the students.\n\n## 1. Workforce\n\nRe-skilling of the current workforce will require integration with relevant existing skilling initiatives, building of  new  platforms  that  can  enable  improved  learning,  and  novel  methods  of  allowing  large  scale employment generation through promotion of AI.\n\n- a) Incentivising creation of jobs that could constitute the new service industry: To tackle the challenge of shifts in the services industry, it is important to identify and promote creation of jobs that may replace traditional IT-BPM sector jobs in the future. These jobs would ideally be a part of the AI solution  development  value  chain,  but  require  a  relatively  low  level  of  expertise  so  as  to  create employment at scale. Tasks such as data annotation, for example, have the potential to employ a large  quantum  of  human  resources,  and  serve  countries  all  over  the  world  in  otherwise  capital\n\nintensive projects. Tasks such as image classification or speech transcription require low levels of expertise and present an opportunity to exploit labour cost arbitrage to serve companies globally. Specific policy interventions could be considered like tax holidays, inclusion under CSR activities, etc.  to  help  solve  the  dual  problem  of  workforce  job  displacement  and  creation  of  expertise  in fundamental sections of the solution development value chain.\n\n## Box 18: Impact sourcing through Samasource\n\nSamasource is a pioneer in impact sourcing of technology services, the practice of hiring people from the bottom  of  the  income  pyramid  and  directly  raising  them  out  of  poverty  by  providing  digital  work  for companies like Google, Walmart, eBay, and many startups.\n\nAbout two-thirds of their work is in managed services for image capture and annotation. They need a large  pool  of  skilled,  detail-oriented  workers  to  identify  the  appropriate  images  or  video  frames  and manually tag the scene, specific regions (a forest), or objects (a wolf) with the specific keywords the customer requires for their application.\n\nSamasource quotes its top objective as 'creating technology jobs for the impoverished while delivering the highest quality work in a cost-effective manner'. This guided Samasource to focus on East Africa, where  the  majority  of  the  population  has  completed  secondary  or  high  school,  and  has  a  good understanding of basic English language. They have a dedicated training organisation that works within the local communities to identify qualified men, women and youth in need and assess them for key skills. For those with strong visual acuity, there is general computer and business skills training and a 3-week dedicated  machine  learning  and  image  annotation  training  track  with  example  projects  and  ongoing assessments that lead to graduation\n\nAs workers get moved to projects, there is another set of qualification tests and project-specific training. Once they pass those, they are moved into production for the project and their work is reviewed daily by the QA team to correct mistakes and resolve interpretation or requirements issues (do you want to tag a traffic light facing away from the camera?). These reviews are done both locally and in the US, allowing real-time  feedback  with  many  checkpoints  throughout  the  project  lifecycle,  reinforcing  Samasource's tightly managed approach to quality.\n\nSamasource reportedly provide jobs and digital skills training to people below the poverty line in Kenya, Uganda, Haiti, and India. Since the company started in 2008, Samasource has been able to hire nearly 8,000 people. As a result, they've could transition themselves and their dependents out of poverty and provide living wages, transforming over 30,000 lives.\n\n- b) Recognition and standardisation of informal training institutions: The increasing demand for AI or data related job positions has not gone unnoticed by the Indian workforce, with a large percentage of them opting for training institutions to bridge their knowledge gaps. In technology hubs such as Bengaluru, this has led to many traditional IT training institutions establishing courses in new age technologies. However, their standard of education is hard to assess for companies looking to hire. Implementation of recognised certificate courses through higher education institutions could be a major boost to recognising resources spent on re-skilling, and holding these institutions to standards in  delivery  of  knowledge.  International  School  of  Engineering  (INSOFE),  for  example,  provides certification recognised by the Language Technologies Institute of Carnegie Mellon University (CMU) for a post-graduate program in data analytics and optimisation. Jigsaw Academy's data science postgraduate  program  gets  its  students  certified  from  the  University  of  Chicago  Graham  School.\n\nIntegration and application of existing standards such as laid out by the National Skill Qualification Framework (NSQF) should also be explored. Given that standards in areas such as big data exist but are not used by institutions for certification also highlights the need for them to be designed in closer collaboration with the private sector.\n\n- c) Creation of open platforms for learning: Initiatives such as the NASSCOM Future Skills Platform will play an instrumental role in large scale dissemination of requisite skills to some major sections of the employed workforce. Online and self-learning platforms, such as Coursera and edX, are able to connect learners to the best universities and institutions from around the world, and can play a crucial role  in  this  scenario.  There  is  need  to  bring  out  guidelines  for  promoting  these  while  ensuring uniformity,  standards  and  usability.  As  in  the  promotion  of  MOOCs,  large  scale  deployment  and adoption  of  these  platforms  requires  stringent  measuring  of  quality,  and  recognition  of  their certification.\n- d) Creating  financial  incentives  for  reskilling  of  employees: Initiatives  in  reskilling  of  employees  or allowing  employees  to  undergo  reskilling  initiatives  have  a  high  opportunity  cost  for  private companies, and may affect their willingness to let their employees engage in the process at scale. It is thus suggested that co-funded models between the government and companies be explored, in the IT sector particularly. Financial incentives for private companies could include payroll taxes which are dedicated to subsidising training opportunities, income tax deductions for companies participating in reskilling initiatives, special taxes to be paid if a minimum training budget is not disbursed, as well as public grants for subsidising training especially for smaller sized firms. Considering also the time required for reskilling, and the cost it entails to employers, financial incentives may also be tied to mandatory allocation of time for reskilling activities by companies for their workforce. However, in the absence of standardisation of training modules and institutions, such initiatives could be prone to misuse.\n\n## 2. Students\n\nThe  education  sector  needs  to  be  re-aligned  in  order  to  effectively  harness  the  potential  of  AI  in  a sustainable  manner.  In  primary  and  secondary  schools,  there  is  a  need  for  transition  to  skill  based education  in  subjects  relevant  to  AI.  Often  criticised  for  being  overly  knowledge  intensive,  Indian education is in urgent need of transition particularly in subjects relevant to STEM, or computer based education. As jobs based on technology become prominent, so will the need to develop applied skills in a continuously changing environment.\n\nIncreased  amount  of  project  related  work  across  education  levels,  promoting  schemes  like  the establishment of ATLs (Atal Tinkering Labs) in schools, necessary change in curricula in schools, are some of the steps that need to be considered to promote early adoption of technology organically.\n\nIn higher education institutions there is need for increased collaboration between industry and academia through creation of channels of communication between faculty and industry to promote exchange of ideas  and  expertise.  Various  avenues  of  collaboration  need  to  be  explored,  including  workshops, incentives  for  guest  lectures  by  professionals  and  institutional  arrangements  for  regular  re-design  of courses in collaboration with the private sector.\n\nLack of qualified faculty that poses a serious problem in the present scenario can be addressed through innovative  initiatives  like credit-bearing  MOOCs (Massive  Open  Online  Courses).  Acceptability  and adoption of these decentralised teaching mechanisms can be ensured through prescribed certification in collaboration  with  the  private  sector  and  educational  institutions. Initiatives  such  as  the SWAYAM\n\nplatform 35 , are in the right direction but these need to be further reinforced through additional investment and  collaboration  with  the  private  sector  and  educational  institutions  in  order  to  meet  the  market demand.\n\nCountries  like  the  USA,  that  have  a  thriving  student  and  research  community  engaged  in  AI,  have effective bridge courses, generally at post graduate levels for non-related fields. Thus at a post-graduate level, the focus shifts to creating incentives to conduct research in domestic institution s and allow crossdisciplinary collaboration and education . Similar initiatives are required in Indian educational space with bridge courses in AI for post-graduates in non-computer science or data science domains to encourage cross-domain research and the 'AI + X' paradigm. One year courses could be explored that will enable students of a range of subjects to build foundations of knowledge in the AI space, and effectively apply domain expertise to solve pressing problems.\n\nThis  is  an  ever  evolving  area  and  needs  to  go  beyond  the  one  time  solutions  with  an  institutional framework in place that is responsive to changing scenarios. Such a framework would enable a more sustainable and customised solution. A standing committee or task force comprising of all stakeholders may be constituted by the government with the objective of examining and reporting the changes in employment caused by AI in India. This taskforce would consider not only IT related activities, but the job ecosystem as a whole. As AI continues to evolve, this will facilitate evidence based decisions in funding of educational institutions, promotion of specific sectors, and channelling of human resources to be most efficiently utilised.\n\n35 developed by the All India Council for Technical Education (AICTE) and the Ministry for Human Resource Development (MHRD)\n\nSource: Accenture\n\n## Accelerating Adoption\n\n## AI across the value  chain\n\n## Global Context\n\nAdoption of AI globally is still in its nascent stages, but growing rapidly. A 2017 survey by Statista finds that 78% of firms globally are either using AI extensively, or have plans for use in near future. Firms in China and the US especially, are proactively engaging with their research communities to enable early adoption and position themselves competitively.\n\nFigure 25: Survey of global firms on adoption of emerging technologies in 2017 (In which of the following new and emerging technologies is your organisation making investments over the next year?)\n\nA McKinsey report on 'AI: The next digital frontier' concludes that AI adoption outside of the tech sector is at an early and often experimental stage and deployment at scale has been rare. In the survey of 3,000 AI-aware top management executives, across 10 countries and 14 sectors, only 20% use any AI related technology at scale or in a core part of their businesses.\n\nAs the field is rapidly evolving, investments made in core AI research and product development is another indicator of adoption. The McKinsey report estimates that organisations invested around USD26 - USD39 billion in AI while USD6 - USD9 billion was invested in startups in the year 2016.\n\nAdoption of AI in India has been slow and remains limited. Estimates indicate that only 22% of the firms in India use AI in any business process 36 . Indian startups have been able to raise just USD87 million in 2017, as against over USD28 billion raised by the Chinese startups in 2017 37 .\n\nLow  adoption  of  AI  technologies  in  India  is  particularly  troubling,  given  the  country's  prominence  in the global IT industry that could have given it the natural first mover's advantage in AI. However, the IT industry in India has remained content in delivering traditional IT services and has been slow to adapt to new digital technologies compared to its counterparts in China and the US.\n\n36 Intel and IDC Survey Report, dated\n\n37 XinhuaNet 'AI sector sees big investment, financing in 2017'\n\nDespite  its  sectoral  leadership  and  programming  talent,  India's  IT  industry  with  over  USD160  billion annual  revenue,  has  yet  to  build  pioneering  AI  /  ML  capabilities  commensurate  with  its  potential. Nevertheless, the top 5 IT service companies have begun to use AI to cut costs and automate business processes. Wipro has built Holmes , an AI platform that deploys 'bots' to carry out repetitive and mundane tasks. TCS has created its own AI platform, Ignio , and Infosys has built Nia , improving upon its earlier Mano platform. While promising, these early efforts remain far from revolutionary.\n\nThe limited success of Indian technology players to effectively adapt and carry forward the AI revolution suggests the need for government intervention to promote AI adoption, lest India lose the chance to secure  a  prominent  position  on  the  global  AI  map.  While  acknowledging  the  need  to  promote  AI, governments  at  different  levels,  along  with  their  various  instrumentalities,  should  adopt  proactive measures to accelerate AI adoption in various processes.\n\nThe major market segments for the increased AI adoption are:\n\n- (a) Private enterprises : mostly driven by market and enterprise considerations,\n- (b) Public Sector Undertakings : imperative to drive up the operational efficiency of PSUs, and\n- (c) Government : improve process efficiency, reduce human discretion, eliminate middlemen, advance prediction, pro-active and predictive service delivery to citizens.\n\nThe steps taken by the government, in terms of incentives or in providing infrastructural platforms, will have  varying  control  and  influence  on  all  these  segments  -  least  on  private  enterprises  to  most  on government agencies.\n\nAI adoption in India will face the following challenges:\n\n- (d) Lack of adequate talent to build and deploy AI systems at scale . An estimate claims that only 4% of AI professionals in India have worked on emerging technologies such as deep learning and neural networks. There is also a significant gap of PhD research scholars in the field.\n- (e) Difficulty  in  access  to  industry  specific  data  required  to  build  customised  platforms  and solutions currently concentrated in the hands of a few major players . It is difficult for new entrants to deliver tailor made services that can compete with data rich incumbents such as Facebook or Google. This phenomenon results in the creation of a virtuous cycle which reinforces the hegemony of the big few, creating a huge entry barrier for startups.\n- (f) High  cost  and  low  availability  of  computing  infrastructure  required  for  development,  training  and deployment of AI based services . Cloud infrastructure, though growing rapidly, has limited capability. Also lacking are AI-as-a-service models of cloud platforms. Lack of infrastructure has led to many Indian AI startups to incorporate their business outside the country, which makes AI outside the reach of Indian researchers in government labs and many industries. Initiatives like GI Cloud (MeghRaj), are in the right direction.\n- (g) Low awareness of AI for resolving business problems in most public enterprises and government agencies, especially given the scarcity of AI professionals, is obstructing adoption.\n\nFollowing specific initiatives are recommended for promoting AI adoption in the country:\n\n## Recommendation 1: Creating a multi-stakeholder Marketplace\n\nTo encourage the development of sustainable AI solutions at an appropriate price point for sectors such as health, education, and agriculture, it is necessary that a level playing field be ensured and a supportive environment be created for all players in the value chain. The development of any working AI-based product is a long process with very different specialised activities that are necessary for final delivery, just like any other product or service value chain.\n\n## Figure 26: AI Value Chain\n\nIt is exceedingly difficult for a small or medium business / startup to vertically integrate all these processes and have the internal capacity to deploy them simultaneously before even entering the market. Therefore, this acts as a barrier to entry for new players. On the other hand, for different firms to take up different activities and still deliver useful products, a strong, stable price discovery mechanism has to exist for incentives to align and sustainable business models to come up for the different parts of the value chain. Another well documented and substantial barrier to entry is the difficulty of acquiring the raw material (data) in the first place since as noted above, most usable data is in the hands of a few players.\n\nTowards  providing  a  level  playing  field,  addressing  information  asymmetry,  and  incentivising  and simplifying collaboration between the various stakeholders in the AI ecosystem, a marketplace may prove to be a potent tool provided it enables the following:\n\n- (a) Discovery  of  required  AI  component : ability  to  reference  assets,  be  it  data  or  ML  models,  and services, such as annotation, and enable curation and rating of these assets.\n- (b) Platform to execute transactions : with mechanisms to exchange value of a specific good and service for currency or subscription models for APIs.\n- (c) Verification of transactions : ability to verify the occurrence of transactions and the receipt of goods or services in exchange for currency.\n\nSuch a marketplace model would benefit by:\n\n- a) Reducing asymmetry of information: With a reasonable volume of transactions, aberrations caused due to data oligopoly will reduce, thus reducing the spread in pricing and effectively incentivising both data owners and AI model creators.\n- b) Encouraging specialisation in different niches by firms and creation of novel business models: Easy availability  of  raw  components  required  at  different  stages  of  the  AI  solution  development  cycle would allow firms to focus on specific problems, rather than attempt to build capability across the value chain. For example, a new segment of startups could entirely focus on the problem of curating raw  data  to  be  put  on  the  marketplace,  rather  than  attempting  to  do  all  the  above  at  once.\n\nConsequently,  such  startups  will  see  a  better  market  for  VC  funding  as  they  will  be  able  to substantially mitigate their business risks, if an easily accessible, formal market for raw data exists.\n\n- c) Unlocking  new  sources  of  data  and  enabling  more  efficient  use  of  computational  and  human resources: Estimates suggest that only 1% of data today is analysed due to its existence in various unconnected siloes. For example, medical imaging / diagnostic centres today are collecting valuable data. It is currently not used to its potential as there is no way for diagnostic centres to build predictive disease models without hiring AI experts, renting computational expenditure, and indeed shifting gears  completely  to  become  an  AI  company.  In  the  presence  of  a  formal  market  with  a  fair mechanism of price discovery, such diagnostic centres would have an incentive to collect this data, have it curated, and place this data in the market with appropriate permissions and safeguards. Concurrently, machine learning experts in AI firms would be more productive as they could focus on the problem of creating the model rather than that of sourcing the data and curating it.\n- d) Address ethical concerns regarding data sharing: Today, transactions and buying of data occur in an  informal  marketplace.  However,  there  is  no  mechanism  currently  to  ensure  that  appropriate permissions are taken from the actual data owners before data custodians share the data. Going back to the example of diagnostic centres (which are data custodians in this case), it would become necessary for firms to take consent of individuals getting imaged to aggregate and sell their data. This could create mechanisms through which individuals are ultimately compensated. In this way, the informal market for data could be nudged towards entering the formal economy.\n\n## Recommendation 2: Facilitating creation of large foundational annotated data sets\n\nIn  India,  lack  of  annotated  data  in  the  domestic  context  has  emerged  as  a  major  impediment  in development of AI solutions for both startups and core research alike. Availability of general data corpora which can be applied across product functions can serve to provide a ready source of data (in 'plugin' mode) to startups and enable solutions customised to the Indian context. There is evidence to suggest that ready availability of large corpora can spur research and innovation in the field of machine learning.\n\nFigure 27: Breakthroughs in AI\n\n| Year                                  | Breakthroughsin Al                                                                                     | Datasets (First Available)                                                                           | Algorithms (First Proposed)                      |\n|---------------------------------------|--------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|--------------------------------------------------|\n| 1994                                  | Human-level spontaneous specch Spoken Wall Street Journal articles and recognition other texts (1991)  |                                                                                                      | Hidden Markov Model (1984)                       |\n| 1997                                  | IBM Deep Blue defeated Garry Kasparov                                                                  | 700,000 Grandmaster chess games, aka                                                                 | Negascout planning algorithm (1983)              |\n| 2005                                  | Googles Arabic-and Chinese-to English translation                                                      | 18trillion tokens from Google Web and News pages (collected in 2005)                                 | Statistical machine translation algorithm (1988) |\n| 2011                                  | IBM Watson became the world Jeopardy! champion                                                         | 8.6 million documents from Wikipedia , Wiktionary Wikiquote, and Project Gutenberg (updated in 2010) | Mixture of-Experts algorithm (1991)              |\n| 2014                                  | Googles GoogLeNet object classification at near-human performance                                      | ImageNet corpus of 1.5 million labeled imagesand 1,000 object categories (2010)                      | Convolution neural network algorithm (1989)      |\n| 2015                                  | Googles Dccpmind achicved human parityin playing 29 Atari games by learning general control from video | ArcadeLearning Environment dataset of over 50 Atari games (2013)                                     | Q-learning algorithm (1992)                      |\n| Average No. of Years to Breakthrough: | Average No. of Years to Breakthrough:                                                                  | 3years                                                                                               | 18 years                                         |\n\nThe average elapsed :ime between key al Igorithm proposals and corresponding advances Was abour 18years; whereas the average elapsed time\n\nBy its very nature, this task is laborious and despite innovations in automatic annotation, such as the development  of GoogleNet object  classification, human annotation  and  training  of  data  sets  are  not\n\nexpected to be replaced in the near future. This  is  best exemplified by the thriving investments and startups in this area. As lately as 2017, Alegion, Scale, CloudFactory, Mighty AI, and CrowdFlower, all companies that enable human intervention to data annotation, have received about USD50 million in investment funding.\n\nGiven the nature of this task, it is necessary for the government to explore assistance in building of large corpora of data across domains, as a means of laying the foundation for startups and enterprises to build applications and services which are tailor-made to the Indian context, and in the process lowering entry barriers for startups and academia while also encouraging international expertise to focus on problems in the Indian context.\n\nIn areas such as native language NLP (Natural Language Processing) for diverse Indian languages, for example, the funding for creation of these data sets can add incremental value to existing services across many domains, ranging from e-commerce to agricultural advisory. Co-funding by the government would also enable enforcing of standards across development of data sets, and allow interoperability at a large scale. A collaborative approach where the government acts as a catalyst is recommended as a way forward.\n\n## Recommendation 3: Partnerships and collaboration\n\nAI  is  a  highly  collaborative  domain,  and  any  framework  aimed  at  promoting  AI  needs  to  be  aligned accordingly. A multi-pronged approach, involving  various stakeholders and promoting a collaborative approach is required for promoting development of AI tools as well as adoption of AI in different fields of activity.\n\nPerkmann and Walsh (2007) studied different degrees of partnership in research and categorised them in three categories, each having different characteristics.\n\nFigure 28: Categories of partnerships in Research\n\n| High (Relationships)   | Research partnerships                      | Inter-organizational arrangements for pursuing collaborative RRD, including research consortia and joint projects                                                                                        |\n|------------------------|--------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| High (Relationships)   | Research services                          | Research-related activities commissioned to universities by industrial clients , including contract research, consulting; quality control,   testing;   certification; and prototype development.        |\n| High (Relationships)   | Shared infrastructure                      | Use of university labs and equipment by firms, business incubators , and technology parks located within universities .                                                                                  |\n| Medium (Mobility)      | Academic entrepreneurship                  | Development and commercial exploitation of technologies pursued by academic inventors through company they (partly) own (spin-off companies)                                                             |\n| Medium (Mobility)      | Human resource training and transfer       | Training of   industry   employees internship programs, postgraduate   training in industry; secondments to industry of university faculty and research staff , adjunct faculty of industry participants |\n| Low (Transfer)         | Commercialization of intellectual property | Transfer of university-generated IP (such as patents) to firms (e.9 , via licensing)                                                                                                                     |\n| Low (Transfer)         | Scientific publications                    | Use of codified scientific knowledge within industry.                                                                                                                                                    |\n| Low (Transfer)         | Informal interaction                       | Formation of social   relationships   (e.9., conferences, meetings , social networks).                                                                                                                   |\n\nIn India, Academic Entrepreneurship is being taken up through mechanisms such as the development of dedicated e-cells in institutions such as IIT Bombay, IIT Madras and IIM Ahmedabad, among others. Low degrees of partnership, such as direct transfer of knowledge, is being taken up by MNCs and startups that make use of scientific publications and informal interaction to develop. Research partnerships are\n\nalso being explored, but in a very limited capacity. Other partnership mechanisms, however, are all but absent.\n\n- (h) Collaboration between Research Organisations is required to promote the 'AI+X' paradigm where the AI researcher works in close collaboration with the researcher in other domains like healthcare, manufacturing,  agriculture,  etc.  Several  successful  US  universities  have  co-located  departments which enabled close collaboration. DARPA in the USA has close linkages with research facilities housed  in  academic  institutions,  and  has  taken  up  major  initiatives  for  promoting  research  and innovation in collaboration with private enterprises and startups alike. In India these domains are not naturally connected, primarily due to the structural nature of both academia and research labs.  To promote AI in the country, and fully realise the 'AI+X' paradigm, it is also necessary to enable such cross-sectoral collaboration, e.g. between a medical doctor and a computer scientist, to lead research for application of latest technology in solving medical problems and also making real data available in the process.\n- (i) Industry-Research  Collaboration is  required  to  help  continuously  scale  and  improve  the  initial research output based on user feedback from the market. For example, in the domain of search engines, several search datasets like TREC, SMART, etc. were made available by the US universities during the 1970-80s to develop the technology of information retrieval and search. This in turn led to development of several search engines such as Yahoo! and Alta Vista during this period. Over time, this led to improved smarter systems until Google became the market leader in the late 1990s.\n- (j) Collaboration  with  trade  bodies  and  Venture  Capitals is  essential  for  successful  functioning  of  a profitable business which involves various other elements, like deriving the optimal business model, managing human resources, advertisement / marketing and many varied functions depending upon the type of technology and underlying business. Trade bodies and associations are very important for collaborating with other people in similar businesses, as they can share information about the common problems, possible solutions and access to learning from the ground. Such bodies help in collectively identifying new  international markets  for such products / technologies and in lobbying/negotiating for favourable trade norms with the national and international bodies.\n\n## Recommendation 4: Spreading awareness on the advantages AI offers\n\nAnother major hurdle in adoption is low visibility for the work being done across the country. Unless known through networks, work is often duplicated without knowledge of previous work done in the area and consultation with experts. There is a need for an AI Database on an online portal for registered people to access and find this information. This database, primarily managed by the government, could serve as a single source of truth for experts and projects being implemented. The resources can include details like researchers stating their expertise, and professionals with hands-on experience on developing AI solutions showcasing their credentials. This knowledge base can also become a forum for sharing various discussion related to research collaboration, and finding relevant collaborators and finding professionals to deliver on AI projects.\n\nThere is need to make senior level officials among government agencies, public sector undertakings, and other domestic firms aware of the numerous advantages that AI offers, by organising workshops and live demonstrations of possible AI applications and how its implementation can help augment the human workforce,  rather  than  displace  it.  The  constitution  of  an  annual  'AI  Readiness  Index'  may  also  be considered, as highlighted in the DIPP Task Force report on Artificial Intelligence. This may also be further expanded to highlight best practices across states, to be shared in various fora. NITI Aayog, given its mandate of competitive and cooperative federalism, could undertake this task. It has already collaborated\n\nwith organisations such as Google to organise capacity building training and workshops for government functionaries.\n\n## Recommendation 5: Supporting startups\n\nStartups and smaller firms are the engine for growth in a dynamic evolving economy like India, and are constrained in the AI space, thus requiring targeted government interventions.\n\n- (a) Incubation hubs specifically for AI startups in collaboration with State Governments and private sector stakeholders need to be set up to provide space, and other infrastructure facilities for new startups to incubate along with interacting with other startups at various levels of maturity in order to interact and provide advice.\n- (b) Establishment of fund to provide grant funding to startups to facilitate their operation and business. This should be aimed at assisting startups to sustain the initial  years of business when they are unable to generate venture capital funds or have to sacrifice a large share of the business for early stage seed funds.\n\n## Proposed modules of the National AI Marketplace (NAIM)\n\nIt  is  proposed that the marketplace, called here as National AI Marketplace (NAIM), be divided into 3 distinct modules, at least in early stages of development. These are as follows:\n\n- a) Data marketplace\n- b) Data annotation marketplace\n- c) Deployable model marketplace / Solutions marketplace\n\nThe AI development value chain, discussed above, is supported by these three modular marketplaces in terms of easing collaboration, reducing time and cost of collecting &amp; annotating data, and bringing multiple solutions deployment at one place for scale and network effect.\n\nFigure 29: Enablers for AI value chain\n\nThe marketplace mechanism being proposed here will be aimed at easing the adoption efforts of all participants - private enterprises, PSUs, governments, startups and academia. A common platform which brings together enterprises and AI solution builders will trigger off the initial collaboration towards building AI solutions and adopting them at scale.\n\n## Figure 30: Stakeholders for the proposed NAIM\n\n| Enterprises   | Find cost efficient solutions to enterprise specific problems faced A platform to easily connect with Al community Find solution developers and understand the tech development being                                                                                            |\n|---------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| PSUs          | One platform to understand the advances in technology Find working solutions for business problems, improve operations First ones to create the initial traction by posting problems and data                                                                                    |\n| Governments   | One platform to monitor Al development and adoption across the country Can leverage the marletplace to incentivise Al development PSUs, Indian startups (fiscal incentives to organisations adopting Al) Platform to serve as an anchor for Al ecosystem creation in the country |\n| Academia      | Get access to authentic industry data for various use cases Reorient core research towards application and test commercial feasibility                                                                                                                                           |\n| Startups      | Find real world enterprise based problems to be solved Access to data from enterprises and governments to develop and train the Al models As enterprises problems, the solution is financially backed naturally post                                                             |\n\n## Data marketplace\n\nToday, incumbents continue to enjoy an oligopoly in building sustainable business models in AI for two main reasons: (a) they can successfully buy data in the informal market setting due to availability of resources  and  reach  to  negotiate  one-time  contracts  continually,  and  (b)  they  have  specialised departments to work on different facets of the development value chain. In the process of informal data acquisition as well, there is no proper price discovery mechanism in place. Compounded with the issue of a huge asymmetry of information in the sector between data providers and buyers, data providers are likely to be substantially underpaid.\n\nThis further compounds the problem of data access and thwarts the creation of a healthy marketplace as well as incentives. In a formal marketplace being proposed here, new entrants in the AI model creation / training space will find it easier to raise resources for buying data. This will be due to VCs having enough information to verify the funding demands and a lower risk resulting from a more level playing field and equitable access to new data sources.\n\nWhile data has been compared to oil ad nauseam, there are a few differences which must be highlighted:\n\n- a) Reusability: Copied data is as valuable as the 'original'. Therefore, traceability  of  ownership is  a challenge for a viable marketplace model where the originators of the data should get compensated from resale of the data.\n- b) Compounding value: Unlike  oil,  the  value  of  a  dataset  increases  not  just  with  quantity  but  also structural  complexity.  For  example,  the  value  of  a  health  dataset  of  a  million  individuals  and  an education dataset of the same individuals is more than the sum of its parts because of the value added by the connections between the different elements. Therefore, it is difficult to quantify the value of new datasets as it is dependent on the existing datasets one has and how one plans to connect the new data with the existing data.\n\n- c) Permanence : Unlike the oil, the inventory of data continually increases with time. However, this raises the complexity in transporting larger and larger datasets.\n- d) Ubiquity :  Since  data  is  ubiquitous  and  continually  increasing  in  quantity,  it  follows  that  a  way  to automatically curate new datasets is needed so that any market does not overwhelm users with outdated or irrelevant data.\n\nThe fundamental properties of data and its collection outlined above create challenges which make the creation of a centralised data marketplace difficult. The primary assumption of a data marketplace in operation is that data custodians will share the data on the marketplace. Organisations may be reluctant to do so. Further, the operations of the data exchange, financially sustained by transaction fees and rigid pricing models, also add to inefficiencies and discourage data sharing.\n\n## Features of a viable data marketplace - how it can be implemented?\n\nTo incentivise a larger supply of AI training data sets and services, it is necessary to ensure availability of data, an audit trail mechanism to curb reselling of the same data, and ways to address security and privacy concerns. One solution is to have a centralised, trusted party to host the data on behalf of data providers and enforce the rules of the game. However, this is not practical for a variety of reasons, not the least because most data providers will not agree to let a replicable resource such as data be stored somewhere else, but also because of cost, control and trust concerns.\n\nA more effective way to address these concerns is a decentralised data marketplace that is based on blockchain technology.\n\nThe exchange platform should have the following features for data providers to share data:\n\n- a) Traceability,\n- b) Access Controls,\n- c) Compliance with local and international regulations, and\n- d) Robust price discovery mechanism for data\n\nThe proposed data exchange marketplace will attract data providers and model builders / trainers to build AI products. The process of exchange, with enforced provisions of privacy and anonymisation, brings a market determined value to data and thus forces the existing informal data exchange economy, without any privacy protection, to move towards a formal economy.\n\nThe government can establish a committee of experts, researchers, AI developers and regulators to create the standards the data marketplace will adhere by and explore how can it be put in implementation.\n\nThe unique approach that one such initiative, i.e., Ocean Protocol has taken is to create what they call a Proofed Curation Market with two subcomponents: (a) Data exchange validation on blockchain, (b) Data curation  market  based  on  a  derivative  token.  The  former  lays  out  a  mechanism  for  data  and  value exchange, the latter enables the market to decide which datasets are important and creates an incentive for even free data to be put on the platform. Essentially, data consumers can bet on the viability of even free data and thereby earn money.\n\nSee Appendix III for more on data ecosystems as enablers.\n\n## Data annotation marketplace\n\nOf the three marketplace modules defined, the data annotation marketplace is perhaps the most mature.\n\nGiven the large costs associated with the annotation exercise, a popular mechanism that has emerged is that of crowdsourcing using un-trained or non-expert anonymous annotators on the internet. Though this gives rise to its own set of challenges, it may be considered a solution to the problem of cheaply and quickly acquiring annotations for the purposes of constructing a variety of models. To understand the potential of crowdsourcing, consider the observation of a research paper in 2004 38 : a crowd of 5,000 people playing an appropriately designed computer game 24 hours a day, could be made to label all images on Google (425,000,000 images in 2005) in a matter of just 31 days.\n\nHowever, some challenges that emerge in the annotation crowdsourcing process are as follows.\n\n- a) Creation of verification mechanisms : Dependence on untrained professionals gives rise to issues in ensuring high accuracy in annotation and thus potentially higher accuracy of the trained algorithm. Verification mechanisms such as multiple annotation, verification of samples by trained professionals, etc. are some of the ways to solve this problem.\n- b) Establishing verified traceability: Mechanisms must thus be put in place to identify poor annotators, and create mechanisms to reduce the effect of error generated.\n\n## Features of a data annotation marketplace - how it can be implemented?\n\nPlatforms such as Amazon's MTurks, Figure-Eight (previously known as CrowdFlower) or ClickWorker are  perhaps  the  most  popular  crowd-sourced  annotation  platforms.  Each  allows  for  building  of mechanisms of verification such as multiple annotations, creation of test cases, sample verification by professionals, etc. to increase accuracy of annotations.\n\nAnalysis indicates that most annotation tasks can be categorised on the basis of sensitivity to expertise of  annotators. This  is defined as the degree to which annotator expertise can affect the accuracy of annotation.  The  figure  below  considers  how  approaches  to  the  annotation  process  could  differ  with changing nature of the task.\n\n## Figure 31: Approaches to annotation\n\n| Sensitivity to degree of expertise   | Example of task                             | Motivation     | Potential annotators             | Verification mechanism                              |\n|--------------------------------------|---------------------------------------------|----------------|----------------------------------|-----------------------------------------------------|\n| Low                                  | Classification of object in presented image | GWAP, ML, ALTR | General population               | Multiple annotations                                |\n| High                                 | Classification of medical scans             | ML             | College students, professionals, | Multiple annotations, Verification by professionals |\n\nGWAP = Games with a purpose, ML = Mechanised labor for financial incentives, ALTR = Altruistic motivation\n\nSimple object classification or regional language translation are examples of tasks that have low barriers to  annotator  expertise.  However,  tasks  such  as  classification  of  medical  images,  requires  robust mechanisms to verify annotations, and also ensure verified traceability to identify poor annotators, and create mechanisms to reduce the effect of error generated.\n\nIn  India,  vast  public  datasets  are  available  at  organisations  such  as  ISRO  (India  Space  Research Organisation), ICAR (Indian Council of Agricultural Research), All India Radio (AIR) and NIC (National\n\n38  Luis von Ahn and Laura Dabbish , 200 4, Labeling images with a computer game\n\nInformatics Center) among others, but are unfortunately largely unused due to lack of proper annotation, prohibitive  cost  associated  with  the  process,  and  lack  of  proper  mechanisms  for  acquisition.  It  is envisaged that these datasets be used to create initial corpora of datasets, and encourage enterprise action in the area. A crowdsourced platform for annotation, on the lines of the highly popular government's citizen participation platform myGov.in , can be established by the government (to be operated by a private player) where seed data for annotation can be provided by the organisations mentioned above.\n\n## Deployable Model Marketplace\n\nGiven the level of market for AI tools, AI-as-a-Service business model, and a plethora of standardised problems faced by enterprises at scale, a deployable model segment in the marketplace, which brings together the buyers and suppliers of AI solutions, can greatly ease and expedite the adoption of AI. It would give visibility to the existing solutions, address information asymmetry and generate awareness amongst the relevant constituents. This AI-as-a-Service model segment would further build upon and synergise with the previous two layers of the marketplace model viz. data and annotation.\n\nMany  objectives  aimed  to  be  achieved  by  AI  algorithms  can  now  be  categorised  as  standardised problems. The following are some of the standardised and ubiquitous problems most of organisations face in their activity streams:\n\n- a) object detection in images or video streams;\n- b) conversational smart chatbots (text and speech);\n- c) speech-to-text and text-to-speech;\n- d) assistive diagnostic solutions;\n- e) language recognition and transcription;\n- f) contextual data mining to discover complex patterns;\n- g) price optimisation;\n- h) data collection, curation and annotation for specific business use;\n- i) supply and demand forecasting; and\n- j) server, app and web uptime/downtime prediction.\n\nHere models refer to the weights of the AI model trained on the data, which contains the predictive power. The inferencing of the model will require integration with other IT stacks and will be a customised process. Hence, this module of the marketplace should focus on defined deployable models that can be bought or sold. These models could either be bought and sold as data, or more likely, as a service or an API layer that can be charged per use.\n\nThe model marketplace will attract enterprises which can post problems which they are seeking to be solved using AI tools. Governments can be another party to announce specific problems which they intend to be solved. This demand side will be supported by the community of AI solution developers (consisting of startups, enterprises, individual researchers etc.) who will either showcase their existing developed  and  tested  product  suites,  or  customise  their  products  as  per  the  demand  placed  by enterprises. Academic researchers will be another major beneficiary of the marketplace as they will get valuable insights about problems faced by the industry and will get access to real industry data.\n\n## Figure 32: Stakeholders of NAIM\n\n## Private EnterpriseslPSUs\n\n## Governments\n\n- State problem statements\n- Provide industry data\n- Grand Challenges\n- Goals to be achieved\n- Specify terms and conditions\n- Anonymised datasets\n\n## Model Markeplace\n\n## Al Solution Developers\n\n## Academia doing core research\n\n- Can choose the set of problems\n- Understand real world problems\n- Deliver the solution\n- Core research applicability\n- Connect with other developers\n- Access to live industry data\n\nChallenges to adoption of a marketplace model for AI models are as follows:\n\n- a) Ensuring  quality: Marketplaces  require  continuous  monitoring  and  maintenance  of  quality.  For example, Amazon enforces this on vendors, and this goes beyond user ratings. Continuous scrutiny of products, sellers and buyers will be required.\n- b) Responsive product development required: The correct set of features of this platform will have to be discovered through iteration and adaptation, since there isn't precedent of such AI platforms to draw from.  The  platform  should  allow  for  trial  based  access  to  models  to  allow  for  iterative  product evaluation by buyers.\n- c) Sophistication of PSUs for data sharing and evaluation against specs: If data is to be provided over the  platform,  solution-seekers  will  need  to  know  how  to  provide  clean  datasets,  balance  data  to sufficiently represent infrequent occurrences, hide test data for evaluation of solutions while sharing training data, define appropriate specs, decide on appropriate evaluation methods, etc. The platform should be able to prescribe some basic standards for data sharing which will allow non-ML savvy PSUs to post problems and data.\n- d) Incentives  for  seeding  network  effect: The marketplace needs  a certain critical  mass  of  solution seekers and providers for gaining traction, to subsequently trigger network effects. This is true of all marketplaces. Incentives to attract both seekers and providers initially will need to be figured out. PSUs and government agencies may act as initial seeders/users of the platform with right incentives and mandates.\n- e) Potentially rich feature set needed for adoption: Such platforms can work well when there are systems like a credible rating system, payment escrow, search and sort to aid discovery, recommendation engines, etc. These will need to be established at NAIM also.\n\n## How can the stakeholders engage in NAIM?\n\nNAIM,  as  a  marketplace  for  enterprises,  will  encourage  all  business  entities,  government  agencies, startups,  AI  researchers,  system  integrators  and  academic  research  institutions  to  sign  up  on  the platform. Following may look like a snapshot of the marketplace where all the stakeholders engage in their respective activities on the platform:\n\n## Private / public sector enterprises\n\n- a) Hospitals: assistive diagnostics for physicians and radiologists.\n- b) Distribution companies: predict peak load, identify default prone customers.\n- c) Travel  and  tourism:  predict  peak  traffic  routes,  pricing  optimisation  customers,  offer  alternative routes/modes for traffic optimization.\n- d) Large industrial or real estate establishments: smart power management, utilities management, realtime failure detection and analysis.\n- e) Cinema: automated subtitles in regional languages (speech-to-text and translation).\n\n## Government authorities\n\n- a) Traffic  authorities  and police: real-time object detection in CCTV video feeds, face detection and object tracking, number plate detection.\n- b) Citizen  engagement:  conversational  chatbots  (speech  and  text)  in  Indic  languages  for  grievance redressal and query management.\n- c) Document  analysis  and  management:  text  recognition  and  sentiment  analysis  from  physical documents, analysis and summary.\n- d) All India Radio and Prasar Bharti: speech-to-text services for transcription and analysis.\n- e) Road and rail transport: face and eye movement detection (at the edge) for analysing driver fatigue and alarm signal, freight route optimization.\n- f) Agriculture: crop health and soil health analysis through remote sensing and IoT, farmer advisory services for input control and market demand prediction.\n\n## AI Solution Providers\n\n- a. India  AI  startups:  solutions  for  natural  language  processing  and  Indic  languages,  diagnostic assistants, image recognition/object detection.\n- b. Industrial Internet-of-Things: capturing data from machines and providing insights in areas of energy management, retail and inventory management.\n- c. On Edge AI devices: CCTV video feed monitoring and warning signals.\n- d. Academic Research Institutions.\n- e. Centers of Excellence: access to industry data for various use cases, model training and evaluation.\n\n## Box 19: Why the focus on PSUs\n\nPrivate enterprises run on the basis of market conditions and business drivers of revenues and profits. Due to either absence of markets or failure of efficient markets, many sectors of operation of PSUs are for achieving socio-economic goals of equality and distribution of wealth. There is not much incentive for PSUs for improving operational efficiency; they are further constrained by regulations imposed on publicly funded entities in activities of procurement, manpower hiring etc.\n\nTechnology  adoption,  especially  AI,  can  significantly  improve  operational  efficiency  and  drive  down operational costs incurred by PSUs operating in financially unsustainable but socially critical areas. This\n\nimprovement in operational costs will make them financially more viable. The NAIM allows the publicsector firms to directly scout for solutions which they can use in their business operations by significantly easing their information search for solutions. Additionally, PSUs and government agencies can also be the first driver of the network of the NAIM where initial pool of problems and industry data is shared by them which will attract several solution developers, especially startups and researchers to sign up for the platform.\n\n## Mechanisms to realise marketplace model\n\nIt is proposed that a decentralised data marketplace based on distributed ledger technology be set up. In the future, such a platform can enable advanced privacy preserving AI techniques such as multi-party computation directly on individual pieces of data.\n\nInstead of attempting to build such marketplaces, which it is not equipped to do so, the government should come out with enabling regulations, such that these marketplaces can be set up by private players. These would include regulations and standard permissions for any personal data being sold, standards for  anonymisation,  standards  for  ensuring  annotation  accuracy,  and  cybersecurity  standards  for  the module dealing with deployable models.\n\nAn  initial  effort  may  be  made  by  the  government  to  build  the  NAIM  platform  where  all  relevant stakeholders can sign up. However, open market competition will allow other marketplace operators to come in with innovative services and up-to-date data on suppliers and buyers on the marketplace. NAIM will lead to a more engaging collaboration, quicker and easier data access and accelerated adoption of AI among enterprises and public authorities in the country.\n\n## Ethics, Privacy, Security and Artificial Intelligence\n\n## Towards a 'Responsible AI'\n\nAI is going to be the tipping point in technological evolution of mankind, with human dependence on machines and algorithms for decision making never been such deep. Thus, any strategy document on promoting AI, necessarily needs to be conscious of the probable factors of the AI ecosystem that may undermine ethical conduct, impinge on one's privacy and undermine the security protocol. Appropriate steps to mitigate these risks need to be an integral part of any such strategy.\n\nWhile the issue of ethics would concern the biases that an AI system can propagate, the privacy concerns are largely on collection and inappropriate use of data for personal discrimination. Issue of security arises from the implications and the consequent accountability of any AI system.\n\nWhile addressing the above issues, one needs to be conscious of the potential vulnerabilities of our extant regulatory and societal structures which are dependent on human judgment and control, and thus subject  to  inherent  biases  and  discrimination.  Thus,  to  say  that  extant  decision  making  systems  individual, societal, regulatory or even judicial - are entirely devoid of these shortcomings would be a fallacy  as  these  are  dependent  upon  human  limitations  of  knowledge,  precedent,  rationale  and  bias (explicit or subconscious). Delegation of some aspects of that decision making to algorithms, which may well be able to ingest and process many more parameters as compared to a human, may likely result in systems  with  reduced  bias,  discrimination  and  improved  privacy  protection.  However,  even  if  a technological intervention helps us delegate that responsibility to an algorithm with improved outcomes, it is extremely important that we set much higher standards for privacy and protection in case of AI tools.\n\n## Ethics and AI\n\n## Fairness / tackling the biases AI\n\nBased on the premise that a large set of well-diversified data may be an accurate description of the world, most of the developer community takes a technocratic attitude that data-driven decision making is good and algorithms are neutral. However, this argument does not recognise the fact that the existing data may have biases, which may have got reinforced over time. The issue of fairness is at the forefront of discussion  in  academic,  research  and  policy  fora,  and  definitely  merits  a  combined  dialogue  and sustained research to come to an acceptable resolution. One possible way to approach this would be to identify the in-built biases and assess their impact, and in turn find ways to reduce the bias. This reactive approach, use-case based, may help till the time we find techniques to bring neutrality to data feeding AI solutions, or build AI solutions that ensure neutrality despite inherent biases.\n\n## Transparency / opening the 'Black Box'\n\nPresently, most AI solutions suffer from what is commonly known as the 'Black Box Phenomenon', with very little or no understanding of what happens in between and only the input data and results being the known  factors.  This  is  due  to  the  reliance  in  most  current  AI  systems  to  incrementally  improve  the performance as defined by a narrow set of parameters, with developer's emphasis being less on how the\n\nalgorithms  are  achieving  the  requisite  success.  However,  calls  for  explaining  the  decision-making process will gain momentum as AI systems are increasingly relied upon for decision making that has significant consequences for a large section of population.\n\nOpening the Black Box, assuming it is possible and useful at this stage (there is considerable debate on that as well), should not aim towards opening of code or technical disclosure - few clients of AI solutions would be sophisticated AI experts - but should rather aim at ' explainability '. With extended disclosure though, what needs to be balanced is whether the algorithm's parameter may induce the individuals and companies to change their behavior and in turn game the system. Clearly, more collaborative research is required in this area.\n\n## Box 19: Decoding Explainable AI\n\nExplainable Artificial Intelligence (XAI) is an evolving area of research which has received a lot of attention from the research community and the broader society alike. XAI project by DARPA is one such project which has shown substantial progress in explaining how and why machine learning algorithms work in a certain way. The aim of the XAI project, as described by DARPA is:\n\nThe Explainable AI (XAI) program aims to create a suite of machine learning techniques that:\n\n- \u00b7 Produce more explainable models, while maintaining a high level of learning performance; and\n- \u00b7 Enable  human  users  to  understand,  appropriately  trust,  and  effectively  manage  the  emerging generation of artificially intelligent partners.\n\nThe machine learning algorithms of tomorrow should have the built-in capability to explain their logic, enumerate their strengths and weaknesses and specify an understanding of their future behavior.\n\nFigure 33 : XAI Concept\n\nXAI is one of a handful of current DARPA programs expected to enable 'third-wave AI systems', where machines understand the context and environment in which they operate, and over time build underlying explanatory models that allow them to characterise real world phenomena.\n\nIn May 2018, XAI researchers are expected to demonstrate initial implementations of their explainable learning systems and conduct pilot studies of their Phase 1 evaluations. Full Phase 1 system evaluations are expected in November 2018.\n\nCredit : DARPA Explainable Artificial Intelligence (XAI)\n\n## Privacy and AI\n\nAI  models,  solutions  and  their  application  depend  on  generation,  collection  and  processing  of  large amounts of data on individual, entity and community behaviour. Data collection without proper consent, privacy of personal data, inherent selection biases and resultant risk of profiling and discrimination, and non-transparent nature of AI solutions are some of the issues requiring deliberation and proper recourse.\n\nHowever, the current debate on data usage have two distinct aspects. Firstly, there are concerns that companies are harvesting  significant  amounts  of  consumer  data  and  using  it  inappropriately  to  gain insights about consumers. Key here is that the consumer may not have access to these insights or the ability to derive value from them. Beyond compliance, companies can consider how to create awareness of how they use consumer information and the value they provide in return, which can build trust in their brand and services.\n\nSecondly, there are concerns that companies are amassing large data sets and thereby building an unfair competitive  advantage.  Datasets  themselves  have  little  intrinsic  value  without  the  ability  to  extract meaning from them. The dataset is a necessary, but not the only, component of delivering meaningful insights from data. Having the tools to analyse it and the experience to understand its meaning are the others. While those that have access to large datasets and by the nature of their business models have data  network effects,  which  enables  them  in  turn  to  build  a  first  mover  advantage  when  it  comes  to perfecting their algorithms and driving business value, this does not necessarily negatively impact the consumer.\n\n## Dealing with privacy issues\n\n- a. Establish  a  data  protection  framework  with  legal  backing: The  work  being  done  by  Justice Srikrishna Committee on data protection law is very opportune and timely. The 7-core principles of  data  protection  and  privacy  -  informed  consent,  technology  agnosticism,  data  controller accountability, data minimisation, holistic application, deterrent penalties and  structured enforcement - are quite comprehensive and should provide a strong privacy protection regime in the country once enacted.\n- b. Establish sectoral regulatory frameworks: Apart from having a central privacy protection law, due to diverse and fast changing nature of the technology, sectoral regulatory frameworks may also act as additional protection to user privacy and security. Japan and Germany have developed new frameworks applicable to specific AI issues such as regulating next generation robots and self-driving cars respectively.\n- c. Benchmark national data  protection  and  privacy  laws  with  international  standards: European Union's General Data Protection Regulation (GDPR) guidelines, which have been enforced in May  2018,  encourage  design  of  less-privacy  invasive  systems.  French  laws  give  a  right  to explanation for administrative algorithmic decisions, making it much more comprehensive than GDPR on administrative decisions. India's privacy protection regime will have to be continually updated to reflect understanding of new risks and their impact.\n- d. Encourage AI developers to adhere to international standards: Leaders and practitioners from across the world have come together to frame standards for safe and privacy preserving AI. The Global Initiative on Ethics of Autonomous and Intelligent Systems of the IEEE has a chapter on 'Personal Data and Individual Access Control in Ethically Aligned Design'. Indian enterprises and developers need to build these standards into AI design itself.\n- e. Encourage self-regulation: Data Privacy Impact Assessment Tools can be used by AI developers and enterprises adopting AI solutions to manage privacy risks.\n\n- f. Invest  and  collaborate  in  privacy  preserving  AI  research: New  mathematical  models  for preserving  privacy  are  being  researched  upon  where  risks  of  data  exploitation  and  personal identification (from an anonymised dataset) can be reduced by limiting information one can gain from released data, irrespective of amount of side information available otherwise. India should collaborate on areas of research like Differential Privacy, Privacy by Design, Safety-Critical AI and Multi-Party Computations which enable protection of privacy despite data sharing at a wide scale.\n- g. Spread awareness: Privacy has been termed as a fundamental right by the Supreme Court of India.  The  protection  of  this  right  with  its  multiple  facets  in  a  fast-changing  technological environment will not just depend on State enforcement but by also making the citizens aware of their rights and how they can protect them. People often unknowingly give consent to sharing their data which they would not have ordinarily done had they known the purpose their data were being put to. There is an urgent need to spread awareness among the individuals about the importance of consent, ethics and privacy while dealing with technology. A pan-India campaign in multiple languages, and inclusion of privacy rights in school and college curriculum can serve as effective mass outreach mediums to spread awareness.\n\n## Box 20: Differential Privacy\n\nA concept developed by Cynthia Dwork in 2006, Differential Privacy aims at preserving identifiable user information irrespective of any outside information the aggregator agency holds. The dilemma of giving personalised service to users based on their individualised preferences while at the same time ensuring that user is not uniquely identifiable, using the data collected or any other public data, is not solved by traditional privacy preserving methods of cryptography. Differential privacy describes a promise, made by a  data  holder,  or  curator,  to  a  data  subject:  'You  will  not  be  affected,  adversely  or  otherwise,  by allowing  your  data  to  be  used  in  any  study  or  analysis,  no  matter  what  other  studies,  data  sets,  or information sources, are available.' It addresses the paradox of learning nothing about an individual while learning useful information about a population.\n\n## Security in AI\n\nThe accountability debate on AI, which in most of the cases today is aimed at ascertaining the liability, needs to be shifted to objectively identifying the component that failed and how to prevent that in the future. An analogy can be drawn to how the airlines have become a relatively safe industry today. Every accident has been elaborately investigated, and future course of action has been determined. Something similar is needed to ensure safe AI.\n\nOne possible framework that can be mooted involves the following components:\n\n- a. Negligence test for damages caused by AI software, as opposed to strict liability. This involves self-regulation by the stakeholders by conducting damage impact assessment at every stage of development of an AI model.\n- b. As an extension of the negligence test, safe harbours need to be formulated to insulate or limit liability so long as appropriate steps to design, test, monitor, and improve the AI product have been taken.\n- c. Framework for apportionment of damages need to be developed so that the involved parties bear proportionate liability, rather than joint and several liability, for harm caused by products in which\n\nthe AI is embedded, especially where the use of AI was unexpected, prohibited, or inconsistent with permitted use cases.\n\n- d. Actual harm requirements policy may be followed, so that a lawsuit cannot proceed based only on a speculative damage or a fear of future damages.\n\nIndia can also take a leaf out of UK's playbook, where GBP9 million is being invested to establish a new Centre for Data Ethics and Innovation, aimed at enabling and ensuring ethical, safe and innovative uses of data, including AI. This will include engaging with industry to explore the possibilities of establishing data trusts to facilitate easy and secure sharing of data. A consortium of Ethics Councils at each Centre of Excellence may be set up to define the standard practice (on the lines of OpenAI charter). It would be expected that all Centres of Excellence adhere to standard practices while developing AI technology and products.\n\n## Actions for the Government\n\nAchieving the goal of #AIforAll requires long term and engaged institutional collaboration between all the stakeholders including the citizens. However, while playing the primary role in ensuring that this collaborative strategy succeeds, the government needs to be mindful of not crowding out the private sector. Role of the government thus needs to be one of a facilitator, an active promoter and wherever required, of an owner.\n\nThis section summarises the key recommendations, and the role of the government.\n\nFigure 34: Government's role\n\n| Area                     | Recommendation                                                                  | Government role                                                                                                                                                                                                                                                                                                                                                              |\n|--------------------------|---------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Research and Application | Research and Application                                                        | Research and Application                                                                                                                                                                                                                                                                                                                                                     |\n| Core Research            | Setting up Centre of Research Excellence for AI (COREs)                         | Identify academic institutions, provide fiscal support to establish COREs focusing on core technology research in AI.                                                                                                                                                                                                                                                        |\n|                          | PhD Scholarships                                                                | Institute National AI Fellowships to retain outgoing PhD students and attract researchers from foreign universities with attractive incentives and challenging projects.                                                                                                                                                                                                     |\n|                          | Inter-academia collaboration                                                    | Incentivise research collaboration between premier academic institutions through special grants while facilitating the formation of a global expert pool for core AI research.                                                                                                                                                                                               |\n|                          | Faculty Fellowships                                                             | Provide Faculty Fellowships or Chairs in academic institutes to promote research in AI.                                                                                                                                                                                                                                                                                      |\n| Applied Research         | Setting up of International Centres for Transformational AI (ICTAIs)            | Invite Expression of Interests (EoIs) from industry players to lead ICTAIs in various sectors (health, education, agriculture, smart mobility and smart cities), in collaboration with the government and academia. Build governance structure, provide fiscal support, formulate an IP model for ICTAIs and set up the ICTAIs under a PPP model through 'challenge method'. |\n|                          | Setting up ICTAI Inc., overarching entity for ICTAIs                            | Establish 'ICTAI Inc.' as either society / section 8 company, with initial contribution from government and private sector representation, to select and fund ICTAIs.                                                                                                                                                                                                        |\n| Common Compute Platform  | Setting up AI Research, Analytics and knoWledge Assimilation platform (AIRAWAT) | Set up a common cloud platform for Big Data Analytics and Assimilation with a large, power- optimised AI Computing infrastructure connecting all COREs, ICTAIs and other academic institutions with National Knowledge Network.                                                                                                                                              |\n| Intellectual Property    | Building an attractive IP regime for AI innovation                              | Set up a task force, comprising jointly of Ministry of Corporate Affairs and DIPP, to examine and                                                                                                                                                                                                                                                                            |\n\n|                              |                                                                                         | issue appropriate modifications to the IP regulatory regime pertaining to AI.                                                                                                                                                                                                                                                                                                                            |\n|------------------------------|-----------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Supra-national collaboration | Setting up CERN for AI                                                                  | Take the lead in bringing together the relevant parties to create People's AI, the CERN for AI - national governments, industry, academia and international community of researchers.                                                                                                                                                                                                                    |\n| Reskilling and Training      | Reskilling and Training                                                                 | Reskilling and Training                                                                                                                                                                                                                                                                                                                                                                                  |\n| Workforce                    | Promote formation of future service sector jobs                                         | Incentivise creation of service sector jobs of the future such as data annotation through tax holidays or inclusion in CSR activities.                                                                                                                                                                                                                                                                   |\n|                              | Recognition and standardisation of informal training                                    | Set up AI / Data Science training standards, as per National Skills Qualification Framework, and provide certifications to training institutes.                                                                                                                                                                                                                                                          |\n|                              | Promote employee reskilling                                                             | Incentivise investment in training of employees through tax breaks and grants for employers.                                                                                                                                                                                                                                                                                                             |\n| Colleges                     | Expansion of quality education in data science and AI                                   | Incentivise colleges / universities to adopt credit-bearing MOOCs in their curriculum.                                                                                                                                                                                                                                                                                                                   |\n|                              | Promote cross- disciplinary AI education                                                | Introduce Bridge Courses in AI for post- graduates in non-computer science or data science domains.                                                                                                                                                                                                                                                                                                      |\n| Schools                      | Introducing AI / ML in schools                                                          | Introduce AI modules in Atal Tinkering Labs.                                                                                                                                                                                                                                                                                                                                                             |\n| Overall                      | Continuously assess the changing nature of jobs                                         | Constitute a standing committee or taskforce to examine and report on changes in employment induced by adoption AI.                                                                                                                                                                                                                                                                                      |\n| Accelerating Adoption of AI  | Accelerating Adoption of AI                                                             | Accelerating Adoption of AI                                                                                                                                                                                                                                                                                                                                                                              |\n| Data Sharing                 | Opening up government datasets                                                          | Establish platforms for making datasets in the area of social sector (either collected during implementation of a scheme or in normal business processes) available for open public use in a machine readable form.                                                                                                                                                                                      |\n| Data Annotation              | Creating and making India specific annotated datasets public (on the lines of ImageNet) | 1. Catalyse partnerships with the various academic institutions and public / private agencies in making annotated India specific data available for advancing AI research. 2. Explore partnerships and co-fund building of large corpora of data across domains, as a means of laying the foundation for startups and enterprises to build applications and services tailor- made to the Indian context. |\n| Crowdsourcing Annotation     | Annotation of data - images, text, speech etc. via crowdsourcing                        | Announce grand challenge tasks for tagging of images, text or videos, and devising reward based mechanisms through data market place to aggregate the content from the various participating members.                                                                                                                                                                                                    |\n| Nation-wide adoption         | Enabling a multi- stakeholder owned and                                                 | Create governance guidelines, explore partnerships and co-fund the establishment of: 1. Data marketplace                                                                                                                                                                                                                                                                                                 |\n\n|                                                   | managed National AI Marketplace                                      | 2. Data annotation marketplace 3. Deployable model marketplace to develop the data supply ecosystem, ease collaboration, reduce time and cost of collecting & annotating data, and bring multiple solutions deployment at one place for scale and network effect.                           |\n|---------------------------------------------------|----------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Visibility in Collaboration                       | Making information search for collaborations easier                  | Set up an AI Database portal for easy dissemination of information on projects being implemented via collaboration among government-academia-industry-researchers- startups to enable resource matching.                                                                                    |\n| Awareness and Adoption in Government              | Making decision makers aware about transformative potential of AI    | 1. Workshops, live demonstrations, 2. AI Readiness Index to highlight best practices across states, and 3. Create Central-State shared fund for AI led development projects to be taken up by States.                                                                                       |\n| Government and PSUs as seeders for network effect | Making governments and PSUs leaders in adoption of social AI tools   | Help create a pipeline of AI research projects for the COREs, ICTAIs through grand challenges to be given by the government and PSUs. Incentivise public agencies to adopt and employ AI in delivering service through financial support; extra budgets for R&D; tax incentives and awards. |\n| Partnerships and Collaboration                    | Industry - Academia - Trade Bodies - Venture Capital Collaboration   | Encourage close collaboration between industry, academia, trade bodies and venture capital to implement 'AI+X' paradigm.                                                                                                                                                                    |\n| Startup Support                                   | Support systems for AI based startups                                | Establish incubation hubs and venture funds specifically for AI startups in collaboration with State Governments.                                                                                                                                                                           |\n| Responsible AI Development                        | Responsible AI Development                                           | Responsible AI Development                                                                                                                                                                                                                                                                  |\n| Ethical and Responsible Research in AI            | Making COREs and ICTAIs adopt ethical practices                      | Set up a consortium of Ethics Councils at each CORE and ICTAI to define the standard practices and monitor their adoption.                                                                                                                                                                  |\n| Privacy and Security                              | Instituting a data privacy legal framework                           | Address and implement data protection framework, which protects human rights and privacy without stifling innovation in India.                                                                                                                                                              |\n|                                                   | Creating sectoral regulatory guidelines                              | Collaborate with industry to come out with sector specific guidelines on privacy, security and ethics - on manufacturing, financial services, identity, telecommunication, robotics etc.                                                                                                    |\n|                                                   | Collaborating on privacy preserving technology research in AI        | Support COREs to do research in new mathematical models and technology for preserving privacy; encourage international collaboration.                                                                                                                                                       |\n| Sustainable Research                              | Setting up Centre for Studies on Technological Sustainability (CSTS) | Set up CSTS to address issues relating to ethics, privacy, legal aspects, social sustainability and global competitiveness of the technologies developed.                                                                                                                                   |\n\n## Financial implication of recommendations\n\nA greater understanding of the financial implications of the recommendations made in this report will be realised after consultations with the different stakeholders. Given the emphasis on research, skilling and creation of the ecosystem, the recommendations would involve a significant budgetary allocation by the government. This would be in addition to funds being provided as part of the Digital India and Startup India initiatives.\n\nNational Strategy for Artificial Intelligence\n\n95\n\n## Appendix I: Artificial Intelligence Explained\n\n## An Executive Guide to Artificial Intelligence 39\n\n## Machine Learning: a definition\n\nMost recent advances in AI have been achieved by applying machine learning to very large data sets. Machine learning algorithms detect patterns and learn how to make predictions and recommendations by  processing  data  and  experiences,  rather  than  by  receiving  explicit  programming  instruction.  The algorithms also adapt in response to new data and experiences to improve efficacy over time.\n\n## Machine learning provides predictions and prescriptions\n\nTypes of analytics (in order of increasing complexity)\n\nDescriptive\n\nPredictive\n\n- Describe what happened\n- Employed heavily across all industries\n- Anticipate what will happen (inherently probabilistic)\n\n## Prescriptive\n\n- Provide recommendations on what to do to achieve goals\n- Employed in data-driven organizations as a key source of insight\n- Employed heavily by leading data and Internet companies\n\nFocus of machine learning\n\n39 Replicated from McKinsey Analytics An Executive Guide to AI\n\n## Understanding the major types of machine learning\n\n|                 | Supervised Learning                                                                                                                                                                                                                                                                                                                                                                                                                                              | Unsupervised Learning                                                                                                                                                                                                                                                                              | Reinforcement Learning                                                                                                                                                                                                                                                                                                                                         |\n|-----------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| What it is?     | An algorithm uses training data and feedback from humans to learn the relationship of given inputs to a given output (e.g., how the inputs 'time of year' and 'interest rates' predict housing prices)                                                                                                                                                                                                                                                           | An algorithm explores input data without being given an explicit output variable (e.g., explores customer demographic data to identify patterns)                                                                                                                                                   | An algorithm learns to perform a task simply by trying to maximise rewards it receives for its actions (e.g., maximises points it receives for increasing returns of an investment portfolio)                                                                                                                                                                  |\n| When to use it? | You know how to classify the input data and the type of behavior you want to predict, but you need the algorithm to calculate it for you on new data                                                                                                                                                                                                                                                                                                             | You do not know how to classify the data, and you want the algorithm to find patterns and classify the data for you                                                                                                                                                                                | You don't have a lot of training data; you cannot clearly define the ideal end state; or the only way to learn about the environment is to interact with it                                                                                                                                                                                                    |\n| How it works?   | 1. A human labels every element of the input data (e.g., in the case of predicting housing prices, labels the input data as 'time of year,' 'interest rates,' etc.) and defines the output variable (e.g., housing prices) 2. The algorithm is trained on the data to find the connection between the input variables and the output 3. Once training is complete - typically when the algorithm is sufficiently accurate - the algorithm is applied to new data | 1. The algorithm receives unlabeled data (e.g., a set of data describing customer journeys on a website) 2. It infers a structure from the data 3. The algorithm identifies groups of data that exhibit similar behavior (e.g., forms clusters of customers that exhibit similar buying behaviors) | 1. The algorithm takes an action on the environment (e.g., makes a trade in a financial portfolio) 2. It receives a reward if the action brings the machine a step closer to maximising the total rewards available (e.g., the highest total return on the portfolio) 3. The algorithm optimises for the best series of actions by correcting itself over time |\n\n## Deep Learning: a definition\n\nDeep learning is a type of machine learning that can process a wider range of data resources, requires less  data  preprocessing  by  humans,  and  can  often  produce  more  accurate  results  than  traditional machine  learning  approaches.  In  deep  learning,  interconnected  layers  of  software-based  calculators known as 'neurons' form a neural network. The network can ingest vast amounts of input data and process them through multiple layers that learn increasingly complex features of the data at each layer. The network can then make a determination about the data, learn if its determination is correct, and use what it has learned to make determinations about new data. For example, once it learns what an object looks like, it can recognise the object in a new image.\n\nDeep learning can often outperform traditional methods % reduction in error rate achieved by deep learning vs traditional methods\n\n## Understanding the major types of deep learning\n\n|                 | Convolutional neural network                                                                                                                                                                                                                                                                                                                                                                                                                      | Recurrent neural network                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n|-----------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| What it is?     | A multilayered neural network with a special architecture designed to extract increasingly complex features of the data at each layer to determine the output                                                                                                                                                                                                                                                                                     | A multilayered neural network that can store information in context nodes, allowing it to learn data sequences and output a number or another sequence                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |\n| When to use it? | When you have an unstructured data set (e.g., images) and you need to infer information from it                                                                                                                                                                                                                                                                                                                                                   | When you are working with time-series data or sequences (e.g., audio recordings or text)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |\n| How it works?   | Processing an image 1. The convolutional neural network (CNN) receives an image - for example, of the letter 'A' - that it processes as a collection of pixels 2. In the hidden, inner layers of the model, it identifies unique features, for example, the individual lines that make up 'A' 3. The CNN can now classify a different image as the letter 'A' if it finds in it the unique features previously identified as making up the letter | Predicting the next word in the sentence 'Are you free \u2026..?' 1. A recurrent neural network (RNN) neuron receives a command that indicates the start of a sentence 2. The neuron receives the word 'Are' and then outputs a vector of numbers that feeds back into the neuron to help it 'remember' that it received 'Are' (and that it received it first). The same process occurs when it receives 'you' and 'free,' with the state of the neuron updating upon receiving each word 3. After receiving 'free,' the neuron assigns a probability to every word in the English vocabulary that could complete the sentence. If trained well, the RNN will assign the word 'tomorrow' one of the highest probabilities and will choose it to complete the sentence |\n\n## Appendix II: Global Country Strategy Review 40\n\n## What is happening around the world in AI?\n\nCountries  around  the  world  are  becoming  increasingly  aware  of  the  potential  economic  and  social benefits of developing and applying AI. For example, China and U.K. estimate that 26% and 10% of their GDPs respectively in 2030 will be sourced from AI-related activities and businesses. There have been tremendous activity concerning AI policy positions and the development of an AI ecosystem in different countries over the last 18 to 24 month - the USA published its AI report in December 2016; France published the AI strategy in January 2017 followed by a detailed policy document in March 2018; Japan released a document in March 2017; China published the AI strategy in July 2017; and the U.K. released its industrial strategy in November 2017.\n\nGovernments  are  reviewing  and  developing  their  position  on  the  following  areas  to  rapidly  grow  AI ecosystems:\n\n- a) Trigger demand in socially relevant sectors / segments\n- b) Gear up the supply side to fulfil demand - infrastructure (including data ecosystem, data stacks, high speed computing, etc.), talent, research\n- c) Set up an enabling system-governance, funding, partnerships\n\n## Trigger demand in socially relevant sectors\n\nDifferent countries have identified different focus areas for AI development and deployment:\n\n- a) the USA: areas of interest include economic prosperity, educational opportunities, quality of life, national and homeland security. The USA is focusing on growing the AI ecosystem through public spending on contracts, e.g., the US Department of Defense spent over USD2.4 billion on AIrelated technology in 2017 (2x increase from 2015).\n- b) China:  areas  of  interest  include  education,  healthcare,  energy,  transport,  quality  of  life,  city planning  /IoT  /  robotics.  China  is  focusing  on  developing  and  using  AI  for  delivery  of  public services  through  financial  support,  developing  talent  pipeline,  and  leveraging  international cooperation.\n- c) Japan: areas of interest include industrial productivity improvement, healthcare, medical care and welfare, mobility and information security. Japan is focusing on moving from the \"Industry 4.0\" paradigm to \"Society 5.0\" through the development of AI use cases for delivering public services.\n- d) France: areas of interest include healthcare, environment, transport mobility, defence-security. The government is planning to support AI startups through data availability, public spending and talent reskilling.\n\n40 McKinsey\n\n- e) U.K.: areas of interest include services, life sciences, agriculture and public-sector applications. The government is focused on growing innovative tech firms and making deals with the private sector to solve AI use-cases for delivery of public services.\n\n## Gear up the supply side to fulfil demand\n\n## Infrastructure\n\nMost governments have taken the following two action steps, in varying degrees of engagement, to upgrade infrastructure and build a data ecosystem:\n\n- a) Creation of a data-solutions marketplace\n- b) Invest in upgrading computing infrastructure, 5G networks, etc.\n\nMany countries have been reviewing a range of initiatives to facilitate creation of these marketplaces and upgrading computing infrastructure as well as connectivity. For example:\n\n- a) U.K. is exploring the feasibility of creating data trusts where the process of data sharing and storage is  underwritten  by  the  government.  There is  also  a  focus  on  defining  data  rights  for potential participants on the platform. There are plans to invest GBP1 billion to upgrade digital infrastructure including rolling out 5G and full-fibre networks.\n- b) Japan has announced expanding its R&amp;D tax exemption to include AI and big data as well as subsidies for building new robots with integrated AI. Its focus is on developing sector-specific platforms for public and private development of AI, followed by interlinking of different platforms to create an integrated AI ecosystem.\n- c) France  is  trying  to  streamline  its  innovation  track  with  \"innovation  sandboxes\"  which  would provide  an  open  platform  for  innovation  and  offer  resources  for  use  in  field-testing,  etc.  AI research institutes would have supercomputers specifically designed for AI usage and devoted to researchers and their economic partners during their shared initiatives.\n- d) China is focused on developing open source innovation platforms in partnership with private players  like  Baidu,  Alibaba,  and  Tencent.  Funding  is  available  for  5G  networks  to  enable \" intelligentisation \" and deployment of supercomputers, high performance semiconductor chips for AI use.\n- e) the USA is facilitating the creation of open source software libraries and toolkits, e.g., Open NLP, Weka toolkit, etc.\n\n## Talent\n\nCountries are also significantly increasing allocation of resources for STEM talent development through investment in universities, mandating new courses (e.g. AI and law), and offering schemes to retrain people.\n\n- a) U.K. is planning to increase its R&amp;D spend to 2.7% of its GDP by 2027, investing GBP42 million in  teacher development and GBP64 million in the retraining scheme including digital training. They are planning to make it easier for Tier-1 applicants working on AI subjects to obtain work permits and have a path to residency. They are also planning to build over 1,000 government supported PhD institutions by 2025 and set up a Turing fellowship to support an initial cohort of AI fellows.\n\n- b) France is trying to triple the number of AI graduates in three years by offering new courses and doubling the starting salary of researchers in public institutions. They also want to attract talent from across the world by offering substantial salary hikes, supporting improvements in the quality of life and reducing administrative formalities. Further, France and the US have labs and panels to assess the impact of AI on the workforce.\n- c) U.S.  is  planning  a  USD200  million  grant  for  STEM  education  focusing  on  computer  science matched by a USD300 million industry grant.\n- d) Japan has convened a ' national consultative body ' with 3 universities and the Japan business foundation to develop education programs for reskilling.\n- e) China  has  launched  a  five-year  university  program  to  train  at  least  500  teachers  and  5,000 students  working  on  AI  technologies.  The  program  is  a  collaboration  between  government bodies,  private  companies  and  universities  including  Sinovation  Ventures.  China  has  set  in motion a plan to develop 50 world-class teaching institutes and research institutions, 50 nationallevel high quality online open courses and 50 AI faculties by 2020 as part of the 'AI+X' program.\n\n## Research\n\nUniversities and research institutions from the USA, China and Japan have led the publication volume on  AI  research  topics  between  2010  and  2016.  In  the  US,  Carnegie  Mellon  University  (CMU), Massachusetts Institute of Technology (MIT) and Stanford are the top three universities in mean count of papers published across AI, systems, theory and interdisciplinary areas 41 .  These universities have been pioneers of AI research in the US and have more than 100 faculty members across different areas of AI research.\n\n- a) CMU has one of the oldest AI programs in the world - it was also one of the first to offer an undergraduate program. It has started the CMU AI program which is a collaboration forum for faculties across seven departments to work on multidisciplinary AI topics.\n- b) MIT has launched the Intelligence Quest to discover the foundations of human intelligence and its application to develop technology and tools.\n- c) Stanford has a AI4ALL program to increase diversity in AI research and education.\n\nThese three universities also feature on the top of any list on infrastructure and industry relations, e.g., IBM's Watson was developed in research collaboration with CMU:\n\n41 CSRankings.org\n\n| Research and course-work   | \u25aa 100+ faculty members across departments \u25aa 1000+ students engaged in AI research and education \u25aa Launched undergrad degree in AI \u25aa IBM's Watson , World champion robot soccer players, etc.   | \u25aa CS & AI lab has 1200+ people working on 900+ projects \u25aa Research ranges from algorithm and theory to applied AI and machine learning \u25aa Launched MIT Intelligence quest to discover the foundations of human intelligence and develop tools   | \u25aa 80+ faculty across 17 research focus areas \u25aa Andrew Ng is an adjunct associate professor for Machine learning \u25aa AI4ALL programme to increase diversity in the field of AI research   |\n|----------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Research facilities        | \u25aa State of the art robotics institute AI stack Design for AI lab                                                                                                                               | \u25aa Computational genomics lab \u25aa Distributed robotics lab \u25aa Vision lab                                                                                                                                                                           | \u25aa Stanford AI lab - Toyota center for AI research                                                                                                                                      |\n| Research partnerships      | \u25aa U.S. department of defence \u25aa NASA \u25aa Amazon \u25aa Google \u25aa Microsoft \u25aa Oculus                                                                                                                     | \u25aa $240 million investment from IBM for 10 years \u25aa 60+ member companies across telcos, finance, consumer electronics                                                                                                                            | \u25aa JD.com \u25aa Google \u25aa DiDi \u25aa Panasonic \u25aa UST Global \u25aa Tencent \u25aa Samsung                                                                                                                  |\n\n## Source: Press search\n\nChinese  universities  have  also  established  extensive  research  partnerships  with  Baidu,  Alibaba  and Tencent:\n\n- a) Baidu has announced a USD104 million partnership with the Peking University to further research in AI-related topics including information science and medicine.\n- b) An AI centre for law and legal issues was also unveiled at the Peking University to research on applications to improve legal efficiency while decreasing burden on judges.\n- c) Alibaba's Aliyun is working with the National Engineering laboratory on big data systems and software at the Tsinghua University.\n\nJapanese research has historically been hardware centric with robotics as one of the major focus areas of  development.  With  the  growing  demand  for  AI,  academia  in  Japan  is  rapidly  reorienting  itself  to theoretical  and  applied  research  in  the  sector.  Riken  Centre  for  Advanced  Intelligence  Project  and Advanced Industrial Science and Technology are the nodal research institutes for industry collaboration.\n\nWith AI led disruption of multiple industries, it is imperative for traditional industry players to increase speed  and  agility  of  insight  generation,  design  and  digitise  customer  journeys  as  well  as  develop efficiency in delivering journey transformations. Consequently, traditional players like GE and Merck are investing heavily to power their offering through AI interventions.\n\nMake existing operations more efficient\n\nOffer new services and products to existing customer\n\n- \u25aa Optimizing vaccine yield using ML on huge quantities of manufacturing data\n- \u25aa Tesla DC accelerator\n- \u25aa Deep Learning SDK\n- \u25aa Tegra mobile processor\n\nUses Al-driven predictive\n\nmaintenance tools in mining activities to\n\nhalve operations and\n\n- \u25aa Use Al and ML to predict ATV and to generate personalized recommendations\n\nmaintenance costs\n\n- \u25aa Watson, its Developer Cloud Platform and Watson based APIs \u25aa\n- \u25aa DL supercomputer DGX-I\n- \u25aa TrueNorth: chip structure for neural networks testing\n- Offers predictive analytics on buying potential and B2B pricing to current service users through Einstein\n- \u25aa Offers ML based healthcare big data platform for personalized health analysis and prediction\n\nDevelop disruptive business models\n\n- \u25aa Provides AI based face recognition software and robotics, e.g. KoalaCam\n\nSource: Press search\n\n## Set up an enabling system\n\n## Governance\n\nMost of the governments have established / utilised existing centralised umbrella body for budgetary planning of AI interventions and for formulating strategy and drafting policies. The National Science and Technology Council in the USA, Strategic Council for AI technologies in Japan, AI council in the U.K. are nodal  agencies  for  planning  and  designing  AI  initiatives.  These  central  bodies  typically  consist  of ministers, representatives from industry and nominated members from academia, e.g., the UAE has a Minister of State for AI. Similarly, for implementation and delivery of AI initiatives:\n\n- a) U.K.  has  a  dedicated  department  \"Office  of  AI\"  to  collaborate  with  multiple  departments, ministries and other stakeholders to deliver AI projects\n- b) France  has  a  shared  specialist  centre  of  30  members  to  help  provide  specific  inputs  and implement projects in other departments\n- c) In China and Japan, individual ministries and departments are responsible for implementing AI solutions across different sectors. For example,\n- i. China:  National  Development  and  Research  Commission,  Ministry  of  Science  and Technology, Ministry of Industry and Information Technology, Central Military-Civil Fusion Development  Commission  Office,  the  Central  Military  Commission  (CMC)  Science  and Technology Commission, and the CMC Equipment Development Department, etc.\n- ii. Japan: Ministry of Health, Labour and Welfare, Ministry of Land, Infrastructure, Transport and Tourism, and the Ministry of Agriculture, Forestry and Fisheries, etc.\n- \u25aa Developed an autopilot system allowing automatic emergency breaking and trafficaware cruise control\n- \u25aa Intelligent employee management, e.g. city-wise intelligent scheduling Face/voice recognition for cash deposit, customer profiling\n- \u25aa Amelia: NLP based intelligent customer services\n\n\u25aa\n\nWhile  due  importance  is  given  to  the  central  planning  and  implementation  entities,  the  role  of  local governments  in  solving  area-specific  challenges  through  application  of  AI  is  becoming  increasingly important. For example,\n\n- a) London  has  a  Smart  City  board  and  a  Chief  Digital  Officer  to  apply  best  practices  in  smart infrastructure and AI.\n- b) Over 19 Chinese cities, including Beijing, Shanghai, Hangzhou, Zhejiang, Tianjin, have been mandated to develop their own city-level AI agenda.\n\nUtilising AI-related solutions at the grass-roots level to solve real local challenges has the potential to truly democratise its use.\n\n## Funding\n\nGovernments are significantly increasing the funding for the AI ecosystem.\n\n- a) Apart from the increase in R&amp;D spend to 2.7% of its GDP, U.K. has created a GBP725 million industrial  strategy  challenge  fund,  GBP1.7  billion  for  transforming  cities  fund,  reforming enterprise investment scheme and venture capital trusts to unlock GBP7 billion over 10 years. Additionally, they have instituted a GBP2.5 billion investment fund at the British Business Bank to incubate tech startups and reforming rules for pension funds to mandate inclusion of AI in their investment portfolio.\n- b) Japan is planning to increase its science and innovation budget by JPY900 billion by 2020 for AI. Different Japanese ministries are also funding R&amp;D centres, e.g., Ministry of Economy, Trade and  Industry  (METI)  is  funding  R&amp;D  centres  at  the  National  Institute  of  Advanced  Industrial Science and Technology (AIST).\n- c) France is planning to spend EUR1.3 billion to develop AI-led interventions.\n- d) China is funding a massive growth in network infrastructure and creating megaprojects.\n- e) the USA is increasing its spend on AI-related contracts with the Department of Defense alone spending USD2.4 billion. Other large spenders include departments of agriculture, veteran affairs and homeland security.\n\nPrivate  companies  have  dominated  the  investment  in  AI  with  internal  corporate  investments  as  the biggest mode of spend. Other large sources of funding for startups within the sector include venture capital (VC) and private equity (PE). The two biggest areas funded are machine learning and computer vision, followed by natural language processing, autonomous vehicles and smart robotics.\n\n## Technology giants dominate investment in AI\n\n1\n\nInvestment in AI, 2016 $ billion\n\nInvestment by tech giants and other corporations\n\n- 1 Estimate  of 2016 spend by corporations to develop  and deploy  AI-based products. Calculated for top 35 high tech and advanced  manufacturing  companies investing  in AI. Estimate is based on the ratio  of AI spend to total  revenue  calculated  for a subset of the 35 companies.\n- 2 VC value is an estimate of VC investment in companies primarily  focused on AI. PE value is an estimate of PE investment in AI-related companies. M&amp;A value is an estimate of AI deals done by corporations. 'Other' refers to grants and seed fund investments.  Includes only disclosed data available in databases,  and assumes that all registered deals were completed within the year  of transaction.  Compound  annual  growth  rate values  rounded.\n- 3 M&amp;A and PE deals expressed by volume;  VC deals expressed by value.\n\nSource: McKinsey Global Institute report on 'Artificial Intelligence and the next digital frontier'\n\nDigital  native  companies  in  the  USA  and  China  are  exploring  new  areas  for  the  development  and application  of  AI  to  solve  customer-centric  use-cases.  These  range  from  developing  smart  AI  game systems like Google's AlphaGo, to virtual assistants like Amazon's Alexa and Apple's Siri. There is also a push to develop open source AI platforms like Google's TensorFlow to Baidu Brain. Alibaba has also partnered  with  the  Malaysian  government  to  launch  the  first  smart  city  AI  platform  outside  China (Hangzhou was the first example). Apart from internal incubation and development, these tech giants and VCs are also investing heavily in startups focused on AI.\n\n| Make existing operations more efficient              | \u25aa Customized search results \u25aa Customized ad ranking \u25aa Google cloud platform                                                       | \u25aa Developed Amazon web services for cloud computing \u25aa Customer services \u25aa Warehouse management                       | \u25aa Customized search results and ad ranking \u25aa 020: order prioritization and route planning                                                                                | \u25aa Leverages Al to improve operational efficiency and customer experience of e- commerce ecosystem                                                                            |\n|------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Offer new services and products to existing customer | \u25aa Provides open source Al platform Tensorflow \u25aa Offers customized ASIC for ML TPU \u25aa Online translation \u25aa Graphic and voice search | \u25aa Integrates Al into cloud services offering \u25aa Provides mobile robotic based automated storage and retrieval systems | \u25aa Opens Al technology platform Baidu Brain \u25aa Offers Al solutions in finance, healthcare , and traffic & transportation industries \u25aa Netflix like streaming service iQiyi | \u25aa Launches Al data apps construction platform \u25aa Provides enterprise level Al solutions in with Ali-cloud as foundation \u25aa Tmall genie - voice controlled smart home assistant |\n| Develop disruptive business models                   | \u25aa Virtual assistant: Google Now \u25aa Game Al system: AlphaGO \u25aa Self-driving car system \u25aa Smart home: Google Home                     | \u25aa Virtual assistant - Alexa \u25aa Polly - life-like speech \u25aa Rekognition - image analysis \u25aa Lex - conversational engine  | \u25aa DuerOS: Virtual assistant \u25aa Little fish - voice controlled family robot \u25aa Apollo - set of artificial intelligence driven tools for self- driving vehicles              | \u25aa Smart city AI platform developed for Kuala Lumpur \u25aa Smartmesh connectivity solution supports many-to-many bluetooth mesh technology                                        |\n\nSource: Press search\n\n## Partnerships\n\nThese countries are also leveraging different combinations of public-private-academia to develop and promote AI:\n\n- a) In the U.K., a public-private-academia partnership was established as \"sector deals\" to improve productivity. The expansion of tech parks through the tech nation program is also an example of public-private partnership. The government is also trying to develop regional R&amp;D partnerships between universities, large corporations and investors in the sector, e.g., BT has partnered with 15 universities across the U.K. on creating AI powered, next generation data infrastructure.\n- b) Japan has instituted new programs to triple research-industry collaboration by 2025 (including co-locating industry employees with researchers). They have also signed collaboration pacts with the US and Israel for technology transfer and joint R&amp;D projects.\n- c) Japan is trying to foster solutioning of challenges faced by large corporation by connecting them with  startups,  e.g.,  Japan  Open  Innovation  Council,  New  Energy  and  Industrial  Technology Development Organisation (NEDO) pitch, etc. to connect startups with corporations.\n- d) China has formed a \"national team\" with large private players including Baidu and Tencent to undertake fundamental and applied research across different AI topics, e.g., Baidu is working with the Chinese government to develop brain-inspired intelligent technology\n\nMeanwhile, recent developments in the digital ecosystem have triggered a discussion on implications for regulations on data protection and privacy. EU has released a comprehensive legal framework for data protection  called  General  Data  Protection  Regulation  (GDPR).  This  framework  details  the  rights  of individuals (consent, data portability, etc.), obligations of businesses (define and share how they will use personal data, norms for data processing, data protection impact assessment, etc.) and plan of action in case of a data breach (data breach notifications, compensation to individuals, penalties, etc.). As AI grows\n\nrapidly  across  geographies  and  sectors,  governments  across  the  world  are  actively  working  on developing data privacy and security regulations.\n\nFurthermore, governments are playing an active role in developing AI ecosystems to capitalise on the social, economic benefits and establish leadership in the field of AI.\n\n- a) Social  benefits :  Governments  are  focusing  on  sectors  ranging  from  education  to  healthcare, agriculture to transport mobility with a view to significantly improve quality of life of its citizens.\n- b) Economic  benefits :  Governments  have  defined  substantial  economic  aspirations  through development and implementation of AI. While China aims to grow AI's contribution to GDP to 26 percent and the U.K. by 10 percent by 2030, Japan has estimated the economic impact of AI application at JPY 1.1 trillion by 2045.\n- c) Leadership in AI :  Given  the  rapid  pace  at  which  AI  technology  is  evolving,  governments  are setting themselves up for success with support from the private sector and academia. However, the models of engagement vary depending on starting points, challenges and appetite for public funding and regulation.\n\nIf some countries decide to wait for a few years to establish an AI strategy and put in place the foundations for developing the AI ecosystem, it seems unlikely that they would be able to attain and match up to the current momentum in the rapidly changing socio-economic environment. Therefore, the need of the hour is to develop a policy framework that will help set up a vibrant AI ecosystem in India.\n\nThe following table highlights funding commitments made by governments across the world to promote AI research and application:\n\n| Country   | Area                                      | Funding                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |\n|-----------|-------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Belgium   | \uf0b7 AI research in academia                 | \uf0b7 Two funding agencies - FWO(Flanders) and FNRS (Wallonia). \uf0b7 FNRS spent approximately EUR1.8 million per year in the period 2011-2017 and FWO approximately EUR6.7 million per year. \uf0b7 Between 2011 and 2017 around 67 out of 241 AI-related applications (representing 2.3% of all applications) submitted to FNRS were funded, and 175 out of the 832 AI-related applications sent to FWO were also accepted.                                                                                                                                                                                            |\n| China     | \uf0b7 AI startups                             | \uf0b7 In China, governments play a deliberate and explicit role in funding scientific research (giving USD800,000 to USD1 million in subsidies to AI companies).                                                                                                                                                                                                                                                                                                                                                                                                                                                |\n| Denmark   | \uf0b7 AI startups                             | \uf0b7 The Innovation Fund Denmark has provided EUR20 million as funding for big data in 2017.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |\n| Germany   | \uf0b7 AI basic research \uf0b7 Applied AI research | \uf0b7 With an annual budget of more than EUR3 billion, the German Research Foundation (DFG) is the main source of funding for basic research in AI in Germany. \uf0b7 In the past thirty years (1988-2018), applied AI has been funded continuously by the Federal Ministry of Education and Research (Bundesministerium f\u00fcr Bildung und Forschung - BMBF), for a total of EUR215 million. \uf0b7 Current annual investment in AI is EUR40-50 million. Between 1988 and 2017, DFKI received EUR200 million from BMBF. There is additional funding allocated to universities and other research centres by the government. |\n\n|             |                                                        | \uf0b7 BMBF and the Federal Ministry of the Economy and Energy (Bundesministerium f\u00fcr Wirtschaft und Energie - BMWi) are currently funding a selection of Industry 4.0 projects such as Mixed Reality Production 4.0, for a total of EUR550 million since 2013. \uf0b7 The program Smart Services World II aims to address areas where digitalisation could have an impact for the economy. It has funding of EUR50 million from BMWi (2017-2021).    |\n|-------------|--------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| Ireland     | \uf0b7 AI startups                                          | \uf0b7 The Irish government spends, through the Irish Economic Development Agency (IDA), Enterprise Ireland, and Science Foundation Ireland, over EUR700 million on R&D annually. Enterprise Ireland funds Irish companies and is the largest VC fund in Europe.                                                                                                                                                                                 |\n| Israel      | \uf0b7 AI ecosystem - partnerships                          | \uf0b7 The Israeli government has several grant funding schemes for promoting collaboration and knowledge transfer between academia and industry, such as Magnet and Magneton. \uf0b7 The Israeli Science Foundation has a rich history of funding AI projects in academia that provide researchers with a high degree of freedom in their research compared to other countries.                                                                      |\n| Netherlands | \uf0b7 AI research - academia                               | \uf0b7 The main funding body for academia in the Netherlands is the Netherlands Organisation for Scientific Research (NWO). Since 2002, NWOhas funded 119 research projects containing the term 'artificial intelligence' and 142 research projects containing the term 'machine learning'. In 2015, a programme on 'Natural Artificial Intelligence' was launched, which has funded five projects.                                              |\n| Spain       | \uf0b7 AI in industry                                       | \uf0b7 Since 2016, EUR170 million has been invested in the Industry 4.0 project Industria Conectada 4.0 under the National R&D and Innovation Plan. Industry 4.0 focuses on skills, cooperation, industrial adoption, and digital technologies (robotics, AI, cloud, cybersecurity, big data).                                                                                                                                                   |\n| Sweden      | \uf0b7 AI research - academic \uf0b7 AI ecosystem - partnerships | \uf0b7 The Research Institutes of Sweden is currently setting up an AI centre (RISE AI), with an initial turnover of SEK50 million (approx. EUR4.9 million) per year in R&D, over 4 startups, more than 50 experts and around 30 active industrial collaborations (e.g. Nokia, Ericsson, ABB, and H&M). \uf0b7 Vinnova, Sweden's Innovation Agency, has funded 190 AI-projects totaling SEK398 million (approx. EUR38.9 million) in the past 6 years. |\n\n## Appendix III: Data Ecosystem\n\n## A key enabler\n\nThe true value of AI will not be found in, say, an algorithm or a neural network itself.\n\nToday, the leading algorithms are available as software packages either commercially or open source. Storage infrastructure and huge computing resources has become commoditised and easily available from various vendors in the market. The challenge still remains with data - access to high quality, reliable data along with appropriate mark-ups still remains a challenge.\n\nUnderstanding key issues related to data thus becomes crucial while evolving the national AI strategy.\n\nAccess  to  vast  quantities  of  data is  vital  for  AI  to  be  effective.  Large  platforms  and  technology companies who create monoliths of high volumes of data have a distinct advantage compared to smaller companies and startups, thus leading to a very skewed market.\n\nConvergence of data is another challenge, with much data being either 'dark' (unstructured, not readily usable) or disparate (hard to combine). Organisations need to be able to converge and make sense of data from sources such as Internet of Things (IoT) sensors and social networks. The greater the data density and variety, the greater are the chances of finding 'unknown unknowns' - relationships that were not known to exist or were not looked for at all.\n\nData annotation is  crucial,  given  the  requirement  of  tagged  or  annotated  data  required  for  machine learning or AI. In most cases, data needs to be annotated manually or in semi-automated ways for the purpose of machine learning, even though sometimes annotated data can be generated automatically from the source. Technological advancements in data annotation systems are not at a level where manual annotation can be replaced.\n\n## Box 21: ImageNet\n\nThe ImageNet database has led to huge advancement in the field of image recognition. The ImageNet database was presented for the first time as a poster at the 2009 Conference on Computer Vision and Pattern  Recognition  (CVPR)  in  Florida  by  researchers  from  the  Computer  Science  department  at Princeton University. The ImageNet project is a large visual database designed for use in visual object recognition software research. Over 14 million URLs of images have been hand annotated by ImageNet to indicate what objects are pictured; in at least 1 million of the images, bounding boxes are also provided. ImageNet  contains  over  20,000  ambiguous  categories;  a  typical  category,  such  as  \"balloon\"  or \"strawberry\", contains several hundred images. The database of annotations of third-party image URLs is freely available directly from ImageNet; however, the actual images are not owned by ImageNet.\n\nThe 2010s saw dramatic progress in image processing. In 2011, a good ILSVRC classification error rate was 25%. In 2012, a deep convolutional neural net achieved 16%; in the next couple of years, error rates fell  to  a  few  percent.  With  the  2012  breakthrough  \"combined  pieces  that  were  all  there  before\",  the dramatic quantitative improvement marked the start of an industry wide AI boom. By 2015, researchers reported that software exceeded human ability at the narrow ILSVRC tasks. However, as one of the challenge's  organisers,  Olga  Russakovsky,  pointed  out  in  2015,  the  programs  only  have  to  identify\n\nimages  as  belonging  to  one  of  a  thousand  categories;  humans  can  recognise  a  larger  number  of categories, and also (unlike the programs) can judge the context of an image.\n\n## Overcoming issues related to data access\n\n- a) Government data sharing : Government of India has large amounts of data lying in silos across ministries. The government can launch a mission of making all these data available for public good after undertaking proper privacy checks. For example - climate data, non-strategic remote sensing data, regional language speech (from All India Radio), soil health data etc.\n- b) Corporate data sharing : Corporates based in India may be mandated to share their data for social good. For example, sharing transportation pattern of individuals / mass transits, collected by service providers and aggregators, can help the city planners help in planning routes, predicting and managing traffic.\n- c) Consent based data sharing: Lot of the data about individuals are personal in nature and hence cannot be shared by third party who have the access to these data - like financial institutions or hospitals. Upon proper and informed consent from the citizens, these anonymised data may be shared for the purpose of artificial intelligence and data analytics.\n- d) Digitised and crowdsourced collection of data by government : Huge amounts of money and time is  spend  every  few  years  to  carry  out  the  household  consumption  survey.  A  mechanism,  as adopted by online social networks, to incentivise individuals to share details of their consumption pattern  via an app can greatly reduce the cost of manual surveys and lend itself to big data analysis and AI applicability.\n\nOften AI based transformation follows as a next step to digital transformation - in that case, the data for the  purpose  of  learning  exists  with  the  organisation.  For  example,  a  financial  institution  would  have access to large amounts of historic customer records to develop the AI system for predictive loan defaults.\n\nPeople or organisations outside the data ecosystem might have limited access to this data. For example, a new company entering in the space of rural financing would need access to huge amounts of customer data along with information on the default rates to develop the risk based lending model. To bridge this access gap, some of these datasets are made available by the research communities as shown in the tables below.\n\n## Datasets for Computer Vision and Image Processing\n\n| Dataset Name         | Dataset Size         | Publisher                               | Publisher Type       | Country   |\n|----------------------|----------------------|-----------------------------------------|----------------------|-----------|\n| MNIST                | 60,000 United States | Census Bureau                           | Institute and Bureau | USA       |\n| CIFAR 10 & CIFAR 100 | 60,000               | Canadian Institute for Advance Research | Research Institute   | Canada    |\n| ImageNet             | 14,000,000           | Princeton University                    | University           | USA       |\n| LSUN                 | 10,000               | Princeton University                    | University           | USA       |\n| Pascal Voc           | 5,00,000             | Oxford University                       | University           | UK        |\n| SVHN                 | 6,00,000             | Stanford University                     | University           | USA       |\n| MS COCO              | 2,50,000             | Google, CMU, etc.                       | Research Consortium  | USA       |\n| Visual Genome        | 108,000              | Stanford University                     | University           |           |\n\nLabeled Faces In The Wild\n\n13,000\n\nUniversity of Massachusetts\n\nUniversity\n\nUSA\n\n## Datasets for Natural Language Processing and Text Mining\n\n| Dataset Name                 | Dataset Size   | Organisation                           | Org. Type               | Country   |\n|------------------------------|----------------|----------------------------------------|-------------------------|-----------|\n| TREC                         | 120K-3.6M      | NIST Information Technology Laboratory | Research                | USA       |\n| WikiText                     | 100 million    | Salesforce                             | Company                 | USA       |\n| Question Pairs               | 4,00,000       | Kaggle                                 | Company                 | USA       |\n| SQuAD:                       | 1,00,000       | Stanford                               | University              | USA       |\n| CMU Q/A Dataset:             |                | Carnegie Mellon University             | University              | USA       |\n| Maluuba Datasets:            | 120K           | Microsoft                              | Company                 | USA       |\n| Billion Words:               | 1 Billion      | Google                                 | Company                 | USA       |\n| Common Crawl:                | 1.81 billion   | Common Crawl                           | Non-Profit Organisation | USA       |\n| bAbi:                        | Multiple       | Facebook AI Research (FAIR)            | Company                 | USA       |\n| Stanford Sentiment Treebank: | 107,785        | Stanford                               | University              | USA       |\n| 20 Newsgroups:               | 20,000         | CMU & UCI                              | University              | USA       |\n| Reuters                      | 21578          | AT&T Labs                              | Research                | USA       |\n| IMDB                         | 25,000         | Amazon                                 | Company                 | USA       |\n| UCI's Spambase               | 4601           | UCI                                    | University              | USA       |\n\nIt is clearly evident that universities and research laboratories in the USA in particular, have been the leaders in sharing these datasets, which has contributed significantly in developing a strong AI research base in the USA. The Government of India can also play a crucial role, working with the various academic institutions, in making annotated India specific data available for advancing AI research.\n\n## Appendix IV: What Do the Markets Say?\n\n## Approaches to evaluating focus sector areas\n\nOne way of evaluating which sectors to focus on is to follow the money i.e. which sectors have seen the most amount of VC funding in AI space. Venture Capital funding, in a sense, is a long-term view on a technology / solution, given that the median time to exit for most VC investments is more than 8 years.\n\nThe AI ecosystem is essentially based on 5 pillars:\n\n- a) policy makers,\n- b) large companies,\n- c) startups,\n- d) universities and\n- e) multi-stakeholder partnerships.\n\nTaking into account this perspective as well, sectors that are most pursued by VCs could be a good proxy for sectors to be focused on, for well-funded startups are capable of pushing the technology frontiers and bringing ambitious solutions to fruition.\n\nAI remains the most active industry vertical in VC funding landscape, with an aggregate total investment of more than USD31 billion globally across more than 3,600 disclosed deals in past 5 years 42 . Healthcare has been the hottest area of AI startup investments, with USD2.5 billion in VC investments in last 5 years, much of which has been fueled by medical imaging and diagnostics companies. Other active healthcare sub-segments include clinical trials &amp; drug discovery and insights and risk analytics. The healthcare AI space has also been dominated by strong public partnerships in diagnostics: nVIDIA and GE, Google Deep Mind and NHS, AliHealth and AstraZeneca.\n\nAnother way to evaluate this could be to see where the large global tech companies (Google, Apple, Facebook, Amazon and Microsoft, popularly termed GAFAM ,  as well as Alibaba and its peers Baidu, Tencent and Xiaomi, popularly termed BATX in China) are most invested in. Among GAFAM, looking at the mentions of 'Machine Learning' in respective earning transcripts since 2013, Google emerges as the company that has been highlighting its progress in AI / ML more than others.\n\nTracking  Google's  AI  /  ML  initiatives,  it  appears  that  the  Mountain  View  based  company  is  heavily invested in Healthcare. Indeed, GV, formerly Google Ventures, the venture capital investment arm of Alphabet  Inc.,  has  tripled  its  investments  in  Healthcare  deals  in  2017  compared  to  2013.  Google's approach to using AI to tackle diseases and lifestyle management is based on three pillar approach :\n\n- a) Data generation: digitisation and consolidation of data through wearables and medical imaging etc.\n\n42 CB Insights: 'Artificial Intelligence Trends To Watch In 2018' and 'Up And Up: Healthcare AI Startups See Record Deals'\n\n- b) Disease detection\n- c) Disease / lifestyle management\n\nGoogle  is  currently  heavily  focused  on  eye  diseases  (diabetic  retinopathy),  diabetes  (detection  and management), heart disease (including hearth condition monitoring), Parkinson's disease and multiple sclerosis. Google's AI algorithm for diabetic retinopathy, trained on 128,000 images, was on-par with a panel of ophthalmologists. Other areas that Google may be exploring include Chronic Lower Respiratory Disease, several types of cancer, mental and behavioral health and aging.\n\nGoogle is also invested in powering the healthcare data infrastructure, as evident in its USD625 million acquisition of Apigee,  which  is  building  healthcare  APIs  catering  to  the  latest  health  records interoperability protocols. Similarly, Deep Mind is building a data  infrastructure to enabling building of apps that can analyse different data elements. Furthermore, Google is also building health data streams that third parties could integrate in their research. Another one of Google's interesting foray in healthcare AI is developing tools for doctors that are designed to augment their expertise.", "metadata": {"country": "India", "year": "2018", "legally_binding": "yes", "binding_proof": "Mandated by the Hon\u2019ble Finance Minister in the 2018-19 budget speech, NITI Aayog was directed to establish the National Program on AI, guiding national R&D and policy direction", "date": "01/06/2018", "regulator": "NITI Aayog", "type": "law", "status": "enacted", "language": "English", "use_cases": "[2, 3]"}}
{"_id": "686aea40383c6b855905e79e", "title": "Report on AI Governance Guidelines Development", "source": "https://indiaai.s3.ap-south-1.amazonaws.com/docs/subcommittee-report-dec26.pdf", "text": "## Report on AI Governance Guidelines Development\n\nIndia's  unique  demographic  and  socio-economic  landscape  presents  significant opportunities  for  AI-driven  growth.  However,  to  ensure  inclusive  progress  and address the associated risks, it is crucial to establish robust  governance mechanisms. Given the diversity of India\u00d5s needs, a whole-of-government approach is essential for effectively managing AI's potential and challenges.\n\nAccordingly, the Government of India has approved the IndiaAI Mission on 7 th  March 2024,  with  a  budgetary  outlay  of  INR  10,371.92  crore.  The  IndiaAI  mission  will establish  a  comprehensive  ecosystem  catalysing  AI  innovation  through  strategic programs and partnerships across the public and private sectors. By democratizing computing  access,  improving  data  quality,  developing  indigenous  AI  capabilities, attracting top AI talent, enabling industry collaboration, providing startup risk capital, ensuring  socially impactful  AI projects and  bolstering ethical  AI, it will drive responsible, inclusive growth of India's AI ecosystem.  The Mission will be implemented  through  its  seven  key  pillars  of  IndiaAI  Compute  Capacity,  IndiaAI Application  Development  Initiative,  IndiaAI  FutureSkill,  Safe  &amp;  Trusted  AI,  IndiaAI Innovation Centre, IndiaAI Datasets Platform, and IndiaAI Startup Financing.\n\nThe Safe &amp; Trusted AI pillar aims to drive the responsible development, deployment and  adoption  of  AI  by  creating  indigenous  tools,  self-assessment  checklists,  and governance frameworks. To further this mandate, IndiaAI had issued an Expression of  Interest  (EoI)  to  support  Safe  &amp;  Trusted AI  Projects  across  a  range  of  themes, including Machine  Unlearning,  Synthetic  Data  Generation,  AI Bias Mitigation, Privacy-Enhancing  Strategy,  Explainable  AI  Framework,  AI  Governance  Testing Frameworks, AI Ethical Certification Framework and Algorithm Auditing Tools. After a comprehensive  evaluation  process,  eight  projects  have  been  selected  in  the  first round  of  the  EoI  and  are  under  implementation.  Following  the  success  of  this initiative, IndiaAI has also launched the 2nd round of the Expression of Interest (EoI), inviting  organizations  to  submit  proposals  on  themes,  including  Watermarking  and Labelling,  Ethical  AI  Frameworks,  AI  Risk  Assessment  &amp;  Management,  Stress Testing Tools, and Deepfake Detection Tools.\n\nIn  further  recognition  of  the  need  for  an  India-specific  approach  to AI  governance, under  the  chairmanship  of  the  Principal  Scientific Advisor  (PSA)  of  India,  a  multistakeholder Advisory Group has been constituted to undertake development of an \u00d4AI for  India-Specific  Regulatory  Framework\u00d5  including  representatives  from  relevant ministries. The  Advisory Group  was  tasked with providing guidance on  AI governance  and  offering  insights  for  the  necessary  regulatory  oversight  to  enable sustainable and ethical development of AI technologies.\n\nUnder the guidance of the Advisory Group, a Subcommittee on \u00d4AI Governance and Guidelines Development\u00d5 was constituted to provide actionable recommendations for AI  governance in  India. The  Subcommittee\u00d5s  mandate  was  to  examine  key  issues related to AI governance in India, conduct a gap analysis of existing frameworks, and propose recommendations  for a comprehensive  approach  to ensure the trustworthiness and accountability of AI systems in India.\n\nThe  Subcommittee\u00d5s  report  emphasizes  the  need  for  a  coordinated,  whole-ofgovernment approach to ensure effective compliance and enforcement as India\u00d5s AI landscape  continues  to  evolve.  Based  on  its  extensive  deliberations,  the  report outlines a series of recommendations that aim to shape the future of AI governance in India. These recommendations are based on a careful review of the current legal and regulatory context and reflect the Subcommittee\u00d5s independent perspective on fostering AI-driven innovation while safeguarding public interests.\n\nThe Ministry of Electronics and IT acknowledges the valuable recommendations put forward  by  the  committee  to  support  its  ongoing  initiatives  on  AI  governance  as applicable.  In  evaluating  these  recommendations,  the  Ministry  is  publishing  the report for wider public consultation to invite feedback to inform the development of a comprehensive AI governance mechanism that advances India\u00d5s AI aspirations while protecting the interests of all citizens.\n\n## Report\n\n## I. BACKGROUND\n\nThe sub-committee was constituted  by  the  Ministry  of  Electronics  and  Information Technology ( MeitY ) on November  9,  2023, to analyse gaps and offer recommendations  for  developing  a  comprehensive  framework  for  governance  of Artificial Intelligence ( AI ).\n\n## II. GOVERNANCE OF AI\n\nAI  refers  to  a  range  of  technologies  which  can  be  used  for  both  harm  and  good. Governing the use of AI is driven by the need to minimise risks and harms. While AI has been around for many decades, over the last decade, five major developments that  have  brought  AI  into  households  and,  consequently,  into  the  lexicon  of policymaking, regulation, and governance:\n\n- \u221e Significant technical progress in the field of machine learning;\n- \u221e Access to much larger datasets for the purposes of training AI systems;\n- \u221e Advancements in computation performance and scale;\n- \u221e Advancement in natural language processing and capabilities; and\n- \u221e Widespread  availability  of  connected  devices  to  deliver  apps  employing  AI systems to users at scale.\n\nThe combination of these factors has given rise to a new paradigm for developing and  deploying AI  systems  \u00d0  the  creation  of  \u00d4\u00d2foundation  models\u00d3  that,  after  being trained  on  a  huge  amount  of  broad  data,  can  be  adapted  to  many  applications., including \u00d2generative AI\u00d3 tools accessible to end-users to perform a variety of tasks.\n\nAI  systems  today  can  perform  complex  tasks  without  active  human  control  or supervision. This raises the concern that AI might generate outputs that humans may not expect or understand. It can be difficult to understand how different components within  an  AI  system  interact  with  each  other  and  which  specific  component  is responsible for any potential harm caused. Detecting design defects of an AI system can be challenging, especially for downstream users of the system.\n\n## A. AI Governance Principles\n\nSince 2016, several organisations from government, industry, and civil society have published \u00d2principles\u00d3 for \u00d2responsible and trustworthy AI ( RTAI )\u00d3.   These set out a 1 vision  for  the  development,  deployment, and use of AI systems that should inform the design of regulation of such systems as well.\n\nMuch work has also already been done in India to put principles of AI governance into  practice.   In  India,  the  principles  from  the  apex  government  think  tank   and 2 3 NASSCOM  represents a good baseline from government and industry, respectively. 4\n\nFor  examples  of  such  frameworks,  see:  the  UKRI, Report on the Core Principles and Opportunities for Responsible and 1 Trustworthy AI , (2023); Center for Long-term Cybersecurity, Decision Points in AI Governance, (2020); Fjeld et. al., Principled Artificial Intelligence: Mapping Consensus in Ethical and Rights-based Approaches to Principles for AI , Berkman Klein Center for Internet &amp; Society, (2020).\n\nE.g.,  NITI Aayog  Principles  of  Responsible AI  (2021),  Operationalising  Principles  (2021),  and  FRT  Report  (2022);  Indian 2 Council of Medical Research Ethics Guidelines for Application of AI in Biomedical Research and Healthcare (2023); Tamil Nadu Safe  &amp;  Ethical AI  Policy  (2020);  TEC  Voluntary  Standard  for  Fairness Assessment  and  Rating  of AI  systems  (2023);  TEC Voluntary Standard for Robustness of AI systems in Telecom Sector (under development); Telangana AI Procurement Guide (under development - 2023); Nasscom Responsible AI Resource Kit (2022) and Guidelines for Generative AI (2023).\n\nSee: NITI Aayog Principles of Responsible AI (2021). 3\n\nSee: Nasscom Responsible AI Resource Kit (2022) and Guidelines for Generative AI (2023). 4\n\nThe OECD AI Principles exemplifies attempts at global convergence.  These efforts 5 are aligned in substance .\n\nA proposed list of AI Governance principles (with their explanations) is given below . This list is aligned with the OECD, NITI and NASSCOM efforts. The purpose of this list is twofold \u00d0 to be a set of principles aligned with contemporaneous global and  Indian  work,  and  to  set  the  stage  for  examining  how  to  operationalise  these principles in the Indian context:\n\n- 1. Transparency: AI  systems  should  be  accompanied  with  meaningful information  on  their  development,  processes,  capabilities  &amp;  limitations, and  should  be  interpretable  and  explainable,  as  appropriate 6 .  Users should know when they are dealing with AI.\n- 2. Accountability: Developers and deployers should take responsibility for the functioning and outcomes of AI systems and for the respect of user rights, the rule of law, &amp; the above principles. Mechanisms should be in place to clarify accountability 6 .\n- 3. Safety,  reliability  &amp;  robustness: AI  systems  should  be  developed, deployed  &amp;  used  in  a  safe,  reliable,  and  robust  way  so  that  they  are resilient  to  risks,  errors,  or  inconsistencies,  the  scope  for  misuse  and inappropriate  use  is  reduced,  and  unintended  or  unexpected  adverse outcomes  are  identified  and  mitigated.  AI  systems  should  be  regularly monitored to ensure that they operate in accordance  with their specifications and perform their intended functions.\n- 4. Privacy &amp; security: AI systems should be developed, deployed &amp; used in compliance with applicable data protection laws and in ways that respect users\u00d5  privacy.  Mechanisms  should  be  in  place  to  data  quality,  data integrity, and \u00d4security-by-design\u00d5.\n- 5. Fairness  &amp;  non-discrimination: AI  systems  should  be  developed, deployed, &amp; used in ways that are fair and inclusive to and for all and that do  not discriminate or perpetuate  biases or prejudices against, or preferences in favour of, individuals, communities, or groups.\n- 6. Human-centred values &amp; \u00d4do no harm\u00d5: AI systems should be subject to human oversight 6 , judgment, and intervention, as appropriate, to prevent undue reliance on AI systems, and address complex ethical dilemmas that such systems may encounter. Mechanisms should be in place to respect the rule of law and mitigate adverse outcomes on society.\n- 7. Inclusive &amp; sustainable innovation: The development and deployment of AI systems should look to distribute the benefits of innovation equitably. AI systems should be used to pursue beneficial outcomes for all and to deliver on sustainable development goals.\n- 8. Digital  by  design  governance: The  governance  of AI  systems  should leverage  digital  technologies  to  rethink  and  re-engineer  systems  and processes for governance, regulation, and compliance to adopt appropriate technological and techno-legal measures, as  may  be necessary,  to  effectively  operationalise  these  principles  and  to  enable compliance with applicable law.\n\nSee: OECD, AI Principles, (2019). 5\n\nEfforts  to  operationalise  the  above  principles  would  require  commitment  from  both the government and the industry. Meaningful initiatives by the industry ecosystem to demonstrate  self-governance  can  significantly  enhance  trust  in  the  use  of  AI  and complement government led governance initiatives.\n\n## B. Considerations to operationalise the principles\n\nThe  sub-committee has identified three key concepts that can inform the operationalisation of the principles and underpin AI governance in India. 6\n\n## 1. Examining AI systems using a lifecycle approach\n\nA lifecycle approach  to  the  development,  deployment,  and  use  of  AI  systems  is useful to examine putting the principles into practice effectively. This is because the risks of AI  systems play out differently at different  stages  in  a  lifecycle  of  a  given system. It is useful to think in terms of three broad stages:\n\n- \u25cf Development which involves examining the designing, training, and testing of a given system.\n- \u25cf Deployment which  involves  examining  the  putting  of  a  given  AI  system  into operation and use.\n- \u25cf Diffusion which involves taking a long-term view and examining the implications of  multiple AI  systems being widely deployed and used across multiple sectors and domains.\n\nGovernance efforts should consider the entire lifecycle when operationalising a set of principles.\n\n## 2. Taking an ecosystem-view of AI actors\n\nMultiple actors can be involved across the lifecycle of any AI system. Together, they create an ecosystem. For example, in the context of the lifecycle of a foundation model, multiple sets of actors can be involved, including:\n\n- \u25cf Data Principals\n- \u25cf Data Providers\n- \u25cf AI Developers (including Model Builders)\n- \u25cf AI Deployers (including App Builders and Distributors)\n- \u25cf End-users (including both businesses and citizens)\n\nTraditional governance approaches can be limited if they focus on one particular set of  actors  in  isolation.  By  looking  at  governance  across  the  ecosystem,  better  and holistic  outcomes  are  obtained.  An  ecosystem-view  of  actors  could  also  look  to clarify  the  distribution  of  responsibilities  and  liabilities  between  different  actors involved in the ecosystem.\n\n## 3. Leveraging technology for governance\n\nA complex ecosystem of AI models, systems, and actors is currently unfolding and expanding rapidly before us. This complexity and speed can be attributed to various\n\nA complex Adaptive System Framework to Regulate AI, https://eacpm.gov.in/wp-content/uploads/2023/10/EACPM-WP26-A-\n\n6 Complex-Adaptive-System-Framework-to-Regulate-AI.pdf\n\nfactors, including the increasing use of AI models for various applications, the speed at which the new  AI models  are being developed and deployed, and the improvements  in  the  quality  of  the  outputs  being  generated  using  AI  systems (particularly generative AI tools). This ecosystem cuts across sectors and domains, constituting a wide and evolving regulatory space.\n\nGiven this, a conventional \u00d2command-and-control\u00d3 governance strategy may not be able  to  adequately  monitor,  oversee  or  promote  the  growth  and  expansion  of  this space. There is value in integrating a \u00d2techno-legal\u00d3 approach into the governance strategy,  where  legal  and  regulatory  regimes  are  supplemented  with  appropriate technology layers (e.g., of governance technology tools along with adequate human oversight) across actors and systems.  Such a strategy would recognise the value of 7 using  technology  to  mitigate  risks,  scale  and  automate  compliance  across  large ecosystems,  and  enhance  the  monitoring  capabilities  of  regulators  and  market actors.\n\nUsing technologies to identify the allocation of regulatory obligations/liability across the  value  chain  can  also  help  embed  directives  and  guidelines  on  how  different ecosystem players are to work together and collaborate. This could allow players to manage  liabilities in the chain  leading  to lightweight, but gradually scalable, regulatory control.\n\nThere can be several different components to make up such a strategy. As a starting point, there is merit in examining how technology artefacts, similar to the concept of \u00d2consent artefacts\u00d3 already proposed by MeitY in their Electronic  Consent Framework,  can  perhaps  leveraged  to  assign  immutable  and  unique  identities  to participants, so that their activities can be tracked and recorded to establish liability chains between them\n\nSuch artefacts, combined with the contracts between the participants, may allow for liability  to  be  spread  and  distributed  between  them.  Such  a  chain  could  allow  for each member of the chain to enforce or require good behaviour on their own part and the part of the chain they are connected to such as their suppliers. This could potentially enable successful self-regulation across the ecosystem.\n\nA techno-legal approach could also be optimally used by the Government/ regulatory body, or an appropriate technical assistance may be extended by the developers and deployers  of AI  systems  to  identify  or  trace  unlawful  information  and  actors  upon receipt  of  a  valid  request  from  the  Government  on  specified  grounds  such  as prevention,  detection,  investigation  or  prosecution  of  harms,  crimes,  and  security incidents.  However,  it  is  equally  important  to  note  that  any  such  automated  tools using  for  automating  compliance,  monitoring,  or  regulation  would  need  to  be periodically reviewed themselves, keeping in mind their security, accuracy, fairness, and impact on fundamental rights (e.g., like speech and privacy).\n\nThere is a need to strengthen efforts to operationalise the proposed AI Governance principles through a well-defined regulatory framework, which leverages technology and incorporates a \u00d2digital by design\u00d3 approach to achieve the desired outcomes.\n\nExamples  of  governance  technology  tools,  also  known  as  'RegTech  tools',  include  codified-regulations,  AI  compliance 7 systems, blockchain tracking and smart contracting. See, World Economic Forum, Regulatory Technology for the 21 st  Century, (2022).\n\nWhile  considering  techno  legal  approaches,  it  is  important  to  consider  that  laws encoded in technology will be enforced. This may be required in certain context and be desirable in some but may not be appropriate in all. Such an approach should not shut the door on a level of flexibility that will offer us the freedom to innovate and improve. 8\n\n## III. GAP ANALYSIS\n\nAI systems do not have agency, except to the extent we afford them. In undertaking a gap analysis, the sub-committee kept in perspective the fact that existing laws and regulations  continue  to  apply  to  the  use  of  AI.  The  principles  of  responsible  AI, including with respect to safety, equality, inclusivity, non-discrimination, and privacy are grounded in the fundamental rights enshrined in our constitution.\n\nGiven this, there is a need to examine the suitability of existing laws to deal with risks and harms in the context of AI systems. This can provide a meaningful direction to strengthen  the  governance  framework.  Such  an  analysis  should  be  anchored  in areas where concerns already exist and where they are likely.\n\nAn  informed  view  of  the  AI  ecosystem  is  likely  to  improve  efforts  for  effective compliance and enforcement of existing laws and address gaps. Given that use of AI is not confined to certain sectors or use cases, implementation of an appropriate AI governance framework would benefit from a cohesive and co-ordinated effort or a whole-of-government-approach.\n\nAccordingly, the sub-committee focused on identifying gaps taking into consideration that:\n\n- (1) Where AI systems can be used to exacerbate well-understood harms, there is a need to prioritise efforts that enable the effective compliance and enforcement of existing laws;\n- (2) To govern effectively, regulators will first need access to adequate information about the dynamics of the overall AI ecosystem of data, models, apps, actors, users, AI systems, etc;\n- (3) Since the field of AI is rapidly evolving , and AI systems are increasingly crosscutting tools,  there  is  a  need  for  a  whole-of-government-approach to deal with emerging risks of harm.\n\nThe sub-committee discussed a few other topics which may require policy position, or no  action, or further observation of  the  developments  before  appropriate governance mechanisms may be considered. These are listed in the Annexure.\n\nThe three considerations mentioned above are discussed in detail below.\n\n## A. The need to enable effective compliance and enforcement of existing laws.\n\n## 1. Deepfakes/ fakes/ malicious content\n\nThere  are  existing  legal  safeguards/instruments  to  protect  against  misuse  of foundation models  for creating malicious synthetic media  (i.e., malicious \u00d4deepfakes\u00d5). In this case, depending upon the context and negative effect of the malicious synthetic media in question, multiple laws can apply. For example:\n\nSee: Rahul Matthan, The Zone of Mischief (2024) 8\n\n- \u25cf Information  Technology  Act,  2000  (IT  Act): Section  66D  of  the  IT  Act criminalises  the  use  of  computer  resources  for  cheating  by  personation. Section  66E  prescribes  the  punishment  for  capturing  and  publishing  or transmitting  the  image  of  a  private  area  of  any  person  without  his  or  her consent. Publishing or transmitting obscene material for instance, which could be  generated  by  using  deepfake  technology  is  a  punishable  offence  under Section 67A and 67B of the IT Act.\n- \u25cf Indian Penal Code (IPC): In addition to the IT Act, certain harms/cybercrimes perpetuated by AI could also fall under the IPC. For instance, identity theft and cheating by  personation  are  offences  under  Section  419  (cheating  by personation),  section  463  and  465  (forgery  for  the  purpose  of  cheating), section  292  and  294  (selling/circulating/distributing  obscene  objects),  and section 499 (causing harm to reputation/defamation). It is to be noted that the IPC  has  been  recently  replaced  by  the  Bharatiya  Nyaya  (Second)  Sanhita ( BNS2 ), and the BNS2 retains these offences.\n- \u25cf Other laws: In  addition to the IT Act and IPC / BNS2, there could be more laws  depending  on  the  nature  of  crime  or  cause  of  actions  involved,  like Prevention  of  Children  from  Sexual  Offences Act,  2012  (section  12)  in  the event of sexual harassment of children, Juvenile Justice (Care and Protection of  Children)  Act,  2015  (section  75)  for  causing  harm  to  the  children,  the Copyrights Act (section 51), if synthetic content infringes copyrighted work.\n- It  is  worth  noting  that  existing  laws  can  also  require  specific  measures  from platforms and online service providers to detect and remove malicious synthetic media.  Under  the Information  Technology  (Intermediary  Guidelines  and Digital Media Ethics Code) Rules, 2021 :\n- \u25cf Rule  3(1)(b)  requires  intermediaries  to  inform  its  rules  and  regulations, privacy policy and user agreement to a user and to make reasonable efforts to  prevent  the  dissemination  of  specific  types  of  content,  that  may  cause harm  to  its  users  \u00d0  including  information  that  may  violate  bodily  privacy, cause harm to a child, is deceptive, among other things.\n- \u25cf Rule  3(1)(c)  requires  intermediaries  to  periodically  inform  their  users  about the effects of non-compliance with the rules and regulations, privacy policy, or user agreement of such intermediary.\n- \u25cf Rule 3(2)(b)  requires  the  intermediary  to,  within  24  hours  of  receiving  user complaint  of  content  which  is  \u00d4impersonation  in  electronic  form,  including artificially  morphed images of such individual\u00d5 remove or disable its access. Further, the grievance officer appointed by the intermediary should acknowledge user complaints within 24 hours.\n\nThe above shows that the legal framework may be adequate for the purposes of detecting, preventing, removing, and prosecuting the creation and distribution of malicious  synthetic  media.  However,  for  this  legal framework  to  be  effective,  it needs to be backed by requisite capabilities to enable stakeholders to effectively comply and for the authorities to enforce the legal framework.\n\nThis area points to possible gaps and opportunities for using technological measures for enabling effective compliance, so that malicious deepfakes are detected in time and/ or are removed before they cause serious harm. For example, as suggested above, traceability may be established by assigning unique and immutable identities to different participants, such as content creators, publishers, social media platforms, etc. These may then be used to watermark inputs to, and outputs from, generative AI tools. These may be used to track and analyse the lifecycle, from creation to use, of a deepfake \u00d0 and to determine when they have been created without consent or in violation of a law (e.g., cheating by personation).\n\n## 2. Cyber security\n\nExisting laws including the provisions of the IT Act to deal with cyber security are equally applicable when AI is used to compromise cybersecurity.\n\nThe primary national law dealing with cybersecurity is the IT Act. It establishes the Indian Computer Emergency Response Team ( CERT-IN )  (section  70B) and the National Critical Information Infrastructure Protection Centre ( NCIIPC ) (sections 70, 70A). It also defines various types of cybercrimes and establishes both a right for individuals impacted by cybercrime to seek compensation, as well as  criminal  penalties  for  such  crimes  (if  criminal  intent  is  established).  Further, under the IT Act:\n\n- \u25cf The  CERT-IN  Rules,  as  well  as  Cybersecurity  Directions  2021,  require  all body corporates to report cybersecurity incidents as well as adhere to certain requirements  concerning  synchronisation  of  ICT  systems  clocks  as  well  as maintaining  security  logs.  Security  incident  reporting  is  also  required  from intermediaries under the IT Rules 2021.\n- \u25cf The NCIIPC Rules govern operators of \u00d2protected systems\u00d3 and then requires them  to  impose  various  information  security  procedures  and  practices, including ensuring they have a Chief information security officer, establish a Cyber Security Operation Centre, conduct various  risk  management activities,  etc.  The  Central  Government  has  notified  different  protected systems from time to time.\n\nThe second national law that governs cybersecurity is the Digital Personal Data Protection Act ( DPDPA ), which requires data fiduciaries to put in place appropriate security safeguards to protect personal data against breaches.\n\nBeyond  the  above  national  laws,  sectoral  regulators  have  introduced  separate cybersecurity guidelines.\n\n- \u25cf The  Reserve  Bank  of India ( RBI ) has prescribed  comprehensive cybersecurity  standards  and  guidelines  for  banks,  non-banking  financial companies, payment system operators, and payment aggregators.\n- \u25cf The Securities and Exchange Board of India ( SEBI ) has released circulars on cybersecurity for stock market participants.\n- \u25cf The  Insurance  Regulatory  and  Development  Authority  ( IRDAI )  also  has guidelines on cybersecurity for all insurers and insurance intermediaries.\n- \u25cf The  Department  of  Telecom  requires  telecom  licensees  to  report  security incidents under the licensing framework.\n\nGiven  that  AI enables  non-technical  specialists to carry out sophisticated measures, there may be a need to focus on ways to strengthen the application of the above cybersecurity framework in the context of use of AI systems. This could require suitably upgrading compliance and enforcement capabilities to deal with the  rapid  development  of AI  and  related  emerging  threats.  For  example,  there may be a need for guidance to help providers of AI systems build systems that work as intended and are \u00d2secure by design\u00d3.\n\n## 3. Intellectual property rights\n\nA question that is currently the subject of significant analysis, and (in the global context) also a matter of litigation, is accounting, under existing laws, for specific intellectual property rights ( IPR ) violations that occur through use of AI, particularly generative AI.\n\nThe sub-committee examined two areas under the Indian copyright law:\n\n## a. Training models  on  copyrighted  data  and  liability in case  of infringement\n\nGiven that copyright law grants the copyright holder an exclusive right to store, copy  etc.,  creation  of  datasets  using  copyrighted  works  for  training  foundation models, without the approval of the right holder, can lead to infringement. 9\n\nThe Indian law permits a very closed list of activities in using copyrighted data without permission that do not constitute an infringement. Accordingly, it is clear that  the  scope  of  the  exception  under  Section  52(1)(a)(i)  of  the  Copyright Act, 1957 is extremely narrow. Commercial research is not exempted; 10  not-for-profit institutional  research  is  not  exempted.  Not-for-profit  research  for  personal  or private use, not with the intention of gaining profit and which does not compete with the existing copyrighted work is exempted.\n\nTherefore, while the law protects the rights of the copyright holder, do we have the capabilities to enforce compliance to the existing law? Do we need to identify and agree on steps that the entities training on data need to put in place so as to demonstrate compliance with the law?\n\nDespite  some  guardrails,  there  might  still  be  infringements  of  existing  works, given  that  multiple  persons  (e.g.,  the  end-user  giving  prompts  or  the  model developer) may  be  involved in determining the output generated by a foundational model. Who would be held liable in case such an output is found to be infringing upon an existing copyright?\n\nThe above aspects may require a review to ensure compliance with the law as it stands.\n\nThere  are  also  policy  level  questions  \u00d0  for  example,  should  AI  systems  be allowed  to  train  on  bulk  datasets  that  may  include  copyrighted  data,  without taking approval from each copyright holder? If so, under what circumstances this\n\nSection 14(c), Copyright Act, 1957. 9\n\nSee, Rupendra Kashyap v. Jiwan Publishing House, 1996 (38) DRJ 81 at para 21. It says, 'if a publisher publishes a book 10 for commercial exploitation and in doing so infringes a copyright, the defence under section 52(1)(a)(i) would not be available to such a publisher, even though the book published by him may be used or be meant for use in research or private study'.\n\nmay be considered so that rights of the copyright holders are not infringed? Do we  need  to  interpret  or  clarify  the  scope  of  rights  that  should  exist  with  the copyright holder? What guardrails must be introduced, if we are able to address the questions above? The answers can help improve legal certainty and clarify the way forward for a lawful use of AI systems.\n\n## b. Copyrightability of work generated by using foundation models\n\nGiven  the  requirement  of  \u00d4human  authorship\u00d5  for  copyright  protection, the eligibility and scope of granting copyright for works generated by using foundation models is untested under existing law.\n\nIn the case of AI, while human interference is required to initiate the process of creating an output (writing the algorithm, giving a prompt, etc.), there may be not enough interpretation or guidance available, for example, on the following:\n\n- \u25cf How much human input is necessary to qualify the user or developer of an AI system as an \u00d4author\u00d5 of a generated work.\n- \u25cf Whether  work  generated  by  using AI  models  can  be  termed  as  a  type  of \u00d4computer generated work\u00d5 eligible for copyright protection under the Copyright Act.\n\nBy proactively creating appropriate guidance, the relevant authorities (Copyright Office, Ministry of Commerce &amp; Industry) can provide certainty and clarity to the users  as  well  as  to  other  government  authorities  who  may  otherwise  adopt inconsistent practices.\n\nA consultation of what would be appropriate guidance to clarify whether and to what extent creative works generated by using foundation models can be eligible for copyright protection, might be useful.\n\nAfter  answering  these  policy  level  questions,  we  can  examine  opportunities  for leveraging techno-legal measures , including those that enable tracing the use of copyrighted data in training of AI models.\n\n## 4. AI led bias and discrimination\n\nIssues of AI entrenched biases are cross cutting. Biases in a non-AI context are more  likely  to  be  in  pockets  and  less  co-ordinated.  When  they  creep  into  AI systems,  the  effects  would  be  based  on  system  deployment  and  the  concerns would  be  based  on  context  and  scale  of  deployment.  It  is  also  important  to understand that in many decisions there may be a notion of bias, however, only biases that are legally or socially prohibited need to be protected against.\n\nAt a fundamental level, it is important to examine how our existing laws deal with harm  like  biases/  discrimination.  For  example,  our  employment  laws,  laws protecting  minorities  and  consumer  protection  law  provide  protection  against discrimination.  However,  how  consumer/  user  rights  are  adequately  protected when AI is used in decision-making is an evolving subject and requires a whole of the  government  approach  to  assess  and  where  needed  provide  clarity  or appropriate mechanisms to deal with AI entrenched biases.\n\nFor  example,  in  a  non-AI  context,  individual  consumers  would  be  expected  to complain about discriminatory conduct. In an AI context, it is possible individuals\n\nmay not easily  understand  discrimination,  or  even  if  they  see  it,  they  may  just critique the AI logic and it might be more difficult to establish intent. AI systems may  reinforce pre-existing biases and  without transparency, this  may  go undetected.\n\nConsider another scenario, deployers may  use  tools (unknowingly or unforeseeably) that frustrate complying with current law. E.g., if businesses use a biased recruitment tool,  leading  to  violation  of  the  Equal  Remuneration Act  (as subsumed in new Codes), they may not even realise there is a problem. In these kinds of scenarios, there may not be important gaps in the legal provisions, but the need for entities to understand the risks and risk mitigation while deploying \u00d2black box\u00d3 models would become important.\n\n## B. The need for transparency and responsibility across the AI ecosystem in India\n\nTo govern effectively, regulators will first require adequate information from two perspectives \u00d0\n\n- \u25cf traceability of data, models, systems, and actors throughout the lifecycle of AI systems and\n- \u25cf transparency from  actors  regarding  the  allocation  of  liabilities  and  risk management responsibilities between each other through contracts.\n\nThis would be necessary to design effective, targeted, and appropriate governance  mechanisms.  An  ecosystem-view  is especially relevant to understand which AI systems are being developed and deployed in India (and by whom)  that  are  high  capability  and/or  likely  to  be  deployed  widely  and/or deployed in sensitive use-cases. The risks posed by a system depends not just on their capability, but on the context of deployment  as well. The categorisations of systems purely based on computational capacity or data parameters may not be effective .\n\nFor  systems  deployed  in  tightly  regulated  sectors,  they  would  need  to  be assessed under existing sectoral laws before we evaluate the need for additional or fresh laws. The testing of such sectoral laws should, in particular, examine how existing rules on assigning liability for non-compliances (e.g., in health, banking, financial services and insurance, energy, etc.) can be applied to AI systems prone to high-risk.\n\nHowever, there may well be situations where a sectoral view is limiting, since we may not fully understand (i) the risks and/or (ii) the possibility for risks to spillover across  sectors.  Therefore,  a  view  that  \u00d2high  risk  scenarios\u00d3  are  likely  only  in tightly regulated sectors may not be correct. Given this, as well as the fact that many governance concerns may be common or cross-cutting across sectors, it might be useful to start examining a baseline framework to ensure transparency and responsibility across the overall AI ecosystem.\n\n## C. The need for a whole-of-government approach.\n\nThere  are  many  laws  and  regulators,  departments  to  deal  with  many  of  the harms that may arise due to use of AI. Given the sectoral specialisation, this is indeed  desirable.  However,  given  the  rapid  technology  developments  and  the\n\ncross-cutting usage of AI, there is an inefficiency and possibility of gaps due to a fragmented  approach. Existing  departments  and  regulators  are  likely  to  be examining  AI  systems  in  silos.  This  prevents  a  common  understanding  from being built, especially on cross-cutting issues. This gap can make it difficult for the government to organise multiple initiatives around a common roadmap.\n\n## IV. Recommendations\n\nThe committee recommends the following:\n\n- 1. To  implement  a  whole-of-government  approach  to  AI Governance, MeitY and the Principal Scientific Adviser should establish  an  empowered  mechanism  to  coordinate  AI Governance.\n\nThe  empowered  mechanism  should  be  in  the  form  of  an  Inter-Ministerial  AI Coordination Committee or Governance Group ( Committee/ Group ). It should bring together the various authorities and institutions that deal with AI Governance at the national level. The Committee/ Group should have an ongoing status and should not be a limited duration mechanism.\n\nThe overall purpose of this Committee/ Group should be to bring the key institutions around a common roadmap and to coordinate their efforts to implement a whole-ofgovernment  approach.  A  collaborative and  co-ordinated approach  by  various regulators can enable them to be more efficient and effective, given the complexity likely to be involved in dealing with AI systems at scale, especially when we take a long-term  view  of  the  diffusion  stage  of  their  lifecycle.  This  can  be  especially necessary in domains and areas where multiple authorities may be concerned (e.g., consumer protection, food, transportation, agriculture, health care, etc.).\n\nThe  Committee/  Group  should  enable  a  whole  of  government  approach  to  the AI ecosystem.  Currently,  regulators  and  government  departments  may  have  some visibility on the AI systems developed or deployed by entities who are under sectoral regulation  (e.g.,  finance  or  health)  or  where  the  market  is  concentrated  (e.g., ecommerce, social media, aggregators). However, the level of visibility would need to be adequate to assess potential risks associated with such entities in the context of AI. Further, there are likely to be AI systems developed or being developed and/ or deployed by entities who may not have an interface with the government/ regulators from  a  perspective  of  affording  suitable  visibility  to  enable  a  risk  assessment  in relation to AI.\n\nA  pre-requisite  of  governance  would  be  for  the  government  and  the  regulators  to have a credible understanding the AI ecosystem in the country so that governance measures  are  rooted  to  the  realities  of  existing  and  likely  risks.  The  Committee/ Group should facilitate this task.\n\nThis would  require a conversation-led approach  with  a view to  develop  an understanding of the ecosystem which can both serve as feedback for strengthening governance and enable understanding of possible challenges and gaps in complying\n\nand  enforcing  existing  laws.  It  is  important  to  emphasise  that  such  a  mapping exercise should not result in regulatory overreach through at scale registration and reporting requirements.\n\nWith  the  above  context,  the  Committee/  Group  should  meet  at  a  regular  basis  to suggest measures  to catalyse  collaboration  between  departments  and regulators, so that they can:\n\n- \u221e apply and strengthen existing laws to minimise risk of harm due to use of AI;\n- \u221e provide legal clarity and certainty around development and use of AI by issuing joint guidance;\n- \u221e harmonise existing efforts and initiatives around common terminologies and risk inventories;\n- \u221e enable demonstrable self-regulation to operationalise the responsible  AI principles;\n- \u221e take  coordinated  steps  to  respond  to  identified  gaps  with  the  benefit  of  multiregulatory support;\n- \u221e create a policy environment which enables the use of AI for beneficial use-cases; and\n- \u221e promote the development and deployment of responsible AI applications in their domains/sectors.\n\nIn order to enable appropriate measurement  of  fairness, accountability and transparency in the Indian context, it is an essential prerequisite to have access to the right datasets, relevant to the Indian context, which allows users to assess the fairness  and  bias  of  their  models  across  standard  datasets. The  creation  of  better datasets  for  the  Indian  context  should  be  stimulated,  and  sector-specific  datasets should  be  identified  to  enable  creation  and  evaluation  of  fair  models.  These initiatives may be encouraged by the Committee/ Group.\n\nThe Committee/ Group should have a mix of both official and non-official members, because  such  a  forum  focused  on  coordinating AI  governance  must  also  bring  in external expertise from industry and academia, given their central role in operationalising responsible AI principles in practice.\n\nIt may be headed by the Principal Scientific Adviser. Official members could include representatives deputed from MeitY, the NITI  Aayog, the  Telecommunication Engineering Centre, Bureau of Indian Standards, other departments of the Central Government,  as  well  as  sectoral  regulators  (e.g.,  RBI,  Indian  Council  of  Medical Research,  SEBI,  IRDAI,  Telecom  Regulatory  Authority  of  India,  etc.).  Non-official members  could  include  persons  capable  of representing the interests of AI developers, AI deployers, data providers, data principals, and end-users \u00d0 so that the perspectives  of  the  overall  ecosystem  can  be  considered.  The  Committee/  Group should  invite  external  experts  for  discussions  to  understand  and  take  on  board diverse perspectives.\n\n- 2. To develop  a systems-level understanding  of  India\u00d5s  AI ecosystem , MeitY should establish, and administratively house, a  Technical  Secretariat  to  serve  as  a  technical  advisory  body and coordination focal point for the Committee/ Group.\n\nMeitY should establish and host a technical secretariat that  brings  in  officers  on deputation from departments and regulators participating in the Committee/ Group as well as experts from academia and industry.  As the Committee/ Group\u00d5s technical advisory body and coordination focal point, the Secretariat should:\n\n- \u221e pool together multi-disciplinary expertise (tech, law, policy, economics, etc.) from existing  institutions  in  academia  and  industry  to  strengthen  capacity  across departments and regulators;\n- \u221e create a map of the stakeholders and actors involved in India\u00d5s AI ecosystem and conducts regular horizon-scanning exercises of the AI field;\n- \u221e assess  risks  to  consumers  &amp;  society  across  applications  and  domains  (incl. cross-cutting issues like antitrust, online safety, security, data governance, public services, employment, etc.);\n- \u221e facilitate the development of metrics (e.g., measurement standards for assessing environmental  impact  of  AI  in  India)  &amp;  common  frameworks  (e.g.,  on  data provenance,  system  cards,  security,  evaluation  data  sets,  use  of  open  source, transparency reports etc.); and\n- \u221e engage with  industry  to  co-examine  novel  solutions  (e.g.,  labelling  of  synthetic media, privacy-enhancing technologies, etc.) to operationalise responsible use of AI and enable development of appropriate guardrails 6 ; and\n- \u221e identify  gaps,  which  may  not  be  adequately  addressable  through  delegated legislation and/ or existing State capacities (such as where a guardrail is required and  how  it  can  be  implemented,  or  where  existing  adjudicatory  or  compliance capacities need to be strengthened to deal with issues and disputes arising from emerging technology led activities including the use of AI).\n\nIt  is  to  be  noted  that  a  similar  advisory  body  was  recommended  by  NITI Aayog in 2021. The functions  envisaged  by  the  NITI Aayog  for  that  body  may  be  allocated appropriately  between  the  Committee/  Group  under  recommendation  1  (which should  focus  on  coordination  of  policymaking  and  regulatory  functions)  and  its Secretariat (which should focus on horizon-scanning, risk assessment, gap analysis, standardisation, and technical advisory).\n\nThe NITI Aayog had noted that any such body must be an \u00d2 independent technology wheelhouse advising relevant Government agencies \u00d3 and \u00d2 should be autonomous to work  with  individual  regulators  and  Ministries \u00d3. 11   While  these  are  undoubtedly relevant  considerations,  the  sub-committee  notes  that,  at  this  stage,  it  is  not recommended to establish such a Committee/ Group or its Secretariat as statutory\n\nSee: NITI Aayog, Operationalizing the Responsible AI Principles, (2021). 11\n\nauthorities,  as  making  such  a  decision  requires  significant  analysis  of  gaps, requirements, and possible unintended outcomes. Instead, existing pathways should be  used  to  set  up  the  Committee/  Group  (such  as  has  been  done  for  existing mechanisms like the National Startup Advisory Council) and its Secretariat.\n\nThe proposed secretariat could be staffed by existing MeitY officials as well as lateral hires,  young  professionals,  and  consultants.  MeitY  may  form  an AI  Sub-Group to suggest the form and structure of the proposed secretariat along with a detailed term of reference.\n\n- 3. To build evidence on actual risks and to inform harm mitigation, the Technical Secretariat should establish, house, and operate an  AI incident database  as  a repository  of  problems experienced  in  the  real  world  that  should  guide  responses  to mitigate or avoid repeated bad outcomes.\n\nTo  understand  the  actual  incidence  of  AI-related  risks  in  India,  the  Technical Secretariat should establish an AI incident database and nurture reporting to it. In the initial  stages,  the  database should receive reports from public sector organisations deploying  AI  systems  (whether  directly  or  through  public-private  partnerships). Private  entities  should  also  be  encouraged  to  voluntarily  report AI  incidents  to  the database. The  focus should be on defining reporting protocols to ensure confidentiality and to focus on harm mitigation, not fault finding.\n\nIt is important to note that an \u00d2AI incident\u00d3 may include a \u00d2cyber incident\u00d3 or a \u00d2cyber security incident\u00d3 under the IT Act, but the ambit of \"AI incident\" may also go beyond the scope of a cyber incident. While cyber incident relating to AI systems may refer to suspected or potential attack or vulnerability against AI systems, AI incidents may also refer to adverse or dangerous outcome, resulting from the use of AI that can disadvantage  or  harm  individuals,  businesses,  and  societies. 12   AI  incidents  may include malfunctions, unauthorised outcomes,  discriminatory  outcomes, unforeseeable  outcomes  and  unexpected  emergent  behaviour,  system  failures, privacy violations, physical safety problems, etc.\n\nTypically,  these  issues  became  known  when  they  are  reported  in  media  or  when there is an ad-hoc escalation by a victim or an identification by a regulator. There is merit in the development of an AI incidence reporting database to serve as a more systematically collected evidence base to inform governance initiatives. Over time, this  can  help  to  show  patterns  and  establish  a  collective  understanding  of  AI incidents and their multifaceted nature. The OECD AI Incidents Monitor is  a  useful reference \u00d0 it documents AI incidents to help policymakers, AI practitioners, and all stakeholders  worldwide  gain  valuable  information  about  the  real-world  risks  and harms posed by AI systems. 13\n\nSetting up such a database should be taken up as a fresh exercise and not lapsed into  existing  cybersecurity  incident  reporting  regimes,  since  the  concept  of  an  \u00d2AI incidents\u00d3 goes beyond cybersecurity.\n\nSee: AI Incident Database, What is an incident? 12\n\nSee: OECD AI Incidents Monitor, Methodology and disclosures 13\n\nIt is a given that any unlawful activity will be appropriately dealt with through the legal framework.  However,  the  AI  incident  database  should  not  be  started  as  an enforcement  tool.  Its  objective  should  not  be  to  penalise  people  who  report  AI incidents. Instead, the objective should be to encourage reporting and the learnings should flow back into the ecosystem. Given this, the suitability of CERT-IN taking on the  mandate  of  maintaining  an  AI  incident  repository,  under  the  guidance  of  the Technical Secretariat, may be examined.\n\n- 4. To  enhance  transparency  and  governance  across  the  AI ecosystem,  the  Technical Secretariat  should  engage  the industry to  drive  voluntary  commitments  on  transparency across the overall AI ecosystem and on baseline commitments for high capability/widely deployed systems.\n\nEfforts  to  operationalise  the  AI  Governance  principles  would  require  commitment from both the government and the industry. In terms of transparency, this can start by encouraging demonstrable industry self-regulation through examining the adequacy of existing voluntary reports and disclosures being released by current AI developers and deployers (e.g., transparency reports, model cards, etc.).\n\nFurther,  existing  laws  empower  regulators  to  encourage  and,  where  needed, mandate the relevant entities to implement necessary measures to address risks and mitigate harms. Through the Committee/ Group, regulators can collaborate to design and implement efficient and effective responses 6 . That said, there may be a need for a baseline framework that applies to the development and deployment of AI systems that are considered medium-to-high risk across domains and sectors.\n\nConsequently,  the  Technical  Secretariat  could  start  such  work  by  anchoring  a collaboration with industry to build consensus around voluntary commitments. Such commitments can include elements such as:\n\n- \u221e disclosures of the intended purposes of AI systems and applications;\n- \u221e commitments to release regular transparency reports by AI  developers  and deployers;\n- \u221e commitments  to  internal  and  external  red-teaming  of  models  or  systems  in areas;\n- \u221e processes to test and monitor data quality, model robustness, and outcomes;\n- \u221e processes to validate data quality and governance measures;\n- \u221e processes to ensure peer review by third-party qualified experts;\n- \u221e processes  to  ensure  conformity  assessments  with  accepted  responsible  AI principles; and\n- \u221e security, vulnerability assessment, and business continuity requirements.\n\nIn  addition  to  the  private  sector  adoption  of AI,  government  is  also  adopting AI  for citizen  welfare  as  well  as  for  law  enforcement  purposes.  Therefore,  the  above recommendations  of  the  sub-committee,  including  transparency  and  governance measures  listed  above,  may  also  be  adopted  by  the  government  and  their technology providers, wherever relevant.\n\nPart of such commitments can include use of technological solutions to mitigate the risks.    Scalable  and  reliable  technological  artefacts  and  design  elements  can  be encouraged from actors involved in each lifecycle stage, and be embedded across\n\ndata gathering processes, model building and retraining processes, as well as the final  apps and user interactions as the manifestation of the traceability and liability chain.\n\nIndustry could also be encouraged to create standardised risk assessment protocols that developers and organisations could adhere to during the design and development of AI systems for their respective domains.\n\nThe specific voluntary commitments are likely to vary for different industry segments and should be based on understanding of real risks. These should therefore result from deeper engagement through technical workshops and collaborative discussions with  industry.  These  efforts  may  be  led  by  relevant  regulators  and  government departments.\n\nIt  is  expected  that  industry  would  be  able  to  demonstrate  their  adherence  to  the voluntary  commitments.  The  voluntary  commitments  are  expected  to  complement the  legal  framework  and  should  minimise  the  need  for  prescriptive/  onerous regulations. The voluntary commitments should provide the requisite flexibility to the industry  to  commit  to  measures  which  are  meaningful  and  implementable  while providing  the  much-needed  visibility  to  the  regulators  and  government  to  the governance measures being implemented.\n\nThe role of the Technical Secretariat should be to assist these efforts and bring in cross sectoral expertise and a baseline maturity into these commitments.\n\n- 5. The  Technical  Secretariat  should  examine  the  suitability  of technological measures  to  address  AI  related risks. Such measures may aid with establishing a systems-level approach. For example, technology artefacts may be used to model the interactions between  datasets, models, applications and users in different domains and sectors (e.g., healthcare, finance, etc.) and to identify and track negative outcomes in real time.\n\nAs noted earlier, the current legal framework has provisions to deal with malicious synthetic  media  and  is  being  refined  from  time  to  time.  To  complement  the  legal framework,  there  is  a  need  to  focus  on  examining  the  viability  of  technological solutions  to  strengthen  compliance  and  enforcement  tools  across  a  range  of  AI related risks and in-fact across governance and regulatory risks more generally.\n\nOne example, where such viability can be examined, is the proliferation of malicious synthetic media (referred to as \u00d2deepfakes\u00d3). Consequently, one of the first areas of work, where the Technical Secretariat should undertake research, is to examine the viability  of  such  technological  solutions,  including  watermarking,  platform  labelling, and  other  fact-checking  tools.  The  Secretariat  should  engage  with  industry  and governments  globally to evaluate the merit and  feasibility of standards  and mechanisms  to  enable  a  chain  of  content  provenance  even  as  the  content  is modified across different tools and the modifications are watermarked using different technologies. These can then feed into user awareness programs that can be rolled out nation-wide through different channels of communications that can be driven by the Committee/ Council members.\n\nIn parallel with the efforts to examine  technological  solutions, the  Technical Secretariat should also undertake a deeper analysis to identify any specific gaps that\n\nmay  be  required  to  be  addressed  to  better  account  for  the  prevention,  detection, reporting and awareness of malicious synthetic media.\n\n- 6. Form  a  sub-group  to  work  with  MEITY  to  suggest  specific measures  that  may  be  considered  under  the  proposed legislation like Digital India  Act (DIA) to  strengthen  and harmonise  the  legal framework,  regulatory and  technical capacity and the adjudicatory set-up for the digital industries to ensure  effective grievance  redressal and  ease  of  doing business.\n\nGiven  the  rapid  development  of  digital  technologies  and  newer  business  models, there  is  a  need  for  the  proposed  legislation  (DIA)  to  be  suitably  equipped.  It  is important  for  the  proposed  DIA  to  empower  the  government  with  appropriate regulatory  and  technical  capacity  and  capability  to  minimise  risks  of  harm  from malicious use of emerging technologies, including AI.\n\nFor  example,  there  is  a  need  for  the  Government  to  review  and  strengthen  the mechanisms for redress and adjudication of matters concerning digital technologies (including the risks posed by AI applications) keeping in mind the rapid growth in the digital  ecosystem  and  the  adoption  of  digital  technologies  at  scale.  This  should extend to the appellate level. The strengthening should focus on adequate capacity in  terms  of  human resourcing, qualifications and expertise, use of technology, and the  avoidance  of  unnecessary  overlaps  between  different  forums.  MeitY  should consider introducing requirements for Grievance Appellate Committees ( GACs )  and Adjudicating  Officers  ( AOs )  to  be  \u00d2digital  by  design\u00d3  and  to  employ  online  dispute resolution  systems  in  the  discharge  of  their  functions.  Further,  currently,  the  IT Secretaries  in  State  Governments  serve  as  AOs.  These  are  senior  officers  with several other responsibilities. This mechanism should be reviewed so that there is appropriate  capacity  from  a  future  perspective.  The  qualifications  and  eligibility criteria to serve as an AO may be reviewed to enable officers to serve full-time on a dedicated  basis  and  to  also  enable  the  entry  of  external  experts  (e.g.,  lawyers, cybersecurity professionals, etc.).\n\nIn  order  to  holistically  review  possible  areas  in  the  legal  framework  that  can  be suitably  strengthened  through  the  DIA,  the AI  Sub-Group may  be  tasked  to  work closely with MeitY to make detailed recommendations.\n\n## Conclusion\n\nRegulation should aim to minimise the risk of harm. Even enabling innovation is a minimisation of harm as people may not be able to innovate due to lack of clarity or gap in law. Therefore, harm mitigation should be the core regulatory principle while operationalising the seven principles discussed in this report.\n\nThe question - to regulate the \u00d2technology\u00d3 or an \u00d2application,\u00d3 can only be answered in  the  context  of  the  above  core  principle  and  the  answer  will  continue  to  evolve based what is needed to be done to minimise the risk of harm.\n\nRegulation controls the behaviour of people by calling out what is permissible and/ or not  permissible  and  penalising  deviation  from  the  desired  behaviour.  Regulation imposes costs on everyone. Therefore, the risk of harm has to be real and specific for a discussion on regulation and for regulation to be useful.\n\n## Regulation ranges from:\n\n- \u221e some form of licensing/ authorisation ( entity-based regulation \u00d0 banking, health, telecom, car manufacturers) or\n- \u221e a set of applicable regulation ( activity-based regulation \u00d0 taxation, online safety, consumer protection, data protection, anti-trust, copyright, patent, employment, contracting etc.) or\n- \u221e a combination approach (threshold-based identification of entity and application of certain regulations for specified activities).\n\nGiven that the AI development industry is in the nascent stage, the starting point of regulation should be \u00d2activity-based regulation\u00d3 through which people are motivated to minimise the risk of harms. Given the horizontal nature of AI use, when needed, this approach can evolve into a combination approach.\n\nGiven the broad and cross cutting use of AI, Government should:\n\n- \u25cf invest  in  strengthening  existing  regulatory  capabilities  and  implementing  a whole of government approach to effectively govern its use; and\n- \u25cf adopt  a  \u00d2digital  by  design\u00d3  approach  to  regulation  that  encourages  the participants  in  the  AI  ecosystem  to  self-regulate  each  other  and  develop lightweight but effective outcomes-focused regulations for timely intervention on  the  part  of  the  regulator  which  allow  the  liability  to  be  attributed  to  the defaulting parties; and\n- \u25cf leverage  industry  ecosystem  efforts,  including  technology-based  measures, which help demonstrate responsible development and use of AI.\n\n## Annexure.\n\nDiscussions  notes  of the sub-committee  not  directly leading to the recommendations.\n\n## Training of AI models on copyrighted data\n\nThe Indian Copyright Act provides protection to the copyright holder and does not allow AI systems to train on copyrighted content without the approval of the copyright holder.  However,  if AI  systems  were  to  be  allowed  to  train  on  copyrighted  content without an approval from each of the right holder \u00d0 what should be the scope of such training? What guardrails would be required to be mandated? How will the rights of copyright holder be adequately protected? How will compliance and enforcement be implemented? Similar questions arise of eligibility of AI generated work for copyright. All this would need to be examined and based on the answers, the legal framework adapted or left as is.\n\n## Antitrust\n\nUnfair trade practices as a result of abuse of dominance by a few entities owning large  AI  systems  may  be  a  concern  given  the  concentration  of  computation capability, or data clouds. However, this is not a new concern for the competition law, in  India  or  elsewhere.  Abuse  of  dominance,  vertical  integration  etc.  can  also  be examined  by  the  competition  commission  of  india.  Further,  technology  is  rapidly evolving, a shortage of GPUs pushes the competition to look at models that do not need GPUs and would actually be beneficial to the advancement of the field.\n\nGiven  the  development  of  AI,  new  scenarios  may  emerge  which  might  test  the regulatory  systems.  For  example,  there  could  be  scope  for  algorithmic  collusion where  without  explicit  communication  between  entities  providing  or  deploying  the algorithms.  Therefore,  the  regulators  would  be  best  placed  to  keenly  observe  the developments and engage with industry proactively to understand possible risks.\n\nAssessing \u00d2market dominance\u00d3 and \u00d2abuse of such dominance\u00d3 requires regulators to  monitor  and  analyse  the  different  dynamics  across  the AI  ecosystem.  There  is value in examining how techno-legal measures can assist regulators in modelling the ecosystem impact of the models and apps.\n\n## Definition of AI\n\nWhile  some  countries  have  defined  AI,  Indian  laws  have  generally  taken  a technology agnostic position and focussed on harms and effects. A similar approach may be considered at this stage, given the evolving nature of AI technologies. Most definitions attempt to be future ready but are unlikely to capture how the technology may evolve. Other definitions tend to go too broad thereby creating uncertainty as traditional software could also be interpreted to be in scope. Definitions are probably useful when they are used to pinpoint certain kinds of technologies for which specific regulatory  provisions  are  to  be  mandated.  However,  both  the  definitions  and  the manner  of  identifying  systems  for  regulatory  purposes  is  evolving  and  requires deeper evaluation.\n\n## Safe harbour\n\nThe  safe  harbour  provision  (Section  79)  in  the  IT Act  provides  legal  protection  to intermediaries that host or transmit third-party content online. One of the conditions for  availing  safe  harbour  is  that  the  intermediary  does  not  \u00d2select  or  modify  the content\u00d3. In case AI models, this condition would not be met in many scenarios. It is quite evident that AI systems providers or deployers cannot claim safe harbour as a default and where they do, they would need to demonstrate that they have satisfied the conditions under law.", "metadata": {"country": "India", "year": "2025", "legally_binding": "no", "binding_proof": "", "date": "02/01/2025", "regulator": "Ministry of Electronics and Information Technology", "type": "report", "status": "published", "language": "English", "use_cases": "[1, 3, 5]"}}
{"_id": "686aec25383c6b855905e7a0", "title": "THE INFORMATION TECHNOLOGY ACT, 2000", "source": "https://www.indiacode.nic.in/bitstream/123456789/13116/1/it_act_2000_updated.pdf", "text": "## THE INFORMATION TECHNOLOGY ACT, 2000\n\n---------\n\n## ARRANGEMENT OF SECTIONS\n\n---------\n\n## CHAPTER I\n\n## PRELIMINARY\n\n## SECTIONS\n\n- 1. Short title, extent, commencement and application.\n- 2. Definitions.\n\n## CHAPTER II\n\n## DIGITAL SIGNATURE AND ELECTRONIC SIGNATURE\n\n- 3. Authentication of electronic records.\n- 3A. Electronic signature.\n\n## CHAPTER III\n\n## ELECTRONIC GOVERNANCE\n\n- 4. Legal recognition of electronic records.\n- 5. Legal recognition of electronic signatures.\n- 6. Use of electronic records and electronic signatures in Government and its agencies.\n- 6A. Delivery of services by service provider.\n- 7. Retention of electronic records.\n- 7A. Audit of documents, etc., maintained in electronic form.\n- 8. Publication of rule, regulation, etc., in Electronic Gazette.\n- 9. Sections 6, 7 and 8 not to confer right to insist document should be accepted in electronic form.\n- 10. Power to make rules by Central Government in respect of electronic signature.\n- 10A. Validity of contracts formed through electronic means.\n\n## CHAPTER IV\n\n## ATTRIBUTION, ACKNOWLEDGEMENT AND DESPATCH OF ELECTRONIC RECORDS\n\n- 11. Attribution of electronic records.\n- 12. Acknowledgment of receipt.\n- 13. Time and place of despatch and receipt of electronic record.\n\n## CHAPTER V\n\n## SECURE ELECTRONIC RECORDS AND SECURE ELECTRONIC SIGNATURE\n\n- 14. Secure electronic record.\n- 15. Secure electronic signature.\n- 16. Security procedures and practices.\n\n## CHAPTER VI\n\n## REGULATION OF CERTIFYING AUTHORITIES\n\n- 17. Appointment of Controller and other officers.\n- 18. Functions of Controller.\n- 19. Recognition of foreign Certifying Authorities.\n- 20. [ Omitted .].\n- 21. Licence to issue electronic signature Certificates.\n- 22. Application for licence.\n- 23. Renewal of licence.\n- 24. Procedure for grant or rejection of licence.\n- 25. Suspension of licence.\n- 26. Notice of suspension or revocation of licence.\n\n## SECTIONS\n\n- 27. Power to delegate.\n- 28. Power to investigate contraventions.\n- 29. Access to computers and data.\n- 30. Certifying Authority to follow certain procedures.\n- 31. Certifying Authority to ensure compliance of the Act, etc.\n- 32. Display of licence.\n- 33. Surrender of licence.\n- 34. Disclosure.\n- 48. Appellate Tribunal.\n- 49. [ Omitted .].\n- 50. [ Omitted .].\n- 51. [ Omitted .].\n- 52. [ Omitted .].\n- 52A. [ Omitted .].\n- 52B. [ Omitted .].\n- 52C. [ Omitted .].\n- 52D. Decision by majority.\n- 53. [ Omitted .].\n- 54. [ Omitted .].\n- 55. Orders constituting Appellate Tribunal to be final and not to invalidate its proceedings.\n- 56. [ Omitted .].\n- 57. Appeal to Appellate Tribunal.\n- 58. Procedure and powers of the Appellate Tribunal.\n- 59. Right to legal representation.\n- 60. Limitation.\n- 61. Civil court not to have jurisdiction.\n- 62. Appeal to High Court.\n- 63. Compounding of contraventions.\n\n## CHAPTER VII\n\n## ELECTRONIC SIGNATURE CERTIFICATES\n\n- 35. Certifying authority to issue electronic signature Certificate.\n- 36. Representations upon issuance of Digital signature Certificate.\n- 37. Suspension of Digital Signature Certificate.\n- 38. Revocation of Digital Signature Certificate.\n- 39. Notice of suspension or revocation.\n\n## CHAPTER VIII\n\n## DUTIES OF SUBSCRIBERS\n\n- 40. Generating key pair.\n- 40A. Duties of subscriber of Electronic Signature Certificate.\n- 41. Acceptance of Digital Signature Certificate.\n- 42. Control of private key.\n\n## CHAPTER IX\n\n## PENALTIES, COMPENSATION AND ADJUDICATION\n\n- 43. Penalty and compensation for damage to computer, computer system, etc.\n- 43A. Compensation for failure to protect data.\n- 44. Penalty for failure to furnish information, return, etc.\n- 45. Residuary penalty.\n- 46. Power to adjudicate.\n- 47. Factors to be taken into account by the adjudicating officer.\n\n## CHAPTER X\n\n## THE APPELLATE TRIBUNAL\n\n## SECTIONS\n\n## 64. Recovery of penalty or compensation.\n\n## CHAPTER XI\n\n## OFFENCES\n\n- 65. Tampering with computer source documents.\n- 66. Computer related offences.\n- 66A. Punishment for sending offensive messages through communication service, etc.\n- 66B. Punishment for dishonestly receiving stolen computer resource or communication device.\n- 66C. Punishment for identity theft.\n- 66D. Punishment for cheating by personation by using computer resource.\n- 66E. Punishment for violation of privacy.\n- 66F. Punishment for cyber terrorism.\n- 67. Punishment for publishing or transmitting obscene material in electronic form.\n- 67A. Punishment for publishing or transmitting of material containing sexually explicit act, etc., in electronic form.\n- 67B. Punishment for publishing or transmitting of material depicting children in sexually explicit act, etc., in electronic form.\n- 67C. Preservation and retention of information by intermediaries.\n- 68. Power of Controller to give directions.\n- 69. Power to issue directions for interception or monitoring or decryption of any information through any computer resource.\n- 69A.  Power  to  issue  directions  for  blocking  for  public  access  of  any  information  through  any computer resource.\n- 69B.  Power  to  authorise  to  monitor  and  collect  traffic  data  or  information  through  any  computer resource for cyber security.\n- 70. Protected system.\n- 70A. National nodal agency.\n- 70B. Indian Computer Emergency Response Team to serve as national agency for incident response.\n- 71. Penalty for misrepresentation.\n- 72. Penalty for Breach of confidentiality and privacy.\n- 72A. Punishment for disclosure of information in breach of lawful contract.\n- 73. Penalty for publishing electronic signature Certificate false in certain particulars.\n- 74. Publication for fraudulent purpose.\n- 75. Act to apply for offence or contravention committed outside India.\n- 76. Confiscation.\n- 77. Compensation, penalties or confiscation not to interfere with other punishment.\n- 77A. Compounding of offences.\n- 77B. Offences with three years imprisonment to be bailable.\n- 78. Power to investigate offences.\n\n## CHAPTER XII\n\n## INTERMEDIARIES NOT TO BE LIABLE IN CERTAIN CASES\n\n- 79. Exemption from liability of intermediary in certain cases.\n\n## CHAPTER XIIA\n\n## EXAMINER OF ELECTRONIC EVIDENCE\n\n- 79A. Central Government to notify Examiner of Electronic Evidence.\n\n## CHAPTER XIII\n\n## MISCELLANEOUS\n\n- 80. Power of police officer and other officers to enter, search, etc.\n- 81. Act to have overriding effect.\n- 81A. Application of the Act to electronic cheque and truncated cheque.\n- 82. Controller, Deputy Controller and Assistant Controller to be public servants.\n\n## SECTIONS\n\n- 83. Power to give directions.\n- 84. Protection of action taken in good faith.\n- 84A. Modes or methods for encryption.\n- 84B. Punishment for abetment of offences.\n- 84C. Punishment for attempt to commit offences.\n- 85. Offences by companies.\n- 86. Removal of difficulties.\n- 87. Power of Central Government to make rules.\n- 88. Constitution of Advisory Committee.\n- 89. Power of Controller to make regulations.\n- 90. Power of State Government to make rules.\n- 91. [ Omitted. ].\n- 92. [ Omitted. ].\n- 93. [ Omitted. ].\n- 94. [ Omitted. ].\n\nTHE FIRST SCHEDULE.\n\nTHE SECOND SCHEDULE.\n\nTHE THIRD SCHEDULE [ Omitted. ].\n\nTHE FOURTH SCHEDULE [ Omitted. ].\n\n## THE INFORMATION TECHNOLOGY ACT, 2000\n\nACT NO. 21 OF 2000\n\n[9 th June , 2000.]\n\nAn  Act  to  provide  legal  recognition  for  transactions  carried  out  by  means  of  electronic  data interchange  and  other  means  of  electronic  communication,  commonly  referred  to  as -electronic  commerce\u2016,  which  involve  the  use  of  alternatives  to  paper-based  methods  of communication and storage of information, to facilitate electronic filing of documents with the Government agencies and further to amend the Indian Penal Code, the Indian Evidence Act, 1872, the Banker's Books Evidence Act, 1891 and the Reserve Bank of India Act, 1934 and for matters connected therewith or incidental thereto.\n\nWHEREAS the General Assembly of the United Nations by resolution A/RES/51/162, dated the 30th January,  1997  has  adopted  the  Model  Law  on  Electronic  Commerce  adopted  by  the  United  Nations Commission on International Trade Law;\n\nAND  WHEREAS  the  said  resolution  recommends inter alia , that all States give favourable consideration  to  the  said  Model  Law  when  they  enact  or  revise  their  laws,  in  view  of  the  need  for uniformity of the law applicable to alternatives to paper-based methods of communication and storage of information;\n\nAND WHEREAS it is considered necessary to give effect to the said resolution and to promote efficient delivery of Government services by means of reliable electronic records.\n\nBE it enacted by Parliament in the Fifty-first Year of the Republic of India as follows:-\n\n## CHAPTER 1\n\n## PRELIMINARY\n\n- 1.  Short  title,  extent,  commencement  and  application. -( 1 )  This Act  may  be  called  the Information Technology Act, 2000.\n- ( 2 ) It shall extend to the whole of India and, save as otherwise provided in this Act, it applies also to any offence or contravention thereunder committed outside India by any person.\n- ( 3 ) It shall come into force on such date 1 as the Central Government may, by notification, appoint and different  dates  may  be  appointed  for  different  provisions  of  this  Act  and  any  reference  in  any  such provision to the commencement of this Act shall be construed as a reference to the commencement of that provision.\n- 2 [( 4 ) Nothing in this Act shall apply to documents or transactions specified in the First Schedule:\n\nProvided that the Central Government may, by notification in the Official Gazette, amend the First Schedule by way of addition or deletion of entries thereto.\n\n- ( 5 ) Every notification issued under sub-section ( 4 ) shall be laid before each House of Parliament.]\n- 2. Definitions. -( 1 ) In this Act, unless the context otherwise requires,-\n- ( a )  -access\u2016 with its grammatical variations and cognate expressions means gaining entry into, instructing  or  communicating  with  the  logical,  arithmetical,  or  memory  function  resources  of  a computer, computer system or computer network;\n- ( b ) -addressee\u2016 means a person who is intended by the originator to receive the electronic record but does not include any intermediary;\n- ( c )  -adjudicating  officer\u2016  means  an  adjudicating  officer  appointed  under  sub-section  ( 1 )  of section 46;\n\n1.  17th  October,  2000, vide notification  No.  G.S.R.  788  (E),  dated  17th  October,  2000, see Gazette  of  India,  Extraordinary, Part II, sec. 3( ii ).\n\n2. Subs. by Act 10 of 2009, s. 3, for sub-section ( 4 ) (w.e.f. 27-10-2009).\n\n- ( d )  -affixing 1 [electronic  signature]\u2016  with  its  grammatical  variations  and  cognate  expressions means adoption of any methodology or procedure by a person for the purpose of authenticating an electronic record by means of digital signature;\n- 2 [( da ) -Appellate Tribunal\u2016 means the Appellate Tribunal referred to in sub-section ( 1 ) of section 48;]\n- ( e ) -appropriate Government\u2016 means as respects any matter,-\n- ( i ) enumerated in List II of the Seventh Schedule to the Constitution;\n- ( ii )  relating  to  any  State  law  enacted  under  List  III  of  the  Seventh  Schedule  to  the Constitution,\n\nthe State Government and in any other case, the Central Government;\n\n- ( f ) -asymmetric crypto system\u2016 means a system of a secure key pair consisting of a private key for creating a digital signature and a public key to verify the digital signature;\n- ( g ) -Certifying Authority\u2016 means a person who has been granted a licence to issue a 1 [electronic signature] Certificate under section 24;\n- ( h )  -certification  practice  statement\u2016  means  a  statement  issued  by  a  Certifying  Authority  to specify  the  practices  that  the  Certifying  Authority  employs  in  issuing 1 [electronic signature] Certificates;\n- 3 [( ha ) -communication device\u2016 means cell phones, personal digital assistance or combination of both or any other device used to communicate, send or transmit any text, video, audio or image;]\n- ( i ) -computer\u2016 means any electronic, magnetic, optical or other high-speed data processing device or system which performs logical, arithmetic, and memory functions by manipulations of electronic, magnetic or optical impulses, and includes all input, output, processing, storage, computer software or communication facilities  which  are  connected  or  related  to  the  computer  in  a  computer  system  or computer network;\n- 4 [( j )  -computer  network\u2016  means  the  inter-connection  of  one  or  more  computers  or  computer systems or communication device through-\n- ( i )  the  use  of  satellite,  microwave,  terrestrial  line,  wire,  wireless  or  other  communication media; and\n- ( ii )  terminals  or  a  complex  consisting  of  two  or  more  interconnected  computers  or communication device whether or not the inter-connection is continuously maintained;]\n- ( k )  -computer resource\u2016 means computer, computer system, computer network, data, computer data base or software;\n- ( l ) -computer system\u2016 means a device or collection of devices, including input and output support devices  and  excluding  calculators  which  are  not  programmable  and  capable  of  being  used  in conjunction  with  external  files,  which  contain  computer  programmes,  electronic  instructions,  input data  and  output  data,  that  performs  logic,  arithmetic,  data  storage  and  retrieval,  communication control and other functions;\n- ( m ) -Controller\u2016 means the Controller of Certifying Authorities appointed under sub-section ( 1 ) of section 17;\n\n5 *\n\n*\n\n*\n\n*\n\n*\n\n2 [( na ) -cyber cafe\u2016 means any facility from where access to the internet is offered by any person in the ordinary course of business to the members of the public;\n\n1. Subs. by Act 10 of 2009, s. 2, for -digital signature\u2016 (w.e.f. 27-10-2009).\n\n2. Ins. by Act 7 of 2017, s. 169 (w.e.f. 26-5-2017).\n\n3. Ins. by Act 10 of 2009, s. 4, ibid . (w.e.f. 27-10-2009).\n\n4. Subs. by s. 4, ibid ., for clause ( j ) (w.e.f. 27-10-2009).\n\n5. Clause ( n ) omitted by Act 7 of 2017, s.169 (w.e.f. 26-5-2017).\n\n- ( nb )  -cyber  security\u2016  means  protecting  information,  equipment,  devices,  computer,  computer resource,  communication  device  and  information  stored  therein  from  unauthorised  access,  use, disclosure, disruption, modification or destruction;]\n- ( o )  -data\u2016  means  a  representation  of  information,  knowledge,  facts,  concepts  or  instructions which  are  being  prepared  or  have  been  prepared  in  a  formalised  manner,  and  is  intended  to  be processed, is being processed or has been processed in a computer system or computer network, and may be in any form (including computer printouts magnetic or optical storage media, punched cards, punched tapes) or stored internally in the memory of the computer;\n- ( p ) -digital signature\u2016 means authentication of any electronic record by a subscriber by means of an electronic method or procedure in accordance with the provisions of section 3;\n- ( q ) -Digital Signature Certificate\u2016 means a Digital Signature Certificate issued under sub-section ( 4 ) of section 35;\n- ( r )  -electronic  form\u2016  with  reference  to  information,  means  any  information  generated,  sent, received or stored in media, magnetic, optical, computer memory, micro film,  computer generated micro fiche or similar device;\n- ( s ) -Electronic Gazette\u2016 means the Official Gazette published in the electronic form;\n- ( t ) -electronic record\u2016 means data, record or data generated, image or sound stored, received or sent in an electronic form or micro film or computer generated micro fiche;\n- 1 [( ta )  -electronic  signature\u2016  means  authentication  of  any  electronic  record  by  a  subscriber  by means of the electronic technique specified in the Second Schedule and includes digital signature;\n- ( tb )  -Electronic  Signature  Certificate\u2016  means  an  Electronic  Signature  Certificate  issued  under section 35 and includes Digital Signature Certificate;]\n- ( u )  -function\u2016, in relation to a computer, includes logic, control, arithmetical process, deletion, storage and retrieval and communication or telecommunication from or within a computer;\n- 1 [( ua )  Indian  Computer  Emergency  Response  Team\u2016  means  an  agency  established  under  subsection ( 1 ) of Section 70B;]\n- ( v )  -information\u2016  includes 2 [data,  message,  text,]  images,  sound,  voice,  codes,  computer programmes, software and data bases or micro film or computer generated micro fiche;\n- 3 [( w ) -intermediary\u2016, with respect to any particular electronic records, means any person who on behalf of another person receives, stores or transmits that record or provides any service with respect to  that  record  and  includes  telecom  service  providers,  network  service  providers,  internet  service providers, web-hosting service providers, search engines, online payment sites, online-auction sites, online-market places and cyber cafes;]\n- ( x )  -key  pair\u2016,  in  an  asymmetric  crypto  system,  means  a  private  key  and  its  mathematically related public key, which are so related that the public key can verify a digital signature created by the private key;\n- ( y ) -law\u2016 includes any Act of Parliament or of a State Legislature, Ordinances promulgated by the President or a Governor, as the case may be, Regulations made by the President under article 240, Bills enacted as President's Act under sub-clause ( a ) of clause ( 1 ) of article 357 of the Constitution and includes rules, regulations, bye-laws and orders issued or made thereunder;\n- ( z ) -licence\u2016 means a licence granted to a Certifying Authority under section 24;\n- ( za ) -originator\u2016 means a person who sends, generates, stores or transmits any electronic message or causes any electronic message to be sent, generated, stored or transmitted to any other person but does not include an intermediary;\n- ( zb ) -prescribed\u2016 means prescribed by rules made under this Act;\n- ( zc ) -private key\u2016 means the key of a key pair used to create a digital signature;\n\n1. Ins. by Act 10 of 2009, s. 4 (w.e.f. 27-10-2009).\n\n2. Subs. by s. 4, ibid., for -data, text\u2016 (w.e.f. 27-10-2009).\n\n3. Subs. by s. 4, ibid., for clause ( w ) (w.e.f. 27-10-2009).\n\n- ( zd ) -public key\u2016 means the key of a key pair used to verify a digital signature and listed in the Digital Signature Certificate;\n- ( ze ) -secure system\u2016 means computer hardware, software, and procedure that-\n- ( a ) are reasonably secure from unauthorised access and misuse;\n- ( b ) provide a reasonable level of reliability and correct operation;\n- ( c ) are reasonably suited to performing the intended functions; and\n- ( d ) adhere to generally accepted security procedures;\n- ( zf ) -security procedure\u2016 means the security procedure prescribed under section 16 by the Central Government;\n- ( zg ) -subscriber\u2016 means a person in whose name the 1 [electronic signature] Certificate is issued;\n- ( zh )  -verify\u2016,  in  relation  to  a  digital  signature,  electronic  record  or  public  key,  with  its grammatical variations and cognate expressions, means to determine whether-\n- ( a ) the initial electronic record was affixed with the digital signature by the use of private key corresponding to the public key of the subscriber;\n- ( b )  the  initial  electronic  record  is  retained  intact  or  has  been  altered  since  such  electronic record was so affixed with the digital signature.\n- ( 2 ) Any reference in this Act to any enactment or any provision thereof shall, in relation to an area in which such enactment or such provision is not in force, be construed as a reference to the corresponding law or the relevant provision of the corresponding law, if any, in force in that area.\n\n## CHAPTER II\n\n2 [DIGITAL SIGNATURE AND ELECTRONIC SIGNATURE]\n\n- 3. Authentication of electronic records.-( 1 ) Subject to the provisions of this section any subscriber may authenticate an electronic record by affixing his digital signature.\n- ( 2 )  The  authentication  of  the  electronic  record  shall  be  effected  by  the  use  of  asymmetric  crypto system and hash function which envelop and transform the initial electronic record into another electronic record.\n\nExplanation .-For the purposes of this sub-section, -hash function\u2016 means an algorithm mapping or translation of one sequence of bits into another, generally smaller, set known as -hash result\u2016 such that an electronic record yields the same hash result every time the algorithm is executed with the same electronic record as its input making it computationally infeasible-\n\n- ( a )  to  derive  or  reconstruct  the  original electronic  record from  the  hash  result produced  by the algorithm;\n- ( b ) that two electronic records can produce the same hash result using the algorithm.\n- ( 3 ) Any person by the use of a public key of the subscriber can verify the electronic record.\n- ( 4 ) The private key and the public key are unique to the subscriber and constitute a functioning key pair.\n- 3 [3A. Electronic signature. -( 1 ) Notwithstanding anything contained in section 3, but subject to the provisions  of  sub-section  ( 2 ),  a  subscriber  may  authenticate  any  electronic  record  by  such  electronic signature or electronic authentication technique which-\n- ( a ) is considered reliable; and\n- ( b ) may be specified in the Second Schedule.\n- ( 2 )  For  the  purposes  of  this  section  any  electronic  signature  or  electronic  authentication  technique shall be considered reliable if-\n\n1. Subs. by Act 10 of 2009, s. 2, for -digital signature\u2016 (w.e.f. 27-10-2009).\n\n2. Subs. by s. 5, ibid ., for the heading -DIGITAL SIGNATURE\u2016 (w.e.f. 27-10-2009).\n\n3. Ins. by s. 6, ibid. (w.e.f. 27-10-2009).\n\n- ( a ) the signature creation data or the authentication data are, within the context in which they are used, linked to the signatory or, as the case may be, the authenticator and to no other person;\n- ( b )  the signature creation data or the authentication data were, at the time of signing, under the control of the signatory or, as the case may be, the authenticator and of no other person;\n- ( c ) any alteration to the electronic signature made after affixing such signature is detectable;\n- ( d )  any  alteration  to  the  information  made  after  its  authentication  by  electronic  signature  is detectable; and\n- ( e ) it fulfils such other conditions which may be prescribed.\n- ( 3 )  The  Central  Government  may  prescribe  the  procedure  for  the  purpose  of  ascertaining  whether electronic signature is that of the person by whom it is purported to have been affixed or authenticated.\n- ( 4 )  The  Central  Government  may,  by  notification  in  the  Official  Gazette,  add  to  or  omit  any electronic signature or electronic authentication technique and the procedure for affixing such signature from the Second Schedule:\n\nProvided  that  no  electronic  signature  or  authentication  technique  shall  be  specified  in  the  Second Schedule unless such signature or technique is reliable.\n\n- ( 5 ) Every notification issued under sub-section ( 4 ) shall be laid before each House of Parliament.]\n\n## CHAPTER III\n\n## ELECTRONIC GOVERNANCE\n\n- 4. Legal recognition of electronic records. -Where any law provides that information or any other matter shall be in writing or in the typewritten or printed form, then, notwithstanding anything contained in such law, such requirement shall be deemed to have been satisfied if such information or matter is-\n- ( a ) rendered or made available in an electronic form; and\n- ( b ) accessible so as to be usable for a subsequent reference.\n- 5. Legal recognition of 1 [electronic signatures]. -Where any law provides that information or any other matter shall be authenticated by affixing the signature or any document shall be signed or bear the signature of any person, then, notwithstanding anything contained in such law, such requirement shall be deemed to have been satisfied, if such information or matter is authenticated by  means of 1 [electronic signature] affixed in such manner as may be prescribed by the Central Government.\n\nExplanation .-For the purposes of this section, -signed\u2016, with its grammatical variations and cognate expressions, shall, with reference to a person, mean affixing of his hand written signature or any mark on any document and the expression -signature\u2016 shall be construed accordingly.\n\n- 6.  Use  of  electronic  records  and 1 [electronic  signatures]  in  Government  and  its  agencies. -( 1 ) Where any law provides for-\n- ( a )  the  filing  of  any  form,  application  or  any  other  document  with  any  office,  authority,  body  or agency owned or controlled by the appropriate Government in a particular manner;\n- ( b )  the  issue  or  grant  of  any  licence,  permit,  sanction  or  approval  by  whatever  name  called  in  a particular manner;\n- ( c ) the receipt or payment of money in a particular manner,\n\nthen, notwithstanding anything contained in any other law for the time being in force, such requirement shall be deemed to have been satisfied if such filing, issue, grant, receipt or payment, as the case may be, is effected by means of such electronic form as may be prescribed by the appropriate Government.\n\n- ( 2 ) The appropriate Government may, for the purposes of sub-section ( 1 ), by rules, prescribe-\n- ( a ) the manner and format in which such electronic records shall be filed, created or issued;\n\n1. Subs. by Act 10 of 2009, s. 2, for -digital signatures\u2016 (w.e.f. 27-10-2009).\n\n- ( b )  the  manner  or  method  of  payment  of  any  fee  or  charges  for  filing,  creation  or  issue  any electronic record under clause ( a ).\n- 1 [6A.  Delivery  of  services  by  service  provider. -( 1 )  The  appropriate  Government  may,  for  the purposes  of  this  Chapter  and  for  efficient  delivery  of  services  to  the  public  through  electronic  means authorise, by order, any service provider to set up, maintain and upgrade the computerised facilities and perform such other services as it may specify, by notification in the Official Gazette.\n\nExplanation .-For  the  purposes  of  this  section, service provider  so authorised includes  any individual, private agency, private company, partnership firm, sole proprietor firm or any such other body or agency which has been granted permission by the appropriate Government to offer services through electronic means in accordance with the policy governing such service sector.\n\n- ( 2 ) The  appropriate Government  may  also  authorise any service provider authorised under sub-section  ( 1 )  to  collect,  retain  and  appropriate  such  service  charges,  as  may  be  prescribed  by  the appropriate  Government  for  the  purpose  of  providing  such  services,  from  the  person  availing  such service.\n- ( 3 ) Subject to the provisions of sub-section ( 2 ), the appropriate Government may authorise the service providers to collect, retain and appropriate service charges under this section notwithstanding the fact that there  is  no  express  provision  under  the  Act,  rule,  regulation  or  notification  under  which  the  service  is provided to collect, retain and appropriate e-service charges by the service providers.\n- ( 4 )  The  appropriate  Government  shall,  by  notification  in  the  Official  Gazette,  specify  the  scale  of service charges which may be charged and collected by the service providers under this section:\n\nProvided that the appropriate Government may specify different scale of service charges for different types of services.]\n\n- 7.  Retention  of  electronic  records. -( 1 )  Where  any  law  provides  that  documents,  records  or information shall be retained for any specific period, then, that requirement shall be deemed to have been satisfied if such documents, records or information are retained in the electronic form, if-\n- ( a )  the  information  contained  therein  remains  accessible  so  as  to  be  usable  for  a  subsequent reference;\n- ( b )  the  electronic  record  is  retained  in  the  format  in  which  it  was  originally  generated,  sent  or received or in a format which can be demonstrated to represent accurately the information originally generated, sent or received;\n- ( c ) the details which will facilitate the identification of the origin, destination, date and time of despatch or receipt of such electronic record are available in the electronic record:\n\nProvided that  this  clause  does  not  apply  to  any  information  which  is  automatically  generated solely for the purpose of enabling an electronic record to be despatched or received.\n\n- ( 2 )  Nothing  in  this  section  shall  apply  to  any  law  that  expressly  provides  for  the  retention  of documents, records or information in the form of electronic records.\n- 2 [ 7A. Audit of documents, etc., maintained in electronic form. -Where in any law for the time being in force, there is a provision for audit of documents, records or information, that provision shall also be applicable for audit of documents, records or information processed and maintained in the electronic form.]\n- 8. Publication of rule, regulation, etc., in Electronic Gazette. -Where any law provides that any rule, regulation, order, bye-law, notification or any other matter shall be published in the Official Gazette, then, such requirement shall be deemed to have been satisfied if such rule, regulation, order, bye-law, notification or any other matter is published in the Official Gazette or Electronic Gazette:\n\nProvided that where any rule, regulation, order, by-law, notification or any other matter is published in the Official Gazette or Electronic Gazette, the date of publication shall be deemed to be the date of the Gazette which was first published in any form.\n\n- 9.  Sections  6,  7  and  8  not  to  confer  right  to  insist  document  should  be  accepted  in  electronic form. -Nothing contained in sections 6, 7 and 8 shall confer a right upon any person to insist that any\n\n1. Ins. by Act 10 of 2009, s. 7 (w.e.f. 27-10-2009).\n\n2. Ins. by s. 8, ibid. (w.e.f. 27-10-2009).\n\nMinistry or Department of the Central Government or the State Government or any authority or body established  by  or  under  any  law  or  controlled  or  funded  by  the  Central  or  State  Government  should accept,  issue,  create,  retain  and  preserve  any  document  in  the  form  of  electronic  records  or  effect  any monetary transaction in the electronic form.\n\n- 10.  Power  to  make  rules  by  Central  Government  in  respect  of 1 [electronic  signature]. -The Central Government may, for the purposes of this Act, by rules, prescribe-\n- ( a ) the type of 1 [electronic signature];\n- ( b ) the manner and format in which the 1 [electronic signature] shall be affixed;\n- ( c ) the manner or procedure which facilitates identification of the person affixing the 1 [electronic signature];\n- ( d ) control processes and procedures to ensure adequate integrity, security and confidentiality of electronic records or payments; and\n- ( e ) any other matter which is necessary to give legal effect to 1 [electronic signatures].\n- 2 [10A. Validity of contracts formed through electronic means. -Where in a contract formation, the communication  of  proposals,  the acceptance  of proposals, the revocation of proposals and acceptances, as the case may be, are expressed in electronic form or by means of an electronic records, such contract shall not be deemed to be unenforceable solely on the ground that such electronic form or means was used for that purpose.]\n\n## CHAPTER IV\n\nATTRIBUTION, ACKNOWLEDGMENT AND DESPATCH OF ELECTRONIC RECORDS\n\n- 11. Attribution of electronic records. -An electronic record shall be attributed to the originator-\n- ( a ) if it was sent by the originator himself;\n- ( b )  by  a  person  who  had  the  authority  to  act  on  behalf  of  the  originator  in  respect  of  that electronic record; or\n- ( c )  by  an  information  system  programmed  by  or  on  behalf  of  the  originator  to  operate automatically.\n- 12. Acknowledgment  of  receipt. -( 1 ) Where  the originator has not 3 [stipulated] that the acknowledgment of receipt of electronic record be given in a particular form or by a particular method, an acknowledgment may be given by-\n- ( a ) any communication by the addressee, automated or otherwise; or\n- ( b ) any conduct of the addressee, sufficient to indicate to the originator that the electronic record has been received.\n- ( 2 ) Where the originator has stipulated that the electronic record shall be binding only on receipt of an acknowledgment of such electronic record by him, then unless acknowledgment has been so received, the electronic record shall he deemed to have been never sent by the originator.\n- ( 3 ) Where the originator has not stipulated that the electronic record shall be binding only on receipt of  such  acknowledgment,  and  the  acknowledgment  has  not  been received  by  the  originator  within  the time specified or agreed or, if no time has been specified or agreed to within a reasonable time, then the originator may give notice to the addressee stating that no acknowledgment has been received by him and specifying  a  reasonable  time  by  which  the  acknowledgment  must  be  received  by  him  and  if  no acknowledgment is received within the aforesaid time limit he may after giving notice to the addressee, treat the electronic record as though it has never been sent.\n- 13. Time and place of despatch and receipt of electronic record. -( 1 ) Save as otherwise agreed to between the originator and the addressee, the  despatch of an electronic record occurs when it enters a computer resource outside the control of the originator.\n\n1. Subs. by Act 10 of 2009, s. 2, for -digital signature\u2016 (w.e.f. 27-10-2009).\n\n2. Ins. by s. 9, ibid . (w.e.f. 27-10-2009).\n\n3. Subs. by s. 10, ibid ., for  -agreed with the addressee\u2016 (w.e.f. 27-10-2009).\n\n- ( 2 ) Save  as  otherwise  agreed  between the originator and  the  addressee, the  time  of  receipt of an electronic record shall be determined as follows, namely:-\n- ( a )  if  the  addressee  has  designated  a  computer  resource for the purpose of receiving electronic records,-\n- ( i )  receipt  occurs  at  the  time  when  the  electronic  record  enters  the  designated  computer resource; or\n- ( ii )  if  the  electronic  record  is  sent  to  a  computer  resource  of  the  addressee  that  is  not  the designated computer resource, receipt occurs at the time when the electronic record is retrieved by the addressee;\n- ( b ) if the addressee has not designated a computer resource along with specified timings, if any, receipt occurs when the electronic record enters the computer resource of the addressee.\n- ( 3 )  Save  as  otherwise  agreed  to  between  the  originator  and  the  addressee,  an  electronic  record  is deemed to be despatched at the place where the originator has his place of business, and is deemed to be received at the place where the addressee has his place of business.\n- ( 4 ) The provisions of sub-section ( 2 ) shall apply notwithstanding that the place where the computer resource is located may be different from the place where the electronic record is deemed to have been received under sub-section ( 3 ).\n- ( 5 ) For the purposes of this section,-\n- ( a ) if the originator or the addressee has more than one place of business, the principal place of business, shall be the place of business;\n- ( b )  if  the  originator  or  the  addressee  does  not  have  a  place  of  business,  his  usual  place  of residence shall be deemed to be the place of business;\n- ( c )  -usual  place  of  residence\u2016,  in  relation  to  a  body  corporate,  means  the  place  where  it  is registered.\n\n## CHAPTER V\n\n## SECURE ELECTRONIC RECORDS AND SECURE  1 [ELECTRONIC SIGNATURE]\n\n- 14.  Secure  electronic  record. -Where  any  security  procedure  has  been  applied  to  an  electronic record at a specific point of time, then such record shall he deemed to be a secure electronic record from such point of time to the time of verification.\n- 2 [15. Secure electronic signature. -An electronic signature shall be deemed to be a secure electronic signature if-\n- ( i ) the signature creation data, at the time of affixing signature, was under the exclusive control of signatory and no other person; and\n- ( ii )  the  signature  creation  data  was  stored  and  affixed  in  such  exclusive  manner  as  may  be prescribed.\n- Explanation. -In case of digital signature, the -signature creation data\u2016 means the private key of the subscriber.\n- 16. Security procedures and practices. -The Central Government may, for the purposes of sections 14 and 15, prescribe the security procedures and practices:\n\nProvided that  in  prescribing  such  security  procedures  and  practices,  the  Central  Government  shall have regard to the commercial circumstances, nature of transactions and such other related factors as it may consider appropriate.]\n\n## CHAPTER VI\n\n## REGULATION OF CERTIFYING AUTHORITIES\n\n- 17.  Appointment  of  Controller  and  other  officers. -( 1 )  The  Central  Government  may,  by notification in the Official Gazette, appoint a Controller of Certifying Authorities for the purposes of this Act  and  may  also  by  the  same  or  subsequent  notification  appoint  such  number  of  Deputy  Controllers 3 [, Assistant Controllers, other officers and employees]  as it deems fit.\n\n1. Subs. by Act 10 of 2009, s. 2, for -digital signatures\u2016 (w.e.f. 27-10-2009).\n\n2. Subs. by s 11, ibid., for sections 15 and 16 (w.e.f. 27-10-2009).\n\n3. Subs. by s.12, ibid., for -and Assistant Controllers\u2016 (w.e.f. 27-10-2009).\n\n- ( 2 )  The  Controller  shall  discharge  his  functions  under  this  Act  subject  to  the  general  control  and directions of the Central Government.\n- ( 3 ) The Deputy Controllers and Assistant Controllers shall perform the functions assigned to them by the Controller under the general superintendence and control of the Controller.\n- ( 4 )  The  qualifications,  experience  and  terms  and  conditions  of  service  of  Controller,  Deputy Controllers 1 [,Assistant Controllers, other officers and employees] shall be such as may be prescribed by the Central Government.\n- ( 5 ) The Head Office and Branch Office of the office of the Controller shall be at such places as the Central Government may specify, and these may be established at such places as the Central Government may think fit.\n- ( 6 ) There shall be a seal of the Office of the Controller.\n- 18.  Functions  of  Controller. -The Controller may perform all or any of the following functions, namely:-\n- ( a ) exercising supervision over the activities of the Certifying Authorities;\n- ( b ) certifying public keys of the Certifying Authorities;\n- ( c ) laying down the standards to be maintained by the Certifying Authorities;\n- ( d )  specifying  the  qualifications  and  experience  which  employees  of  the  Certifying  Authority should possess;\n- ( e )  specifying  the  conditions  subject  to  which  the  Certifying  Authorities  shall  conduct  their business;\n- ( f ) specifying the contents of written, printed or visual materials and advertisements that may be distributed or used in respect of a 2 [electronic signature] Certificate and the public key;\n- ( g ) specifying the form and content of a 2 [electronic signature] Certificate and the key;\n- ( h )  specifying  the  form  and  manner  in  which  accounts  shall  be  maintained  by  the  Certifying Authorities;\n- ( i )  specifying  the  terms  and  conditions  subject  to  which  auditors  may  be  appointed  and  the remuneration to be paid to them;\n- ( j ) facilitating the establishment of any electronic system by a Certifying Authority either solely or jointly with other Certifying Authorities and regulation of such systems;\n- ( k ) specifying the manner in which the Certifying Authorities shall conduct their dealings with the subscribers;\n- ( l ) resolving any conflict of interests between the Certifying Authorities and the subscribers;\n- ( m ) laying down the duties of the Certifying Authorities;\n- ( n )  maintaining  a  data  base  containing  the  disclosure  record  of  every  Certifying  Authority containing such particulars as may be specified by regulations, which shall be accessible to public.\n- 19. Recognition of foreign Certifying Authorities. -( 1 ) Subject to such conditions and restrictions as  may  be  specified  by  regulations,  the  Controller  may  with  the  previous  approval  of  the  Central Government, and by notification in the Official Gazette, recognise any foreign Certifying Authority as a Certifying Authority for the purposes of this Act.\n- ( 2 )  Where any Certifying Authority is recognised under sub-section ( 1 ),  the 2 [electronic  signature] Certificate issued by such Certifying Authority shall be valid for the purposes of this Act.\n- ( 3 )  The  Controller may, if he is satisfied that any Certifying Authority has contravened  any of the conditions and restrictions subject to which it was granted recognition under sub-section ( 1 ) he may, for reasons to be recorded in writing, by notification in the Official Gazette, revoke such recognition.\n\n1. Subs. by Act 10 of 2009, s. 12, for -Assistant Controllers\u2016 (w.e.f. 27-10-2009).\n\n2. Subs. by s. 2, ibid., for -Digital Signature\u2016 (w.e.f. 27-10-2009).\n\n- 20. [ Controller  to  act  as  repository . ] Omitted  by  the  Information  Technology ( Amendment ) Act , 2008 (10 of 2009), s . 13 ( w . e . f . 27-10-2009).\n- 21.  Licence  to  issue 1 [electronic  signature]  Certificates. -( 1 ) Subject  to  the  provisions  of sub-section ( 2 ), any person may make an application, to the Controller, for a licence to issue 1 [electronic signature] Certificates.\n- ( 2 )  No  licence  shall  be  issued  under  sub-section  ( 1 ),  unless  the  applicant  fulfils  such  requirements with respect to qualification, expertise, manpower, financial resources and other infrastructure facilities, which  are  necessary  to  issue 1 [electronic  signature]  Certificates  as  may  be  prescribed  by  the  Central Government.\n- ( 3 ) A licence granted under this section shall-\n- ( a ) be valid for such period as may be prescribed by the Central Government;\n- ( b ) not be transferable or heritable;\n- ( c ) be subject to such terms and conditions as may be specified by the regulations.\n- 22. Application for licence. -( 1 )  Every application for issue of a licence shall be in such form as may be prescribed by the Central Government.\n- ( 2 ) Every application for issue of a licence shall be accompanied by-\n- ( a ) a certification practice statement;\n- ( b ) a statement including the procedures with respect to identification of the applicant;\n- ( c ) payment of such fees, not exceeding twenty-five thousand rupees as may be prescribed by the Central Government;\n- ( d ) such other documents, as may be prescribed by the Central Government.\n- 23. Renewal of licence. -An application for renewal of a licence shall be-\n- ( a ) in such form;\n- ( b ) accompanied by such fees, not exceeding five thousand rupees, as may be prescribed by the Central Government and shall be made not less than forty-five days before the date of expiry of the period of validity of the licence.\n- 24. Procedure for grant or rejection of licence. -The Controller may, on receipt of an application under sub-section ( 1 )  of  section 21, after considering the documents accompanying the application and such other factors, as he deems fit, grant the licence or reject the application:\n\nProvided that no application shall be rejected under this section unless the applicant has been given a reasonable opportunity of presenting his case.\n\n- 25. Suspension of licence. -( 1 ) The Controller may, if he is satisfied after making such inquiry, as he may think fit, that a Certifying Authority has-\n- ( a ) made a statement in, or in relation to, the application for the issue or renewal of the licence, which is incorrect or false in material particulars;\n- ( b ) failed to comply with the terms and conditions subject to which the licence was granted;\n- 2 [( c ) failed to maintain the procedures and standards specified in section 30;]\n- ( d ) contravened any provisions of this Act, rule, regulation or order made thereunder,\n\n## revoke the licence:\n\nProvided that no licence shall be revoked unless the Certifying Authority has been given a reasonable opportunity of showing cause against the proposed revocation.\n\n- ( 2 ) The Controller may, if he has reasonable cause to believe that there is any ground for revoking a licence  under  sub-section  ( 1 ),  by  order  suspend  such  licence  pending  the  completion  of  any  enquiry ordered by him:\n\n1. Subs. by Act 10 of 2009, s. 2, for -Digital Signature\u2016 (w.e.f. 27-10-2009).\n\n2. Subs. by notification No. S.O. 1015(E) (w.e.f. 19-9-2002).\n\nProvided that  no licence  shall  be  suspended  for  a  period  exceeding  ten  days  unless  the  Certifying Authority has been given a reasonable opportunity of showing cause against the proposed suspension.\n\n- ( 3 ) No Certifying Authority whose licence has been suspended shall issue any 1 [electronic signature] Certificate during such suspension.\n- 26.  Notice  of  suspension  or  revocation  of  licence. -( 1 )  Where  the  licence  of  the  Certifying Authority is suspended or revoked, the Controller shall publish notice of such suspension or revocation, as the case may be, in the data base maintained by him.\n- ( 2 )  Where  one  or  more  repositories  are  specified,  the  Controller  shall  publish  notices  of  such suspension or revocation, as the case may be, in all such repositories:\n\nProvided that the data base containing the notice of such suspension or revocation, as the case may be, shall be made available through a web site which shall be accessible round the clock:\n\nProvided further that the Controller may, if he considers necessary, publicise the contents of data base in such electronic or other media, as he may consider appropriate.\n\n- 27. Power to delegate. -The Controller may, in writing, authorise the Deputy Controller, Assistant Controller or any officer to exercise any of the powers of the Controller under this Chapter.\n- 28. Power to investigate contraventions. -( 1 )  The Controller or any officer authorised by him in this  behalf  shall  take  up  for  investigation  any  contravention  of  the  provisions  of  this  Act,  rules  or regulations made thereunder.\n- ( 2 ) The Controller or any officer authorised by him in this behalf shall exercise the like powers which are conferred on Income-tax authorities under Chapter XIII of the Income-tax Act, 1961 (43 of 1961), and shall exercise such powers, subject to such limitations laid down under that Act.\n- 29. Access to computers and data. -( 1 )  Without prejudice to the provisions of sub-section ( 1 )  of section 69, the Controller or any person authorised by him shall, if he has reasonable cause to suspect that 2 [any contravention of the provisions of this Chapter] has been committed, have access to any computer system,  any  apparatus,  data  or  any  other  material  connected  with  such  system,  for  the  purpose  of searching or causing a search to be made for obtaining any information or data contained in or available to such computer system.\n- ( 2 ) For the purposes of sub-section ( 1 ), the Controller or any person authorised by him may, by order, direct any person in charge of, or otherwise concerned with the operation of, the computer system, data apparatus  or  material,  to  provide  him  with  such  reasonable  technical  and  other  assistance  as  he  may consider necessary.\n- 30. Certifying Authority to follow certain procedures. -Every Certifying Authority shall,-\n- ( a ) make use of hardware, software and procedures that are secure from intrusion and misuse;\n- ( b )  provide  a  reasonable  level  of  reliability  in  its  services  which  are  reasonably  suited  to  the performance of intended functions;\n- ( c )  adhere  to  security  procedures  to  ensure  that  the  secrecy  and  privacy  of  the 1 [electronic signatures] are assured; 3 ***\n\n4 [( ca ) be the repository of all electronic signature Certificates issued under this Act;\n\n- ( cb )  publish  information  regarding  its  practices,  electronic  signature  Certificates  and  current status of such certificates; and ]\n- ( d ) observe such other standards as may be specified by regulations.\n- 31. Certifying Authority to ensure compliance of the Act, etc. -Every Certifying Authority shall ensure that every person employed or otherwise engaged by it complies, in the course of his employment or engagement, with the provisions of this Act, rules, regulations and orders made thereunder.\n\n1. Subs. by Act 10 of 2009, s. 2, for -Digital Signature\u2016 (w.e.f. 27-10-2009).\n\n2.  Subs.  by  s.  14, ibid., for  -any  contravention  of  the  provisions  of  this  Act,  rules  and  regulations  made  thereunder\u2016 (w.e.f. 27-10-2009).\n\n3. The word -and\u2016 omitted by s. 15, ibid. (w.e.f. 27-10-2009).\n\n4. Ins. by s. 15, ibid . (w.e.f. 27-10-2009).\n\n- 32. Display of licence. -Every Certifying Authority shall display its licence at a conspicuous place of the premises in which it carries on its business.\n- 33. Surrender of licence. -( 1 )  Every Certifying Authority whose licence is suspended or revoked shall immediately after such suspension or revocation, surrender the licence to the Controller.\n- ( 2 ) Where any Certifying Authority fails to surrender a licence under sub-section ( 1 ), the person in whose favour a licence is issued, shall be guilty of an offence and shall be punished with imprisonment which may extend up to six months or a fine which may extend up to ten thousand rupees or with both.\n- 34. Disclosure. -( 1 ) Every Certifying Authority shall disclose in the manner specified by regulations-\n- ( a ) its 1 [electronic signature] Certificate 2 ***;\n- ( b ) any certification practice statement relevant thereto;\n- ( c ) notice of the revocation or suspension of its Certifying Authority certificate, if any; and\n- ( d ) any other fact that materially and adversely affects either the reliability of a 1 [electronic signature] Certificate, which that Authority has issued, or the Authority's ability to perform its services.\n- ( 2 )  Where  in  the  opinion  of  the  Certifying  Authority  any  event  has  occurred  or  any  situation  has arisen which may materially and adversely affect the integrity of its computer system or the conditions subject to which a 1 [electronic signature] Certificate was granted, then, the Certifying Authority shall-\n- ( a ) use reasonable efforts to notify any person who is likely to be affected by that occurrence; or\n- ( b )  act  in  accordance with the procedure specified in its certification practice statement to deal with such event or situation.\n\n## CHAPTERVII\n\n1 [ELECTRONIC SIGNATURE] CERTIFICATES\n\n- 35. Certifying authority to issue 1 [electronic signature] Certificate. -( 1 ) Any person may make an application to the Certifying Authority for the issue of a 1 [electronic signature] Certificate in such form as may be prescribed by the Central Government.\n- ( 2 )  Every  such  application  shall  be  accompanied  by  such  fee  not  exceeding  twenty-five  thousand rupees as may be prescribed by the Central Government, to be paid to the Certifying Authority:\n- Provided  that  while  prescribing  fees  under  sub-section  ( 2 )  different  fees  may  be  prescribed  for different classes of applicants.\n- ( 3 ) Every such application shall be accompanied by a certification practice statement or where there is no such statement, a statement containing such particulars, as may be specified by regulations.\n- ( 4 )  On  receipt  of  an  application  under  sub-section  ( 1 ),  the  Certifying  Authority  may,  after consideration of the certification practice statement or the other statement under sub-section ( 3 ) and after making such enquiries as it may deem fit, grant the 1 [electronic signature] Certificate or for reasons to be recorded in writing, reject the application:\n\n3\n\n*\n\n*\n\n*\n\n*\n\n*\n\n- 4 [Provided]  that  no  application  shall  be  rejected  unless  the  applicant  has  been  given  a  reasonable opportunity of showing cause against the proposed rejection.\n- 36.  Representations  upon  issuance  of  Digital  Signature  Certificate. -A  Certifying  Authority while issuing a Digital Signature Certificate shall certify that-\n- ( a ) it has complied with the provisions of this Act and the rules and regulations made thereunder;\n- ( b ) it has published the Digital Signature Certificate or otherwise made it available to such person relying on it and the subscriber has accepted it;\n\n1. Subs. by Act 10 of 2009, s. 2, for -Digital Signature\u2016  (w.e.f. 27-10-2009).\n\n2. Certain words omitted by s. 16, ibid . (w.e.f. 27-10-2009).\n\n3. The first proviso omitted by s. 17, ibid . (w.e.f. 27-10-2009).\n\n4. Subs. by s. 17, ibid ., for -Provided further\u2016 (w.e.f. 27-10-2009).\n\n- ( c )  the  subscriber  holds  the  private  key  corresponding  to  the  public  key,  listed  in  the  Digital Signature Certificate;\n- 1 [( ca ) the subscriber holds a private key which is capable of creating a digital signature;\n- ( cb ) the public key to be listed in the certificate can be used to verify a digital signature affixed by the private key held by the subscriber;]\n- ( d ) the subscriber's public key and private key constitute a functioning key pair;\n- ( e ) the information contained in the Digital Signature Certificate is accurate; and\n- ( f ) it has no knowledge of any material fact, which if it had been included in the Digital Signature Certificate would adversely affect the reliability of the representations in clauses ( a ) to ( d ).\n- 37. Suspension of Digital Signature Certificate. -( 1 ) Subject to the provisions of sub-section ( 2 ), the Certifying Authority which has issued a Digital Signature Certificate may suspend such Digital Signature Certificate,-\n- ( a ) on receipt of a request to that effect from-\n- ( i ) the subscriber listed in the Digital Signature Certificate; or\n- ( ii ) any person duly authorised to act on behalf of that subscriber;\n- ( b ) if it is of opinion that the Digital Signature Certificate should be suspended in public interest.\n- ( 2 ) A Digital Signature Certificate shall not be suspended for a period exceeding fifteen days unless the subscriber has been given an opportunity of being heard in the matter.\n- ( 3 ) On suspension of a Digital Signature Certificate under this section, the Certifying Authority shall communicate the same to the subscriber.\n- 38. Revocation of Digital Signature Certificate. -( 1 )  A Certifying Authority may revoke a Digital Signature Certificate issued by it-\n- ( a ) where the subscriber or any other person authorised by him makes a request to that effect; or\n- ( b ) upon the death of the subscriber; or\n- ( c ) upon the dissolution of the firm or winding up of the company where the subscriber is a firm or a company.\n- ( 2 )  Subject  to  the  provisions  of  sub-section  ( 3 ) and  without  prejudice  to  the  provisions  of sub-section ( 1 ), a Certifying Authority may revoke a Digital Signature Certificate which has been issued by it at any time, if it is of opinion that-\n- ( a ) a material fact represented in the Digital Signature Certificate is false or has been concealed;\n- ( b ) a requirement for issuance of the Digital Signature Certificate was not satisfied;\n- ( c )  the  Certifying  Authority's  private  key  or  security  system  was  compromised  in  a  manner materially affecting the Digital Signature Certificate's reliability;\n- ( d )  the  subscriber  has  been  declared  insolvent  or  dead  or  where  a  subscriber  is  a  firm  or  a company, which has been dissolved, wound-up or otherwise ceased to exist.\n- ( 3 )  A  Digital  Signature  Certificate  shall  not  be  revoked  unless  the  subscriber  has  been  given  an opportunity of being heard in the matter.\n- ( 4 ) On revocation of a Digital Signature Certificate under this section, the Certifying Authority shall communicate the same to the subscriber.\n- 39. Notice of suspension or revocation. -( 1 )  Where a Digital Signature Certificate is suspended or revoked under section 37 or section 38, the Certifying Authority shall publish a notice of such suspension or  revocation,  as  the  case  may  be,  in  the  repository  specified  in  the  Digital  Signature  Certificate  for publication of such notice.\n\n1. Ins. by Act 10 of 2009, s. 18 (w.e.f. 27-10-2009).\n\n- ( 2 )  Where one or more repositories are specified, the Certifying Authority shall publish notices of such suspension or revocation, as the case may be, in all such repositories.\n\n## CHAPTER VIII\n\n## DUTIES OF SUBSCRIBERS\n\n- 40.  Generating  key  pair. -Where  any  Digital  Signature  Certificate  the  public  key  of  which corresponds to the private key of that subscriber which is to be listed in the Digital Signature Certificate has  been  accepted  by  a  subscriber, 1 *** the  subscriber  shall  generate 2 [that  key]  pair  by  applying  the security procedure.\n- 3 [40A. Duties of subscriber of Electronic Signature Certificate.In respect of Electronic Signature Certificate the subscriber shall perform such duties as may be prescribed.]\n- 41. Acceptance of Digital Signature Certificate. -( 1 ) A subscriber shall be deemed to have accepted a  Digital  Signature  Certificate  if  he  publishes  or  authorises  the  publication  of  a  Digital  Signature Certificate-\n- ( a ) to one or more persons;\n- ( b ) in a repository; or\n\notherwise demonstrates his approval of the Digital Signature Certificate in any manner.\n\n- ( 2 ) By accepting a Digital Signature Certificate the subscriber certifies to all who reasonably rely on the information contained in the Digital Signature Certificate that-\n- ( a )  the  subscriber  holds  the  private  key  corresponding  to  the  public  key  listed  in  the  Digital Signature Certificate and is entitled to hold the same;\n- ( b ) all representations made by the subscriber to the Certifying Authority and all material relevant to the information contained in the Digital Signature Certificate are true;\n- ( c )  all  information  in  the  Digital  Signature  Certificate  that  is  within  the  knowledge  of  the subscriber is true.\n- 42. Control of private key.-( 1 ) Every subscriber shall exercise reasonable care to retain control of the private key corresponding to the public key listed in his Digital Signature Certificate and take all steps to prevent its disclosure 4 ***.\n- ( 2 )  If  the  private key corresponding to the public key listed in the Digital Signature  Certificate has been compromised, then, the subscriber shall communicate the same without any delay to the Certifying Authority in such manner as may be specified by the regulations.\n\nExplanation .-For the removal of doubts, it is hereby declared that the subscriber shall be liable till he has informed the Certifying Authority that the private key has been compromised.\n\n## CHAPTER IX\n\n5 [PENALTIES, COMPENSATION AND ADJUDICATION]\n\n- 43. 6 [Penalty and compensation] for damage to computer, computer system, etc. -If any person without permission of the owner or any other person who is in charge of a computer, computer system or computer network,-\n- ( a )  accesses  or  secures  access  to  such  computer,  computer system   or computer  network 7 [or computer resource];\n\n1. The word -then\u2016 omitted by notification No. S.O. 1015(E) (w.e.f. 19-9-2002).\n\n2. Subs. ibid., for -the key\u2016 (w.e.f. 19-9-2002).\n\n3. Ins. by Act 10 of 2009, s. 19 (w.e.f. 27-10-2009).\n\n4. The words -to a person not authorised to affix the digital signature of the subscriber\u2016 omitted by notification No. S.O.1015(E) (w.e.f. 19-9-2002).\n\n5. Subs. by Act 10 of 2009, s. 20, for -PENALTIES AND ADJUDICATION\u2016 (w.e.f. 27-10-2009).\n\n6. Subs. by s. 21, ibid ., for -Penalty\u2016 (w.e.f. 27-10-2009).\n\n7. Ins. by s. 21, ibid. (w.e.f. 27-10-2009).\n\n- ( b )  downloads,  copies  or  extracts  any  data,  computer  data  base  or  information  from  such computer, computer system or computer network including information or data held or stored in any removable storage medium;\n- ( c ) introduces or causes to be introduced any computer contaminant or computer virus into any computer, computer system or computer network;\n- ( d ) damages or causes to be damaged any computer, computer system or computer network, data, computer  data  base  or  any  other  programmes  residing  in  such  computer,  computer  system  or computer network;\n- ( e ) disrupts or causes disruption of any computer, computer system or computer network;\n- ( f )  denies  or  causes  the  denial  of  access  to  any  person  authorised  to  access  any  computer, computer system or computer network by any means;\n- ( g ) provides any assistance to any person to facilitate access to a computer, computer system or computer  network  in  contravention  of  the  provisions  of  this  Act,  rules  or  regulations  made thereunder;\n- ( h ) charges the services availed of by a person to the account of another person by tampering with or manipulating any computer, computer system, or computer network;\n- 1 [( i ) destroys, deletes or alters any information residing in a computer resource or diminishes its value or utility or affects it injuriously by any means;\n- ( j )  steal,  conceal, destroys or alters or causes any person to steal, conceal, destroy or alter any computer source code used for a computer resource with an intention to cause damage;]\n\n2 [he shall be liable to pay damages by way of compensation to the person so affected.]\n\nExplanation .-For the purposes of this section,-\n\n- ( i ) -computer contaminant\u2016 means any set of computer instructions that are designed-\n- ( a )  to  modify,  destroy,  record,  transmit  data  or  programme  residing  within  a  computer, computer system or computer network; or\n- ( b )  by  any  means  to  usurp  the  normal  operation  of  the  computer,  computer  system,  or computer network;\n- ( ii )  -computer data-base\u2016 means a representation of information, knowledge, facts, concepts or instructions in text, image, audio, video that are being prepared or have been prepared in a formalised manner  or  have  been  produced  by  a  computer,  computer  system  or  computer  network  and  are intended for use in a computer, computer system or computer network;\n- ( iii )  -computer  virus\u2016  means  any  computer  instruction,  information,  data  or  programme  that destroys, damages, degrades or adversely affects the performance of a computer resource or attaches itself to another computer resource and operates when a programme, data or instruction is executed or some other event takes place in that computer resource;\n- ( iv ) -damage\u2016 means to destroy, alter, delete, add, modify or rearrange any computer resource by any means.\n\n1 [( v ) -computer source code\u2016 means the listing of programme, computer commands, design and layout and programme analysis of computer resource in any form.]\n\n3 [43A. Compensation for failure to protect data. -Where a body corporate, possessing, dealing or handling any sensitive personal data or information in a computer resource which it owns, controls or operates, is negligent in implementing and maintaining reasonable security practices and procedures and thereby causes wrongful loss or wrongful gain to any person, such body corporate shall be liable to pay damages by way of compensation to the person so affected.\n\n1. Ins. by Act 10 of 2009, s. 21 (w.e.f. 27-10-2009).\n\n2. Subs. by s. 21, ibid ., for certain words (w.e.f. 27-10-2009).\n\n3. Ins. by s. 22, ibid. (w.e.f. 27-10-2009).\n\nExplanation .-For the purposes of this section,-\n\n- ( i )  -body  corporate\u2016  means  any  company  and  includes  a  firm,  sole  proprietorship  or  other association of individuals engaged in commercial or professional activities;\n- ( ii )  -reasonable  security  practices  and  procedures\u2016  means  security  practices  and  procedures designed to protect such information from unauthorised access, damage, use, modification, disclosure or impairment, as may be specified in an agreement between the parties or as may be specified in any law for the time being in force and in the absence of such agreement or any law, such reasonable security practices and procedures, as may be prescribed by the Central Government in consultation with such professional bodies or associations as it may deem fit;\n- ( iii )  -sensitive  personal  data  or  information\u2016  means  such  personal  information  as  may  be prescribed by the Central Government in consultation with such professional bodies or associations as it may deem fit.]\n- 44. Penalty for failure to furnish information, return, etc. -If any person who is required under this Act or any rules or regulations made thereunder to-\n- ( a )  furnish any document, return or report to the Controller or the Certifying Authority fails to furnish the same, he shall be liable to a penalty not exceeding one lakh and fifty thousand rupees for each such failure;\n- ( b ) file any return or furnish any information, books or other documents within the time specified therefor in the regulations fails to file return or furnish the same within the time specified therefor in the regulations, he shall be liable to a penalty not exceeding five thousand rupees for every day during which such failure continues;\n- ( c ) maintain books of account or records, fails to maintain the same, he shall be liable to a penalty not exceeding ten thousand rupees for every day during which the failure continues.\n- 45. Residuary penalty. -Whoever contravenes any rules or regulations made under this Act, for the contravention of which no penalty has been separately provided, shall be liable to pay a compensation not exceeding  twenty-five  thousand  rupees  to  the  person  affected  by  such  contravention  or  a  penalty  not exceeding twenty-five thousand rupees.\n- 46. Power to adjudicate. -( 1 )  For the purpose of adjudging under this Chapter whether any person has committed a contravention of any of the provisions of this Act or of any rule, regulation, 1 [direction or order made thereunder which renders him liable to pay penalty or compensation,] the Central Government shall, subject to the provisions of sub-section ( 3 ), appoint any officer not below the rank of a Director to the Government of India or an equivalent officer of a State Government to be an adjudicating officer for holding an inquiry in the manner prescribed by the Central Government.\n- 2 [( 1A )  The  adjudicating  officer  appointed  under  sub-section  ( 1 )  shall  exercise  jurisdiction  to adjudicate matters in which the claim for injury or damage does not exceed rupees five crore:\n- Provided  that  the  jurisdiction  in  respect  of  the  claim  for  injury  or  damage  exceeding  rupees  five crores shall vest with the competent court.]\n- ( 2 ) The adjudicating officer shall, after giving the person referred to in sub-section ( 1 ) a reasonable opportunity for making representation in the matter and if, on such inquiry, he is satisfied that the person has committed the contravention, he may impose such penalty or award such compensation as he thinks fit in accordance with the provisions of that section.\n- ( 3 ) No person shall be appointed as an adjudicating officer unless he possesses such experience in the field  of  Information  Technology  and  legal  or  judicial  experience  as  may  be  prescribed  by  the  Central Government.\n- ( 4 ) Where more than one adjudicating officers are appointed, the Central Government shall specify by order the matters and places with respect to which such officers shall exercise their jurisdiction.\n- ( 5 )  Every  adjudicating  officer  shall  have  the  powers  of  a  civil  court  which  are  conferred  on  the -Appellate Tribunal\u2016 under sub-section ( 2 ) of section 58, and-\n\n1. Subs. by Act 10 of 2009, s. 23, for -direction or order made thereunder\u2016 (w.e.f. 27-10-2009).\n\n2. Ins. by s. 23, ibid . (w.e.f. 27-10-2009).\n\n- ( a )  all  proceedings  before it  shall  be  deemed  to  be judicial  proceedings  within the meaning of sections 193 and 228 of the Indian Penal Code (45 of 1860);\n- ( b ) shall be deemed to be a civil court for the purposes of sections 345 and 346 of the Code of Criminal Procedure, 1973 (2 of 1974);\n- 1 [( c ) shall be deemed to be a civil court for purposes of Order XXI of the Civil Procedure Code, 1908 (5 of 1908).]\n- 47. Factors to be taken into account by the adjudicating officer. -While adjudging the quantum of compensation under this Chapter, the adjudicating officer shall have due regard to the following factors, namely:-\n- ( a ) the amount of gain of unfair advantage, wherever quantifiable, made as a result of the default;\n- ( b ) the amount of loss caused to any person as a result of the default;\n- ( c ) the repetitive nature of the default.\n\n## CHAPTER X\n\n## THE 2 [APPELLATE TRIBUNAL]\n\n- 48. 3 [Appellate Tribunal]. -4 [( 1 ) The Telecom Disputes Settlement and Appellate Tribunal established under section 14 of the Telecom Regulatory Authority of India Act, 1997 (24 of 1997), shall, on and from the commencement of Part XIV of Chapter VI of the Finance Act, 2017 (7 of 2017), be the Appellate  Tribunal  for  the  purposes  of  this  Act  and  the  said  Appellate  Tribunal  shall  exercise  the jurisdiction, powers and authority conferred on it by or under this Act.]\n- ( 2 )  The  Central  Government 5 [shall  specify,  by  notification] the  matters  and  places  in  relation  to which the 2 [Appellate Tribunal] may exercise jurisdiction.\n- 6 [49. [Composition of Cyber Appellate Tribunal .] Omitted by the Finance Act ,  2017 (7 of 2017), s .  169 ( w.e.f . 26-5-2017).\n- 50. [Qualifications  for  appointment  as  Chairperson  and  Members  of  Cyber  Appellate Tribunal .] Omitted by s. 169 ,  ibid. ( w.e.f. 26-5-2017).\n- 51. [Term of office, conditions of service, etc., of Chairperson and Members .] Omitted by s. 169 ibid. ( w.e.f. 26-5-2017).\n\n,\n\n- 52.  [Salary,  allowances  and  other  terms  and  conditions  of  service  of  Chairperson  and Members .] Omitted by s. 169 ,  ibid. ( w.e.f. 26-5-2017).\n- 52A. [Powers of superintendence, direction, etc .] Omitted by s. 169 ,  ibid. ( w.e.f. 26-5-2017).\n- 52B. [Distribution of business among Benches. ] Omitted by s. 169 ,  ibid. ( w.e.f. 26-5-2017).\n- 52C. [Power of Chairperson to transfer cases .] Omitted by s. 169 , ibid. ( w.e.f. 26-5-2017).\n- 52D. Decision by majority. -If the Members of a Bench consisting of two Members differ in opinion on  any  point,  they  shall  state  the  point  or  points  on  which  they  differ,  and  make  a  reference  to  the Chairperson  of the 2 [Appellate Tribunal]  who  shall hear  the  point  or  points  himself  and  such  point  or points shall be decided according to the opinion of the majority of the Members who have heard the case, including those who first heard it.]\n- 53. [Filling up of vacancies .] Omitted by the Finance Act , 2017 (7 of 2017), s . 169 ( w.e.f . 26-5-2017).\n- 54. [Resignation and removal .] Omitted by s . 169, ibid . ( w.e.f . 26-5-2017).\n- 55. Orders constituting Appellate Tribunal to be final and not to invalidate its proceedings. -No order  of  the  Central  Government  appointing  any  person  as  the 7 [Chairperson  or  the  Member]  of  a 2 [Appellate  Tribunal]  shall  be  called  in  question  in  any  manner  and  no  act  or  proceeding  before  a\n\n1. Ins. by Act 10 of 2009, s. 23 (w.e.f. 27-10-2009).\n\n2. Subs. by Act  7 of 2017, s. 169, for -Cyber Appellate Tribunal\u2016 (w.e.f. 26-5-2017)\n\n3. Subs. by s. 169, ibid., for - Establishment of Appellate Tribunal\u2016 (w.e.f. 26-5-2017).\n\n4. Subs. by s. 169, ibid ., for sub-section ( 1 ) (w.e.f. 26-5-2017).\n\n5. Subs. by s. 169, ibid ., for -shall also specify, in the notification referred to in sub-section ( 1 )\u2016 (w.e.f. 26-5-2017).\n\n6. Subs. by Act 10 of 2009, s. 26, for sections 49 to 52 (w.e.f. 27-10-2009).\n\n7. Subs. by s. 29, ibid., for -Presiding Officer\u2016 (w.e.f. 27-10-2009).\n\n1 [Appellate Tribunal] shall be called in question in any manner on the ground merely of any defect in the constitution of a 1 [Appellate Tribunal].\n\n- 56. [Staff of the Cyber Appellate Tribunal .] Omitted by the Finance Act , 2017 (7 of 2017), s .  169 ( w.e.f . 26-5-2017).\n- 57. Appeal to 1 [ Appellate Tribunal]. -( 1 ) Save as provided in sub-section ( 2 ), any person aggrieved by  an  order  made  by  controller  or  an  adjudicating  officer  under  this  Act  may  prefer  an  appeal  to  a 1 [Appellate Tribunal] having jurisdiction in the matter.\n- ( 2 )  No appeal shall lie to the 1 [Appellate Tribunal] from an order made by an adjudicating officer with the consent of the parties.\n- ( 3 ) Every appeal under sub-section ( 1 ) shall be filed within a period of forty-five days from the date on which a copy of the order made by the Controller or the adjudicating officer is received by the person aggrieved and it shall be in such form and be accompanied by such fee as may be prescribed:\n- Provided that the 1 [Appellate Tribunal] may entertain an appeal after the expiry of the said period of forty-five days if it is satisfied that there was sufficient cause for not filing it within that period.\n- ( 4 )  On  receipt  of  an  appeal  under  sub-section  ( 1 ),  the 1 [Appellate  Tribunal]  may,  after  giving  the parties to the appeal, an opportunity of being heard, pass such orders thereon as it thinks fit, confirming, modifying or setting aside the order appealed against.\n- ( 5 ) The 1 [Appellate Tribunal] shall send a copy of every order made by it to the parties to the appeal and to the concerned Controller or adjudicating officer.\n- ( 6 ) The appeal filed before the 1 [Appellate Tribunal] under sub-section ( 1 ) shall be dealt with by it as expeditiously as possible and endeavour shall be made by it to dispose of the appeal finally within six months from the date of receipt of the appeal.\n- 58. Procedure and powers of the Appellate Tribunal]. -( 1 ) The 1 [Appellate Tribunal] shall not be bound by the procedure laid down by the Code of Civil Procedure, 1908 (5 of 1908) but shall be guided by the principles of natural justice and, subject to the other provisions of this Act and of any rules, the 1 [Appellate Tribunal] shall have powers to regulate its own procedure including the place at which it shall have its sittings.\n- ( 2 ) The 1 [Appellate Tribunal] shall have, for the purposes of discharging its functions under this Act, the same powers as are vested in a civil court under the Code of Civil Procedure, 1908 (5 of 1908), while trying a suit, in respect of the following matters, namely:-\n- ( a ) summoning and enforcing the attendance of any person and examining him on oath;\n- ( b ) requiring the discovery and production of documents or other electronic records;\n- ( c ) receiving evidence on affidavits;\n- ( d ) issuing commissions for the examination of witnesses or documents;\n- ( e ) reviewing its decisions;\n- ( f ) dismissing an application for default or deciding it ex parte ;\n- ( g ) any other matter which may be prescribed.\n- ( 3 )  Every  proceeding  before the 1 [Appellate Tribunal] shall be deemed to be a judicial proceeding within the meaning of sections 193 and 228, and for the purposes of section 196 of the Indian Penal Code (45 of 1860) and the 1 [Appellate Tribunal] shall be deemed to be a civil court for the purposes of section 195 and Chapter XXVI of the Code of Criminal Procedure, 1973 (2 of 1974).\n- 59.  Right to legal representation. -The appellant may either appear in person or authorise one or more legal practitioners or any of its officers to present his or its case before the 1 [Appellate Tribunal].\n- 60.  Limitation. -The provisions of the Limitation Act, 1963 (36 of 1963), shall, as far as may be, apply to an appeal made to the 1 [Appellate Tribunal].\n\n1. Subs. by Act 7 of 2017, s, 169, for -Cyber Appellate Tribunal\u2016 (w.e.f. 26-5-2017)\n\n- 61.  Civil  court  not  to  have  jurisdiction. -No court shall have jurisdiction to entertain any suit or proceeding  in  respect  of  any  matter  which  an  adjudicating  officer  appointed  under  this  Act  or  the 1 [Appellate Tribunal] constituted under this Act is empowered by or under this Act to determine and no injunction shall be granted by any court or other authority in respect of any action taken or to be taken in pursuance of any power conferred by or under this Act.\n- 62.  Appeal  to  High  Court. -Any  person  aggrieved  by  any  decision  or  order  of  the 1 [Appellate Tribunal] may file an appeal to the High Court within sixty days from the date of communication of the decision or order of the 1 [Appellate Tribunal] to him on any question of fact or law arising out of such order:\n\nProvided that the High Court may, if it is satisfied that the appellant was prevented by sufficient cause from filing the appeal within the said period, allow it to be filed within a further period not exceeding sixty days.\n\n- 63. Compounding of contraventions. -( 1 ) Any contravention under this 2 [Act] may, either before or after the institution of adjudication proceedings, be compounded by the Controller or such other officer as may be specially  authorised  by  him  in  this  behalf  or  by  the  adjudicating  officer,  as  the  case  may  be, subject to such conditions as the Controller or such other officer or the adjudicating officer may specify:\n\nProvided that such sum shall not, in any case, exceed the maximum amount of the penalty which may be imposed under this Act for the contravention so compounded.\n\n- ( 2 ) Nothing in sub-section ( 1 ) shall apply to a person who commits the same or similar contravention within a period of three years from the date on which the first contravention, committed by him,  was compounded.\n\nExplanation .-For the purposes of this sub-section, any second or subsequent contravention committed  after  the  expiry  of  a  period  of  three  years  from  the  date  on  which  the  contravention  was previously compounded shall be deemed to be a first contravention.\n\n- ( 3 ) Where any contravention has been compounded under sub-section ( 1 ),  no proceeding or further proceeding, as the case may be, shall be taken against the person guilty of such contravention in respect of the contravention so compounded.\n- 64. Recovery of 3 [penalty or compensation]. -A 4 [penalty imposed or compensation awarded] under this Act, if it is not paid, shall he recovered as an arrear of land revenue and the licence or the 5 [electronic signature] Certificate, as the case may be, shall be suspended till the penalty is paid.\n\n## CHAPTER XI\n\n## OFFENCES\n\n- 65. Tampering with computer source documents. -Whoever knowingly or intentionally conceals, destroys or alters or intentionally or knowingly causes another to conceal, destroy, or alter any computer source code used for a computer, computer programme, computer system or computer network, when the computer source code is required to be kept or maintained by law for the time being in force, shall be punishable with imprisonment up to three years, or with fine which may extend up to two lakh rupees, or with both.\n\nExplanation. -For  the  purposes  of  this  section,  -computer  source  code\u2016  means  the  listing  of programmes, computer commands, design and layout and programme analysis of computer resource in any form.\n\n- 6 [ 66. Computer related offences. -If any person, dishonestly or fraudulently, does any act referred to in section 43, he shall be punishable with imprisonment for a term which may extend to three years or with fine which may extend to five lakh rupees or with both.\n\n1. Subs. by Act 7 of 2017, s. 169, for -Cyber Appellate Tribunal\u2016 (w.e.f. 26-5-2017).\n\n2. Subs. by notification No. S.O. 1015(E) (w.e.f. 19-9-2002).\n\n3. Subs. by Act 10 of 2009, s. 31, for -penalty\u2016 (w.e.f. 27-10-2009).\n\n4. Subs. by s. 31, ibid ., for -penalty imposed\u2016 (w.e.f. 27-10-2009).\n\n5. Subs. by s. 2, ibid ., for -Digital Signature\u2016 (w.e.f. 27-10-2009).\n\n6. Subs. by s. 32, ibid., for sections 66 and 67 (w.e.f. 27-10-2009).\n\nExplanation .-For the purposes of this section,-\n\n- ( a ) the word -dishonestly\u2016 shall have the meaning assigned to it in section 24 of the Indian Penal Code (45 of 1860);\n- ( b ) the word -fraudulently\u2016 shall have the meaning assigned to it in section 25 of the Indian Penal Code (45 of 1860).\n- 1 [66A.  Punishment  for  sending  offensive  messages  through  communication  service,  etc. -Any person who sends, by means of a computer resource or a communication device,-\n- ( a ) any information that is grossly offensive or has menacing character; or\n- ( b )  any  information  which  he  knows  to  be  false,  but  for  the  purpose  of  causing  annoyance, inconvenience,  danger,  obstruction,  insult,  injury,  criminal  intimidation,  enmity,  hatred  or  ill  will, persistently by making use of such computer resource or a communication device;\n- ( c )  any  electronic  mail  or  electronic  mail  message  for  the  purpose  of  causing  annoyance  or inconvenience  or  to  deceive  or  to  mislead  the  addressee  or  recipient  about  the  origin  of  such messages,\n\nshall be punishable with imprisonment for a term which may extend to three years and with fine.\n\nExplanation .-For the purposes of this section, terms -electronic mail\u2016 and -electronic mail message\u2016 means  a  message  or  information  created  or  transmitted  or  received  on  a  computer,  computer  system, computer resource or communication device including attachments in text, image, audio, video and any other electronic record, which may be transmitted with the message.]\n\n- 66B.  Punishment  for  dishonestly  receiving  stolen  computer  resource  or  communication device. -Whoever dishonestly receive or retains any stolen computer resource or communication device knowing or having reason to believe the same to be stolen computer resource or communication device, shall be punished with imprisonment of either description for a term which may extend to three years or with fine which may extend to rupees one lakh or with both.\n- 66C.  Punishment  for  identity  theft. -Whoever,  fraudulently  or  dishonestly  make  use  of  the electronic  signature,  password  or  any  other  unique  identification  feature  of  any  other  person,  shall  be punished with imprisonment of either description for a term which may extend to three years and shall also be liable to fine which may extend to rupees one lakh.\n- 66D. Punishment for cheating by personation by using computer resource. -Whoever, by means of any  communication  device  or  computer  resource  cheats  by  personation,  shall  be  punished  with imprisonment of either description for a term which may extend to three years and shall also be liable to fine which may extend to one lakh rupees.\n- 66E. Punishment for violation of privacy. -Whoever, intentionally or knowingly captures, publishes or transmits the image of a private area of any person without his or her consent, under circumstances violating the privacy of that person, shall be punished with imprisonment which may extend to three years or with fine not exceeding two lakh rupees, or with both.\n\nExplanation .-For the purposes of this section-\n\n- ( a ) -transmit\u2016 means to electronically send a visual image with the intent that it be viewed by a person or persons;\n- ( b )  -capture\u2016, with respect to an image, means to videotape, photograph, film or record by any means;\n- ( c ) -private area\u2016 means the naked or undergarment clad genitals, public area, buttocks or female breast:\n- ( d ) -publishes\u2016 means reproduction in the printed or electronic form and making it available for public;\n\n1. Section 66A has been struck down by Supreme Court's Order dated 24 th March, 2015 in the Shreya Singhal vs. Union of India, AIR 2015 SC. 1523.\n\n- ( e ) -under circumstances violating privacy\u2016 means circumstances in which a person can have a reasonable expectation that-\n- ( i ) he or she could disrobe in privacy, without being concerned that an image of his private area was being captured; or\n- ( ii ) any part of his or her private area would not be visible to the public, regardless of whether that person is in a public or private place.\n\n## 66F. Punishment for cyber terrorism. -( 1 ) Whoever,-\n\n- ( A ) with intent to threaten the unity, integrity, security or sovereignty of India or to strike terror in the people or any section of the people by-\n- ( i )  denying  or  cause  the  denial  of  access  to  any  person  authorised  to  access  computer resource; or\n- ( ii ) attempting to penetrate or access a computer resource without authorisation or exceeding authorised access; or\n- ( iii ) introducing or causing to introduce any computer contaminant,\n\nand by means of such conduct causes or is likely to cause death or injuries to persons or damage to or destruction of property or disrupts or knowing that it is likely to cause damage or disruption of supplies or services essential to the life of the community or adversely affect the critical information infrastructure specified under section 70; or\n\n- ( B ) knowingly or intentionally penetrates or accesses a computer resource without authorisation or exceeding  authorised  access,  and  by  means  of  such  conduct  obtains  access  to  information,  data  or computer data base that is restricted for reasons of the security of the State or foreign relations; or any restricted information, data or computer data base, with reasons to believe that such information, data or computer data base so obtained may be used to cause or likely to cause injury to the interests of the sovereignty  and  integrity  of  India,  the  security  of  the  State,  friendly  relations  with  foreign  States, public order, decency or morality, or in relation to contempt of court, defamation or incitement to an offence, or to the advantage of any foreign nation, group of individuals or otherwise,\n\ncommits the offence of cyber terrorism.\n\n- ( 2 ) Whoever commits or conspires to commit cyber terrorism shall be punishable with imprisonment which may extend to imprisonment for life.\n- 67.  Punishment  for  publishing  or  transmitting  obscene  material  in  electronic  form. -Whoever publishes or transmits or causes to be published or transmitted in the electronic form, any material which is lascivious or appeals to the prurient interest or if its effect is such as to tend to deprave and corrupt persons  who  are  likely,  having  regard  to  all  relevant  circumstances,  to  read,  see  or  hear  the  matter contained or embodied in it, shall be punished on first conviction with imprisonment of either description for a term which may extend to three years and with fine which may extend to five lakh rupees and in the event of second or subsequent conviction with imprisonment of either description for a term which may extend to five years and also with fine which may extend to ten lakh rupees.\n- 67A. Punishment for publishing or transmitting of material containing sexually explicit act, etc., in  electronic  form. -Whoever  publishes  or  transmits  or  causes  to  be  published  or  transmitted  in  the electronic form any material which contains sexually explicit act or conduct shall be punished on first conviction with imprisonment of either description for a term which may extend to five years and with fine  which  may  extend  to  ten  lakh  rupees  and  in  the  event  of  second  or  subsequent  conviction  with imprisonment of either description for a term which may extend to seven years and also with fine which may extend to ten lakh rupees.\n\n## 67B.  Punishment  for  publishing  or  transmitting  of  material  depicting  children  in  sexually explicit act, etc., in electronic form. -Whoever,-\n\n- ( a ) publishes or transmits or causes to be published or transmitted material in any electronic form which depicts children engaged in sexually explicit act or conduct; or\n- ( b )  creates  text  or  digital  images,  collects,  seeks,  browses,  downloads,  advertises,  promotes, exchanges or distributes material in any electronic form depicting children in obscene or indecent or sexually explicit manner; or\n\n- ( c ) cultivates, entices or induces children to online relationship with one or more children for and on sexually explicit act or in a manner that may offend a reasonable adult on the computer resource; or\n- ( d ) facilitates abusing children online, or\n- ( e )  records in any electronic form own abuse or that of others pertaining to sexually explicit act with children,\n\nshall be punished on first conviction with imprisonment of either description for a term which may extend to five years and with fine which may extend to ten lakh rupees and in the event of second or subsequent conviction with imprisonment of either description for a term which may extend to seven years and also with fine which may extend to ten lakh rupees:\n\nProvided  that  provisions  of  section  67,  section  67A  and  this  section  does  not  extend  to  any  book, pamphlet, paper, writing, drawing, painting representation or figure in electronic form-\n\n- ( i ) the publication of which is proved to be justified as being for the public good on the ground that such book, pamphlet, paper, writing, drawing, painting representation or figure is the interest of science, literature, art or learning or other objects of general concern; or\n- ( ii ) which is kept or used for bona fide heritage or religious purposes.\n\nExplanation -For the purposes of this section, -children\u2016 means a person who has not completed the age of 18 years.\n\n- 67C. Preservation and retention of information by intermediaries. -( 1 ) Intermediary shall preserve and retain such information as may be specified for such duration and in such manner and format as the Central Government may prescribe.\n- ( 2 )  any  intermediary  who  intentionally  or  knowingly  contravenes  the  provisions  of  sub-section  ( 1 ) shall be punished with an imprisonment for a term which may extend to three years and also be liable to fine.]\n- 68.  Power  of  Controller to  give  directions. -( 1 )  The  Controller  may,  by  order,  direct  a  Certifying Authority or any employee of such Authority to take such measures or cease carrying on such activities as specified in the order if those are necessary to ensure compliance with the provisions of this Act, rules or any regulations made thereunder.\n- 1 [( 2 ) Any person who intentionally or knowingly fails to comply with any order under sub-section ( 1 ) shall be guilty of an offence and shall be liable on conviction to imprisonment for a term not exceeding two years or a fine not exceeding one lakh rupees or with both.]\n- 2 [69. Power to issue directions for interception or monitoring or decryption of any information through any computer resource. -( 1 ) Where the Central Government or a State Government or any of its officers specially authorised by the Central Government or the State Government, as the case may be, in this behalf may, if satisfied that it is necessary or expedient so to do, in the interest of the sovereignty or integrity of India, defence of India, security of the State, friendly relations with foreign States or public order or for preventing incitement to the commission of any cognizable offence relating to above or for investigation of any offence, it may subject to the provisions of sub-section ( 2 ), for reasons to be recorded in writing, by order, direct any agency of the appropriate Government to intercept, monitor or decrypt or cause  to  be  intercepted  or  monitored  or  decrypted  any  information  generated,  transmitted,  received  or stored in any computer resource.\n- ( 2 ) The procedure and safeguards subject to which such interception or monitoring or decryption may be carried out, shall be such as may be prescribed.\n- ( 3 ) The subscriber or intermediary or any person in-charge of the computer resource shall, when called upon by any agency referred to in sub-section ( 1 ), extend all facilities and technical assistance to-\n- ( a ) provide access to or secure access to the computer resource generating, transmitting, receiving or storing such information; or\n- ( b ) intercept, monitor, or decrypt the information, as the case may be; or\n- ( c ) provide information stored in computer resource.\n\n1. Subs. by Act 10 of 2009, s. 33, for sub-section ( 2 ) (w.e.f. 27-10-2009).\n\n2. Subs. by s. 34, ibid ., for section 69 (w.e.f. 27-10-2009).\n\n- ( 4 )  The  subscriber  or  intermediary  or  any  person  who  fails  to  assist  the  agency  referred  to  in sub-section ( 3 ) shall be punished with imprisonment for a term which may extend to seven years and shall also be liable to fine.\n- 69A. Power to issue directions for blocking for public access of any information through any computer resource. -( 1 ) Where the Central Government or any of its officers specially authorised by it in this behalf is satisfied that it is necessary or expedient so to do, in the interest of sovereignty and integrity of India, defence of India, security of the State, friendly relations with foreign States or public order or for preventing incitement to the commission of any cognizable offence relating to above, it may subject to the provisions of sub-section ( 2 ),  for  reasons  to  be  recorded  in  writing,  by  order,  direct  any  agency  of  the Government or intermediary to block for access by the public or cause to be blocked for access by the public any information generated, transmitted, received, stored or hosted in any computer resource.\n- ( 2 )  The  procedure  and  safeguards  subject  to  which  such  blocking  for  access  by  the  public  may  be carried out, shall be such as may be prescribed.\n- ( 3 )  The  intermediary  who  fails  to  comply  with  the  direction  issued  under  sub-section  ( 1 )  shall  be punished with an imprisonment for a term which may extend to seven years and also be liable to fine.\n- 69B.  Power  to  authorise  to  monitor  and  collect  traffic  data  or  information  through  any computer resource for cyber security. -( 1 ) The Central Government may, to enhance cyber security and for identification, analysis and prevention of intrusion or spread of computer contaminant in the country, by notification in the Official Gazette, authorise any agency of the Government to monitor and collect traffic data or information generated, transmitted, received or stored in any computer resource.\n- ( 2 ) The intermediary or any person in-charge or the computer resource shall, when called upon by the agency  which  has  been  authorised  under  sub-section  ( 1 ),  provide  technical  assistance  and  extend  all facilities to such agency to enable online access or to secure and provide online access to the computer resource generating, transmitting, receiving or storing such traffic data or information.\n- ( 3 )  The procedure and safeguards for monitoring and collecting traffic data or information, shall be such as may be prescribed.\n- ( 4 )  Any  intermediary  who  intentionally  or  knowingly  contravenes  the  provisions  of  sub-section  ( 2 ) shall be punished with an imprisonment for a term which any extend to three years and shall also be liable to fine.\n- Explanation .-For the purposes of this section,-\n- ( i ) -computer contaminant\u2016 shall have the meaning assigned to it in section 43;\n- ( ii )  -traffic  data\u2016  means  any  data  identifying  or  purporting  to  identify  any  person,  computer system  or  computer  network  or  location  to  or  from  which  the  communication  is  or  may  be transmitted  and  includes  communications  origin,  destination,  route,  time,  data,  size,  duration  or type of underlying service and any other information.]\n- 70. Protected system. -1 [( 1 ) The appropriate Government may, by notification in the Official Gazette, declare  any  computer  resource  which  directly  or  indirectly  affects  the  facility  of  Critical  Information Infrastructure, to be a protected system.\n- Explanation .-For  the  purposes  of  this  section,  -Critical  Information  Infrastructure\u2016  means  the computer resource, the incapacitation or destruction of which, shall have debilitating impact on national security, economy, public health or safety.]\n- ( 2 ) The appropriate Government may, by order in writing, authorise the persons who are authorised to access protected systems notified under sub-section ( 1 ).\n- ( 3 ) Any person who secures access or attempts to secure access to a protected system in contravention of  the  provisions  of  this  section  shall  be  punished  with  imprisonment  of  either  description  for  a  term which may extend to ten years and shall also be liable to fine.\n- 2 [( 4 )  The  Central  Government  shall  prescribe  the  information  security  practices  and  procedures  for such protected system.]\n- 3 [70A.  National  nodal  agency. -( 1 )  The  Central  Government  may,  by  notification  published  in  the Official Gazette, designate any organisation of the Government as the national nodal agency in respect of Critical Information Infrastructure Protection.\n\n1. Subs. by Act 10 of 2009, s. 35, for sub-section ( 1 ) (w.e.f. 27-10-2009).\n\n2. Ins. by s. 35, ibid. (w.e.f. 27-10-2009).\n\n3. Ins. by s. 36, ibid. (w.e.f. 27-10-2009).\n\n- ( 2 ) The national nodal agency designated under sub-section ( 1 ) shall be responsible for all measures including Research and Development relating to protection of Critical Information Infrastructure.\n- ( 3 ) The manner of performing functions and duties of the agency referred to in sub-section ( 1 ) shall be such as may be prescribed.\n- 70B.  Indian  Computer  Emergency  Response  Team  to  serve  as  national  agency  for  incident response. -( 1 ) The Central Government shall, by notification in the Official Gazette, appoint an agency of the Government to be called the Indian Computer Emergency Response Team.\n- ( 2 )  The  Central Government shall provide the agency referred to in sub-section ( 1 )  with  a  Director General and such other officers and employees as may be prescribed.\n- ( 3 ) The salary and allowances and terms and conditions of the Director-General and other officers and employees shall be such as may be prescribed.\n- ( 4 )  The  Indian  Computer  Emergency  Response  Team  shall  serve  as  the  national  agency  for performing the following functions in the area of cyber security,-\n- ( a ) collection, analysis and dissemination of information on cyber incidents;\n- ( b ) forecast and alerts of cyber security incidents;\n- ( c ) emergency measures for handling cyber security incidents;\n- ( d ) coordination of cyber incidents response activities;\n- ( e )  issue  guidelines,  advisories,  vulnerability  notes  and  white  papers  relating  to  information security practices, procedures, preventation, response and reporting of cyber incidents;\n- ( f ) such other functions relating to cyber security as may be prescribed.\n- ( 5 ) The manner of performing functions and duties of the agency referred to in sub-section ( 1 ) shall be such as may be prescribed.\n- ( 6 )  For carrying out the provisions of sub-section ( 4 ),  the  agency referred to in sub-section ( 1 )  may call  for  information  and  give  direction  to  the  service  providers,  intermediaries,  data  centres,  body corporate and any other person.\n- ( 7 ) Any service provider, intermediaries, data centres, body corporate or person who fails to provide the information called for or comply with the direction under sub-section ( 6 ),  shall  be  punishable with imprisonment for a term which may extend to one year or with fine which may extend to one lakh rupees or with both.\n- ( 8 ) No court shall take cognizance of any offence under this section, except on a complaint made by an officer authorised in this behalf by the agency referred to in sub-section ( 1 ).]\n- 71.  Penalty  for  misrepresentation. -Whoever  makes  any  misrepresentation  to,  or  suppresses  any material  fact  from  the  Controller  or  the  Certifying  Authority  for  obtaining  any  licence  or 1 [electronic signature] Certificate, as the case may be, shall be punished with imprisonment for a term which may extend to two years, or with fine which may extend to one lakh rupees, or with both.\n- 72. Penalty for Breach of confidentiality and privacy.Save as otherwise provided in this Act or any other law for the time being in force, if any person who, in pursuance of any of the powers conferred under this Act, rules or regulations made thereunder, has secured access to any electronic record, book, register,  correspondence,  information,  document  or  other  material  without  the  consent  of  the  person concerned  discloses  such  electronic  record,  book,  register,  correspondence,  information,  document  or other material to any other person shall be punished with imprisonment for a term which may extend to two years, or with fine which may extend to one lakh rupees, or with both.\n- 2 [72A. Punishment for disclosure of information in breach of lawful contract. -Save as otherwise provided in this Act or any other law for the time being in force, any person including an intermediary who,  while  providing  services  under  the  terms  of  lawful  contract,  has  secured  access  to  any  material containing personal information about another person, with the intent to cause or knowing that he is likely\n\n1 . Subs. by Act 10 of 2009, s. 2, for -Digital Signature\u2016 (w.e.f. 27-10-2009).\n\n2. Ins. by s. 37, ibid. (w.e.f. 27-10-2009).\n\nto  cause  wrongful  loss  or  wrongful  gain  discloses,  without  the  consent  of  the  person  concerned,  or  in breach of a lawful contract, such material to any other person, shall be punished with imprisonment for a term which may extend to three years, or with fine which may extend to five lakh rupees, or with both.]\n\n- 73. Penalty for publishing 1 [electronic signature] Certificate false in certain particulars. -( 1 ) No person shall publish a 1 [electronic signature] Certificate or otherwise make it available to any other person with the knowledge that-\n- ( a ) the Certifying Authority listed in the certificate has not issued it; or\n- ( b ) the subscriber listed in the certificate has not accepted it; or\n- ( c ) the certificate has been revoked or suspended,\n\nunless  such  publication  is  for  the  purpose  of  verifying  a 1 [electronic  signature]  created  prior  to  such suspension or revocation.\n\n- ( 2 )  Any  person  who  contravenes  the  provisions  of  sub-section  ( 1 ) shall  be  punished  with imprisonment for a term which may extend to two years, or with fine which may extend to one lakh rupees, or with both.\n- 74. Publication for fraudulent purpose. -Whoever knowingly creates, publishes or otherwise makes available  a 1 [electronic  signature]  Certificate  for  any  fraudulent  or  unlawful  purpose shall  be  punished with imprisonment for a term which may extend to two years, or with fine which may extend to one lakh rupees, or with both.\n- 75.  Act  to  apply  for  offence  or  contravention  committed  outside  India. -( 1 )  Subject  to  the provisions of sub-section ( 2 ), the provisions of this Act shall apply also to any offence or contravention committed outside India by any person irrespective of his nationality.\n- ( 2 ) For the purposes of sub-section ( 1 ), this Act shall apply to an offence or contravention committed outside  India  by  any  person  if  the  act  or  conduct  constituting  the  offence  or  contravention  involves  a computer, computer system or computer network located in India.\n- 76. Confiscation. -Any computer, computer system, floppies, compact disks, tape drives or any other accessories related thereto, in respect of which any provision of this Act, rules, orders or regulations made thereunder has been or is being contravened, shall be liable to confiscation:\n\nProvided that where it is established to the satisfaction of the court adjudicating the confiscation that the  person  in  whose  possession,  power  or  control  of  any  such  computer,  computer  system,  floppies, compact disks, tape  drives  or  any  other  accessories  relating  thereto  is  found is  not  responsible  for  the contravention of the provisions of this Act, rules, orders or regulations made thereunder, the court may, instead of making an order for confiscation of such computer, computer system, floppies, compact disks, tape drives or any other accessories related thereto, make such other order authorised by this Act against the person contravening of the provisions of this Act, rules, orders or regulations made thereunder as it may think fit.\n\n- 1 [77.  Compensation,  penalties  or  confiscation  not  to  interfere  with  other  punishment. -No compensation awarded, penalty imposed or confiscation made under this Act shall prevent the award of compensation or imposition of any other penalty or punishment under any other law for the time being in force.\n- 77A. Compounding of offences. -A court of competent jurisdiction may compound offences, other than  offences  for  which  the  punishment  for  life  or  imprisonment  for a  term  exceeding  three  years has been provided, under this Act:\n\nProvided  that  the  court  shall  not  compound  such  offence  where  the  accused  is,  by  reason  of  his previous conviction, liable to either enhanced punishment or to a punishment of a different kind:\n\nProvided further that the court shall not compound any offence where such offence affects the socio economic conditions of the country or has been committed against a child below the age of 18 years or a woman.\n\n1 . Subs. by Act 10 of 2009, s. 38, for section 77 (w.e.f. 27-10-2009).\n\n- ( 2 ) The person accused of an offence under this Act may file an application for compounding in the court in which offence is pending for trial and the provisions of sections 265B and 265C of the Code of Criminal Procedure, 1973 (2 of 1974) shall apply.\n- 77B. Offences with three years imprisonment to be bailable. -Notwithstanding anything contained in the Code of Criminal Procedure, 1973 (2 of 1974), the offence punishable with imprisonment of three years and above shall be cognizable and the offence punishable with imprisonment of three years shall be bailable.]\n- 78.  Power  to  investigate  offences. -Notwithstanding  anything  contained  in  the  Code  of  Criminal Procedure,  1973  (2  of  1974),  a  police  officer  not  below  the  rank  of 1 [Inspector]  shall  investigate  any offence under this Act.\n\n## 2 [CHAPTER XII\n\n## INTERMEDIARIES NOT TO BE LIABLE IN CERTAIN CASES\n\n- 79.  Exemption  from  liability  of  intermediary  in  certain  cases. -( 1 )  Notwithstanding  anything contained in any law for the time being in force but subject to the provisions of sub-sections ( 2 ) and ( 3 ), an  intermediary  shall  not  be  liable  for  any  third  party  information,  data,  or  communication  link  made available or hosted by him.\n- ( 2 ) The provisions of sub-section ( 1 ) shall apply if-\n- ( a ) the function of the intermediary is limited to providing access to a communication system over which information made available by third parties is transmitted or temporarily stored or hosted; or\n- ( b ) the intermediary does not-\n- ( i ) initiate the transmission,\n- ( ii ) select the receiver of the transmission, and\n- ( iii ) select or modify the information contained in the transmission;\n- ( c )  the  intermediary observes due diligence while discharging his duties under this Act and also observes such other guidelines as the Central Government may prescribe in this behalf.\n- ( 3 ) The provisions of sub-section ( 1 ) shall not apply if-\n- ( a ) the intermediary has conspired or abetted or aided or induced, whether by threats or promise or otherwise in the commission of the unlawful act;\n- ( b )  upon  receiving  actual knowledge,  or  on  being  notified  by  the  appropriate Government  or  its agency  that  any  information,  data  or  communication  link  residing  in  or  connected  to  a  computer resource controlled by the intermediary is being used to commit the unlawful act, the intermediary fails to expeditiously remove or disable access to that material on that resource without vitiating the evidence in any manner.\n\nExplanation. -For the purposes of this section, the expression -third party information\u2016 means any information dealt with by an intermediary in his capacity as an intermediary.\n\n## CHAPTER XIIA\n\n## EXAMINER OF ELECTRONIC EVIDENCE\n\n- 79A. Central Government to notify Examiner of Electronic Evidence. -The Central Government may, for the purposes of providing expert opinion on electronic form evidence before any court or other authority specify, by notification in the Official Gazette, any Department, body or agency of the Central Government or a State Government as an Examiner of Electronic Evidence.\n\nExplanation. -For the purposes of this section, -electronic form evidence\u2016 means any information of probative value that is  either  stored  or transmitted  in  electronic form  and  includes  computer evidence, digital audio, digital video, cell phones, digital fax machines.]\n\n1. Subs. by Act 10 of 2009, s. 39, for -Deputy Superintendent of Police\u2016 (w.e.f. 27-10-2009).\n\n2. Subs. by, s. 40, ibid ., for Chapter XII (w.e.f. 27-10-2009).\n\n## CHAPTER XIII\n\n## MISCELLANEOUS\n\n- 80. Power of police officer and other officers to enter, search, etc. -( 1 )  Notwithstanding anything contained in the Code of Criminal Procedure, 1973 (2 of 1974), any police officer, not below the rank of a 1 [Inspector],  or  any  other  officer  of  the  Central  Government  or  a  State  Government  authorised  by  the Central Government in this behalf may enter any public place and search and arrest without warrant any person  found  therein  who  is  reasonably  suspected  of  having  committed  or  of  committing  or  of  being about to commit any offence under this Act.\n\nExplanation. -For the purposes of this sub-section, the expression -public place\u2016 includes any public conveyance, any hotel, any shop or any other place intended for use by, or accessible to the public.\n\n- ( 2 ) Where any person is arrested under sub-section ( 1 ) by an officer other than a police officer, such officer  shall,  without  unnecessary  delay,  take  or  send  the  person  arrested  before  a  magistrate  having jurisdiction in the case or before the officer-in-charge of a police station.\n- ( 3 ) The provisions of the Code of Criminal Procedure, 1973 (2 of 1974) shall, subject to the provisions of this section, apply, so far as may be, in relation to any entry, search or arrest, made under this section.\n- 81.  Act  to  have  overriding  effect. -The  provisions  of  this  Act  shall  have  effect  notwithstanding anything inconsistent therewith contained in any other law for the time being in force.\n\n2 [Provided  that  nothing  contained  in  this  Act  shall  restrict  any  person  from  exercising  any  right conferred under the Copyright Act, 1957 (14 of 1957) or the Patents Act, 1970 (39 of 1970).]\n\n- 3 [81A. Application of the Act to electronic cheque and truncated cheque.-( 1 )  The provisions of this Act, for the time being in force, shall apply to, or in relation to, electronic cheques and the truncated cheques subject to such modifications and amendments as may be necessary for carrying out the purposes of the Negotiable Instruments Act, 1881 (26 of 1881) by the Central Government, in consultation with the Reserve Bank of India, by notification in the Official Gazette.\n- ( 2 ) Every notification made by the Central Government under sub-section ( 1 ) shall be laid, as soon as may be after it is made, before each House of Parliament, while it is in session, for a total period of thirty days which may be comprised in one session or in two or more successive sessions, and if, before the expiry of the session immediately following the session or the successive sessions aforesaid, both Houses agree in making any modification in the notification or both Houses agree that the notification should not be made, the notification shall thereafter have effect only in such modified form or be of no effect, as the case  may  be;  so,  however,  that  any  such  modification  or  annulment  shall  be  without  prejudice  to  the validity of anything previously done under that notification.\n\nExplanation. -For the purposes of this Act, the expressions -electronic cheque\u2016 and -truncated cheque\u2016 shall have the same meaning as assigned to them in section 6 of the Negotiable Instruments Act, 1881 (26 of 1881).]\n\n- 4 [ 82.  Controller,  Deputy  Controller  and  Assistant  Controller  to  be  public  servants .-The Controller,  the  Deputy  Controller  and  the  Assistant  Controllers  shall  be  deemed  to  be  public  servants within the meaning of section 21 of the Indian Penal Code (45 of 1860).]\n- 83. Power to give directions. -The Central Government may give directions to any State Government as to the carrying into execution in the State of any of the provisions of this Act or of any rule, regulation or order made thereunder.\n- 84. Protection of action taken in good faith. -No suit, prosecution or other legal proceeding shall lie against the Central Government, the State Government, the Controller or any person acting on behalf of him, 5 [and  adjudicating  officers] for  anything  which  is  in  good  faith  done  or  intended  to  be  done  in pursuance of this Act or any rule, regulation or order made thereunder.\n\n1. Subs. by Act 10 of 2009, s. 41, for -Deputy Superintendent of Police\u2016 (w.e.f. 27-10-2009).\n\n2. Ins. by s. 42, ibid. (w.e.f. 27-10-2009).\n\n3. Ins. by Act 55 of 2002, s. 13 (w.e.f. 26-2-2003).\n\n4. Subs. by 7 of 2017, s. 169, for section 82 (w.e.f. 26-5-2017)\n\n5. Subs. by s. 169, ibid ., for - the Chairperson Members, adjudicating officers and the staff of the Cyber Appellate Tribunal\u2016 (w.e.f. 26-5-2017).\n\n- 1 [84A.  Modes  or  methods  for  encryption. -The  Central  Government  may,  for  secure  use  of  the electronic medium and for promotion of e-governance and e-commerce, prescribe the modes or methods for encryption.\n- 84B. Punishment for abetment of offences. -Whoever abets any offence shall, if the act abetted is committed  in  consequence  of  the  abetment,  and  no  express  provision  is  made  by  this  Act  for  the punishment of such abetment, be punished with the punishment provided for the offence under this Act.\n\nExplanation. -An  act  or  offence  is  said  to  be  committed  in  consequence  of  abetment,  when  it  is committed in consequence of the instigation, or  in pursuance of the conspiracy, or with the aid  which constitutes the abetment.\n\n- 84C.  Punishment  for  attempt  to  commit  offences. -Whoever  attempts  to  commit  an  offence punishable by this Act or causes such an offence to be committed, and in such an attempt does any act towards the commission of the offence, shall, where no express provision is made for the punishment of such  attempt,  be  punished  with  imprisonment  of  any  description  provided  for  the  offence,  for  a  term which may extend to one-half of the longest term of imprisonment provided for that offence, or with such fine as is provided for the offence, or with both.]\n- 85. Offences by companies. -( 1 ) Where a person committing a contravention of any of the provisions of this Act or of any rule, direction or order made thereunder is a company, every person who, at the time the contravention was committed, was in charge of, and was responsible to, the company for the conduct of business of the company as well as the company, shall be guilty of the contravention and shall be liable to be proceeded against and punished accordingly:\n\nProvided that nothing contained in this sub-section shall render any such person liable to punishment if he proves that the contravention took place without his knowledge or that he exercised all due diligence to prevent such contravention.\n\n- ( 2 )  Notwithstanding  anything  contained  in  sub-section  ( 1 ),  where  a  contravention  of  any  of  the provisions  of  this  Act  or  of  any  rule,  direction  or  order  made  thereunder  has  been  committed  by  a company and it is proved that the contravention has taken place with the consent or connivance of, or is attributable to any neglect on the part of, any director, manager, secretary or other officer of the company, such director, manager, secretary or other officer shall also be deemed to be guilty of the contravention and shall be liable to be proceeded against and punished accordingly.\n\nExplanation. -For the purposes of this section,-\n\n- ( i ) -company\u2016 means any body corporate and includes a firm or other association of individuals; and\n- ( ii ) -director\u2016, in relation to a firm, means a partner in the firm.\n- 86. Removal of difficulties. -( 1 ) If any difficulty arises in giving effect to the provisions of this Act, the  Central  Government  may,  by  order  published  in  the  Official  Gazette,  make  such  provisions  not inconsistent with the provisions of this Act as appear to it to be necessary or expedient for removing the difficulty:\n\nProvided that no order shall be made under this section after the expiry of a period of two years from the commencement of this Act.\n\n- ( 2 ) Every order made under this section shall be laid, as soon as may be after it is made, before each House of Parliament.\n- 87. Power of Central Government to make rules. -( 1 ) The Central Government may, by notification in the Official Gazette and in the Electronic Gazette, make rules to carry out the provisions of this Act.\n- ( 2 )  In  particular,  and  without  prejudice  to  the  generality  of  the  foregoing  power,  such  rules  may provide for all or any of the following matters, namely:-\n\n2 [( a )  the  conditions  for  considering  reliability  of  electronic  signature  or  electronic  authentication technique under sub-section ( 2 ) of section 3A;\n\n1. Ins. by 10 of 2009, s. 45 (w.e.f. 27-10-2009).\n\n2. Subs. by s. 46, ibid., for clause ( a ) (w.e.f. 27-10-2009).\n\n- ( aa )  the procedure for ascertaining electronic signature or authentication under sub-section ( 3 )  of section 3A;\n- ( ab ) the manner in which any information or matter may be authenticated by means of electronic signature under section 5;]\n- ( b ) the electronic form in which filing, issue, grant or payment shall be effected under sub-section ( 1 ) of section 6;\n- ( c ) the manner and format in which electronic records shall be filed, or issued and the method of payment under sub-section ( 2 ) of section 6;\n- 1 [( ca )  the  manner  in  which  the  authorised  service  provider  may  collect,  retain  and  appropriate service charges under sub-section ( 2 ) of section 6A;]\n- ( d ) the matters relating to the type of 2 [electronic signature], manner and format in which it may be affixed under section 10;\n- 3 [( e ) the manner of storing and affixing electronic signature creation data under section 15;\n- ( ea ) the security procedures and practices under section 16;]\n- ( f )  the  qualifications,  experience  and  terms  and  conditions  of  service  of  Controller,  Deputy Controllers 4 [, Assistant Controllers, other officers and employees] under section 17;\n- 5 * *\n\n*\n\n*\n\n*\n\n- ( h ) the requirements which an applicant must fulfil under sub-section ( 2 ) of section 21;\n- ( i ) the period of validity of licence granted under clause ( a ) of sub-section ( 3 ) of section 21;\n- ( j ) the form in which an application for licence may be made under sub-section ( 1 ) of section 22;\n- ( k ) the amount of fees payable under clause ( c ) of sub-section ( 2 ) of section 22;\n- ( l ) such other documents which shall accompany an application for licence under clause ( d ) of subsection ( 2 ) of section 22;\n- ( m ) the form and the fee for renewal of a licence and the fee payable thereof under section 23;\n- 6 [( ma )  the  form  of  application  and  fee  for  issue  of  Electronic  Signature  Certificate  under section 35;]\n- ( n )  the  form  in  which  application  for  issue  of  a 2 [electronic  signature]  Certificate  may  be  made under sub-section ( 1 ) of section 35;\n- ( o )  the fee to be paid to the Certifying Authority for issue of a 2 [electronic signature] Certificate under sub-section ( 2 ) of section 35;\n- 1 [( oa ) the duties of subscribers under section 40A;\n- ( ob )  the  reasonable  security  practices  and  procedures  and  sensitive  personal  data  or  information under section 43A;]\n- ( p ) the manner in which the adjudicating officer shall hold inquiry under sub-section ( 1 ) of section 46;\n- ( q ) the qualification and experience which the adjudicating officer shall possess under sub-section ( 3 ) of section 46;\n\n7\n\n*\n\n*\n\n*\n\n*\n\n- ( u ) the form in which appeal may be filed and the fee thereof under sub-section ( 3 ) of section 57;\n\n1. Ins. by Act 10 of 2009, s. 46 (w.e.f. 27-10-2009).\n\n2. Subs. by s. 5, ibid. , for -digital signature\u2016 (w.e.f. 27-10-2009).\n\n3. Subs. by s. 46, ibid., for clause ( e ) (w.e.f. 27-10-2009).\n\n4. Subs. by s. 46, ibid., for -and Assistant Controllers\u2016 (w.e.f. 27-10-2009).\n\n5. Clause ( g ) omitted by s. 46, ibid. (w.e.f. 27-10-2009).\n\n6. Ins. by s. 46, ibid. (w.e.f. 27-10-2009).\n\n7. Clauses ( r ), ( s ) and ( t ) omitted by Act 7 of 2017, s. 169 (w.e.f. 26-5-2017).\n\n- ( v ) any other power of a civil court required to be prescribed under clause ( g ) of sub-section ( 2 ) of section 58; and\n- 1 [( w ) the powers and functions of the Chairperson of the 2 [Appellate Tribunal] under section 52A;\n- ( x )  the information, duration, manner and form of such information to be retained and preserved under section 67C;\n- ( y ) the procedures and safeguards for interception, monitoring or decryption under sub-section ( 2 ) of section 69;\n- ( z )  the  procedures  and  safeguards  for  blocking  for access  by  the  public  under sub-section  ( 3 )  of section 69 A;\n- ( za ) the procedure and safeguards for monitoring and collecting traffic data or information under sub-section ( 3 ) of section 69B;\n- ( zb ) the information security practices and procedures for protected system under section 70;\n- ( zc ) manner  of performing functions and duties of the agency  under sub-section ( 3 ) of section 70A;\n- ( zd ) the officers and employees under sub-section ( 2 ) of section 70B;\n- ( ze ) salaries and allowances and terms and conditions of service of the Director General and other officers and employees under sub-section ( 3 ) of section 70B;\n- ( zf ) the manner  in  which  the  functions and  duties of agency  shall be performed  under sub-section ( 5 ) of section 70B;\n- ( zg ) the guidelines to be observed by the intermediaries under sub-section ( 2 ) of section 79;\n- ( zh ) the modes or methods for encryption under section 84A.]\n- ( 3 ) 3 [Every notification made by the Central Government under sub-section ( 1 )  of section 70A and every rule made by it] shall be laid, as soon as may be after it is made, before each House of Parliament, while it is in session, for a total period of thirty days which may be comprised in one session or in two or more successive sessions, and if, before the expiry of the session immediately following the session or the successive  sessions  aforesaid,  both  Houses  agree  in  making  any  modification  in 4 *** the  rule  or  both Houses agree that 4 *** the rule should not be made, 4 *** the rule shall thereafter have effect only in such modified  form  or  be  of  no  effect,  as  the  case  may  be;  so,  however,  that  any  such  modification  or annulment shall be without prejudice to the validity of anything previously done under that notification or rule.\n- 88.  Constitution  of  Advisory  Committee. -( 1 )  The  Central  Government  shall,  as  soon  as  may  be after  the  commencement  of  this  Act,  constitute  a  Committee  called  the  Cyber  Regulations  Advisory Committee.\n- ( 2 ) The Cyber Regulations Advisory Committee shall consist of a Chairperson and such number of other official and non-official members representing the interests principally affected or having special knowledge of the subject-matter as the Central Government may deem fit.\n- ( 3 ) The Cyber Regulations Advisory Committee shall advise-\n- ( a )  the  Central  Government  either  generally  as  regards  any  rules  or  for  any  other  purpose connected with this Act;\n- ( b ) the Controller in framing the regulations under this Act.\n- ( 4 )  There  shall  be  paid  to  the  non-official  members  of  such  Committee  such  travelling  and  other allowances as the Central Government may fix.\n\n1. Subs. by Act 10 of 2009, s. 46, for clause ( w ) (w.e.f. 27-10-2009).\n\n2. Subs. by Act 7 of 2017, s. 169, for -Cyber Appellate Tribunal\u2016(w.e.f. 26-5-2017).\n\n3. Subs. by Act 10 of 2009, s. 46, for certain words, brackets, letter and figures (w.e.f. 27-10-2009).\n\n4. The words -the notification or\u2016 omitted by s. 46, ibid. (w.e.f. 27-10-2009).\n\n- 89. Power of Controller to make regulations. -( 1 ) The Controller may, after consultation with the Cyber Regulations Advisory Committee and with the previous approval of the Central Government, by notification  in  the  Official  Gazette,  make  regulations  consistent  with  this  Act  and  the  rules  made thereunder to carry out the purposes of this Act.\n- ( 2 ) In particular, and without prejudice to the generality of the foregoing power, such regulations may provide for all or any of the following matters, namely:-\n- ( a ) the particulars relating to maintenance of data base containing the disclosure record of every Certifying Authority under clause 1 [( n )] of section 18;\n- ( b )  the  conditions  and  restrictions  subject  to  which  the  Controller  may  recognise  any  foreign Certifying Authority under sub-section ( 1 ) of section 19;\n- ( c )  the  terms  and  conditions  subject  to  which  a  licence  may  be  granted  under  clause  ( c )  of sub-section ( 3 ) of section 21;\n- ( d ) other standards to be observed by a Certifying Authority under clause ( d ) of section 30;\n- ( e )  the  manner  in  which  the  Certifying  Authority  shall  disclose  the  matters  specified  in sub-section ( 1 ) of section 34;\n- ( f )  the  particulars  of  statement  which  shall  accompany  an  application  under  sub-section  ( 3 )  of section 35.\n- ( g ) the manner by which the subscriber shall communicate the compromise of private key to the Certifying Authority under sub-section ( 2 ) of section 42.\n- ( 3 ) Every regulation made under this Act shall be laid, as soon as may be after it is made, before each House of Parliament, while it is in session, for a total period of thirty days which may be comprised in one session or in two or more successive sessions, and if, before the expiry of the session immediately following the session or the successive sessions aforesaid, both Houses agree in making any modification in  the  regulation  or  both  Houses  agree  that  the  regulation  should  not  be  made,  the  regulation  shall thereafter have effect only in such modified form or be of no effect, as the case may be; so, however, that any such modification or annulment shall be without prejudice to the validity of anything previously done under that regulation.\n- 90. Power of State Government to make rules. -( 1 ) The State Government may, by notification in the Official Gazette, make rules to carry out the provisions of this Act.\n- ( 2 )  In  particular,  and  without  prejudice  to  the  generality  of  the  foregoing  power,  such  rules  may provide for all or any of the following matters, namely:-\n- ( a )  the  electronic form in which filing, issue, grant, receipt or payment shall be effected under sub-section ( 1 ) of section 6;\n- ( b ) for matters specified in sub-section ( 2 ) of section 6;\n\n2\n\n*\n\n*\n\n*\n\n*\n\n*\n\n- ( 3 ) Every rule made by the State Government under this section shall be laid, as soon as may be after it  is  made,  before  each  House  of the  State  Legislature  where it consists of two Houses, or where such Legislature consists of one House, before that House.\n- 91. [ Amendment of Act 45 of 1860 .] Omitted by the Information Technology ( Amendment ) Act, 2008 (10 of 2009) , s. 48 ( w.e.f. 27-10-2009).\n- 92. [ Amendment of Act 1 of 1872.] Omitted by s. 48, ibid. ( w.e.f. 27-10-2009).\n- 93. [ Amendment of Act 18 of 1891.] Omitted by s. 48, ibid. ( w.e.f. 27-10-2009).\n- 94. [ Amendment of Act 2 of 1934.] Omitted by s. 48, ibid. ( w.e.f. 27-10-2009).\n\n1. Subs. by notification No. S.O. 1015(E), for -( m )\u2016 (w.e.f. 19-9-2002).\n\n2. Clause ( c ) omitted by Act 10 of 2009, s. 47 (w.e.f. 27-10-2009).\n\n## 1 [THE FIRST SCHEDULE\n\n## [ See sub-section ( 4 ) of section 1]\n\n## DOCUMENTS OR TRANSACTIONS TO WHICH THE ACT SHALL NOT APPLY\n\n|   Sl. No. | Description of documents or transactions                                                                                                                              |\n|-----------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n|         1 | A negotiable instrument (other than a cheque) as defined in section 13 of the Negotiable Instruments Act, 1881 (26 of 1881).                                          |\n|         2 | A power-of-attorney as defined in section 1A of the Powers-of-Attorney Act, 1882 (7 of 1882).                                                                         |\n|         3 | A trust as defined in section 3 of the Indian Trust Act, 1882 (2 of 1882).                                                                                            |\n|         4 | A will as defined in clause ( h ) of section 2 of the Indian Succession Act, 1925 (39 of 1925), including any other testamentary disposition by whatever name called. |\n|         5 | Any contract for the sale or conveyance of immovable property or any interest in such property.                                                                       |\n\n______________\n\n## THE SECOND SCHEDULE\n\n[ See sub-section ( 1 ) of section 3A]\n\n## ELECTRONIC SIGNATURE OR ELECTRONIC AUTHENTICATION TECHNIQUE AND PROCEDURE\n\n| Sl. No.   | Description   | Procedure   |\n|-----------|---------------|-------------|\n| (1)       | (2)           | (3)         |\n\n.]\n\n________________\n\n[ THE  THIRD  SCHEDULE. ] Omitted  by  the  Information  Technology ( Amendment ) Act, 2008 (10 of 2009) , s. 50 ( w.e.f. 27-10-2009).\n\n[ THE FOURTH SCHEDULE .] Omitted by s. 50, ibid. ( w.e.f. 27-10-2009).\n\n1. Subs. by Act 10 of 2009, s. 49, for the First Schedule and the Second Schedule (w.e.f. 27-10-2009).", "metadata": {"country": "India", "year": "2000", "legally_binding": "yes", "binding_proof": "enacted as a law by the Ministry of Electronics and Information Technology", "date": "09/06/2000", "regulator": "Ministry of Electronics and Information Technology", "type": "law", "status": "enacted", "language": "English", "use_cases": "[1, 3, 6]"}}
{"_id": "686aecf3383c6b855905e7a1", "title": "The Information Technology (Intermediary Guidelines and Digital Media Ethics Code) ", "source": "https://www.meity.gov.in/static/uploads/2024/02/Information-Technology-Intermediary-Guidelines-and-Digital-Media-Ethics-Code-Rules-2021-updated-06.04.2023-.pdf", "text": "## The Information Technology (Intermediary Guidelines and Digital Media Ethics Code) Rules, 2021 1\n\n[updated as on 6.4.2023]\n\nIn exercise of the powers conferred by sub-section (1), clauses (z) and (zg) of sub-section (2) of section 87 of the Information Technology Act, 2000 (21 of 2000), and in supersession of the Information  Technology  (Intermediaries  Guidelines)  Rules,  2011,  except  as  respect  things done or omitted to be done before such supersession, the Central Government hereby makes the following rules, namely: -\n\n## PART I\n\n## PRELIMINARY\n\n- 1.  Short  Title  and  Commencement.(1)  These  rules  may  be  called  the  Information Technology (Intermediary Guidelines and Digital Media Ethics Code) Rules, 2021.\n- (2) They shall come into force on the date of their publication in the Official Gazette.\n- 2. Definitions.(1) In these rules, unless the context otherwise requires,-\n- (a) 'access control mechanism' means any measure, including a technical measure, through  which  access  to  online  curated  content  may  be  restricted  based  on verification of the identity or age of a user;\n- (b) 'access services' means any measure, including technical measure such as closed captioning,  subtitles  and  audio  descriptions,  through  which  the  accessibility  of online curated content may be improved for persons with disabilities;\n- (c) 'Act' means the Information Technology Act, 2000 (21 of 2000);\n- (d) 'child' means any person below the age of eighteen years;\n- (e) 'committee' means the Inter-Departmental Committee constituted under rule 14;\n- (f) 'communication  link'  means  a  connection  between  a  hypertext  or  graphical element,  and  one  or  more  items  in  the  same  or  different  electronic  document wherein upon clicking on a hyperlinked item, the user is automatically transferred to the other end of the hyperlink which can be another electronic record or another website or application or graphical element;\n- (g) 'content' means the electronic record defined in clause (t) of section 2 of the Act;\n- (h) 'content  descriptor'  means  the  issues  and  concerns  which  are  relevant  to  the classification of any online curated content, including discrimination, depiction of illegal or harmful substances, imitable behaviour, nudity, language, sex, violence, fear, threat, horror and other such concerns as specified in the Schedule annexed to the rules;\n- (i) 'digital media' means digitized content that can be transmitted over the internet or computer networks and includes content received, stored, transmitted, edited or processed by-\n\n1 Vide G.S.R. 139(E), dated 25.2.2021, published in the Gazette of India, Extra., Pt. II, Sec. 3(i), dated 25.2.2021.\n\n- (i) an intermediary; or\n- (ii) a publisher of news and current affairs content or a publisher of online curated content;\n- (j) 'grievance' includes any complaint, whether regarding any content, any duties of an  intermediary  or  publisher  under  the  Act,  or  other  matters  pertaining  to  the computer resource of an intermediary or publisher, as the case may be;\n- (k) 'Grievance Officer' means an officer appointed by the intermediary or the 1 [online gaming self-regulatory body or the] publisher, as the case may be, for the purposes of these rules;\n- 2 [(ka)  'Grievance  Appellate  Committee'  means  a  grievance  appellate  committee constituted under rule 3A;]\n- (l) 'Ministry'  means,  for  the  purpose  of  Part  II  of  these  rules  unless  specified otherwise, the Ministry of Electronics and Information Technology, Government of India, and for the purpose of Part III of these rules, the Ministry of Information and Broadcasting, Government of India;\n- (m)   'news and current affairs content' includes newly received or noteworthy content, including  analysis,  especially  about  recent  events  primarily  of  socio-political, economic  or  cultural  nature,  made  available  over  the  internet  or  computer networks, and any digital media shall be news and current affairs content where the context, substance, purpose, import and meaning of such information is in the nature of news and current affairs content.\n- (n) 'newspaper'  means  a  periodical  of  loosely  folded  sheets  usually  printed  on newsprint and brought out daily or at least once in a week, containing information on current events, public news or comments on public news;\n- (o) 'news  aggregator'  means  an  entity  who,  performing  a  significant role in determining  the  news  and  current  affairs  content  being  made  available,  makes available to users a computer resource that enable such users to access the news and current  affairs  content  which  is  aggregated,  curated  and  presented  by  such entity.\n- (p) 'on  demand'  means  a  system  where  a  user,  subscriber  or  viewer  is  enabled  to access, at a time chosen by such user, any  content in electronic form, which is transmitted over a computer resource and is selected by the user;\n- (q)   'online curated content' means any curated catalogue of audio-visual content, other than news and current affairs content, which is owned by, licensed to or contracted to be transmitted by a publisher of online curated content, and made available on demand,  including  but  not  limited  through  subscription,  over  the  internet  or computer networks, and includes films, audio visual programmes, documentaries, television programmes, serials, podcasts and other such content;\n\n1 Ins. by G.S.R. 275(E), dated 6.4.2023.\n\n2 Ins. by G.S.R. 794(E), dated 28.10.2022 (w.e.f. 28.10.2022).\n\n- 1 [(qa) 'online game' means a game that is offered on the Internet and is accessible by a user through a computer resource or an intermediary.\n- Explanation .-In  this  clause,  'Internet'  means  the  combination  of  computer facilities  and  electromagnetic  transmission  media,  and  related  equipment  and software, comprising the interconnected worldwide network of computer networks that transmits information based on a protocol for controlling such transmission;\n- (qb) 'online gaming intermediary' means any intermediary that enables the users of its computer resource to access one or more online games;\n- (qc)  'online gaming self-regulatory body' means an entity designated as such under rule 4A;\n- (qd)  'online real money game' means an online game where a user makes a deposit in cash or kind with the expectation of earning winnings on that deposit.\n- Explanation .-In this clause, 'winnings' means any prize, in cash or kind, which is distributed or intended to be distributed to a user of an online game based on the performance of the user and in accordance with the rules of such online game;\n- (qe) 'permissible online game' means a permissible online real money game or any other online game that is not an online real money game;\n- (qf)  'permissible online real money game' means an online real money game verified by an online gaming self-regulatory body under rule 4A;]\n- (r) 'person' means a person as defined in sub-section (31) of section 2 of the Income tax Act, 1961 (43 of 1961);\n- (s) 'publisher' means a publisher of news and current affairs content or a publisher of online curated content;\n- (t)    'publisher of news and current affairs content' means an online paper, news portal, news aggregator, news  agency  and  such  other  entity  called  by  whatever  name, which is functionally similar to publishers of news and current affairs content but shall not include newspapers, replica e-papers of the newspaper and any individual or  user  who  is  not  transmitting  content  in  the  course  of  systematic  business, professional or commercial activity;\n- (u) 'publisher  of  online  curated  content'  means  a  publisher  who,  performing  a significant role in determining the online curated content being made available, makes available to users a computer resource that enables such users to access online curated content over the internet or computer networks, and such other entity called  by  whatever  name,  which  is  functionally  similar  to  publishers  of  online curated content but does not include any individual or user who is not transmitting online  curated  content  in  the  course  of  systematic  business,  professional  or commercial activity;\n\n1 Ins. by G.S.R. 275(E), dated 6.4.2023.\n\n- (v) 'significant social media intermediary' means a social media intermediary having number of registered users in India above such threshold as notified by the Central Government;\n- (w)    'social  media  intermediary'  means  an  intermediary  which  primarily  or  solely enables online interaction between two or more users and allows them to create, upload, share, disseminate, modify or access information using its services;\n- (x)    'user'  means  any  person  who  accesses  or  avails  any  computer  resource  of  an intermediary  or  a  publisher  for  the  purpose  of  hosting,  publishing,  sharing, transacting,  viewing,  displaying,  downloading  or  uploading  information  and includes other persons jointly participating in using such computer resource and addressee and originator;\n- (y) 'user account' means the account registration of a user with an intermediary or publisher  and  includes  profiles,  accounts,  pages,  handles  and  other  similar presences by means of which a user is able to access the services offered by the intermediary or publisher.\n- (2) Words and expressions used and not defined in these rules but defined in the Act and rules made thereunder shall have the same meaning as assigned to them in the Act and the said rules, as the case may be.\n\n## PART II\n\n## DUE DILIGENCE BY INTERMEDIARIES AND GRIEVANCE REDRESSAL MECHANISM\n\n- 3. (1) Due  diligence  by  an  intermediary: An  intermediary,  including 1 [a  social  media intermediary, a significant social media intermediary and an online gaming intermediary], shall observe the following due diligence while discharging its duties, namely: -\n- 2 [(a)  the  intermediary  shall  prominently  publish  on  its  website,  mobile  based application or both, as the case may be, the rules and regulations, privacy policy\n\n1 Subs.  by  G.S.R.  275(E),  dated  6.4.2023  for  'social  media  intermediary  and  significant  social  media intermediary'.\n\n2 Subs. by G.S.R. 794(E), dated 28.10.2022, for clauses (a) and (b) (w.e.f. 28.10.2022). Clauses (a) and (b), before substitution, stood as under:\n\n'(a) the intermediary shall prominently publish on its website, mobile based application or both, as the case may be, the rules and regulations, privacy policy and user agreement for access or usage of its computer resource by any person;\n\n(b) the rules and regulations, privacy policy or user agreement of the intermediary shall inform the user of its  computer  resource  not  to  host,  display,  upload,  modify,  publish,  transmit,  store,  update  or  share  any information that,-\n\n(i) belongs to another person and to which the user does not have any right;\n\n(ii) is  defamatory,  obscene,  pornographic,  paedophilic,  invasive  of  another's  privacy,  including bodily  privacy,  insulting  or  harassing  on  the  basis  of  gender,  libellous,  racially  or  ethnically objectionable, relating or encouraging money laundering or gambling, or otherwise inconsistent with or contrary to the laws in force;\n\n(iii) is harmful to child;\n\n(iv) infringes any patent, trademark, copyright or other proprietary rights;\n\n(v) violates any law for the time being in force;\n\n(vi) deceives or misleads the addressee about the origin of the message or knowingly and intentionally communicates any information which is patently false or misleading in nature but may reasonably be perceived as a fact;\n\n(vii) impersonates another person;\n\n- and user agreement in English or any language specified in the Eighth Schedule to the Constitution for access or usage of its computer resource by any person in the language of his choice and ensure compliance of the same;\n- (b)  the intermediary shall inform its rules and regulations, privacy policy and user agreement to the user in English or any language specified in the Eighth Schedule to the Constitution in the language of his choice and shall make reasonable efforts 1 [by itself, and to cause the users of its computer resource to not host], display, upload, modify, publish, transmit, store, update or share any information that,-\n- (i) belongs to another person and to which the user does not have any right;\n- (ii) is  obscene,  pornographic,  paedophilic,  invasive  of  another's  privacy including bodily privacy, insulting or harassing on the basis of gender, racially  or  ethnically  objectionable,  relating  or  encouraging  money laundering or gambling, 2 [or an online game that causes user harm,] or promoting enmity between different groups on the grounds of religion or caste with the intent to incite violence;\n- (iii) is harmful to child;\n- (iv) infringes any patent, trademark, copyright or other proprietary rights;\n- (v) deceives or misleads the addressee about the origin of the message or knowingly  and  intentionally  communicates  any  misinformation  or information which is patently false and untrue or misleading in nature 3 [or, in respect of any business of the Central Government, is identified as  fake  or  false  or  misleading  by  such  fact  check  unit  of  the  Central Government  as  the  Ministry  may,  by  notification  published  in  the Official Gazette, specify];\n- (vi) impersonates another person;\n- (vii) threatens the unity, integrity, defence, security or sovereignty of India, friendly  relations  with  foreign  States,  or  public  order,  or  causes incitement  to  the  commission  of  any  cognisable  offence,  or  prevents investigation of any offence, or is insulting other nation;\n- (viii) contains  software  virus  or  any  other  computer  code,  file  or  program designed to interrupt, destroy or limit the functionality of any computer resource;\n\n(viii) threatens the unity, integrity, defence, security or sovereignty of India, friendly relations with foreign States, or public order, or causes incitement to the commission of any cognisable offence or prevents investigation of any offence or is insulting other nation;\n\n(ix) contains software virus or any other computer code, file or program designed to interrupt, destroy or limit the functionality of any computer resource;\n\n(x) is patently false and untrue, and is written or published in any form, with the intent to mislead or harass a person, entity or agency for financial gain or to cause any injury to any person;'.\n\n1 Subs. by G.S.R. 275(E), dated 6.4.2023 for 'to cause the user of its computer resource not to host,'.\n\n2 Ins. by G.S.R. 275(E), dated 6.4.2023.\n\n3 Ins. by G.S.R. 275(E), dated 6.4.2023.\n\n- 1 [(ix)  is  in  the  nature  of  an  online  game  that  is  not  verified  as  a  permissible online game;\n- (x)  is in the nature of advertisement or surrogate advertisement or promotion of an online game that is not a permissible online game, or of any online gaming intermediary offering such an online game;\n- (xi)  violates any law for the time being in force;\n\nExplanation.In this clause, 'user harm' and 'harm' mean any effect which is detrimental to a user or child, as the case may be;]]\n\n- (c) an intermediary shall periodically inform its users, at least once every year, that in  case  of  non-compliance with rules and regulations, privacy policy or user agreement for access or usage of the computer resource of such intermediary, it has the right to terminate the access or usage rights of the users to the computer resource immediately or remove non-compliant information or both, as the case may be;\n- (d) an intermediary, on whose computer resource the information is stored, hosted or published, upon receiving actual knowledge in the form of an  order by a court  of  competent  jurisdiction  or  on  being  notified  by  the  Appropriate Government or its agency under clause (b) of sub-section (3) of section 79 of the  Act,  shall  not  host,  store  or  publish  any  unlawful  information,  which  is prohibited under any law for the time being in force in relation to the interest of the sovereignty and integrity of India;  security of the State; friendly relations with foreign States; public order; decency or morality; in relation to contempt of court; defamation;  incitement to an offence relating to the above, or any information which is prohibited under any law for the time being in force:\n\nProvided that any notification made by the Appropriate Government or its agency in relation to any information which is prohibited under any law for the  time  being  in  force  shall  be  issued  by  an  authorised  agency,  as  may  be notified by the Appropriate Government:\n\nProvided  further  that if  any  such  information  is  hosted,  stored  or published, the intermediary shall remove or disable access to that information, as early as possible, but in no case later than thirty-six hours from the receipt of the  court  order  or  on  being  notified  by  the  Appropriate  Government  or  its agency, as the case may be:\n\nProvided also that the removal or disabling of access to any information, data or communication link within the categories of information specified under this clause, under clause (b) on a voluntary basis, or on the basis of grievances received under sub-rule (2) by such intermediary, shall not amount to a violation of the conditions of clauses (a) or (b) of sub-section (2) of section 79 of the Act;\n\n1 Subs.by G.S.R. 275(E), dated 6.4.2023 for clause (ix). Clause (ix), before substitution, stood as under: '(ix) violates any law for the time being in force;'.\n\n- (e) the temporary or transient or intermediate storage of information automatically by  an  intermediary  in  a  computer  resource  within  its  control  as  an  intrinsic feature  of  that  computer  resource,  involving  no  exercise  of  any  human, automated or algorithmic editorial control for onward transmission or communication  to  another  computer  resource  shall  not  amount  to  hosting, storing or publishing any information referred to under clause (d) ;\n- 1 [(f) the intermediary shall periodically, and at least once in a year, inform its users in English or any language specified in the Eighth Schedule to the Constitution in the language of his choice of its rules and regulations, privacy policy or user agreement or any change in the rules and regulations, privacy policy or user agreement, as the case may be:]\n- 2 [Provided that an online gaming intermediary who enables the users to access any permissible online real money game shall inform its users of such change as soon as possible, but not later than twenty-four hours after the change is effected;]\n- (g) where upon receiving actual knowledge under clause (d), on a voluntary basis on violation of clause (b), or on the basis of grievances received under sub-rule (2) , any information has been removed or access to which has been disabled, the intermediary shall, without vitiating the evidence in any manner, preserve such information  and  associated  records  for  one  hundred  and  eighty  days  for investigation purposes, or for such longer period as may be required by the court or by Government agencies who are lawfully authorised;\n- (h) where an intermediary collects information from a user for registration on the computer resource, it shall retain his information for a period of one hundred and eighty days after any cancellation or withdrawal of his registration, as the case may be;\n- (i) the  intermediary  shall  take  all  reasonable  measures  to  secure  its  computer resource and information contained therein following the reasonable security practices and procedures as prescribed in the Information Technology (Reasonable Security Practices and Procedures and Sensitive Personal Information) Rules, 2011;\n- (j) the intermediary shall, as soon as possible, but not later than seventy two hours 3 [and in case of an online gaming intermediary who enables the users to access any permissible online real money game not later than twenty-four hours] of the receipt  of  an  order,  provide  information  under  its  control  or  possession,  or assistance to  the  Government  agency  which  is  lawfully  authorised for investigative  or  protective  or  cyber  security  activities,  for  the  purposes  of verification  of  identity,  or  for  the  prevention,  detection,  investigation,  or\n\n1 Subs. by G.S.R. 794(E), dated 28.10.2022 (w.e.f. 28.10.2022), for clause (f). Clause (f), before substitution stood as under:\n\n'(f)  the intermediary shall periodically, and at least once in a year, inform  its users of its rules and regulations, privacy  policy  or  user  agreement  or  any  change  in  the  rules  and  regulations,  privacy  policy  or  user agreement, as the case may be;'.\n\n2 Ins. by G.S.R. 275(E), dated 6.4.2023.\n\n3 Ins. by G.S.R. 275(E), dated 6.4.2023.\n\nprosecution, of offences under any law for the time being in force, or for cyber security incidents:\n\nProvided  that any  such  order  shall  be  in  writing  stating  clearly  the purpose of seeking information or assistance, as the case may be;\n\n- (k) the  intermediary  shall  not  knowingly  deploy  or  install  or  modify  technical configuration of computer resource or become party to any act that may change or has the potential to change the normal course of operation of the computer resource than what it is supposed to perform thereby circumventing any law for the time being in force:\n- Provided  that the  intermediary  may  develop,  produce,  distribute  or employ technological means for the purpose of performing the acts of securing the computer resource and information contained therein;\n- (l) the  intermediary  shall report cyber  security  incidents  and  share  related information with the Indian Computer Emergency Response Team  in accordance with the policies and procedures as mentioned in the Information Technology (The Indian Computer Emergency Response Team and Manner of Performing Functions and Duties) Rules, 2013.\n- 1 [(m) the intermediary shall take all reasonable measures to ensure accessibility of its services to users along with reasonable expectation of due diligence, privacy and transparency;\n- (n) the intermediary shall respect all the rights accorded to the citizens under the Constitution, including in the articles 14, 19 and 21.]\n- (2) Grievance redressal mechanism of intermediary: (a) The intermediary shall prominently publish on its website, mobile based application or both, as the case may be, the name of the Grievance Officer and his contact details as well as mechanism by which a user or a victim may make complaint against violation of the provisions of this rule or 2 [sub-rules (11) to (13) of rule 4, or in respect of] any other matters pertaining to the computer resources made available by it, and the Grievance Officer shall-\n- 3 [(i)  acknowledge  the  complaint  within  twenty-four  hours  and  resolve  such  complaint within a period of fifteen days from the date of its receipt:\n\nProvided that the complaint in the nature of request for removal of information or communication link relating to clause (b) of sub-rule (1) of rule 3, except sub-clauses (i),  (iv)  and 4 [(xi)],  shall  be  acted  upon  as  expeditiously  as  possible  and  shall  be resolved within seventy-two hours of such reporting;\n\nProvided further that appropriate safeguards may  be developed by the intermediary to avoid any misuse by users;]\n\n1 Ins. by G.S.R. 794(E), dated 28.10.2022 (w.e.f. 28.10.2022).\n\n2 Ins. by G.S.R. 275(E), dated 6.4.2023.\n\n3 Subs.  by  G.S.R.  794(E),  dated  28.10.2022,  for  sub-clause  (i)  (w.e.f.  28.10.2022).  Sub-clause  (i),  before substitution, stood as under:\n\n'(i) acknowledge the complaint within twenty four hours and dispose off such complaint within a period of fifteen days from the date of its receipt;'.\n\n4 Subs. by G.S.R. 275(E), dated 6.4.2023 for '(ix)'.\n\n- (ii)  receive  and  acknowledge  any  order,  notice  or  direction  issued  by  the  Appropriate Government, any competent authority or a court of competent jurisdiction.\n\n1 [ Explanation.In this rule, 'prominently publish' shall mean publishing in a clearly visible manner on the home page of the website or the home screen of the mobile based application, or both, as the case may be, or on a web page or an app screen directly accessible from the home page or home screen.]\n\n- (b) The intermediary shall, within twenty-four hours from the receipt of a complaint made by an individual or any person on his behalf under this sub-rule, in relation to any content which is prima facie in the nature of any material which exposes the private area of such individual, shows such individual in full or partial nudity or shows or depicts such individual in any sexual act or conduct, or is in the nature of impersonation in an electronic form, including artificially morphed images of such individual, take all reasonable and practicable measures to remove or disable access to such content which is hosted, stored, published or transmitted by it:\n- (c) The intermediary shall implement a mechanism for the receipt of complaints under clause (b) of this sub-rule which may enable the individual or person to provide details, as may be necessary, in relation to such content or communication link.\n- 2 [ 3A. Appeal to Grievance Appellate Committee(s).(1) The Central Government shall, by notification, establish one or more Grievance Appellate Committees within three months from the  date  of  commencement  of  the  Information  Technology  (Intermediary  Guidelines  and Digital Media Ethics Code) Amendment Rules, 2022.\n- (2) Each Grievance Appellate Committee shall consist of a chairperson and two whole time members appointed by the Central Government, of which one shall be a member ex-officio and two shall be independent members.\n- (3) 3 [Any person who is aggrieved by a decision of the Grievance Officer or whose grievance is not resolved within the period specified for resolution in sub-clause (i) of clause (a) of subrule (2) of rule 3 or clause (b) of sub-rule (2) of rule 3 or sub-rule (11) of rule 4A, as the case may be,] may prefer an appeal to the Grievance Appellate Committee within a period of thirty days from the date of receipt of communication from the Grievance Officer.\n- (4) The Grievance Appellate Committee shall deal with such appeal expeditiously and shall make an endeavour to resolve the appeal finally within thirty calendar days from the date of receipt of the appeal.\n- (5) While dealing with the appeal if the Grievance Appellate Committee feels necessary, it may seek assistance from any person having requisite qualification, experience and expertise in the subject matter.\n- (6) The Grievance Appellate Committee shall adopt an online dispute resolution mechanism wherein  the  entire  appeal  process,  from  filing  of  appeal  to  the  decision  thereof,  shall  be conducted through digital mode.\n\n1 Ins. by G.S.R. 275(E), dated 6.4.2023.\n\n2 Ins. by G.S.R. 794(E), dated 28.10.2022 (w.e.f. 28.10.2022).\n\n3  Subs. by G.S.R. 275(E), dated 6.4.2023 for 'Any person aggrieved by a decision of the Grievance Officer'.\n\n- (7) Every order passed by the Grievance Appellate Committee shall be complied with by the intermediary concerned 1 [or the online gaming self-regulatory body concerned, as the case may be,] and a report to that effect shall be uploaded on its website.]\n- 4. Additional due diligence to be observed by significant social media intermediary  2 [and online gaming intermediary].(1) In addition to the due diligence observed under rule 3, a significant social media 3 [intermediary, within three months from the date of notification of the threshold under clause (v) of sub-rule (1) of rule 2, and an online gaming intermediary that enables  the  users  to  access  any  permissible  online  real  money  game,  shall]  observe  the following additional due diligence while discharging its duties, namely: -\n- (a) appoint  a  Chief  Compliance  Officer  who  shall  be  responsible  for  ensuring compliance  with  the  Act  and  rules  made  thereunder  and  shall  be  liable  in  any proceedings relating to any relevant third-party information, data or communication link made available or hosted by that intermediary where he fails to ensure that such intermediary observes due diligence while discharging its duties under the Act and rules made thereunder:\n\nProvided that no liability under the Act or rules made thereunder may be imposed on such significant social media intermediary 4 [or such online gaming intermediary] without being given an opportunity of being heard.\n\nExplanation .-For the purposes of this clause ' Chief Compliance Officer ' means a key managerial personnel or such other senior employee of a significant social media intermediary 5 [or an online gaming intermediary, as the case may be,] who is resident in India;\n\n- (b) appoint  a  nodal  contact  person  for  24x7  coordination  with  law  enforcement agencies and officers to ensure compliance to their orders or requisitions made in accordance with the provisions of law or rules made thereunder.\n\n6 [ Explanation .-In this clause, 'nodal contact person' means the employee of-\n\n- (i) a  significant  social  media  intermediary, other than its Chief Compliance Officer; or\n- (ii) an online gaming intermediary,\n\nwho is resident in India;]\n\n- (c) appoint  a  Resident  Grievance  Officer,  who  shall,  subject  to  clause  (b),  be responsible for the functions referred to in sub-rule (2) of rule 3.\n\n1 Ins. by G.S.R. 275(E), dated 6.4.2023.\n\n2 Ins. by G.S.R. 275(E), dated 6.4.2023.\n\n3 Subs. by G.S.R. 275(E), dated 6.4.2023 for 'intermediary shall, within three months from the date of notification of the threshold under clause (v) of sub-rule (1) of rule 2,'.\n\n4 Ins. by G.S.R. 275(E), dated 6.4.2023.\n\n5 Ins. by G.S.R. 275(E), dated 6.4.2023.\n\n6 Subs. by G.S.R. 275(E), dated 6.4.2023 for the existing Explanation. The Explanation, before substitution, stood as under:\n\n' Explanation . -For the purposes of this clause ' nodal contact person ' means the employee of a significant social media intermediary, other than the Chief Compliance Officer, who is resident in India;'.\n\n- Explanation .-For  the  purposes  of  this  clause,  ' Resident  Grievance  Officer ' means  the  employee  of  a  significant  social  media 1 [intermediary  or  an  online gaming intermediary, as the case may be,] who is resident in India;\n- (d) publish  periodic  compliance  report  every  month  mentioning  the  details  of complaints  received  and  action  taken 2 [thereon,  and,  in  respect  of  a  significant social media intermediary,] the number of specific communication links or parts of information that the intermediary has removed or disabled access to in pursuance of  any  proactive  monitoring  conducted  by  using  automated  tools  or  any  other relevant information as may be specified;\n- (2)  A  significant  social  media  intermediary  providing  services  primarily  in  the  nature  of messaging  shall  enable  the  identification  of  the  first  originator  of  the  information  on  its computer resource as may be required by a judicial order passed by a  court of competent jurisdiction  or  an  order  passed  under  section  69  by  the  Competent  Authority  as  per  the Information Technology (Procedure and Safeguards for interception, monitoring and decryption  of  information)  Rules,  2009,  which  shall  be  supported  with  a  copy  of  such information in electronic form:\n\nProvided that an order shall only be passed for the purposes of prevention, detection, investigation, prosecution or punishment of an offence related to the sovereignty and integrity of India, the security of the State, friendly relations with foreign States, or public order, or of incitement to an offence relating to the above or in relation with rape, sexually explicit material or child sexual abuse material, punishable with imprisonment for a term of not less than five years:\n\nProvided further that no order shall be passed in cases where other less intrusive means are effective in identifying the originator of the information:\n\nProvided also that in complying with an order for identification of the first originator, no  significant  social  media  intermediary  shall  be  required  to  disclose  the  contents  of  any electronic message, any other information related to the first originator, or any information related to its other users:\n\nProvided  also  that where  the  first  originator  of  any  information  on  the  computer resource of an intermediary is located outside the territory of India, the first originator of that information  within  the  territory  of  India  shall  be  deemed  to  be  the  first  originator  of  the information for the purpose of this clause.\n\n- (3)  A  significant  social  media  intermediary  that  provides  any  service  with  respect  to  an information  or  transmits  that  information  on  behalf  of  another  person  on  its  computer resource-\n- (a) for direct financial benefit in a manner that increases its visibility or prominence, or targets the receiver of that information; or\n- (b) to which it owns a copyright, or has an exclusive license, or in relation with which it has entered into any contract that directly or indirectly restricts the publication\n\n1 Subs. by G.S.R. 275(E), dated 6.4.2023 for 'intermediary,'.\n\n2 Subs. by G.S.R. 275(E), dated 6.4.2023 for 'thereon, and'.\n\nor transmission of that information through any means other than those provided through the computer resource of such social media intermediary, shall  make  that  information  clearly  identifiable  to  its  users  as  being  advertised,  marketed, sponsored, owned, or exclusively controlled, as the case may be, or shall make it identifiable as such in an appropriate manner.\n\n- (4)  A  significant  social  media  intermediary  shall  endeavour  to  deploy  technology-based measures, including automated tools or other mechanisms to proactively identify information that depicts any act or simulation in any form depicting rape, child sexual abuse or conduct, whether  explicit  or  implicit,  or  any  information  which  is  exactly  identical  in  content  to information that has previously been removed or access to which has been disabled on the computer resource of such intermediary under clause (d) of sub-rule (1) of rule 3, and shall display a notice to any user attempting to access such information stating that such information has been identified by the intermediary under the categories referred to in this sub-rule:\n\nProvided  that the  measures  taken  by  the  intermediary  under  this  sub-rule  shall  be proportionate having regard to the interests of free speech and expression, privacy of users on the  computer  resource  of  such  intermediary,  including  interests  protected  through  the appropriate use of technical measures:\n\nProvided further that such intermediary shall implement mechanisms for appropriate human oversight of measures deployed under this sub-rule, including a periodic review of any automated tools deployed by such intermediary:\n\nProvided also that the review of automated tools under this sub-rule shall evaluate the automated tools having regard to the accuracy and fairness of such tools, the propensity of bias and discrimination in such tools and the impact on privacy and security of such tools.\n\n- (5) 1 [A significant social media intermediary and an online gaming intermediary who enables the  users  to  access  any  permissible  online  real  money  game]  shall  have  a  physical  contact address in India published on its website, mobile based application or both, as the case may be, for the purposes of receiving the communication addressed to it.\n- (6) 2 [A significant social media intermediary and an online gaming intermediary who enables the users to access any permissible online real money game] shall implement an appropriate mechanism for the receipt of complaints under sub-rule (2) of rule 3 and grievances in relation to the violation of provisions under this rule, which shall enable the complainant to track the status of such complaint or grievance by providing a unique ticket number for every complaint or grievance received by such intermediary:\n\nProvided  that such  intermediary  shall,  to  the  extent  reasonable,  provide  such complainant with reasons for any action taken or not taken by such intermediary in pursuance of the complaint or grievance received by it.\n\n- (7) 3 [A significant social media intermediary and an online gaming intermediary who enables the users to access any permissible online real money game] shall enable users who register for their services from India, or use their services in India, to voluntarily verify their accounts by\n\n1 Subs. by G.S.R. 275(E), dated 6.4.2023 for 'The significant social media intermediary'.\n\n2 Subs. by G.S.R. 275(E), dated 6.4.2023 for 'The significant social media intermediary'.\n\n3 Subs. by G.S.R. 275(E), dated 6.4.2023 for 'The significant social media intermediary'.\n\nusing any appropriate mechanism, including the active Indian mobile number of such users, and  where  any  user  voluntarily  verifies  their  account,  such  user  shall  be  provided  with  a demonstrable and visible mark of verification, which shall be visible to all users of the service:\n\nProvided that the information received for the purpose of verification under this subrule shall not be used for any other purpose, unless the user expressly consents to such use.\n\n- (8)  Where  a  significant  social  media  intermediary  removes  or  disables  access  to  any information, data or communication link, under clause (b) of sub-rule (1) of rule 3 on its own accord, such intermediary shall, -\n- (a) ensure that prior to the time at which such intermediary removes or disables access, it has provided the user who has created, uploaded, shared, disseminated, or modified information, data or communication link using its services with a notification explaining the action being taken and the grounds or reasons for such action;\n- (b) ensure  that  the  user  who  has  created,  uploaded,  shared,  disseminated,  or modified  information  using  its  services  is  provided  with  an  adequate  and reasonable opportunity to dispute the action being taken by such intermediary and  request  for  the  reinstatement  of  access  to  such  information,  data  or communication link, which may be decided within a reasonable time;\n- (c) ensure  that  the  Resident  Grievance  Officer  of  such  intermediary  maintains appropriate oversight over the mechanism for resolution of any disputes raised by the user under clause (b).\n- (9) The Ministry may call for such additional information from any significant social media intermediary as it may consider necessary for the purposes of this part.\n- 1 [(10) An online gaming intermediary who enables access to its users to any permissible online real money game, shall display a demonstrable and visible mark of verification by an online gaming self-regulatory body on such permissible online real money game.\n- (11) While informing the users of its rules and regulations, privacy policy, terms of service and user agreements under clause (b) of sub-rule (1) of rule 3, an online gaming intermediary who enables the users to access any permissible online real money game, shall include the following information in respect of every such online games, namely: -\n- (a) the policy related to withdrawal or refund of the deposit made with the expectation of  earning  winnings,  the  manner  of  determination  and  distribution  of  such winnings, and the fees and other charges payable by the user;\n- (b) the know-your-customer procedure followed by it for verifying the identity of the users of such online game;\n- (c) the measures taken for protection of deposit made by a user for such online game; and\n- (d) the framework referred to in rule 4A, relating to such online game.\n- (12) An online gaming intermediary shall, before accepting any deposit in cash or kind from any user for a permissible online real money game, identify such user and verify his identity:\n\nProvided  that  the  procedure  required  to  be  followed  by  an  entity  regulated  by  the Reserve Bank of India for identification and verification of a customer at the commencement\n\n1 Ins. by G.S.R. 275(E), dated 6.4.2023.\n\nof an account-based  relationship shall apply, mutatis  mutandis , in identification  and verification of the users of such online gaming intermediary.\n\n- (13) An online gaming intermediary who enables the users to access any permissible online real money game shall not itself finance by way of credit or enable financing to be offered by third party for the purpose of playing such online game.]\n- 1 [ 4A. Verification of online real money game.(1) The Ministry may, by a notification in the Official Gazette, designate as many online gaming self-regulatory bodies as it may consider necessary for the purposes of verifying an online real money game as a permissible online real money game under these rules.\n- (2) An entity which fulfils the following criteria may apply to the Ministry for designation as an online gaming self-regulatory body, namely:-\n- (a) the entity is a company registered under section 8 of the Companies Act, 2013 (18 of 2013);\n- (b) its membership is representative of the gaming industry;\n- (c) its members have been offering and promoting online games in a responsible manner;\n- (d) its Board of Directors is comprised of individuals of repute and do not have any conflict of  interest  and  possess  special  knowledge  or  practical  experience  suitable  for  the performance of the functions of such self-regulatory body, and consists of-\n- (i) an individual having special knowledge of or practical experience in the online gaming industry;\n- (ii) an  individual  having  experience  in  promoting  the  interests  of  users  of online games;\n- (iii) an educationist;\n- (iv) an expert in the field of psychology or mental health or such other relevant field;\n- (v) an individual having special knowledge of or practical experience in the field of information and communications technology;\n- (vi) an individual who is or has been a member or officer of an organisation dealing with the protection of child rights;\n- (vii) an individual having practical experience in the field of public policy or public  administration  or  law  enforcement  or  public  finance  or  other relevant field, to be nominated by the Ministry; and\n- (viii) such other individuals as may be appointed with the previous approval of the Ministry;\n- (e) its memorandum of association and articles of association contain provisions relating to-\n- (i) the performance of its functions under these rules, including the redressal of  grievances  under  sub-rule  (11),  in  a  manner  free  from  conflict  of interest and at arm's length from its members;\n- (ii) the  disclosure  and  reporting  by  and  accountability  of  its  members  in relation to the online games verified by such body;\n\n1 Ins. by G.S.R. 275(E), dated 6.4.2023.\n\n- (iii) the  clear  and  relevant  criteria,  consistent  with  these  rules,  for  the acceptance and continuation of a person as its member, and for revoking or suspending such membership after giving such person an opportunity of being heard; and\n- (iv) the requirement that the amendment in the memorandum of association and articles  of  association  in  relation  to  any  matter  referred  to  in  subclauses  (i),  (ii)  or  (iii)  is  carried  out  with  the  previous  approval  of  the Ministry; and\n- (f) the entity has sufficient capacity, including financial capacity, to perform its functions as an online gaming self-regulatory body under these rules.\n- (3) The online gaming self-regulatory body, upon an application made to it by its member in respect of an online real money game, may declare such online real money game as permissible online real money game, if, after making such inquiry as it deems fit, it is satisfied that-\n- (a) the online real money game does not involve wagering on any outcome; and\n- (b) the  online  gaming  intermediary  and  such  online  game  is  in  compliance  with  the provisions of rules 3 and 4, the provisions of any law relating to the age at which an individual is competent to enter into a contract, and the framework made by the online gaming self-regulatory body under sub-rule (8):\n\nProvided  that  an  online  gaming  self-regulatory  body  may,  initially  rely  upon  the information  furnished  by  the  applicant  for  verification  of  the  online  real  money  game  and declare such game as a permissible online real money game for a period not exceeding three months:\n\nProvided  further  that  the  online  gaming  self-regulatory  body  shall  endeavour  to complete the inquiry within the said period of three months and, upon its completion, either declare the online real money game as a permissible online real money game or inform the applicant  in  writing  with  the  reasons  thereof  that  such  online  game  does  not  meet  the requirements under these rules.\n\n- (4) The online gaming self-regulatory body shall publish and maintain on its website, mobile based application or both, at all times, an updated list of all permissible online real money games verified under sub-rule (3), along with the details of such online games including the details of the applicant, the dates and period of validity of the verification, the reasons of such verification and the details of the suspension or revocation, if any, of verification of any online real money game.\n- (5) Every online gaming self-regulatory body shall publish and maintain on its website, mobile based application or both, at all times, an updated list of all its members, whether present or former, the dates of their acceptance as member, their corporate or business-related identity number and other details, and the details of suspension or revocation of membership of any member.\n- (6) The online gaming self-regulatory body may, at any time, after giving the applicant member an  opportunity  of  being  heard  and  for  reasons  to  be  communicated  in  writing,  suspend  or revoke the verification, if it is satisfied that the online real money game verified by it is not in compliance with the provisions of these rules.\n- (7)  The  online  real  money  game  verified  under  sub-rule  (3),  and  the  online  gaming intermediary  which  enables  access  to  such  online  real  money  game,  shall  display  a demonstrable and visible mark of such verification stating that the online real money game is verified by the online gaming self-regulatory body as a permissible online real money game under these rules.\n- (8) The online gaming self-regulatory body shall prominently publish on its website, mobile based application or both, as the case may be, a framework for verifying an online real money game, which, among other things, includes the following, namely:-\n- (a) the measures to ensure that such online real money game is not against the interests of sovereignty and integrity of India, security of the State, friendly relations with foreign States and public order;\n- (b) the safeguards against user harm, including self-harm and psychological harm;\n- (c) the measures to safeguard children, including measures for parental or access control and classifying online games through age-rating mechanism, based on the nature and type of content; and\n- (d) the measures to safeguard users against the risk of gaming addiction, financial loss and financial  fraud,  including  repeated  warning  messages  at  higher  frequency  beyond  a reasonable duration for a gaming session and provision to enable a user to exclude himself upon user-defined limits being reached for time or money spent.\n- (9) The Ministry may, if it considers it necessary, by a notice in writing, require an online gaming self-regulatory body to furnish to the Ministry or disclose on such body's website or mobile based application or both, such information as the Ministry may specify in the notice.\n- (10) Before issuing a direction under section 69A of the Act in respect of a permissible online real money game, the Central Government may take into consideration the details published by an online gaming self-regulatory body under sub-rule (4).\n- (11) Every online gaming self-regulatory body shall prominently publish on its website, mobile based application or both, the framework for redressal of grievances and the contact details of the Grievance Officer to which an applicant aggrieved by a decision of such body with respect to verification may make a complaint in respect of any matter related to such online real money game or verification which shall be acknowledged by the Grievance Officer within twentyfour hours and resolved within a period of fifteen days from the date of its receipt.\n- (12) Where the Ministry is of the view that any verification of a permissible online real money game by an online gaming self-regulatory body is not in conformity with these rules, it may, after giving such body an opportunity of being heard, communicate, in writing, the fact of such non-conformity to that body and direct it to take measures to rectify the same.\n- (13) The Ministry may, if it is satisfied that it is necessary so to do, after giving the online gaming self-regulatory body an opportunity of being heard, by order, for reasons to be recorded in writing, suspend or revoke the designation of such body:\n\nProvided that the Ministry may, in the interest of the users of any online game that was verified by such body at the same time or at any subsequent time, give such interim directions as it may deem necessary to any intermediary or class of intermediaries regarding enabling its users to access such online game.\n\n- (14) In this rule, 'prominently publish' shall mean publishing in a clearly visible manner on the home page of the website or the home screen of the mobile based application, or both, as the case may be, or on a web page or an app screen directly accessible from the home page or home screen.\n- 4B. Applicability of certain obligations after an initial period.The obligations under rules 3 and 4 shall not apply in relation to online games until the expiry of a period of three months from the date on which at least three online gaming self-regulatory bodies have been designated under rule 4A:\n\nProvided that the Central Government may, at any time before the expiry of the said period of three months, by a notification in the Official Gazette, direct that the obligations under rules 3 and 4 shall apply in relation to an online game from such date as may be specified in the notification.\n\n- 4C. Obligations in relation to online game other than online real money game. -(1) If the Central  Government  considers  it  necessary  so  to  do  in  the  interest  of  the  sovereignty  and integrity of India or security of the State or friendly relations with foreign States or public order, or preventing user harm, it may, by a notification in the Official Gazette, for reasons to be recorded in writing,-\n- (a) direct that an intermediary in respect of such online game, shall observe, mutatis mutandis , the obligations under sub-clauses (ix) and (x) of clause (b) of sub-rule (1) of rule 3and sub-rules (1), (5), (6), (7), (10) and clause (d) of sub-rule (11) of rule 4 as if it is a permissible online real money game; and\n- (b) specify  the  period  within  which  the  online  gaming  intermediary  which  enables access to such online game shall observe the obligations referred to in clause (a).\n- (2) Where an online game is notified under sub-rule (1), the provisions of rule 4A shall apply as they apply to a permissible online real money game.\n\nExplanation.In this rule, 'user harm' means any effect which is detrimental to users.]\n\n- 5. Additional due diligence to be observed by an intermediary in relation to news and current affairs content.In addition to adherence to rules 3 and 4, as may be applicable, an intermediary shall publish, on an appropriate place on its website, mobile based application or both,  as  the  case  may  be,  a  clear  and  concise  statement  informing  publishers  of  news  and current  affairs  content  that  in  addition  to  the  common  terms  of  service  for  all  users,  such publishers shall furnish the details of their user accounts on the services of such intermediary to the Ministry as  may be required under rule 18:\n\nProvided  that an  intermediary  may  provide  such  publishers  who  have  provided information  under  rule  18  with  a  demonstrable  and  visible  mark  of  verification  as  being publishers, which shall be visible to all users of the service.\n\nExplanation .-This  rule  relates  only  to  news  and  current  affairs  content  and  shall  be administered by the Ministry of Information and Broadcasting.\n\n- 6. Notification of other intermediary.(1) The Ministry may by order, for reasons to be recorded  in  writing,  require  any  intermediary,  which  is  not  a  significant  social  media\n\nintermediary, to comply with all or any of the obligations mentioned under rule 4, if the services of that intermediary permits the publication or transmission of information in a manner that may create a material risk of harm to the sovereignty and integrity of India, security of the State, friendly relations with foreign States or public order.\n\n- (2) The assessment of material risk of harm referred to in sub-rule (1) shall be made having regard to the nature of services of such intermediary, and if those services permit, -\n- (a) interaction between users, notwithstanding, whether it is the primary purpose of that intermediary; and\n- (b) the publication or transmission of information to a significant number of other users as would be likely to result in widespread dissemination of such information.\n- (3)  An  order  under  this  rule  may  be  issued  in  relation  to  a  specific  part  of  the  computer resources of any website, mobile based application or both, as the case may be, if such specific part is in the nature of an intermediary:\n\nProvided that where such order is issued, an entity may be required to comply with all or any of the obligations mentions under rule 4, in relation to the specific part of its computer resource which is in the nature of an intermediary.\n\n- 7.  Non-observance  of  Rules.Where  an  intermediary  fails  to  observe  these  rules,  the provisions  of  sub-section  (1)  of  section  79  of  the  Act  shall  not  be  applicable  to  such intermediary and the intermediary shall be liable for punishment under any law for the time being in force including the provisions of the Act and the Indian Penal Code.\n\n## PART III\n\n## CODE OF ETHICS AND PROCEDURE AND SAFEGUARDS IN RELATION TO DIGITALMEDIA\n\n- 8. Application of this Part.(1) The rules made under this Part shall apply to the following persons or entities, namely: -\n- (a) publishers of news and current affairs content;\n- (b) publishers of online curated content; and\n\nshall be administered by the Ministry of Information and Broadcasting, Government of India, which shall be referred to in this Part as the 'Ministry':\n\nProvided  that the  rules  made  under  this  Part  shall  apply  to  intermediaries  for  the purposes of rules 15 and 16;\n\n- (2) the rules made under this Part shall apply to the publishers, where, -\n- (a) such publisher operates in the territory of India; or\n- (b) such  publisher  conducts  systematic  business  activity  of  making  its  content available in India.\n\nExplanation .-For the purposes of this rule, -\n\n- (a) a  publisher  shall  be  deemed  to  operate  in  the  territory  of  India  where  such publisher has a physical presence in the territory of India;\n- (b) ' systematic activity ' shall mean any structured or organised activity that involves an element of planning, method, continuity or persistence.\n- (3) The rules made under this Part shall be in addition to and not in derogation of the provisions of  any  other  law  for  the  time  being  in  force  and  any  remedies  available  under  such  laws including the Information Technology (Procedure and Safeguards for Blocking of Access of Information by the Public) Rules, 2009.\n- 9.  Observance  and  adherence  to  the  Code.(1)  A  publisher  referred  to  in  rule  8  shall observe and adhere to the Code of Ethics laid down in the Appendix annexed to these rules.\n- (2) Notwithstanding anything contained in these rules, a publisher referred to in rule 8 who contravenes any law for the time being in force, shall also be liable for consequential action as provided in such law which has so been contravened.\n- (3) For ensuring observance and adherence to the Code of Ethics by publishers operating in the territory of India, and for addressing the grievances made in relation to publishers under this Part, there shall be a three-tier structure as under -\n- (a) Level I - Self-regulation by the publishers;\n- (b) Level II - Self-regulation by the self-regulating bodies of the publishers;\n- (c) Level III - Oversight mechanism by the Central Government.\n\n## CHAPTER I\n\n## GRIEVANCE REDRESSAL MECHANISM\n\n- 10. Furnishing and processing of grievance.(1) Any person having a grievance regarding content published by a publisher in relation to the Code of Ethics may furnish his grievance on the grievance mechanism established by the publisher under rule 11.\n- (2) The publisher shall generate and issue an acknowledgement of the grievance for the benefit of the complainant within twenty-four hours of it being furnished for information and record.\n- (3) The manner of grievance redressal shall have the following arrangement-\n- (a) the publisher shall address the grievance and inform the complainant of its decision within fifteen days of the registration of the grievance;\n- (b) if the decision of the publisher is not communicated to the complainant within the stipulated fifteen days, the grievance shall be escalated to the level of the selfregulating body of which such publisher is a member.\n- (c) where the complainant is not satisfied with the decision of the publisher, it may prefer to appeal to the self-regulating body of which such publisher is a member within fifteen days of receiving such a decision.\n- (d) the self-regulating body shall address the grievance referred to in clauses (b) and (c), and convey its decision in the form of a guidance or advisory to the publisher, and inform the complainant of such decision within a period of fifteen days.\n- (e) where the complainant is not satisfied with the decision of the self-regulating body, it  may,  within  fifteen  days  of  such  decision,  prefer  an  appeal  to  the  Oversight Mechanism referred to in rule 13 for resolution.\n\n## CHAPTER II\n\n## SELF REGULATING MECHANISM - LEVEL I\n\n- 11. Self-Regulating mechanism at Level I.(1) The publisher shall be the Level I of the selfregulating mechanism.\n- (2) A publisher shall -\n- (a) establish a grievance redressal mechanism and shall appoint a Grievance Officer based in India, who shall be responsible for the redressal of grievances received by him;\n- (b) display the contact details  related  to  its  grievance  redressal  mechanism  and  the name and contact details of its Grievance Officer at an appropriate place on its website or interface, as the case may be;\n- (c) ensure that the Grievance Officer takes a decision on every grievance received by it  within fifteen days, and communicate the same to the complainant within the specified time:\n- (d) be a member of a self-regulating body as referred to in rule 12 and abide by its terms and conditions.\n- (3) The Grievance Officer shall, -\n- (a) be the contact point for receiving any grievance relating to Code of Ethics;\n- (b) act as the nodal point for interaction with the complainant, the self-regulating body and the Ministry.\n\n(4) Online curated content shall be classified by the publisher of such content into the categories referred  to  in  the Schedule ,  having  regard  to  the  context,  theme,  tone,  impact  and  target audience of such content, with the relevant rating for such categories based on an assessment of the relevant content descriptors in the manner specified in the said Schedule .\n\n- (5) Every publisher of online curated content shall display the rating of any online curated content and an explanation of the relevant content descriptors, prominently to its users at an appropriate place, as the case may be, in a manner that ensures that such users are aware of this information before accessing such content.\n\n## CHAPTER III\n\n## SELF REGULATING MECHANISM - LEVEL II\n\n- 12. Self-regulating body.(1) There may be one or more self-regulatory bodies of publishers, being an independent body constituted by publishers or their associations.\n- (2) The self-regulatory body referred to in sub-rule (1) shall be headed by a retired judge of the Supreme Court, a High Court, or an independent eminent person from the field of media, broadcasting, entertainment, child rights, human rights or such other relevant field, and have\n\nother  members,  not  exceeding  six,  being  experts  from  the  field  of  media,  broadcasting, entertainment, child rights, human rights and such other relevant fields.\n\n- (3) The self-regulating body shall, after its constitution in accordance with sub-rule (2), register itself with the Ministry within a period of thirty days from the date of notification of these rules, and where a self-regulating body is constituted after such period, within thirty days from the date of its constitution:\n\nProvided that before grant of registration to the self-regulating body, the Ministry shall satisfy itself that the self-regulating body has been constituted in accordance with sub-rule (2) and has agreed to perform the functions laid down in sub-rules (4) and (5).\n\n- (4) The self-regulating body shall perform the following functions, namely: -\n- (a) oversee and ensure the alignment and adherence by the publisher to the Code of Ethics;\n- (b) provide guidance to publishers on various aspects of the Code of Ethics;\n- (c) address grievances which have not been resolved by publishers within the specified period of fifteen days;\n- (d) hear appeals filed by the complainant against the decision of publishers;\n- (e) issue such guidance or advisories to such publishers as specified in sub-rule (5) for ensuring compliance to the Code of Ethics.\n- (5) The self-regulating body while disposing a grievance or an appeal referred to it in sub-rule\n- (4) may issue following guidance or advisories to the publishers as under, namely: -\n- (a) warning, censuring, admonishing or reprimanding the publisher; or\n- (b) requiring an apology by the publisher; or\n- (c) requiring the publisher to include a warning card or a disclaimer; or\n- (d) in case of online curated content, direct the publisher to, -\n- (i) reclassify ratings of relevant content;\n- (ii) make appropriate modification in the content descriptor, age classification and access control measures;\n- (iii) edit synopsis of relevant content; or\n- (e) in case of any content where it is satisfied that there is a need for taking action to delete or modify the content for preventing incitement to the commission of a cognizable  offence  relating  to  public  order,  or  in  relation  to  the  reasons enumerated in sub-section (1) of section 69A of the Act, refer such content to the Ministry for consideration by the Oversight Mechanism referred to in rule 13 for appropriate action.\n- (6) Where the self-regulating body is of the opinion that there is no violation of the Code of Ethics, it shall convey such decision to the complainant and such entity.\n- (7) Where a publisher fails to comply with the guidance or advisories of the self-regulating body within the time specified in such guidance or advisory, the self-regulating body shall refer\n\nthe matter to the Oversight Mechanism referred to in rule 13 within fifteen days of expiry of the specified date.\n\n## CHAPTER IV\n\n## OVERSIGHT MECHANISM - LEVEL III\n\n- 13. Oversight mechanism.(1) The Ministry shall co-ordinate and facilitate the adherence to the Code of Ethics by publishers and self regulating bodies, develop an Oversight Mechanism, and perform the following functions, namely: -\n- (a) publish a charter for self regulating bodies, including Codes of Practices for such bodies;\n- (b) establish an Inter-Departmental Committee for hearing grievances;\n- (c) refer to the Inter-Departmental Committee grievances arising out of the decision of the self-regulating body under rule 12, or where no decision has been taken by the self-regulating body within the specified time period, or such other complaints or references relating to violation of Code of Ethics as it may consider necessary;\n- (d) issue appropriate guidance and advisories to publishers;\n- (e) issue orders and directions to the publishers for maintenance and adherence to the Code of Ethics.\n- (2) The Ministry shall appoint an officer of the Ministry not below the rank of a Joint Secretary to the Government of India, as the ' Authorised Officer ', for the purposes of issuing directions under rules 15 or 16, as the case may be.\n- 14. Inter-Departmental Committee.(1) The Ministry shall constitute an InterDepartmental  Committee,  called  the  Committee,  consisting  of  representatives  from  the Ministry  of  Information  and  Broadcasting,  Ministry  of  Women  and  Child  Development, Ministry  of  Law  and  Justice,  Ministry  of  Home  Affairs,  Ministry  of  Electronics  and Information Technology, Ministry of External Affairs, Ministry of Defence, and such other Ministries and Organisations, including domain experts, that it may decide to include in the Committee:\n\nProvided that the Authorised Officer designated under sub-rule (2) of rule 13 shall be the Chairperson of such Committee.\n\n- (2)  The  Committee  shall  meet  periodically  and  hear  the  following  complaints  regarding violation or contravention of the Code of Ethics by the entities referred to in Rule 8-\n- (a) arising out of the grievances in respect of the decisions taken at the Level I or II, including the cases where no such decision is taken within the time specified in the grievance redressal mechanism; or\n- (b) referred to it by the Ministry.\n- (3) Any complaint referred to the Committee, whether arising out of the grievances or referred to it by the Ministry, shall be in writing and may be sent either by mail or fax or by e-mail signed  with  electronic  signature  of  the  authorised  representative  of  the  entity  referring  the grievance, and the Committee shall ensure that such reference is assigned a number which is recorded along with the date and time of its receipt.\n- (4) The Ministry shall make all reasonable efforts to identify the entity referred to in Rule 8 which has created, published or hosted the content or part thereof, and  where it is able to identify such entity, it shall issue a duly signed notice to such entity to appear and submit their reply and clarifications, if any, before the Committee.\n- (5)  In  the  hearing,  the  Committee  shall  examine  complaints  or  grievances,  and  may  either accept or allow such complaint or grievance, and make the following recommendations to the Ministry, namely: -\n- (a) warning, censuring, admonishing or reprimanding such entity; or\n- (b) requiring an apology by such entity; or\n- (c) requiring such entity to include a warning card or a disclaimer; or\n- (d) in case of online curated content, direct a publisher to -\n- (i) reclassify ratings of relevant content; or\n- (ii) edit synopsis of relevant content; or\n- (iii) make appropriate modification in the content descriptor, age classification and parental or access control;\n- (e) delete  or  modify  content  for  preventing  incitement  to  the  commission  of  a cognisable offence relating to public order;\n- (f) in case of content where the Committee is satisfied that there is a need for taking action in relation to the reasons enumerated in sub-section (1) of section 69A of the Act, it may recommend such action.\n- (6) The Ministry may, after taking into consideration the recommendations of the Committee, issue appropriate orders and directions for compliance by the publisher:\n\nProvided  that no  such  order  shall  be  issued  without  the  approval  of  the  Secretary, Ministry of Information and Broadcasting, Government of India (hereinafter referred to as the 'Secretary, Ministry of Information and Broadcasting').\n\n- 15. Procedure for issuing of direction.(1)  In  respect of recommendations referred to in clauses (e) and (f) of sub-rule (5) of rule 14, the Authorised Officer shall place the matter for consideration  before  the    Secretary,  Ministry  of  Information  and  Broadcasting  for  taking appropriate decision.\n- (2) The Authorised Officer shall, on approval of the decision by the Secretary, Ministry of Information  and  Broadcasting,  direct  the  publisher,  any  agency  of  the  Government  or  any intermediary,  as  the  case  may  be  to  delete  or  modify  or  block  the  relevant  content  and information generated, transmitted, received, stored or hosted in their computer resource for public access within the time limit specified in the direction:\n\nProvided that in case the recommendation of the Authorised Officer is not approved by the Secretary, Ministry of Information and Broadcasting, the Authorised Officer shall convey the same to the Committee.\n\n- (3) A direction under this rule may be issued only in respect of a specific piece of content or an enumerated list of content, as the case may be, and shall not require any entity to cease its operations.\n- 16. Blocking of information in case of emergency.(1) Notwithstanding anything contained in rules 14 and 15, the Authorised Officer, in any case of emergency nature, for which no delay is acceptable, shall examine the relevant content and consider whether it is within the grounds referred to in sub-section (1) of section 69A of the Act and it is necessary or expedient and justifiable to block such information or part thereof and submit a specific recommendation in writing to the Secretary, Ministry of Information and Broadcasting.\n- (2) In case of emergency nature, the Secretary, Ministry of Information and Broadcasting may, if he is satisfied that it is necessary or expedient and justifiable for blocking for public access of any information or part thereof through any computer resource and after recording reasons in writing, as an interim measure issue such directions as he may consider necessary to such identified  or  identifiable  persons,  publishers  or  intermediary  in  control  of  such  computer resource hosting such information or part thereof without giving him an opportunity of hearing.\n- (3)  The  Authorised  Officer,  at  the  earliest  but  not  later  than  forty-eight  hours  of  issue  of direction under sub-rule (2), shall bring the request before the Committee for its consideration and recommendation.\n- (4)  On  receipt  of  recommendations  of  the  Committee  under  sub-rule  (3),  the  Secretary, Ministry of Information and Broadcasting, shall pass the final order as regard to approval of such request and in case the request for blocking is not approved by the Secretary, Ministry of Information and Broadcasting in his final order, the interim direction issued under sub-rule (2) shall be revoked and the person, publisher or intermediary in control of such information shall be accordingly, directed to unblock the information for public access.\n- 17. Review of directions issued.(1) The Authorised Officer shall maintain complete records of the proceedings of the Committee, including any complaints referred to the Committee, and shall also maintain records of recommendations made by the Committee and any directions issued by the Authorised Officer.\n- (2 )The Review Committee shall meet at least once in every two months and record its findings whether the directions of blocking of content or information issued under these rules are in accordance with the provisions of sub-section (1) of section 69A of the Act and if it is of the opinion that the directions are not in accordance with the said provisions, it may set aside the directions and issue order for unblocking of such content or information generated, transmitted, received, stored or hosted in a computer resource.\n\nExplanation .-For  the  purpose  of  this  rule,  ' Review  Committee '  shall  mean  the  Review Committee constituted under rule 419A of the Indian Telegraph Rules, 1951.\n\n## CHAPTER V\n\n## FURNISHING OF INFORMATION\n\n- 18. Furnishing of information.(1) A publisher of news and current affairs content and a publisher of online curated content operating in the territory of India, shall inform the Ministry about the details of its entity by furnishing information along with such documents as may be specified, for the purpose of enabling communication and coordination.\n- (2) The information referred to in sub-rule (1) shall be furnished within a period of thirty days of the publication of these rules, and where such publisher begins operation in the territory of India or comes into existence after commencement of these rules, within thirty days from the date of start of its operations in the territory of India or its coming into existence, as the case may be.\n- (3) The publisher of news and current affairs content and the publisher of online curated content shall  publish  periodic  compliance  report  every  month  mentioning  the  details  of  grievances received and action taken thereon.\n- (4) The Ministry may call for such additional information from the publisher as it may consider necessary for the implementation of this Rule.\n\n## CHAPTER VI\n\n## MISCELLANEOUS\n\n- 19. Disclosure of Information.(1) A publisher and a self-regulating body, shall make true and full disclosure of all grievances received by it, the manner in which the grievances are disposed of, the action taken on the grievance, the reply sent to the complainant, the orders or directions received by it under these rules and action taken on such orders or directions.\n- (2) The information referred to in sub-rule (1) shall be displayed publicly and updated monthly.\n- (3) Subject to any law for the time being in force, the publisher shall preserve records of content transmitted by it for a minimum period of sixty days and make it available to the self-regulating body or the Central Government, or any other Government agency, as may be requisitioned by them for implementation of these rules.\n\n## CODE OF ETHICS\n\n## I News and current affairs:\n\n- (i) Norms of Journalistic Conduct of the Press Council of India under the Press Council Act, 1978;\n- (ii) Programme Code under section 5 of the Cable Television Networks Regulation) Act, 1995;\n- (iii) Content which is prohibited under any law for the time being in force shall not be published or transmitted.\n\n## II Online curated content:\n\n## (A) General Principles:\n\n- (a) A publisher shall not transmit or publish or exhibit any content which is prohibited under any law for the time being in force or has been prohibited by any court of competent jurisdiction.\n- (b)  A  publisher  shall  take  into  consideration  the  following  factors,  when  deciding  to feature  or  transmit  or  publish  or  exhibit  any  content,  after  duly  considering  the implications  of  any  content  as  falling  under  the  following  categories,  and  shall exercise due caution and discretion in relation to the same, namely: -\n- (i) content which affects the sovereignty and integrity of India;\n- (ii) content which threatens, endangers or jeopardises the security of the State;\n- (iii) content  which  is  detrimental  to  India's  friendly  relations  with  foreign countries;\n- (iv) content which is likely to incite violence or disturb the maintenance of public order.\n- (c) A publisher shall take into consideration India's multi-racial and multi-religious context  and  exercise  due  caution  and  discretion  when  featuring  the  activities, beliefs, practices, or views of any racial or religious group.\n\n## (B) Content Classification:\n\n- (i) All  content  transmitted  or  published  or  exhibited  by  a  publisher  of  online  curated content shall be classified, based on the nature and type of content, into the following rating categories, namely: -\n- (a) Online curated content which is suitable for children as well as people of all ages shall be classified as 'U' rating;\n- (b) Online curated content which is suitable for persons aged 7 years and above, and can be viewed by a person under the age of 7 years with parental guidance, shall be classified as 'U/A 7+' rating;\n- (c) Online curated content which is suitable for persons aged 13 years and above, and can be viewed by a person under the age of 13 years with parental guidance, shall be classified as 'U/A 13+' rating;\n- (d) Online curated content which is suitable for persons aged 16 years and above, and can be viewed by a person under the age of 16 years with parental guidance, shall be classified as 'U/A 16+' rating; and\n- (e) Online curated content which is restricted to adults shall be classified as 'A' rating.\n- (ii) The Content may be classified on the basis of .-i) Themes and messages; ii) Violence; iii)  Nudity;  iv)  Sex;  v)  Language;  vi)  Drug  and  substance  abuse;  and  (vii)  Horror  as described  in  the Schedule ,  as  may  be  modified  from  time  to  time  by  the  Ministry  of Information &amp; Broadcasting.\n\n## (C) Display of Classification :\n\n- (a) The publisher of online curated content shall prominently display the classification rating  specific  to  each  content  or  programme  together  with  a  content  descriptor informing the user about the nature of the content, and advising on viewer discretion (if applicable) at the beginning of every programme enabling the user to make an informed decision, prior to watching the programme.\n- (b) The publisher of online curated content making available content that is classified as  U/A  13+  or  higher  shall  ensure  that  access  control  mechanisms,  including parental locks, are made available for such content.\n- (c) A publisher of online curated content which makes available content or programme that is classified as 'A' shall implement a reliable age verification mechanism for viewership of such content.\n- (d) A publisher of online curated content must strive to include classification rating and consumer advice for their programmes in any print, televised or online promotional or publicity material and prominently display the classification rating specific to each such content.\n- (D) Restriction of access to certain curated content by a child:\n\nEvery publisher of online curated content providing access to online curated content which has an 'A' rating shall take all efforts to restrict access to such content by a child through the implementation of appropriate access control measures.\n\n- (E) Measures  to  improve  accessibility of online curated  content by  persons  with disabilities:\n\nEvery publisher of online curated content shall, to the extent feasible, take reasonable efforts to  improve  the  accessibility  of  online  curated  content  transmitted  by  it  to  persons  with disabilities through the implementation of appropriate access services.\n\n## SCHEDULE\n\nClassification of any curated content shall be guided by the following sets of guidelines, namely:-\n\n## PART I\n\n## GENERAL GUIDELINES FOR CLASSIFICATION OF FILMS AND OTHER ENTERTAINMENT PROGRAMMES, INCLUDING WEB BASED SERIALS\n\nThere  are  general  factors  that  may  influence  a  classification  decision  at  any  level  and  in connection with any issue and the following factors are elucidated which may be read along with Part II of the Guidelines -\n\n## (a) Context:\n\nCurated content may be considered in the light of the period depicted in such content and the contemporary standards of the country and the people to which such content relates. Therefore, the context in which an issue is presented within a film or video may be given consideration.  Factors  such  as  the  setting  of  a  work  (historical,  fantasy,  realistic, contemporary etc.), the manner of presentation of the content, the apparent intention of the content, the original production date of the content, and any special merits of the work may influence the classification decision.\n\n## (b) Theme:\n\nClassification  decisions  may  take  into  the  theme  of  any  content  but  will  depend significantly on the treatment of that theme, especially the sensitivity of its presentation. The most challenging themes (for example, drug misuse, violence, pedophilia, sex, racial or communal hatred or violence etc.) are unlikely to be appropriate at the junior levels of classification.\n\n## (c) Tone and impact:\n\nCurated content may be judged in its entirety from the point of view of its overall impact. The tone of content can be an important factor in deciding the influence it may have on various groups of people. Thus, films/serials that have a stronger depiction of violence may receive a higher classification.\n\n## (d) Target audience:\n\nThe classification of any content may also depend upon the target audience of the work and the impact of the work on such audience.\n\n## PART II\n\n## ISSUE RELATED GUIDELINES\n\nThis part of the guidelines comprises the issues and concerns that apply in varying degrees to all categories of classification and elaborates the general approach that may be taken in this regard to the same. These concerns are listed in alphabetical order, and are to be read with the four General Guidelines listed in Part I -\n\n## (a) Discrimination:\n\nThe categorical classification of content shall take into account the impact of a film on matters such as caste, race, gender, religion, disability or sexuality that may arise in a wide range of works, and the classification decision will take account of the strength or impact of their inclusion.\n\n## (b) Psychotropic substances, liquor, smoking and tobacco:\n\nFilms or serials, etc. that as a whole portray misuse of psychotropic substances, liquor, smoking and tobacco would qualify for a higher category of classification.\n\n## (c) Imitable behaviour:\n\n- (1) Classification decisions may take into account any portrayal of criminal and violent behaviour with weapons.\n- (2) Portrayal of potentially dangerous  behaviour that are likely to incite the commission of any offence (including suicide, and infliction of self-harm) and that children and young  people may  potentially copy, shall receive a higher classification.\n- (3) Films or serials with song and dance scenes comprising lyrics and gestures that have sexual innuendos would receive a higher classification.\n\n## (d) Language:\n\n- (1) Language  is  of  particular  importance,  given  the  vast  linguistic  diversity  of  our country. The use of language, dialect, idioms and euphemisms vary from region to region and are culture-specific. This factor has to be taken into account during the process of classification of a work in a particular category.\n- (2) Language that people may find offensive includes the use of expletives. The extent of  offence  may  vary  according  to  age,  gender,  race,  background,  beliefs  and expectations of the target audience from the work as well as the context, region and language in which the word, expression or gesture is used.\n- (3) It is not possible to set out a comprehensive list of words, expressions or gestures that  are  acceptable  at  each  category  in  every  Indian  language.  The  advice  at different  classification  levels,  therefore,  provides  general  guidance  to  consider while judging the level of classification for content, based on this guideline.\n\n## (e) Nudity:\n\n- (1) No content that is prohibited by law at the time being in force can be published or transmitted.\n- (2) Nudity with a sexual context will receive a higher classification of 'A'.\n\n## (f) Sex:\n\nNo content that is prohibited by law at the time being in force can be published or transmitted. The classification of content in various ratings from U/A 16+ to 'A' shall depend  upon  the  portrayal  of  non-explicit  (implicit)  to  explicit  depiction  of  sexual behaviour.\n\n## (g) Violence:\n\nClassification decisions shall take account of the degree and nature of violence in a work.", "metadata": {"country": "India", "year": "2021", "legally_binding": "yes", "binding_proof": "enacted as part of law by the Ministry of Electronics and Information Technology", "date": "25/02/2021", "regulator": "Ministry of Electronics and Information Technology", "type": "law", "status": "enacted", "language": "English", "use_cases": "[1, 3, 4, 6]"}}
{"_id": "686c0906383c6b855905e7a2", "title": "THE DIGITAL PERSONAL DATA PROTECTION ACT", "source": "https://www.meity.gov.in/static/uploads/2024/06/2bf1f0e9f04e6fb4f8fef35e82c42aa5.pdf", "text": "\n## PUBLISHED  BY  AUTHORITY\n\n## MINISTRY OF LAW AND JUSTICE (Legislative Department)\n\nNew Delhi, the 11 th August, 2023/ Sravana 20 , 1945  ( Saka )\n\nThe following Act  of  Parliament  received  the  assent  of  the  President  on  the 11th August, 2023 and is hereby published for general information:-\n\n## THE DIGITAL PERSONAL DATA PROTECTION ACT, 2023\n\n(NO. 22 OF 2023)\n\n[11 th August , 2023.]\n\nAn Act to provide for the processing of digital personal data in a manner that recognises both the right of individuals to protect their personal data and the need to process such personal data for lawful purposes and for matters connected therewith or incidental thereto.\n\nBE it enacted by Parliament in the Seventy-fourth Year of the Republic of India as follows:--\n\n## CHAPTER I\n\nPRELIMINARY\n\n1. ( 1 ) This Act may be called the Digital Personal Data Protection Act, 2023.\n\n( 2 )  It shall come into force on such date as the Central Government may, by notification in the Official Gazette, appoint and different dates may be appointed for different provisions of this Act and any reference in any such provision to the commencement of this Act shall be construed as a reference to the coming into force of that provision.\n\nShort  title  and commencement.\n\nDefinitions.\n\n- 2. In this Act, unless the context otherwise requires,-\n- ( a ) 'Appellate Tribunal' means the Telecom Disputes Settlement and  Appellate Tribunal established under section 14 of the Telecom Regulatory Authority of India Act, 1997;\n- ( b ) 'automated' means any digital process capable of operating automatically in response to instructions given or otherwise for the purpose of processing data;\n- ( c ) 'Board' means the Data Protection Board of India established by the Central Government under section 18;\n- ( d ) 'certain legitimate uses' means the uses referred to in section 7;\n- ( e ) 'Chairperson' means the Chairperson of the Board;\n- ( f ) 'child' means an individual who has not completed the age of eighteen years;\n- ( g ) 'Consent Manager' means a person registered with the Board, who acts as a single point of contact to enable a Data Principal to give, manage, review and withdraw her consent through an accessible, transparent and interoperable platform;\n- ( h ) 'data' means a representation of information, facts, concepts, opinions or instructions in a manner suitable for communication, interpretation or processing by human beings or by automated means;\n- ( i ) 'Data Fiduciary' means any person who alone or in conjunction with other persons determines the purpose and means of processing of personal data;\n- ( j ) 'Data Principal' means the individual to whom the personal data relates and where such individual is-\n- ( i ) a child, includes the parents or lawful guardian of such a child;\n- ( ii ) a person with disability, includes her lawful guardian, acting on her behalf;\n- ( k ) 'Data Processor' means any person who processes personal data on behalf of a Data Fiduciary;\n- ( l ) 'Data Protection Officer' means an individual appointed by the Significant Data Fiduciary under clause ( a ) of sub-section ( 2 ) of section 10;\n- ( m ) 'digital office' means an office that adopts an online mechanism wherein the proceedings, from receipt of intimation or complaint or reference or directions or appeal, as the case may be, to the disposal thereof, are conducted in online or digital mode;\n- ( n ) 'digital personal data' means personal data in digital form;\n- ( o ) 'gain' means-\n- ( i )  a  gain  in  property  or  supply  of  services,  whether  temporary  or permanent; or\n- ( ii ) an opportunity to earn remuneration or greater remuneration or to gain a financial advantage otherwise than by way of legitimate remuneration;\n- ( p ) 'loss' means-\n- ( i )  a  loss  in  property  or  interruption  in  supply  of  services,  whether temporary or permanent; or\n- ( ii ) a loss of opportunity to earn remuneration or greater remuneration or to gain a financial advantage otherwise than by way of legitimate remuneration;\n\n24  of  1997.\n\n- ( q ) 'Member' means a Member of the Board and includes the Chairperson;\n- ( r ) 'notification' means a notification published in the Official Gazette and the expressions 'notify' and 'notified' shall be construed accordingly;\n- ( s ) 'person' includes-\n- ( i ) an individual;\n- ( ii ) a Hindu undivided family;\n- ( iii ) a company;\n- ( iv ) a firm;\n- ( v )  an  association  of  persons  or  a  body  of  individuals,  whether incorporated or not;\n\n( vi\n\n- ) the State; and\n- ( vii ) every artificial juristic person, not falling within any of the preceding sub-clauses;\n- ( t ) 'personal data' means any data about an individual who is identifiable by or in relation to such data;\n- ( u )  'personal  data  breach'  means  any  unauthorised  processing  of  personal data or accidental disclosure, acquisition, sharing, use, alteration, destruction or loss of access to personal data, that compromises the confidentiality, integrity or availability of personal data;\n- ( v ) 'prescribed' means prescribed by rules made under this Act;\n- ( w ) 'proceeding' means any action taken by the Board under the provisions of this Act;\n- ( x ) 'processing' in relation to personal data, means a wholly or partly automated operation  or  set  of  operations  performed  on  digital  personal  data,  and  includes operations such as collection, recording, organisation, structuring, storage, adaptation, retrieval, use, alignment or combination, indexing, sharing, disclosure by transmission, dissemination or otherwise making available, restriction, erasure or destruction;\n- ( y ) 'she' in relation to an individual includes the reference to such individual irrespective of gender;\n- ( z ) 'Significant Data Fiduciary' means any Data Fiduciary or class of Data Fiduciaries as may be notified by the Central Government under section 10;\n- ( za ) 'specified purpose' means the purpose mentioned in the notice given by the Data Fiduciary to the Data Principal in accordance with the provisions of this  Act and the rules made thereunder; and\n- ( zb ) 'State' means the State as defined under article 12 of the Constitution.\n- 3. Subject to the provisions of this Act, it shall-\n- ( a ) apply to the processing of digital personal data within the territory of India where the personal data is collected--\n- ( i ) in digital form; or\n- ( ii ) in non-digital form and digitised subsequently;\n- ( b ) also apply to processing of digital personal data outside the territory of India, if such processing is in connection with any activity related to offering of goods or services to Data Principals within the territory of India;\n\nApplication of Act.\n\nGrounds for processing personal  data.\n\nNotice.\n\n- ( c ) not apply to-\n- ( i ) personal data processed by an individual for any personal or domestic purpose; and\n- ( ii ) personal data that is made or caused to be made publicly available by -\n- ( A ) the Data Principal to whom such personal data relates; or\n- ( B ) any other person who is under an obligation under any law for the  time  being  in  force  in  India  to  make  such  personal  data  publicly available.\n\n## Illustration.\n\nX, an individual, while blogging her views, has publicly made available her personal data on social media. In such case, the provisions of this Act shall not apply.\n\n## CHAPTER II\n\nOBLIGATIONS OF DATA FIDUCIARY\n\n- 4. ( 1 ) A person may process the personal data of a Data Principal only in accordance with the provisions of this Act and for a lawful purpose,-\n- ( a ) for which the Data Principal has given her consent; or\n- ( b ) for certain legitimate uses.\n- ( 2 ) For the purposes of this section, the expression 'lawful purpose' means any purpose which is not expressly forbidden by law.\n- 5. ( 1 ) Every request made to a Data Principal under section 6 for consent shall be accompanied or preceded by a notice given by the Data Fiduciary to the Data Principal, informing her, -\n- ( i ) the personal data and the purpose for which the same is proposed to be processed;\n- ( ii ) the manner in which she may exercise her rights under sub-section ( 4 ) of section 6 and section 13; and\n- ( iii ) the manner in which the Data Principal may make a complaint to the Board, in such manner and as may be prescribed.\n\n## Illustration.\n\nX, an individual, opens a bank account using the mobile app or website of Y, a bank. To complete the Know-Your-Customer requirements under law for opening of bank account, X opts for processing of her personal data by Y in a live, video-based customer identification process. Y shall accompany or precede the request for the personal data with notice to X, describing the personal data and the purpose of its processing.\n\n- ( 2 ) Where a Data Principal has given her consent for the processing of her personal data before the date of commencement of this Act,-\n- ( a ) the Data Fiduciary shall, as soon as it is reasonably practicable, give to the Data Principal a notice informing her,--\n- ( i ) the  personal  data  and  the  purpose  for  which  the  same  has  been processed;\n- ( ii ) the manner in which she may exercise her rights under sub-section ( 4 ) of section 6 and section 13; and\n- ( iii ) the manner in which the Data Principal may make a complaint to the Board,\n\nin such manner and as may be prescribed.\n\n( b ) the Data Fiduciary may continue to process the personal data until and unless the Data Principal withdraws her consent.\n\n## Illustration.\n\nX, an individual, gave her consent to the processing of her personal data for an online shopping app or website operated by Y, an e-commerce service provider, before the commencement of this Act. Upon commencement of the Act, Y shall, as soon as practicable, give through email, in-app notification or other effective method information to X, describing the personal data and the purpose of its processing.\n\n- ( 3 ) The Data Fiduciary shall give the Data Principal the option to access the contents of the notice referred to in sub-sections ( 1 ) and ( 2 ) in English or any language specified in the Eighth Schedule to the Constitution.\n- 6. ( 1 )  The  consent  given  by  the  Data  Principal  shall  be  free,  specific,  informed, unconditional and unambiguous with a clear affirmative action, and shall signify an agreement to the processing of her personal data for the specified purpose and be limited to such personal data as is necessary for such specified purpose.\n\n## Illustration.\n\nX, an individual, downloads Y, a telemedicine app. Y requests the consent of X for ( i ) the processing of her personal data for making available telemedicine services, and ( ii ) accessing her mobile phone contact list, and X signifies her consent to both. Since phone contact list is not necessary for making available telemedicine services, her consent shall be limited to the processing of her personal data for making available telemedicine services.\n\n- ( 2 )  Any part of consent referred in sub-section ( 1 ) which constitutes an infringement of the provisions of this  Act or the rules made thereunder or any other law for the time being in force shall be invalid to the extent of such infringement.\n\n## Illustration.\n\nX, an individual, buys an insurance policy using the mobile app or website of Y , an insurer. She gives to Y her consent for ( i ) the processing of her personal data by Y for the purpose of issuing the policy, and ( ii ) waiving her right to file a complaint to the Data Protection Board of India. Part ( ii ) of the consent , relating to waiver of her right to file a complaint, shall be invalid.\n\n- ( 3 )  Every request for consent under the provisions of this Act or the rules made thereunder shall be presented to the Data Principal in a clear and plain language, giving her the  option  to  access  such  request  in  English  or  any  language  specified  in  the  Eighth Schedule to the Constitution and providing the contact details of a Data Protection Officer, where applicable, or of any other person authorised by the Data Fiduciary to respond to any communication from the Data Principal for the purpose of exercise of  her rights under the provisions of this Act.\n- ( 4 ) Where consent given by the Data Principal is the basis of processing of personal data, such Data Principal shall have the right to withdraw her consent at any time, with the ease of doing so being comparable to the ease with which such consent was given.\n- ( 5 ) The consequences of the withdrawal referred to in sub-section ( 4 ) shall be borne by the Data Principal, and such withdrawal shall not affect the legality of processing of the personal data based on consent before its withdrawal.\n\n## Illustration.\n\n- X, an individual, is the user of an online shopping app or website operated by Y , an e-commerce service provider. X consents to the processing of her personal data by Y for the purpose of fulfilling her supply order and places an order for supply of a good while making payment for the same. If X withdraws her consent, Y may stop enabling X to use the app or website for placing orders, but may not stop the processing for supply of the goods already ordered and paid for by X.\n\n( 6 ) If a Data Principal withdraws her consent to the processing of personal data under sub-section ( 5 ), the Data Fiduciary shall, within a reasonable time, cease and cause its Data Processors to  cease  processing  the  personal  data  of  such  Data  Principal  unless  such processing without her consent is required or authorised under the provisions of this Act or the rules made thereunder or any other law for the time being in force in India.\n\nConsent.\n\n## Illustration.\n\n- X, a telecom service provider, enters into a contract with Y , a Data Processor, for emailing telephone bills to the customers of X. Z, a customer of X, who had earlier given her consent to X for the processing of her personal data for emailing of bills, downloads the mobile app of X and opts to receive bills only on the app. X shall itself cease, and shall cause Y to cease, the processing of the personal data of Z for emailing bills.\n- ( 7 ) The Data Principal may give, manage, review or withdraw her consent to the Data Fiduciary through a Consent Manager.\n- ( 8 ) The Consent Manager shall be accountable to the Data Principal and shall act on her behalf in such manner and subject to such obligations as may be prescribed.\n- ( 9 ) Every Consent Manager shall be registered with the Board in such manner and subject to such technical, operational, financial and other conditions as may be prescribed.\n- ( 10 )  Where a consent given by the Data Principal is the basis of processing of personal data and a question arises in this regard in a proceeding, the Data Fiduciary shall be obliged to prove that a notice was given by her to the Data Principal and consent was given by such Data Principal to the Data Fiduciary in accordance with the provisions of this Act and the rules made thereunder.\n- 7. A Data Fiduciary may process personal data of a Data Principal for any of following uses, namely:Certain legitimate  uses.\n- ( a )  for  the  specified  purpose  for  which  the  Data  Principal  has  voluntarily provided her personal data to the Data Fiduciary, and in respect of which she has not indicated to the Data Fiduciary that she does not consent to the use of her personal data.\n\n## Illustrations.\n\n- ( I ) X, an individual, makes a purchase at Y, a pharmacy. She voluntarily provides Y her personal data and requests Y to acknowledge receipt of the payment made for the purchase by sending a message to her mobile phone. Y may process the personal data of X for the purpose of sending the receipt.\n- ( II ) X, an individual, electronically messages Y, a real estate broker, requesting Y to help identify a suitable rented accommodation for her and shares her personal data for this purpose. Y may process her personal data to identify and intimate to her the details of accommodation available on rent. Subsequently, X informs Y that X no longer needs help from Y. Y shall cease to process the personal data of X;\n- ( b ) for the State and any of its instrumentalities to provide or issue to the Data Principal  such  subsidy,  benefit,  service,  certificate,  licence  or  permit  as  may  be prescribed, where--\n- ( i ) she has previously consented to the processing of her personal data by the State or any of its instrumentalities for any subsidy, benefit, service, certificate, licence or permit; or\n- ( ii ) such personal data is available in digital form in, or in non-digital form and digitised subsequently from, any database, register, book or other document which is maintained by the State or any of its instrumentalities and is notified by the Central Government,\n\nsubject to standards followed for processing being in accordance with the policy issued by the Central Government or any law for the time being in force for governance of personal data.\n\n## Illustration.\n\n- X. a pregnant woman, enrols herself on an app or website to avail of government's maternity benefits programme, while consenting to provide her personal data for the purpose of availing of such benefits. Government may process the personal data of X processing to determine her eligibility to receive any other prescribed benefit from the government;\n\n53  of  2005.\n\n- ( c ) for the performance by the State or any of its instrumentalities of any function under any law for the time being in force in India or in the interest of sovereignty and integrity of India or security of the State;\n- ( d ) for fulfilling any obligation under any law for the time being in force in India on any person to disclose any information to the State or any of its instrumentalities, subject  to  such  processing  being  in  accordance  with  the  provisions  regarding disclosure of such information in any other law for the time being in force;\n- ( e ) for compliance with any judgment or decree or order issued under any law for the time being in force in India, or any judgment or order relating to claims of a contractual or civil nature under any law for the time being in force outside India;\n- ( f )  for  responding to a medical emergency involving a threat to the life or immediate threat to the health of the Data Principal or any other individual;\n- ( g ) for taking measures to provide medical treatment or health services to any individual during an epidemic, outbreak of disease, or any other threat to public health;\n- ( h ) for taking measures to ensure safety of, or provide assistance or services to , any individual during any disaster, or any breakdown of public order.\n- Explanation.For the purposes of this clause, the expression 'disaster' shall have the same meaning as assigned to it in clause ( d ) of section 2 of the Disaster Management Act, 2005; or\n- ( i ) for the purposes of employment or those related to safeguarding the employer from loss or liability, such as prevention of corporate espionage, maintenance of confidentiality of trade secrets, intellectual property, classified information or provision of any service or benefit sought by a Data Principal who is an employee.\n- 8. ( 1 )  A Data Fiduciary shall, irrespective of any agreement to the contrary or failure of a Data Principal to carry out the duties provided under this  Act, be responsible for complying with the provisions of this Act and the rules made thereunder in respect of any processing undertaken by it or on its behalf by a Data Processor.\n- ( 2 )  A Data Fiduciary may engage, appoint, use or otherwise involve a Data Processor to  process  personal  data  on  its  behalf  for  any  activity  related  to  offering  of  goods  or services to Data Principals only under a valid contract.\n- ( 3 ) Where personal data processed by a Data Fiduciary is likely to be-\n- ( a ) used to make a decision that affects the Data Principal; or\n- ( b ) disclosed to another Data Fiduciary,\n\nthe  Data  Fiduciary  processing  such  personal  data  shall  ensure  its  completeness, accuracy and consistency.\n\n- ( 4 )  A Data Fiduciary shall implement appropriate technical and organisational measures to ensure effective observance of  the provisions of this Act and the rules made thereunder.\n- ( 5 )  A Data Fiduciary shall protect personal data in its possession or under its control, including in respect of any processing undertaken by it or on its behalf by a Data Processor, by taking reasonable security safeguards to prevent personal data breach.\n- ( 6 ) In the event of a personal data breach, the Data Fiduciary shall give the Board and each affected Data Principal, intimation of such breach in such form and manner as may be prescribed.\n- ( 7 )  A Data Fiduciary shall, unless retention is necessary for compliance with any law for the time being in force,-\n- ( a ) erase personal data, upon the Data Principal withdrawing her consent or as\n\nGeneral obligations  of Data Fiduciary.\n\nProcessing  of personal  data of  children.\n\nAdditional obligations  of Significant Data Fiduciary.\n\nsoon as it  is  reasonable  to  assume  that  the  specified  purpose  is  no  longer  being served, whichever is earlier; and\n\n- ( b ) cause its Data Processor to erase any personal data that was made available by the Data Fiduciary for processing to such Data Processor.\n\n## Illustrations.\n\n- ( I ) X, an individual, registers herself on an online marketplace operated by Y, an e-commerce service provider. X gives her consent to Y for the processing of her personal data for selling her used car. The online marketplace helps conclude the sale. Y shall no longer retain her personal data.\n- ( II ) X, an individual, decides to close her savings account with Y , a bank. Y is required by law applicable to banks to maintain the record of the identity of its clients for a period of ten years beyond closing of accounts. Since retention is necessary for compliance with law, Y shall retain X's personal data for the said period.\n- ( 8 ) The purpose referred to in clause ( a ) of sub-section ( 7 ) shall be deemed to no longer be served, if the Data Principal does not--\n- ( a ) approach the Data Fiduciary for the performance of the specified purpose; and\n- ( b ) exercise any of her rights in relation to such processing,\n\nfor such time period as may be prescribed, and different time periods may be prescribed for different classes of Data Fiduciaries and for different purposes.\n\n- ( 9 )  A Data Fiduciary shall publish, in such manner as may be prescribed, the business contact information of a Data Protection Officer, if applicable, or a person who is able to answer on behalf of the Data Fiduciary, the questions, if any, raised by the Data Principal about the processing of her personal data.\n- ( 10 ) A Data Fiduciary shall establish an effective mechanism to redress the grievances of Data Principals.\n- ( 11 ) For the purposes of this section, it is hereby clarified that a Data Principal shall be considered as not having approached the Data Fiduciary for the performance of the specified purpose, in any period during which she has not initiated contact with the Data Fiduciary for such performance, in person or by way of communication in electronic or physical form.\n- 9. ( 1 ) The Data Fiduciary shall, before processing any personal data of a child or a person with disability who has a lawful guardian obtain verifiable consent of the parent of such child or the lawful guardian, as the case may be, in such manner as may be prescribed.\n- Explanation. -For the purpose of this sub-section, the expression 'consent of the parent' includes the consent of lawful guardian, wherever applicable.\n- ( 2 ) A Data Fiduciary shall not undertake such processing of personal data that is likely to cause any detrimental effect on the well-being of a child.\n- ( 3 )  A Data Fiduciary shall not undertake tracking or behavioural monitoring of children or targeted advertising directed at children.\n- ( 4 ) The provisions of sub-sections ( 1 ) and ( 3 ) shall not be applicable to processing of personal data of a child by such classes of Data Fiduciaries or for such purposes, and subject to such conditions, as may be prescribed.\n- ( 5 ) The Central Government may, if satisfied that a Data Fiduciary has ensured that its processing of personal data of children is done in a manner that is verifiably safe, notify for such processing by such Data Fiduciary the age above which that Data Fiduciary shall be exempt from the applicability of all or any of the obligations under sub-sections ( 1 ) and ( 3 ) in respect of processing by that Data Fiduciary as the notification may specify.\n- 10. ( 1 )  The Central Government may notify any Data Fiduciary or class of Data Fiduciaries as Significant Data Fiduciary, on the basis of an assessment of such relevant factors as it may determine, including-\n\n- ( a ) the volume and sensitivity of personal data processed;\n- ( b ) risk to the rights of  Data Principal;\n- ( c ) potential impact on the sovereignty and integrity of India;\n- ( d ) risk to electoral democracy;\n- ( e ) security of the State; and\n- ( f ) public order.\n- ( 2 ) The Significant Data Fiduciary shall-\n- ( a ) appoint a Data Protection Officer who shall-\n- ( i ) represent the Significant Data Fiduciary under the provisions of this Act;\n- ( ii ) be based in India;\n- ( iii )  be an individual responsible to the Board of Directors or similar governing body of the Significant Data Fiduciary; and\n- ( iv ) be the point of contact for the grievance redressal mechanism under the provisions of this Act;\n- ( b )  appoint  an  independent  data  auditor  to  carry  out  data  audit,  who  shall evaluate the compliance of the Significant Data Fiduciary in accordance with the provisions of this Act; and\n- ( c ) undertake the following other measures, namely:-\n- ( i ) periodic Data Protection Impact Assessment, which shall be a process comprising a description of the rights of Data Principals and the purpose of processing of their personal data, assessment and management of the risk to the rights of the Data Principals, and such other matters regarding such process as may be prescribed;\n- ( ii ) periodic audit; and\n- ( iii ) such other measures, consistent with the provisions of this Act, as may be prescribed.\n\n## CHAPTER III\n\nRIGHTS AND DUTIES OF DATA PRINCIPAL\n\n- 11. ( 1 ) The Data Principal shall have the right to obtain from the Data Fiduciary to whom she has previously given consent, including consent as referred to in clause ( a ) of section 7 (hereinafter referred to as the said Data Fiduciary), for processing of personal data, upon making to it a request in such manner as may be prescribed,-\n- ( a ) a summary of personal data which is being processed by such Data Fiduciary and the processing activities undertaken by that Data Fiduciary with respect to such personal data;\n- ( b ) the identities of all other Data Fiduciaries and Data Processors with whom the personal data has been shared by such Data Fiduciary, along with a description of the personal data so shared; and\n- ( c ) any other information related to the personal data of such Data Principal and its processing, as may be prescribed.\n- ( 2 ) Nothing contained in clause ( b ) or clause ( c ) of sub-section ( 1 ) shall apply in respect of the sharing of any personal data by the said Data Fiduciary with any other Data Fiduciary authorised by law to obtain such personal data, where such sharing is pursuant\n\nRight  to access information about  personal data.\n\nRight  to correction  and erasure  of personal  data.\n\nRight  of grievance redressal.\n\nRight  to nominate.\n\nDuties  of  Data Principal.\n\nto a request made in writing by such other Data Fiduciary for the purpose of prevention or detection or investigation of offences or cyber incidents, or for prosecution or punishment of offences.\n\n- 12. ( 1 ) A Data Principal shall have the right to correction, completion, updating and erasure of her personal data for the processing of which she has previously given consent, including consent as referred to in clause ( a ) of section 7, in accordance with any requirement or procedure under any law for the time being in force.\n- ( 2 ) A Data Fiduciary shall, upon receiving a request for correction, completion or updating from a Data Principal,-\n- ( a ) correct the inaccurate or misleading personal data;\n- ( b ) complete the incomplete personal data; and\n- ( c ) update the personal data.\n- ( 3 ) A Data Principal shall make a request in such manner as may be prescribed to the Data Fiduciary for erasure of her personal data, and upon receipt of such a request, the Data Fiduciary shall erase her personal data unless retention of the same is necessary for the specified purpose or for compliance with any law for the time being in force.\n- 13. ( 1 ) A Data Principal shall have the right to have readily available means of grievance redressal provided by a Data Fiduciary or Consent Manager in respect of any act or omission of such Data Fiduciary or Consent Manager regarding the performance of its obligations in relation to the personal data of such Data Principal or the exercise of her rights under the provisions of this Act and the rules made thereunder.\n- ( 2 ) The Data Fiduciary or Consent Manager shall respond to any grievances referred to in sub-section ( 1 ) within such period as may be prescribed from the date of its receipt for all or any class of Data Fiduciaries.\n- ( 3 )  The Data Principal shall exhaust the opportunity of redressing her grievance under this section before approaching the Board.\n- 14. ( 1 ) A Data Principal shall have the right to nominate, in such manner as may be prescribed, any other individual, who shall, in the event of death or incapacity of the Data Principal, exercise the rights of the Data Principal in accordance with the provisions of this Act and the rules made thereunder.\n- ( 2 ) For the purposes of this section, the expression 'incapacity' means inability to exercise the rights of the Data Principal under the provisions of this Act or the rules made thereunder due to unsoundness of mind or infirmity of  body.\n- 15. A Data Principal shall perform the following duties, namely:-\n- ( a ) comply with the provisions of all applicable laws for the time being in force while exercising rights under the provisions of this Act;\n- ( b ) to ensure not to impersonate another person while providing her personal data for a specified purpose;\n- ( c )  to  ensure  not  to  suppress  any  material information while providing her personal data for any document, unique identifier, proof of identity or proof of address issued by the State or any of its instrumentalities;\n- ( d ) to ensure not to register a false or frivolous grievance or complaint with a Data Fiduciary or the Board; and\n- ( e ) to furnish only such information as is verifiably authentic, while exercising the right to correction or erasure under the provisions of this Act or the rules made thereunder.\n\n31  of  2016.\n\n## CHAPTER IV\n\n## SPECIAL PROVISIONS\n\n- 16. ( 1 ) The Central Government may, by notification, restrict the transfer of personal data by a Data Fiduciary for processing to such country or territory outside India as may be so notified.\n- ( 2 ) Nothing contained in this section shall restrict the applicability of any law for the time being in force in India that provides for a higher degree of protection for or restriction on transfer of personal data by a Data Fiduciary outside India in relation to any personal data or Data Fiduciary or class thereof.\n- 17. ( 1 ) The provisions of Chapter II, except sub-sections ( 1 ) and ( 5 ) of section 8, and those of Chapter III and section 16 shall not apply where-\n- ( a ) the processing of personal data is necessary for enforcing any legal right or claim;\n- ( b ) the processing of personal data by any court or tribunal or any other body in India which is entrusted by law with the performance of any judicial or quasi-judicial or regulatory or supervisory function, where such processing is necessary for the performance of such function;\n- ( c )  personal  data  is  processed  in  the  interest  of  prevention,  detection, investigation or prosecution of any offence or contravention of any law for the time being in force in India;\n- ( d ) personal data of Data Principals not within the territory of India is processed pursuant to any contract entered into with any person outside the territory of India by any person based in India;\n- ( e ) the processing is necessary for a scheme of compromise or arrangement or merger or amalgamation of two or more companies or a reconstruction by way of demerger or otherwise of a company, or transfer of undertaking of one or more company to another company, or involving division of one or more companies, approved by a court or tribunal or other authority competent to do so by any law for the time being in force; and\n- ( f ) the processing is for the purpose of ascertaining the financial information and assets and liabilities of any person who has defaulted in payment due on account of a loan or advance taken from a financial institution, subject to such processing being in accordance with the provisions regarding disclosure of information or data in any other law for the time being in force.\n- Explanation.For the purposes of this clause, the expressions 'default' and 'financial  institution'  shall  have  the  meanings  respectively  assigned  to  them  in sub-sections ( 12 ) and ( 14 ) of section 3 of the Insolvency and Bankruptcy Code, 2016.\n\n## Illustration.\n\nX, an individual, takes a loan from Y, a bank.  X defaults in paying her monthly loan repayment instalment on the date on which it falls due. Y may process the personal data of X for ascertaining her financial information and assets and liabilities.\n\n- ( 2 ) The provisions of this Act shall not apply in respect of the processing of personal data-\n\n( a ) by such instrumentality of the State as the Central Government may notify, in the interests of sovereignty and integrity of India, security of the State, friendly relations with foreign States, maintenance of public order or preventing incitement to any cognizable offence relating to any of these, and the processing by the Central Government of any personal data that such instrumentality may furnish to it; and\n\nProcessing  of personal  data outside  India.\n\nExemptions.\n\nEstablishment of  Board.\n\nComposition and qualifications for appointment of Chairperson and  Members.\n\nSalary, allowances payable  to  and term  of office.\n\n- ( b ) necessary for research, archiving or statistical purposes if the personal data is not to be used to take any decision specific to a Data Principal and such processing is carried on in accordance with such standards as may be prescribed.\n- ( 3 ) The Central Government may, having regard to the volume and nature of personal data processed, notify certain Data Fiduciaries or class of Data Fiduciaries, including startups, as  Data  Fiduciaries  to  whom  the  provisions  of  section  5,  sub-sections  ( 3 )  and  ( 7 )  of section 8 and sections 10 and 11 shall not apply.\n\nExplanation.For the purposes of this sub-section, the term 'startup' means a private limited company or a partnership firm or a limited liability partnership incorporated in India, which is eligible to be and is recognised as such in accordance with the criteria and process notified by the department to which matters relating to startups are allocated in the Central Government.\n\n- ( 4 ) In respect of processing by the State or any instrumentality of the State, the provisions of sub-section ( 7 ) of section 8 and sub-section ( 3 ) of section 12 and, where such processing is for a purpose that does not include making of a decision that affects the Data Principal, sub-section ( 2 ) of section 12 shall not apply.\n- ( 5 )  The  Central  Government  may,  before  expiry  of  five  years  from  the  date  of commencement of this Act, by notification, declare that any provision of this Act shall not apply to such Data Fiduciary or classes of Data Fiduciaries for such period as may be specified in the notification.\n\n## CHAPTER V\n\nDATA PROTECTION BOARD OF INDIA\n\n- 18. ( 1 ) With effect from such date as the Central Government may, by notification, appoint, there shall be established, for the purposes of this Act, a Board to be called the Data Protection Board of India.\n- ( 2 ) The Board shall be a body corporate by the name aforesaid, having perpetual succession and a common seal, with power, subject to the provisions of this Act, to acquire, hold and dispose of property, both movable and immovable, and to contract and shall, by the said name, sue or be sued.\n- ( 3 ) The headquarters of the Board shall be at such place as the Central Government may notify.\n- 19. ( 1 ) The Board shall consist of a Chairperson and such number of other Members as the Central Government may notify.\n- ( 2 ) The Chairperson and other Members shall be appointed by the Central Government in such manner as may be prescribed.\n- ( 3 ) The Chairperson and other Members shall be a person of ability, integrity and standing who possesses special knowledge or practical experience in the fields of data governance, administration or implementation of laws related to social or consumer protection, dispute resolution, information and communication technology, digital economy, law, regulation or techno-regulation, or in any other field which in the opinion of the Central Government may be useful to the Board, and at least one among them shall be an expert in the field of law.\n- 20. ( 1 )  The  salary,  allowances  and  other  terms  and  conditions  of  service  of  the Chairperson and other Members shall be such as may be prescribed, and shall not be varied to their disadvantage after their appointment.\n- ( 2 ) The Chairperson and other Members shall hold office for a term of two years and shall be eligible for re-appointment.\n\n45  of  1860.\n\n- 21. ( 1 ) A  person  shall  be  disqualified  for  being  appointed  and  continued  as  the Chairperson or a Member, if she-\n- ( a ) has been adjudged as an insolvent;\n- ( b ) has been convicted of an offence, which in the opinion of the Central Government, involves moral turpitude;\n- ( c ) has become physically or mentally incapable of acting as a Member;\n- ( d ) has acquired such financial or other interest, as is likely to affect prejudicially her functions as a Member; or\n- ( e ) has so abused her position as to render her continuance in office prejudicial to the public interest.\n- ( 2 ) The Chairperson or Member shall not be removed from her office by the Central Government unless she has been given an opportunity of being heard in the matter.\n- 22. ( 1 ) The Chairperson or any other Member may give notice in writing to the Central Government of resigning from her office, and such resignation shall be effective from the date on which the Central Government permits her to relinquish office, or upon expiry of a period of three months from the date of receipt of such notice, or upon a duly appointed successor entering upon her office, or upon the expiry of the term of her office, whichever is earliest.\n- ( 2 ) A vacancy caused by the resignation or removal or death of the Chairperson or any other Member, or otherwise, shall be filled by fresh appointment in accordance with the provisions of this Act.\n- ( 3 ) The Chairperson and any other Member shall not, for a period of one year from the date on which they cease to hold such office, except with the previous approval of the Central  Government, accept any employment, and shall also disclose to the Central Government any subsequent acceptance of employment with any Data Fiduciary against whom proceedings were initiated by or before such Chairperson or other Member.\n- 23. ( 1 )  The  Board  shall  observe  such  procedure  in  regard  to  the  holding  of  and transaction of business at its meetings, including by digital means, and authenticate its orders, directions and instruments in such manner as may be prescribed.\n- ( 2 ) No act or proceeding of the Board shall be invalid merely by reason of-\n- ( a ) any vacancy in or any defect in the constitution of the Board;\n- ( b ) any defect in the appointment of a person acting as the Chairperson or other Member of the Board; or\n- ( c ) any irregularity in the procedure of the Board, which does not affect the merits of the case.\n- ( 3 ) When the Chairperson is unable to discharge her functions owing to absence, illness or any other cause, the senior-most Member shall discharge the functions of the Chairperson until the date on which the Chairperson resumes her duties.\n- 24. The Board may, with previous approval of the Central Government, appoint such officers and employees as it may deem necessary for the efficient discharge of its functions under the provisions of this Act, on such terms and conditions of appointment and service as may be prescribed.\n\nOfficers  and employees  of Board.\n\n- 25. The Chairperson, Members, officers and employees of the Board shall be deemed, when acting or purporting to act in pursuance of provisions of this Act, to be public Members and\n- servants within the meaning of section 21 of the Indian Penal Code.\n\nofficers  to  be public servants.\n\nDisqualifications for appointment and continuation as Chairperson and  Members of  Board.\n\nResignation by  Members and filling  of vacancy.\n\nProceedings of  Board.\n\nPowers of Chairperson.\n\nPowers and functions  of Board.\n\nProcedure  to be followed by Board.\n\n- 26. The Chairperson shall exercise the following powers, namely:-\n- ( a ) general superintendence and giving direction in respect of all administrative matters of the Board;\n- ( b ) authorise any officer of the Board to scrutinise any intimation, complaint, reference or correspondence addressed to the Board; and\n- ( c ) authorise performance of any of the functions of the Board and conduct any of its proceedings, by an individual Member or groups of Members and to allocate proceedings among them.\n\n## CHAPTER VI\n\nPOWERS, FUNCTIONS AND PROCEDURE TO BE FOLLOWED BY BOARD\n\n- 27. ( 1 ) The Board shall exercise and perform the following powers and functions, namely:-\n- ( a ) on receipt of an intimation of personal data breach under sub-section ( 6 ) of section 8, to direct any urgent remedial or mitigation measures in the event of a personal data breach, and to inquire into such personal data breach and impose penalty as provided in this Act;\n- ( b ) on a complaint made by a Data Principal in respect of a personal data breach or a breach in observance by a Data Fiduciary of its obligations in relation to her personal data or the exercise of her rights under the provisions of this Act, or on a reference made to it by the Central Government or a State Government, or in compliance of the directions of any court, to inquire into such breach and impose penalty as provided in this Act;\n- ( c ) on a complaint made by a Data Principal in respect of a breach in observance by a Consent Manager of its obligations in relation to her personal data, to inquire into such breach and impose penalty as provided in this Act;\n- ( d ) on receipt of an intimation of breach of any condition of registration of a Consent Manager, to inquire into such breach and impose penalty as provided in this Act; and\n- ( e ) on a reference made by the Central Government in respect of the breach in observance of the provisions of sub-section ( 2 ) of section 37 by an intermediary, to inquire into such breach and impose penalty as provided in this Act.\n- ( 2 ) The Board may, for the effective discharge of its functions under the provisions of this  Act, after giving the person concerned an opportunity of being heard and after recording reasons in writing, issue such directions as it may consider necessary to such person, who shall be bound to comply with the same.\n- ( 3 ) The Board may, on a representation made to it by a person affected by a direction issued under sub-section ( 1 )  or  sub-section ( 2 ),  or  on  a  reference made by the Central Government, modify, suspend, withdraw or cancel such direction and, while doing so, impose such conditions as it may deem fit, subject to which the modification, suspension, withdrawal or cancellation shall have effect.\n- 28. ( 1 ) The Board shall function as an independent body and shall, as far as practicable, function as a digital office, with the receipt of complaints and the allocation, hearing and pronouncement of decisions in respect of the same being digital by design, and adopt such techno-legal measures as may be prescribed.\n- ( 2 ) The Board may, on receipt of an intimation or complaint or reference or directions as referred to in sub-section ( 1 ) of section 27, take action in accordance with the provisions of this Act and the rules made thereunder.\n\n5  of  1908.\n\n- ( 3 ) The Board shall determine whether there are sufficient grounds to proceed with an inquiry.\n- ( 4 ) In case the Board determines that there are insufficient grounds, it may, for reasons to be recorded in writing, close the proceedings.\n- ( 5 ) In case the Board determines that there are sufficient grounds to proceed with inquiry, it may, for reasons to be recorded in writing, inquire into the affairs of any person for ascertaining whether such person is complying with or has complied with the provisions of this Act.\n- ( 6 ) The Board shall conduct such inquiry following the principles of natural justice and shall record reasons for its actions during the course of such inquiry.\n- ( 7 ) For the purposes of discharging its functions under this Act, the Board shall have the same powers as are vested in a civil court under the Code of Civil Procedure, 1908, in respect of matters relating to-\n- ( a ) summoning and enforcing the attendance of any person and examining her on oath;\n- ( b ) receiving evidence of affidavit requiring the discovery and production of documents;\n- ( c )  inspecting any data, book, document, register, books of account or any other document; and\n- ( d ) such other matters as may be prescribed.\n- ( 8 ) The Board or its officers shall not prevent access to any premises or take into custody any equipment or any item that may adversely affect the day-to-day functioning of a person.\n- ( 9 ) The Board may require the services of any police officer or any officer of the Central Government or a State Government to assist it for the purposes of this section and it shall be the duty of every such officer to comply with such requisition.\n- ( 10 ) During the course of the inquiry, if the Board considers it necessary, it may for reasons to be recorded in writing, issue interim orders after giving the person concerned an opportunity of being heard.\n- ( 11 ) On completion of the inquiry and after giving the person concerned an opportunity of  being  heard,  the  Board  may  for  reasons  to  be  recorded  in  writing,  either  close  the proceedings or proceed in accordance with section 33.\n- ( 12 ) At any stage after receipt of a complaint, if the Board is of the opinion that the complaint is false or frivolous, it may issue a warning or impose costs on the complainant.\n\n## CHAPTER VII\n\nAPPEAL AND ALTERNATE DISPUTE RESOLUTION\n\n- 29. ( 1 ) Any person aggrieved by an order or direction made by the Board under this Act may prefer an appeal before the Appellate Tribunal.\n- ( 2 ) Every appeal under sub-section ( 1 ) shall be filed within a period of sixty days from the date of receipt of the order or direction appealed against and it shall be in such form and manner and shall be accompanied by such fee as may be prescribed.\n- ( 3 ) The Appellate Tribunal may entertain an appeal after the expiry of the period specified in sub-section ( 2 ), if it is satisfied that there was sufficient cause for not preferring the appeal within that period.\n- ( 4 ) On receipt of an appeal under sub-section ( 1 ), the Appellate Tribunal may, after giving the parties to the appeal, an opportunity of being heard, pass such orders thereon as it thinks fit, confirming, modifying or setting aside the order appealed against.\n\nAppeal  to Appellate Tribunal.\n\nOrders passed by Appellate Tribunal  to  be executable  as decree.\n\nAlternate dispute resolution.\n\nVoluntary undertaking.\n\nPenalties.\n\n- ( 5 ) The Appellate Tribunal shall send a copy of every order made by it to the Board and to the parties to the appeal.\n- ( 6 ) The appeal filed before the Appellate Tribunal under sub-section ( 1 ) shall be dealt with by it as expeditiously as possible and endeavour shall be made by it to dispose of the appeal finally within six months from the date on which the appeal is presented to it.\n- ( 7 )  Where any appeal under sub-section ( 6 )  could  not  be  disposed  of  within  the period of six months, the Appellate Tribunal shall record its reasons in writing for not disposing of the appeal within that period.\n- ( 8 ) Without prejudice to the provisions of section 14A and section 16 of the Telecom Regulatory Authority of India Act, 1997, the Appellate Tribunal shall deal with an appeal under this section in accordance with such procedure as may be prescribed.\n- ( 9 ) Where an appeal is filed against the orders of the Appellate Tribunal under this Act, the provisions of section 18 of the Telecom Regulatory Authority of India Act, 1997 shall apply.\n- ( 10 ) In respect of appeals filed under the provisions of this Act, the  Appellate Tribunal shall, as far as practicable, function as a digital office, with the receipt of appeal, hearing and pronouncement of decisions in respect of the same being digital by design.\n- 30. ( 1 ) An order passed by the Appellate Tribunal under this Act shall be executable by it as a decree of civil court, and for this purpose, the Appellate Tribunal shall have all the powers of a civil court.\n- ( 2 ) Notwithstanding anything contained in sub-section ( 1 ), the Appellate Tribunal may transmit any order made by it to a civil court having local jurisdiction and such civil court shall execute the order as if it were a decree made by that court.\n- 31. If the Board is of the opinion that any complaint may be resolved by mediation, it may direct the parties concerned to attempt resolution of the dispute through such mediation by such mediator as the parties may mutually agree upon, or as provided for under any law for the time being in force in India.\n- 32. ( 1 ) The Board may accept a voluntary undertaking in respect of any matter related to observance of the provisions of this Act from any person at any stage of a proceeding under section 28.\n- ( 2 )  The  voluntary  undertaking  referred  to  in  sub-section  ( 1 )  may  include  an undertaking to take such action within such time as may be determined by the Board, or refrain from taking such action, and or publicising such undertaking.\n- ( 3 ) The Board may, after accepting the voluntary undertaking and with the consent of the person who gave the voluntary undertaking vary the terms included in the voluntary undertaking.\n- ( 4 ) The acceptance of the voluntary undertaking by the Board shall constitute a bar on proceedings under the provisions of this Act as regards the contents of the voluntary undertaking, except in cases covered by sub-section ( 5 ).\n- ( 5 ) Where a person fails to adhere to any term of the voluntary undertaking accepted by the Board, such breach shall be deemed to be breach of the provisions of this Act and the Board may, after giving such person an opportunity of being heard, proceed in accordance with the provisions of section 33.\n\n## CHAPTER VIII\n\nPENALTIES AND ADJUDICATION\n\n- 33. ( 1 ) If the Board determines on conclusion of an inquiry that breach of the provisions of this Act or the rules made thereunder by a person is significant, it may, after giving the\n\n24  of  1997.\n\n24  of  1997.\n\nperson an opportunity of being heard, impose such monetary penalty specified in the Schedule.\n\n- ( 2 )  While  determining  the  amount  of  monetary  penalty  to  be  imposed  under sub-section ( 1 ), the Board shall have regard to the following matters, namely:-\n- ( a ) the nature, gravity and duration of the breach;\n- ( b ) the type and nature of the personal data affected by the breach;\n- ( c ) repetitive nature of the breach;\n- ( d ) whether the person, as a result of the breach, has realised a gain or avoided any loss;\n- ( e ) whether the person took any action to mitigate the effects and consequences of the breach, and the timeliness and effectiveness of such action;\n- ( f ) whether the monetary penalty to be imposed is proportionate and effective, having regard to the need to secure observance of and deter breach of the provisions of this Act; and\n\n( g ) the likely impact of the imposition of the monetary penalty on the person.\n\n- 34. All sums realised by way of penalties imposed by the Board under this Act, shall be credited to the Consolidated Fund of India.\n\n## CHAPTER IX\n\n## MISCELLANEOUS\n\n- 35. No suit,  prosecution  or  other  legal  proceedings  shall  lie  against  the  Central Government, the Board, its Chairperson and any Member, officer or employee thereof for anything which is done or intended to be done in good faith under the provisions of this Act or the rules made thereunder.\n- 36. The Central Government may, for the purposes of this Act, require the Board and any Data Fiduciary or intermediary to furnish such information as it may call for.\n- 37. ( 1 ) The Central Government or any of its officers specially authorised by it in this behalf may, upon receipt of a reference in writing from the Board that-\n- ( a ) intimates the imposition of monetary penalty by the Board on a Data Fiduciary in two or more instances; and\n- ( b ) advises, in the interests of the general public, the blocking for access by the public to any information generated, transmitted, received, stored or hosted, in any computer resource that enables such Data Fiduciary to carry on any activity relating to offering of goods or services to Data Principals within the territory of India,\n\nafter giving an opportunity of being heard to that Data Fiduciary, on being satisfied that it is necessary or expedient so to do, in the interests of the general public, for reasons to be recorded in writing, by order, direct any agency of the Central Government or any intermediary to block for access by the public or cause to be blocked for access by the public any such information.\n\n- ( 2 ) Every intermediary who receives a direction issued under sub-section ( 1 ) shall be bound to comply with the same.\n- ( 3 ) For  the  purposes  of  this  section,  the  expressions  'computer  resource', 'information' and 'intermediary' shall have the meanings respectively assigned to them in the Information Technology Act, 2000.\n\nCrediting  sums realised  by way of penalties  to Consolidated Fund of India.\n\nProtection  of action  taken in  good  faith.\n\nPower to call for information.\n\nPower of Central Government to  issue directions.\n\nConsistency with  other laws.\n\nBar  of jurisdiction.\n\nPower  to make rules.\n\n- 38. ( 1 ) The provisions of this Act shall be in addition to and not in derogation of any other law for the time being in force.\n- ( 2 ) In the event of any conflict between a provision of this Act and a provision of any other law for the time being in force, the provision of this Act shall prevail to the extent of such conflict.\n- 39. No civil court shall have the jurisdiction to entertain any suit or proceeding in respect of any matter for which the Board is empowered under the provisions of this Act and no injunction shall be granted by any court or other authority in respect of any action taken or to be taken in pursuance of any power under the provisions of this Act.\n- 40. ( 1 ) The Central Government may, by notification, and subject to the condition of previous publication, make rules not inconsistent with the provisions of this Act, to carry out the purposes of this Act.\n- ( 2 ) In particular and without prejudice to the generality of the foregoing power, such rules may provide for all or any of the following matters, namely:-\n- ( a ) the manner in which the notice given by the Data Fiduciary to a Data Principal shall inform her, under sub-section ( 1 ) of section 5;\n- ( b ) the manner in which the notice given by the Data Fiduciary to a Data Principal shall inform her, under sub-section ( 2 ) of section 5;\n- ( c ) the manner of accountability and the obligations of Consent Manager under sub-section ( 8 ) of section 6;\n- ( d ) the manner of registration of Consent Manager and the conditions relating thereto, under sub-section ( 9 ) of section 6;\n- ( e ) the subsidy, benefit, service, certificate, licence or permit for the provision or issuance of which, personal data may be processed under clause ( b ) of section 7;\n- ( f ) the form and manner of intimation of personal data breach to the Board under sub-section ( 6 ) of section 8;\n- ( g ) the time period for the specified purpose to be deemed as no longer being served, under sub-section ( 8 ) of section 8;\n- ( h )  the  manner  of  publishing  the  business  contact  information  of  a  Data Protection Officer under sub-section ( 9 ) of section 8;\n- ( i )  the  manner  of  obtaining  verifiable  consent  under  sub-section  ( 1 )  of section 9;\n- ( j ) the classes of Data Fiduciaries, the purposes of processing of personal data of a child and the conditions relating thereto, under sub-section ( 4 ) of section 9;\n- ( k )  the  other  matters  comprising  the  process  of  Data  Protection  Impact Assessment under sub-clause ( i ) of clause ( c ) of sub-section ( 2 ) of section 10;\n- ( l ) the other measures that the Significant Data Fiduciary shall undertake under sub-clause ( iii ) of clause ( c ) of sub-section ( 2 ) of section 10;\n- ( m ) the manner in which a Data Principal shall make a request to the Data Fiduciary to obtain information and any other information related to the personal data of such Data Principal and its processing, under sub-section ( 1 ) of section 11;\n- ( n )  the  manner in which a Data Principal shall make a request to the Data Fiduciary for erasure of her personal data under sub-section ( 3 ) of section 12;\n- ( o ) the period within which the Data Fiduciary shall respond to any grievances under sub-section ( 2 ) of section 13;\n\n24  of  1997.\n\n- ( p ) the manner of nomination of any other individual by the Data Principal under sub-section ( 1 ) of section 14;\n- ( q ) the standards for processing the personal data for exemption under clause ( b ) of sub-section ( 2 ) of section 17;\n- ( r ) the manner of appointment of the Chairperson and other Members of the Board under sub-section ( 2 ) of section 19;\n- ( s ) the salary, allowances and other terms and conditions of services of the Chairperson and other Members of the Board under sub-section ( 1 ) of section 20;\n- ( t ) the manner of authentication of orders, directions and instruments under sub-section ( 1 ) of section 23;\n- ( u )  the  terms  and  conditions  of  appointment  and  service  of  officers  and employees of the Board under section 24;\n- ( v ) the techno-legal measures to be adopted by the Board under sub-section ( 1 ) of section 28;\n- ( w ) the other matters under clause ( d ) of sub-section ( 7 ) of section 28;\n- ( x )  the  form,  manner  and  fee  for  filing  an  appeal  under  sub-section  ( 2 )  of section 29;\n- ( y ) the procedure for dealing an appeal under sub-section ( 8 ) of section 29;\n- ( z ) any other matter which is to be or may be prescribed or in respect of which provision is to be, or may be, made by rules.\n- 41. Every rule made and every notification issued under section 16 and section 42 of this Act shall be laid, as soon as may be after it is made, before each House of Parliament, while it is in session, for a total period of thirty days which may be comprised in one session or in two or more successive sessions, and if before the expiry of the session immediately following the session or the successive sessions aforesaid, both Houses agree in making any modification in the rule or notification or both Houses agree that the rule or notification should not be made or issued, the rule or notification shall thereafter have effect only in such modified form or be of no effect, as the case may be; so, however, that any such modification or annulment shall be without prejudice to the validity of anything previously done under that rule or notification.\n- 42. ( 1 ) The Central Government may, by notification, amend the Schedule, subject to the restriction that no such notification shall have the effect of increasing any penalty specified therein to more than twice of what was specified in it when this Act was originally enacted.\n- ( 2 ) Any amendment notified under sub-section ( 1 ) shall have effect as if enacted in this Act and shall come into force on the date of the notification.\n- 43. ( 1 ) If any difficulty arises in giving effect to the provisions of this  Act, the Central Government may, by order published in the Official Gazette, make such provisions not inconsistent with the provisions of this Act as may appear to it to be necessary or expedient for removing the difficulty.\n- ( 2 ) No order as referred to in sub-section ( 1 ) shall be made after the expiry of three years from the date of commencement of this Act.\n- ( 3 ) Every order made under this section shall be laid, as soon as may be after it is made, before each House of Parliament.\n- 44. ( 1 ) In section 14 of the Telecom Regulatory Authority of India Act, 1997, in clause ( c ),  for  sub-clauses ( i )  and ( ii ),  the  following  sub-clauses  shall  be  substituted, namely:-\n\nLaying  of rules  and certain notifications.\n\nPower  to amend Schedule.\n\nPower  to remove difficulties.\n\nAmendments to  certain Acts.\n\n## THE GAZETTE OF INDIA EXTRAORDINARY\n\n| '( i ) the Appellate Tribunal under the Information Technology Act, 2000;                                                                            | 21 of 2000.   |\n|------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|\n| ( ii ) the Appellate Tribunal under the Airports Economic Regulatory Authority of India Act, 2008; and                                               | 27 of 2008.   |\n| ( iii ) the Appellate Tribunal under the Digital Personal Data Protection Act, 2023.'. ( 2 )The Information                                          | 21 of 2000.   |\n| ( a ) section 43A shall be omitted; ( b Act, 1970',                                                                                                  | 39 of 1970.   |\n| ( 3 ) In section 8 of the Right to InformationAct, 2005, in sub-section ( 1 ), for clause ( j ), the following clause shall be substituted, namely:- | 22 of 2005.   |\n\n'( j ) information which relates to personal information;'.\n\n## THE  SCHEDULE\n\n## [ See section 33 ( 1 )]\n\n| Sl.No.   | Breach of provisions of thisAct or rules madethereunder                                                                                                           | Penalty                                                                                                          |\n|----------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|\n| (1)      | (2)                                                                                                                                                               | (3)                                                                                                              |\n| 1.       | Breach in observing the obligation of Data Fiduciary to take reasonable security safeguards to prevent personal data breach under sub-section ( 5 ) of section 8. | Mayextend to two hundred and fifty crore rupees.                                                                 |\n| 2.       | Breach in observing the obligation to give the Board or affected Data Principal notice of a personal data breach under sub-section ( 6 ) of section 8.            | Mayextend to two hundred crore rupees.                                                                           |\n| 3.       | Breach in observance of additional obligations in relation to children under section 9.                                                                           | Mayextend to two hundred crore rupees.                                                                           |\n| 4.       | Breach in observance of additional obligations of Significant Data Fiduciary under section 10.                                                                    | Mayextend to one hundred and fifty crore rupees.                                                                 |\n| 5.       | Breach in observance of the duties under section 15.                                                                                                              | May extend to ten thousand rupees.                                                                               |\n| 6.       | Breach of any term of voluntary undertaking accepted by the Board under section 32.                                                                               | Up to the extent applicable for the breach in respect of which the proceedings under section 28 were instituted. |\n| 7.       | Breach of any other provision of this Act or the rules made thereunder.                                                                                           | Mayextendtofifty crore rupees.                                                                                   |\n\n----\n\nDR. REETA VASISHTA, Secretary to the Govt. of  India.\n\n&lt;unknown&gt;\n\n", "metadata": {"country": "India", "year": "2023", "legally_binding": "yes", "binding_proof": "enacted as part of law by the Ministry of Electronics and Information Technology", "date": "08/11/2023", "regulator": "Ministry of Electronics and Information Technology", "type": "law", "status": "enacted", "language": "English", "use_cases": "[1, 3]"}}
