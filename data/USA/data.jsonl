{"_id": "6867425fe42c5bd68ce39c6d", "title": "National AI Initiative Act", "source": "https://www.congress.gov/bill/116th-congress/house-bill/6216/text", "text": "  \nIntroduced in House (03/12/2020)\n\n\n116th CONGRESS\n2d Session\nH. R. 6216\n\nTo establish the National Artificial Intelligence Initiative, and for other purposes.\n\nIN THE HOUSE OF REPRESENTATIVES\nMarch 12, 2020\nMs. Johnson of Texas (for herself, Mr. Lucas, Mr. McNerney, Mr. Olson, Mr. Lipinski, and Mr. Weber of Texas) introduced the following bill; which was referred to the Committee on Science, Space, and Technology\n\nA BILL\nTo establish the National Artificial Intelligence Initiative, and for other purposes.\n\nBe it enacted by the Senate and House of Representatives of the United States of America in Congress assembled,\n\n\nSECTION 1. Short title; table of contents.\n(a) Short title.\u2014This Act may be cited as the \u201cNational Artificial Intelligence Initiative Act of 2020\u201d.\n\n(b) Table of contents.\u2014The table of contents for this Act is as follows:\n\n\nSec. 1. Short title; table of contents.\nSec. 2. Findings.\nSec. 3. Definitions.\nTITLE I\u2014NATIONAL ARTIFICIAL INTELLIGENCE INITIATIVE\n\nSec. 101. National Artificial Intelligence Initiative.\nSec. 102. National Artificial Intelligence Initiative Office.\nSec. 103. Coordination by Interagency Committee.\nSec. 104. National Artificial Intelligence Advisory Committee.\nSec. 105. National Academies artificial intelligence impact study on workforce.\nSec. 106. GAO report on computational needs.\nTITLE II\u2014NATIONAL ARTIFICIAL INTELLIGENCE RESEARCH INSTITUTES\n\nSec. 201. National Artificial Intelligence Research Institutes.\nTITLE III\u2014NATIONAL INSTITUTE OF STANDARDS AND TECHNOLOGY ARTIFICIAL INTELLIGENCE ACTIVITIES\n\nSec. 301. National Institute of Standards and Technology activities.\nTITLE IV\u2014NATIONAL SCIENCE FOUNDATION ARTIFICIAL INTELLIGENCE ACTIVITIES\n\nSec. 401. Artificial intelligence research and education.\nTITLE V\u2014DEPARTMENT OF ENERGY ARTIFICIAL INTELLIGENCE RESEARCH PROGRAM\n\nSec. 501. Department of Energy Artificial Intelligence Research Program.\n\nSEC. 2. Findings.\nCongress finds the following:\n\n(1) Artificial intelligence is a tool that has the potential to change and possibly transform every sector of the United States economy and society.\n\n(2) The Federal Government should continue to play an important role advancing research, development, standards, and education activities in artificial intelligence through coordination and collaboration between government, academia, and the private sector to leverage the intellectual, physical, and digital resources of each stakeholder.\n\n(3) The Federal Government lacks clear understanding of the capabilities of artificial intelligence and its potential to affect various social and economic sectors, including ethical concerns, national security implications, and workforce impacts.\n\n(4) Researchers from academia, Federal laboratories, and much of the private sector have limited access to many high-quality datasets, computing resources, or real-world testing environments to design and deploy safe and trustworthy artificial intelligence systems.\n\n(5) There is a lack of standards and benchmarking for artificial intelligence systems that academia and the public and private sectors can use to evaluate the performance of these systems before and after deployment.\n\n(6) Artificial intelligence is increasingly becoming a highly interdisciplinary field with expertise required from a diverse range of scientific and other scholarly disciplines that traditionally work independently and continue to face cultural and institutional barriers to large scale collaboration.\n\n(7) Current Federal investments and funding mechanisms are largely insufficient to incentivize and support the large-scale interdisciplinary and public-private collaborations that will be required to advance trustworthy artificial intelligence systems in the United States.\n\n(8) The United States education pipeline for artificial intelligence fields faces significant challenges. Not only does the artificial intelligence research field lack the gender and racial diversity of the American population as a whole, but it is failing to both retain researchers and adequately support educators to meet the demands of the next generation of students studying artificial intelligence.\n\n(9) In order to help drive forward advances in trustworthy artificial intelligence across all sectors and to the benefit of all Americans, the Federal Government must provide sufficient resources and use its convening power to facilitate the growth of artificial intelligence human capital, research, and innovation capacity in academia and other nonprofit research organizations, companies of all sizes and across all sectors, and within the Federal Government.\n\n\nSEC. 3. Definitions.\nIn this Act:\n\n(1) ADVISORY COMMITTEE.\u2014The term \u201cAdvisory Committee\u201d means the National Artificial Intelligence Advisory Committee established under section 104(a).\n\n(2) AGENCY HEAD.\u2014The term \u201cagency head\u201d means the head of any Executive agency (as defined in section 105 of title 5, United States Code) other than the Department of Defense.\n\n(3) ARTIFICIAL INTELLIGENCE.\u2014The term \u201cartificial intelligence\u201d means a machine-based system that can, for a given set of human-defined objectives, make predictions, recommendations or decisions influencing real or virtual environments. Artificial intelligence systems use machine and human-based inputs to\u2014\n\n(A) perceive real and virtual environments;\n\n(B) abstract such perceptions into models through analysis in an automated manner; and\n\n(C) use model inference to formulate options for information or action.\n\n(4) INITIATIVE.\u2014The term \u201cInitiative\u201d means the National Artificial Intelligence Initiative established under section 101(a).\n\n(5) INITIATIVE OFFICE.\u2014The term \u201cInitiative Office\u201d means the National Artificial Intelligence Initiative Office established under section 102(a).\n\n(6) INSTITUTE.\u2014The term \u201cInstitute\u201d means an Artificial Intelligence Research Institute described in section 201(b)(1).\n\n(7) INTERAGENCY COMMITTEE.\u2014The term \u201cInteragency Committee\u201d means the interagency committee established under section 103(a).\n\n(8) K-12 EDUCATION.\u2014The term \u201cK-12 education\u201d means elementary school and secondary education, as such terms are defined in section 8101 of the Elementary and Secondary Education Act of 1965 (20 U.S.C. 7801).\n\n(9) MACHINE LEARNING.\u2014The term \u201cmachine learning\u201d means an application of artificial intelligence that is characterized by providing systems the ability to automatically learn and improve on the basis of data or experience, without being explicitly programmed.\n\nTITLE I\u2014National Artificial Intelligence Initiative\n\nSEC. 101. National Artificial Intelligence Initiative.\n(a) Establishment; purposes.\u2014The President shall establish and implement an initiative to be known as the \u201cNational Artificial Intelligence Initiative\u201d. The purposes of the Initiative shall be to\u2014\n\n(1) ensure continued United States leadership in artificial intelligence research and development;\n\n(2) lead the world in the development and use of trustworthy artificial intelligence systems in the public and private sectors;\n\n(3) maximize the benefits of artificial intelligence systems for all American people; and\n\n(4) prepare the present and future United States workforce for the integration of artificial intelligence systems across all sectors of the economy and society.\n\n(b) Initiative activities.\u2014In carrying out the Initiative, the President, acting through the Initiative Office, the Interagency Committee, and agency heads as the President considers appropriate, shall carry out activities that include the following:\n\n(1) Sustained, consistent, and coordinated support for artificial intelligence research and development through grants, cooperative agreements, testbeds, and access to data and computing resources.\n\n(2) Support for the development of voluntary standards, best practices, and benchmarks for the development and use of trustworthy artificial intelligence systems.\n\n(3) Support for educational programs at all levels, in both formal and informal learning environments, to prepare the American workforce and the general public to be able to use and interact with artificial intelligence systems, as well as adapt to the potentially transformative impact of artificial intelligence on society and the economy.\n\n(4) Support for interdisciplinary research, education, and training programs for students and researchers that promote learning in the methods and systems used in artificial intelligence and foster interdisciplinary perspectives and collaborations among subject matter experts in relevant fields, including computer science, mathematics, statistics, engineering, social sciences, psychology, behavioral science, ethics, security, legal scholarship, and other disciplines that will be necessary to advance artificial intelligence research and development responsibly.\n\n(5) Support for partnerships to leverage knowledge, computing resources, access to open datasets, and other resources from industry, government, nonprofit organizations, Federal laboratories, State programs, and institutions of higher education to advance activities under the Initiative.\n\n(6) Interagency planning and coordination of Federal artificial intelligence research, development, demonstration, standards engagement, and other activities under the Initiative.\n\n(7) Outreach to diverse stakeholders, including citizen groups and industry, to ensure public input is taken into account in the activities of the Initiative.\n\n(8) Leveraging existing Federal investments to advance objectives of the Initiative.\n\n(9) Support for a network of interdisciplinary artificial intelligence research institutes, as described in section 201(b)(7)(B).\n\n(10) Support opportunities for international cooperation with strategic allies, as appropriate, on the research and development, assessment, and resources for trustworthy artificial intelligence systems and the development of voluntary consensus standards for those systems.\n\n\nSEC. 102. National Artificial Intelligence Initiative Office.\n(a) In general.\u2014The Director of the Office of Science and Technology Policy shall establish or designate, and appoint a director of, an office to be known as the \u201cNational Artificial Intelligence Initiative Office\u201d to carry out the responsibilities described in subsection (b) with respect to the Initiative. The Initiative Office shall have sufficient staff to carry out such responsibilities, including staff detailed from the Federal departments and agencies described in section 103(c).\n\n(b) Responsibilities.\u2014The Director of the Initiative Office shall\u2014\n\n(1) provide technical and administrative support to the Interagency Committee and the Advisory Committee;\n\n(2) serve as the point of contact on Federal artificial intelligence activities for Federal departments and agencies, industry, academia, nonprofit organizations, professional societies, State governments, and such other persons as the Initiative Office considers appropriate to exchange technical and programmatic information;\n\n(3) conduct regular public outreach to diverse stakeholders, including through the convening of conferences and educational events, the publication of information about significant Initiative activities on a publicly available website, and the dissemination of findings and recommendations of the Advisory Committee, as appropriate; and\n\n(4) promote access to and early adoption of the technologies, innovations, lessons learned, and expertise derived from Initiative activities to agency missions and systems across the Federal Government, and to industry, including startup companies.\n\n(c) Funding estimate.\u2014The Director of the Office of Science and Technology Policy shall develop an estimate of the funds necessary to carry out the activities of the Initiative Coordination Office, including an estimate of how much each participating Federal department and agency described in section 103(c) will contribute to such funds, and submit such estimate to Congress not later than 90 days after the enactment of this Act. The Director shall update this estimate each year based on participating agency investments in artificial intelligence.\n\n\nSEC. 103. Coordination by Interagency Committee.\n(a) Interagency committee.\u2014The Director of the Office of Science and Technology Policy, acting through the National Science and Technology Council, shall establish or designate an Interagency Committee to coordinate Federal programs and activities in support of the Initiative.\n\n(b) Co-Chairs.\u2014The Interagency Committee shall be co-chaired by the Director of the Office of Science and Technology Policy and, on an annual rotating basis, a representative from the National Institute of Standards and Technology, the National Science Foundation, or the Department of Energy, as selected by the Director of the Office of Science and Technology Policy.\n\n(c) Agency participation.\u2014The Committee shall include representatives from\u2014\n\n(1) the National Institute of Standards and Technology;\n\n(2) the National Science Foundation;\n\n(3) the Department of Energy;\n\n(4) the National Aeronautics and Space Administration;\n\n(5) the Department of Defense;\n\n(6) the Defense Advanced Research Projects Agency;\n\n(7) the Department of Commerce;\n\n(8) the Office of the Director of National Intelligence;\n\n(9) the Office of Management and Budget;\n\n(10) the Office of Science and Technology Policy;\n\n(11) the Department of Health and Human Services;\n\n(12) the Department of Education;\n\n(13) the Department of Labor;\n\n(14) the Department of the Treasury;\n\n(15) the General Services Administration;\n\n(16) the Department of Transportation;\n\n(17) the Department of State;\n\n(18) the Department of Veterans Affairs; and\n\n(19) any other Federal agency as considered appropriate by the Director of the Office of Science and Technology Policy.\n\n(d) Responsibilities.\u2014The Interagency Committee shall\u2014\n\n(1) provide for interagency coordination of Federal artificial intelligence research, development, and demonstration activities, development of voluntary consensus standards and guidelines for research, development, testing, and adoption of ethically developed, safe, and trustworthy artificial intelligence systems, and education and training activities and programs of Federal departments and agencies undertaken pursuant to the Initiative;\n\n(2) not later than 2 years after the date of the enactment of this Act, develop a strategic plan for artificial intelligence (to be updated not less than every 3 years) that\u2014\n\n(A) establishes goals, priorities, and metrics for guiding and evaluating the Initiative\u2019s activities; and\n\n(B) describes how the agencies carrying out the Initiative will\u2014\n\n(i) determine and prioritize areas of artificial intelligence research, development, and demonstration requiring Federal Government leadership and investment;\n\n(ii) support long-term funding for interdisciplinary artificial intelligence research, development, demonstration, education and public outreach activities;\n\n(iii) support research and other activities on ethical, legal, environmental, safety, security, and other appropriate societal issues related to artificial intelligence;\n\n(iv) provide or facilitate the availability of curated, standardized, secure, representative, and privacy-protected data sets for artificial intelligence research and development;\n\n(v) provide or facilitate the necessary computing, networking, and data facilities for artificial intelligence research and development;\n\n(vi) reduce barriers to transferring artificial intelligence systems from the laboratory into application for the benefit of society and United States competitiveness;\n\n(vii) support and coordinate the network of artificial intelligence research institutes described in section 201(b)(7)(B); and\n\n(viii) in consultation with the Council of Economic Advisers, measure and track the contributions of artificial intelligence to United States economic growth and other societal indicators;\n\n(3) propose an annually coordinated interagency budget for the Initiative to the Office of Management and Budget that is intended to ensure that the balance of funding across the Initiative is sufficient to meet the goals and priorities established for the Initiative; and\n\n(4) in carrying out this section, take into consideration the recommendations of the Advisory Committee, existing reports on related topics, and the views of academic, State, industry, and other appropriate groups.\n\n(e) Annual report.\u2014For each fiscal year beginning with fiscal year 2022, not later than 90 days after submission of the President\u2019s annual budget request for such fiscal year, the Interagency Committee shall prepare and submit to the Committee on Science, Space, and Technology of the House of Representatives and the Committee on Commerce, Science, and Transportation of the Senate a report that includes\u2014\n\n(1) a summarized budget in support of the Initiative for such fiscal year and the preceding fiscal year, including a disaggregation of spending for each Federal agency participating in the Initiative and for the development and acquisition of any research facilities and instrumentation; and\n\n(2) an assessment of how Federal agencies are implementing the plan described in subsection (d)(2), and a description of those efforts.\n\n\nSEC. 104. National Artificial Intelligence Advisory Committee.\n(a) In general.\u2014The Secretary of Energy shall, in consultation with the Director of the Office of Science and Technology Policy, establish an advisory committee to be known as the \u201cNational Artificial Intelligence Advisory Committee\u201d.\n\n(b) Qualifications.\u2014The Advisory Committee shall consist of members, appointed by the Secretary of Energy, who are representing broad and interdisciplinary expertise and perspectives, including from academic institutions, companies across diverse sectors, nonprofit and civil society entities, and Federal laboratories, that are qualified to provide advice and information on science and technology research, development, ethics, standards, education, technology transfer, commercial application, security, and economic competitiveness related to artificial intelligence.\n\n(c) Membership consideration.\u2014In selecting the members of the Advisory Committee, the Secretary of Energy may seek and give consideration to recommendations from the Congress, industry, nonprofit organizations, the scientific community (including the National Academy of Sciences, scientific professional societies, and academic institutions), the defense community, and other appropriate organizations.\n\n(d) Duties.\u2014The Advisory Committee shall advise the President and the Initiative Office on matters related to the Initiative, including recommendations related to\u2014\n\n(1) the current state of United States competitiveness and leadership in artificial intelligence, including the scope and scale of United States investments in artificial intelligence research and development in the international context;\n\n(2) the progress made in implementing the Initiative, including a review of the degree to which the Initiative has achieved the goals under the metrics established by the Interagency Committee under section 103(d)(2);\n\n(3) the state of the science around artificial intelligence, including progress towards artificial general intelligence;\n\n(4) the need to update the Initiative;\n\n(5) the balance of activities and funding across the Initiative;\n\n(6) whether the strategic plan developed or updated by the Interagency Committee established under section 103(d)(2) is helping to maintain United States leadership in artificial intelligence;\n\n(7) the management, coordination, and activities of the Initiative;\n\n(8) whether ethical, legal, safety, security, and other appropriate societal issues are adequately addressed by the Initiative; and\n\n(9) opportunities for international cooperation with strategic allies on artificial intelligence research activities and standards development.\n\n(e) Reports.\u2014Not later than 1 year after the date of the enactment of this Act, and not less frequently than once every 3 years thereafter, the Advisory Committee shall submit to the President, the Committee on Science, Space, and Technology of the House of Representatives, and the Committee on Commerce, Science, and Transportation of the Senate, a report on the Advisory Committee\u2019s findings and recommendations under subsection (d).\n\n(f) Travel expenses of non-Federal members.\u2014Non-Federal members of the Advisory Committee, while attending meetings of the Advisory Committee or while otherwise serving at the request of the head of the Advisory Committee away from their homes or regular places of business, may be allowed travel expenses, including per diem in lieu of subsistence, as authorized by section 5703 of title 5, United States Code, for individuals in the Government serving without pay. Nothing in this subsection shall be construed to prohibit members of the Advisory Committee who are officers or employees of the United States from being allowed travel expenses, including per diem in lieu of subsistence, in accordance with existing law.\n\n(g) FACA exemption.\u2014The Secretary of Energy shall charter the Advisory Committee in accordance with the Federal Advisory Committee Act (5 U.S.C. App.), except that the Advisory Committee shall be exempt from section 14 of such Act.\n\n\nSEC. 105. National Academies artificial intelligence impact study on workforce.\n(a) In general.\u2014Not later than 90 days after the date of the enactment of this Act, the National Science Foundation shall enter into a contract with the National Research Council of the National Academies of Sciences, Engineering, and Medicine to conduct a study of the current and future impact of artificial intelligence on the workforce of the United States across sectors.\n\n(b) Contents.\u2014The study shall address\u2014\n\n(1) workforce impacts across sectors caused by the increased adoption of artificial intelligence, automation, and other related trends;\n\n(2) workforce needs and employment opportunities generated by the increased adoption of artificial intelligence across sectors;\n\n(3) research gaps and data needed to better understand and track both workforce impacts and workforce needs and opportunities generated by adoption of artificial intelligence systems across sectors; and\n\n(4) recommendations to address the challenges and opportunities described in paragraphs (1), (2), and (3).\n\n(c) Stakeholders.\u2014In conducting the study, the National Academies of Sciences, Engineering, and Medicine shall seek input from a wide range of stakeholders in the public and private sectors.\n\n(d) Report to Congress.\u2014The contract entered into under subsection (a) shall require the National Academies of Sciences, Engineering, and Medicine, not later than 2 years after the date of the enactment of this Act, to\u2014\n\n(1) submit to the Committee on Science, Space, and Technology of the House of Representatives and the Committee on Commerce, Science, and Transportation of the Senate a report containing the findings and recommendations of the study conducted under subsection (a); and\n\n(2) make a copy of such report available on a publicly accessible website.\n\n\nSEC. 106. GAO report on computational needs.\n(a) In general.\u2014Not later than 1 year after the date of the enactment of this Act, the Comptroller General of the United States shall conduct a study of artificial intelligence computer hardware and computing required in order to maintain U.S. leadership in artificial intelligence research and development. The Comptroller General shall\u2014\n\n(1) assess the composition of civilian computing resources supported by the Federal Government at universities and Federal Laboratories, including programs with laboratory computing, high performance computing, cloud computing, quantum computing, edge computing, and other computing resources;\n\n(2) evaluate projected needs for computing consumption and performance required by the public and private sector for the training, auditing, validation, testing, and use of artificial intelligence over the next five years; and\n\n(3) offer recommendations to meet these projected needs.\n\nTITLE II\u2014National Artificial Intelligence Research Institutes\n\nSEC. 201. National Artificial Intelligence Research Institutes.\n(a) In general.\u2014As part of the Initiative, the Director of the National Science Foundation shall establish a program to award financial assistance for the planning, establishment, and support of Institutes (as described in subsection (b)(2)) in accordance with this section.\n\n(b) Financial assistance To establish and support national artificial intelligence research institutes.\u2014\n\n(1) IN GENERAL.\u2014Under the Initiative, the Secretary of Energy, the Secretary of Commerce, the Director of the National Science Foundation, and every other agency head may award financial assistance to an eligible entity, or consortia thereof, as determined by an agency head, to establish and support an Institute.\n\n(2) ARTIFICIAL INTELLIGENCE INSTITUTES.\u2014An Institute described in this subsection is an artificial intelligence research institute that\u2014\n\n(A) is focused on\u2014\n\n(i) a particular economic or social sector, including health, education, manufacturing, agriculture, security, energy, and environment, and includes a component that addresses the ethical, societal, safety, and security implications relevant to the application of artificial intelligence in that sector; or\n\n(ii) a cross-cutting challenge for artificial intelligence systems, including trustworthiness, or foundational science;\n\n(B) requires partnership among public and private organizations, including, as appropriate, Federal agencies, research universities, community colleges, nonprofit research organizations, Federal laboratories, State, local, and tribal governments, and industry (or consortia thereof);\n\n(C) has the potential to create an innovation ecosystem, or enhance existing ecosystems, to translate Institute research into applications and products, as appropriate to the topic of each Institute;\n\n(D) supports interdisciplinary research and development across multiple institutions and organizations involved in artificial intelligence research and related disciplines, including physics, engineering, mathematical sciences, computer and information science, robotics, biological and cognitive sciences, material science, social and behavioral sciences, cybersecurity, and technology ethics;\n\n(E) supports interdisciplinary education activities, including curriculum development, research experiences, and faculty professional development across two-year, undergraduates, masters, and doctoral level programs; and\n\n(F) supports workforce development in artificial intelligence related disciplines in the United States, including broadening participation of underrepresented communities.\n\n(3) USE OF FUNDS.\u2014Financial assistance awarded under paragraph (1) may be used by an Institute for\u2014\n\n(A) managing and making available to researchers accessible, curated, standardized, secure, and privacy protected data sets from the public and private sectors for the purposes of training and testing artificial intelligence systems and for research using artificial intelligence systems, pursuant to section 301(b) and 301(c);\n\n(B) developing and managing testbeds for artificial intelligence systems, including sector-specific test beds, designed to enable users to evaluate artificial intelligence systems prior to deployment;\n\n(C) conducting research and education activities involving artificial intelligence systems to solve challenges with social, economic, health, scientific, and national security implications;\n\n(D) providing or brokering access to computing resources, networking, and data facilities for artificial intelligence research and development relevant to the Institute\u2019s research goals;\n\n(E) providing technical assistance to users, including software engineering support, for artificial intelligence research and development relevant to the Institute\u2019s research goals;\n\n(F) engaging in outreach and engagement to broaden participation in artificial intelligence research and workforce; and\n\n(G) such other activities that an agency head, whose agency\u2019s missions contribute to or are affected by artificial intelligence, considers consistent with the purposes described in section 101(a).\n\n(4) DURATION.\u2014\n\n(A) INITIAL PERIODS.\u2014An award of financial assistance under paragraph (1) shall be awarded for an initial period of 5 years.\n\n(B) EXTENSION.\u2014An established Institute may apply for, and the agency head may grant, extended funding for periods of 5 years on a merit-reviewed basis using the merit review criteria of the sponsoring agency.\n\n(5) APPLICATION FOR FINANCIAL ASSISTANCE.\u2014\n\n(A) IN GENERAL.\u2014A person or group of persons seeking financial assistance under paragraph (1) shall submit to an agency head an application at such time, in such manner, and containing such information as the agency head may require.\n\n(B) REQUIREMENTS.\u2014An application submitted under subparagraph (A) for an Institute shall, at a minimum, include the following:\n\n(i) A plan for the Institute to include\u2014\n\n(I) the proposed goals and activities of the Institute;\n\n(II) how the Institute will form partnerships with other research institutions, industry, and nonprofits to leverage expertise in artificial intelligence and access to data, including non-governmental data and computing resources;\n\n(III) how the institute will support long-term and short-term education and workforce development in artificial intelligence, including broadening participation of underrepresented communities; and\n\n(IV) a plan for how the Institute will transition from planning into operations.\n\n(ii) A description of the anticipated sources and nature of any non-Federal contributions, including privately held data sets, computing resources, and other types of in-kind support.\n\n(iii) A description of the anticipated long-term impact of such Institute.\n\n(6) COMPETITIVE, MERIT REVIEW.\u2014In awarding financial assistance under paragraph (1), the agency head shall\u2014\n\n(A) use a competitive, merit review process that includes peer review by a diverse group of individuals with relevant expertise from both the private and public sectors; and\n\n(B) ensure the focus areas of the Institute do not substantially duplicate the efforts of any other Institute.\n\n(7) COLLABORATION.\u2014\n\n(A) IN GENERAL.\u2014In awarding financial assistance under paragraph (1), an agency head may collaborate with Federal departments and agencies whose missions contribute to or are affected by artificial intelligence systems, including the agencies outlined in section 103(c).\n\n(B) COORDINATING NETWORK.\u2014The Director of the National Science Foundation shall establish a network of Institutes receiving financial assistance under this subsection, to be known as the \u201cArtificial Intelligence Leadership Network\u201d, to coordinate cross-cutting research and other activities carried out by the Institutes.\n\n(C) FUNDING.\u2014The head of an agency may request, accept, and provide funds from other Federal departments and agencies, State, United States territory, local, or tribal government agencies, private sector for-profit entities, and nonprofit entities, to be available to the extent provided by appropriations Acts, to support an Institute\u2019s activities. The head of an agency may not give any special consideration to any agency or entity in return for a donation.\n\nTITLE III\u2014National Institute of Standards and Technology Artificial Intelligence Activities\n\nSEC. 301. National Institute of Standards and Technology activities.\n(a) In general.\u2014As part of the Initiative, the Director of the National Institute of Standards and Technology shall\u2014\n\n(1) support measurement research and development of best practices and voluntary standards for trustworthy artificial intelligence systems, including for\u2014\n\n(A) privacy and security, including for datasets used to train or test artificial intelligence systems and software and hardware used in artificial intelligence systems;\n\n(B) advanced computer chips and hardware designed for artificial intelligence systems;\n\n(C) data management and techniques to increase the usability of data, including strategies to systematically clean, label, and standardize data into forms useful for training artificial intelligence systems and the use of common, open licenses;\n\n(D) safety and robustness of artificial intelligence systems, including assurance, verification, validation, security, control, and the ability for artificial intelligence systems to withstand unexpected inputs and adversarial attacks;\n\n(E) auditing mechanisms and benchmarks for accuracy, transparency, verifiability, and safety assurance for artificial intelligence systems;\n\n(F) applications of machine learning and artificial intelligence systems to improve other scientific fields and engineering; and\n\n(G) all other areas deemed by the Director to be critical to the development and deployment of trustworthy artificial intelligence;\n\n(2) produce curated, standardized, representative, secure, and privacy protected data sets for artificial intelligence research, development, and use, prioritizing data for high-value, high-risk research;\n\n(3) support one or more institutes as described in section 201(a) of this Act for the purpose of advancing the field of artificial intelligence;\n\n(4) support and strategically engage in the development of voluntary consensus standards, including international standards, through open, transparent, and consensus-based processes; and\n\n(5) enter into and perform such contracts, including cooperative research and development arrangements and grants and cooperative agreements or other transactions, as may be necessary in the conduct of the work of the National Institute of Standards and Technology and on such terms as the Director considers appropriate, in furtherance of the purposes of this Act.\n\n(b) Risk management framework.\u2014Not later than 2 years after the date of the enactment of this Act, the Director shall work to develop, and periodically update, in collaboration with other public and private sector organizations, including the National Science Foundation and the Department of Energy, a voluntary risk management framework for the trustworthiness of artificial intelligence systems. The framework shall\u2014\n\n(1) identify and provide standards, guidelines, best practices, methodologies, procedures, and processes for assessing the trustworthiness of, and mitigating risks to, artificial intelligence systems;\n\n(2) establish common definitions and characterizations for aspects and levels of trustworthiness, including explainability, transparency, safety, privacy, security, robustness, fairness, bias, ethics, validation, verification, and other properties related to artificial intelligence systems that are common across all sectors;\n\n(3) provide guidance and implementation steps for risk management of artificial intelligence systems;\n\n(4) provide sector-specific case studies of implementation of the framework;\n\n(5) align with voluntary consensus standards, including international standards, to the fullest extent possible;\n\n(6) incorporate voluntary consensus standards and industry best practices; and\n\n(7) not prescribe or otherwise require\u2014\n\n(A) the use of specific solutions; or\n\n(B) the use of specific information or communications technology products or services.\n\n(c) Data sharing best practices.\u2014Not later than 1 year after the date of enactment of this Act, the Director shall, in collaboration with other public and private sector organizations, develop guidance to facilitate the creation of voluntary data sharing arrangements between industry, federally funded research centers, and Federal agencies for the purpose of advancing artificial intelligence research and technologies, including\u2014\n\n(1) options for partnership models between government entities, industry, universities, and nonprofits that incentivize each party to share the data they collected; and\n\n(2) best practices for datasets involving human characteristics, including\u2014\n\n(A) standards for metadata that describe the properties of datasets, including\u2014\n\n(i) how the data was collected;\n\n(ii) what populations are included and excluded from the datasets; and\n\n(iii) any other properties as determined by the Director; and\n\n(B) standards for privacy and security of datasets with human characteristics.\n\n(d) Stakeholder outreach.\u2014In carrying out the activities under this subsection, the Director shall\u2014\n\n(1) solicit input from university researchers, private sector experts, relevant Federal agencies, Federal laboratories, State and local governments, civil society groups, and other relevant stakeholders;\n\n(2) solicit input from experts in relevant fields of social science, technology ethics, and law; and\n\n(3) provide opportunity for public comment on guidelines and best practices developed as part of the Initiative, as appropriate.\n\n(e) Authorization of appropriations.\u2014There are authorized to be appropriated to the National Institute of Standards and Technology to carry out this subsection\u2014\n\n(1) $64,000,000 for fiscal year 2021;\n\n(2) $70,400,000 for fiscal year 2022;\n\n(3) $77,440,000 for fiscal year 2023;\n\n(4) $85,180,000 for fiscal year 2024; and\n\n(5) $93,700,000 for fiscal year 2025.\n\nTITLE IV\u2014National Science Foundation Artificial Intelligence Activities\n\nSEC. 401. Artificial intelligence research and education.\n(a) In general.\u2014As part of the Initiative, the Director of the National Science Foundation shall fund research and education activities in artificial intelligence systems and related fields, including competitive awards or grants to institutions of higher education or eligible nonprofit organizations (or consortia thereof).\n\n(b) Uses of funds.\u2014In carrying out the activities under subsection (a), the Director of the National Science Foundation shall\u2014\n\n(1) support research, including interdisciplinary research on artificial intelligence systems and related areas;\n\n(2) support collaborations among researchers across disciplines, including between social scientists and computer and data scientists, to advance research critical to the development and deployment of trustworthy artificial intelligence systems, including support for interdisciplinary research relating advances in artificial intelligence to changes in the future workplace, in a social and economic context;\n\n(3) use the existing programs of the National Science Foundation, in collaboration with other Federal departments and agencies, as appropriate to\u2014\n\n(A) improve the teaching and learning of artificial intelligence systems at all levels of education; and\n\n(B) increase participation in artificial intelligence related fields, including by individuals identified in sections 33 and 34 of the Science and Engineering Equal Opportunity Act (42 U.S.C. 1885a, 1885b);\n\n(4) engage with institutions of higher education, research communities, industry, Federal laboratories, nonprofit organizations, State and local governments, and potential users of information produced under this section, including through the convening of workshops and conferences, to leverage the collective body of knowledge across disciplines relevant to artificial intelligence, facilitate new collaborations and partnerships, and identify emerging research needs;\n\n(5) support partnerships among institutions of higher education and industry that facilitate collaborative research, personnel exchanges, and workforce development with respect to artificial intelligence systems;\n\n(6) ensure adequate access to research and education infrastructure with respect to artificial intelligence systems, including through the development of new computing resources and partnership with the private sector for the provision of cloud-based computing services;\n\n(7) conduct prize competitions, as appropriate, pursuant to section 24 of the Stevenson-Wydler Technology Innovation Act of 1980 (15 U.S.C. 3719);\n\n(8) coordinate research efforts funded through existing programs across the directorates of the National Science Foundation;\n\n(9) provide guidance on data sharing by grantees to public and private sector organizations consistent with the standards and guidelines developed under section 301(c); and\n\n(10) evaluate opportunities for international collaboration with strategic allies on artificial intelligence research and development.\n\n(c) Artificial intelligence research grants.\u2014\n\n(1) IN GENERAL.\u2014The Director shall award grants for research on artificial intelligence systems. Research areas may include\u2014\n\n(A) artificial intelligence systems, including machine learning, computer vision, robotics, and hardware for accelerating artificial intelligence systems;\n\n(B) artificial intelligence-enabled systems;\n\n(C) fields and research areas that will contribute to the advancement of artificial intelligence systems, including information theory, causal and statistical inference, data mining, information extraction, human-robot interaction, and intelligent interfaces;\n\n(D) fields and research areas that increase understanding of human characteristics relevant to artificial intelligence systems, including computational neuroscience, reasoning and representation, speech and language, multi-agent systems, intelligent interfaces, human-artificial intelligence cooperation, and artificial intelligence-augmented human problem solving;\n\n(E) fields and research areas that increase understanding of learning, adaptability, and resilience beyond the human cognitive model, including topics in developmental biology, zoology, botany, morphological computation, and organismal systems;\n\n(F) fields and research areas that will contribute to the development and deployment of trustworthy artificial intelligence systems, including\u2014\n\n(i) algorithmic explainability;\n\n(ii) methods to assess, characterize, and reduce bias in datasets and artificial intelligence systems; and\n\n(iii) safety and robustness of artificial intelligence systems, including assurance, verification, validation, security, and control;\n\n(G) privacy and security, including for datasets used for the training and inference of artificial intelligence systems, and software and hardware used in artificial intelligence systems;\n\n(H) fields and research areas that address the application of artificial intelligence systems to scientific discovery and societal challenges;\n\n(I) societal, ethical, safety, education, workforce, and security implications of artificial intelligence systems, including social impact of artificial intelligence systems on different groups within society, especially historically marginalized groups; and\n\n(J) qualitative and quantitative forecasting of future capabilities, applications, and impacts.\n\n(2) ENGINEERING SUPPORT.\u2014In soliciting proposals for funding under this section, the Director shall permit applicants to include in their proposed budgets funding for software engineering support to assist with the proposed research.\n\n(3) ETHICS.\u2014\n\n(A) SENSE OF CONGRESS.\u2014It is the sense of Congress that\u2014\n\n(i) a number of emerging areas of research, including artificial intelligence, have potential ethical, social, safety, and security implications that might be apparent as early as the basic research stage;\n\n(ii) the incorporation of ethical, social, safety, and security considerations into the research design and review process for Federal awards may help mitigate potential harms before they happen;\n\n(iii) the National Science Foundation\u2019s intent to enter into an agreement with the National Academies of Sciences, Engineering, and Medicine to conduct a study and make recommendations with respect to governance of research in emerging technologies is a positive step toward accomplishing this goal; and\n\n(iv) the National Science Foundation should continue to work with stakeholders to understand and adopt policies that promote best practices for governance of research in emerging technologies at every stage of research.\n\n(B) ETHICS STATEMENTS.\u2014\n\n(i) IN GENERAL.\u2014Not later than 18 months after the date of enactment of this Act, the Director shall amend grant proposal instructions to include a requirement for an ethics statement to be included as part of any proposal for funding prior to making the award. Such statement shall be considered by the Director in the review of proposals, taking into consideration any relevant input from the peer-reviewers for the proposal, and shall factor into award decisions as deemed necessary by the Director.\n\n(ii) CONTENTS.\u2014Such statements may include, as appropriate\u2014\n\n(I) the potential societal benefits of the research;\n\n(II) any foreseeable or quantifiable risks to society, including how the research could enable products, technologies, or other outcomes that could intentionally or unintentionally cause significant societal harm; and\n\n(III) how technical or social solutions can mitigate such risks and, as appropriate, a plan to implement such mitigation measures.\n\n(iii) GUIDANCE.\u2014The Director shall issue clear guidance on what constitutes a foreseeable or quantifiable risk described in clause (ii)(II), and to the extent practical harmonize this policy with existing ethical policies or related requirements for human subjects.\n\n(iv) ANNUAL REPORTS.\u2014The Director shall encourage grantees to update their ethics statements as appropriate as part of the annual reports required by all grantees under the grant terms and conditions.\n\n(d) Education.\u2014\n\n(1) IN GENERAL.\u2014The Director of the National Science Foundation shall award grants for education programs at the K-12, community college, undergraduate, graduate, postdoctoral, adult learning, and retraining stages of education that\u2014\n\n(A) support the development of a diverse workforce pipeline for science and technology with respect to artificial intelligence systems;\n\n(B) increase awareness of ethical, social, safety, and security implications of artificial intelligence systems; and\n\n(C) promote the widespread understanding of artificial intelligence principles and methods to create an educated workforce and general public able to use products enabled by artificial intelligence systems and adapt to future societal and economic changes caused by artificial intelligence systems.\n\n(2) USE OF FUNDS.\u2014Grants awarded under this section for education activities referred to in paragraph (1) may be used for\u2014\n\n(A) K-12, undergraduate, and community college curriculum development and other educational tools and methods in artificial intelligence related fields;\n\n(B) curriculum development in the field of technology ethics;\n\n(C) support for informal education activities for K-12 students to engage with artificial intelligence systems;\n\n(D) efforts to achieve equitable access to K-12 artificial intelligence education for populations and geographic areas traditionally underrepresented in the artificial intelligence field;\n\n(E) training and professional development programs, including innovative pre-service and in-service programs, in artificial intelligence and related fields for K-12 teachers;\n\n(F) efforts to improve the retention rate for researchers focusing on artificial intelligence systems at institutions of higher learning and other nonprofit research institutions;\n\n(G) outreach programs to educate the general public about the uses of artificial intelligence and its societal implications;\n\n(H) assessments of activities conducted under this subsection; and\n\n(I) any other relevant activities the Director determines will accomplish the aim described in paragraph (1).\n\n(3) ARTIFICIAL INTELLIGENCE TRAINEESHIPS AND FELLOWSHIPS.\u2014\n\n(A) ARTIFICIAL INTELLIGENCE TRAINEESHIPS.\u2014\n\n(i) IN GENERAL.\u2014The Director of the National Science Foundation shall award grants to institutions of higher education to establish traineeship programs for graduate students who pursue artificial intelligence-related research leading to a masters or doctorate degree by providing funding and other assistance, and by providing graduate students opportunities for research experiences in government or industry related to the students\u2019 artificial intelligence studies.\n\n(ii) USE OF FUNDS.\u2014An institution of higher education shall use grant funds provided under clause (i) for the purposes of\u2014\n\n(I) providing traineeships to students who are pursuing research in artificial intelligence leading to a masters or doctorate degree;\n\n(II) paying tuition and fees for students receiving traineeships who are citizens, nationals, or lawfully admitted permanent resident aliens of the United States;\n\n(III) creating and requiring courses or training programs in technology ethics for students receiving traineeships;\n\n(IV) creating opportunities for research in technology ethics for students receiving traineeships;\n\n(V) establishing scientific internship programs for students receiving traineeships in artificial intelligence at for-profit institutions, nonprofit research institutions, or government laboratories; and\n\n(VI) other costs associated with the administration of the program.\n\n(B) ARTIFICIAL INTELLIGENCE FELLOWSHIPS.\u2014The Director of the National Science Foundation shall award fellowships to masters and doctoral students and postdoctoral researchers at institutions of higher education who are pursuing degrees or research in artificial intelligence and related fields, including in the field of technology ethics. In making such awards, the Director shall\u2014\n\n(i) ensure recipients of artificial intelligence fellowships are citizens, nationals, or lawfully admitted permanent resident aliens of the United States; and\n\n(ii) conduct outreach, including through formal solicitations, to solicit proposals from students and postdoctoral researchers seeking to carry out research in aspects of technology ethics with relevance to artificial intelligence systems.\n\n(e) Authorization of appropriations.\u2014There are authorized to be appropriated to the National Science Foundation to carry out this section\u2014\n\n(1) $868,000,000 for fiscal year 2021;\n\n(2) $911,400,000 for fiscal year 2022;\n\n(3) $956,970,000 for fiscal year 2023;\n\n(4) $1,004,820,000 for fiscal year 2024; and\n\n(5) $1,055,060,000 for fiscal year 2025.\n\nTITLE V\u2014Department of Energy Artificial Intelligence Research Program\n\nSEC. 501. Department of Energy Artificial Intelligence Research Program.\n(a) In general.\u2014The Secretary shall carry out a cross-cutting research and development program to advance artificial intelligence tools, systems, capabilities, and workforce needs and to improve the reliability of artificial intelligence methods and solutions relevant to the mission of the Department. In carrying out this program, the Secretary shall coordinate across all relevant offices and programs at the Department, including the Office of Science, the Office of Energy Efficiency and Renewable Energy, the Office of Nuclear Energy, the Office of Fossil Energy, the Office of Electricity, the Office of Cybersecurity, Energy Security, and Emergency Response, the Advanced Research Projects Agency-Energy, and any other relevant office determined by the Secretary.\n\n(b) Research areas.\u2014In carrying out the program under subsection (a), the Secretary shall award financial assistance to eligible entities to carry out research projects on topics including\u2014\n\n(1) the application of artificial intelligence systems to improve large-scale simulations of natural and other phenomena;\n\n(2) the study of applied mathematics, computer science, and statistics, including foundations of methods and systems of artificial intelligence, causal and statistical inference, and the development of algorithms for artificial intelligence systems;\n\n(3) the analysis of existing large-scale datasets from science and engineering experiments and simulations, including energy simulations and other priorities at the Department as determined by the Secretary using artificial intelligence tools and techniques;\n\n(4) the development of operation and control systems that enhance automated, intelligent decisionmaking capabilities;\n\n(5) the development of advanced computing hardware and computer architecture tailored to artificial intelligence systems, including the codesign of networks and computational hardware;\n\n(6) the development of standardized datasets for emerging artificial intelligence research fields and applications, including methods for addressing data scarcity; and\n\n(7) the development of trustworthy artificial intelligence systems, including\u2014\n\n(A) algorithmic explainability;\n\n(B) analytical methods for identifying and mitigating bias in artificial intelligence systems; and\n\n(C) safety and robustness, including assurance, verification, validation, security, and control.\n\n(c) Technology transfer.\u2014In carrying out the program under subsection (a), the Secretary shall support technology transfer of artificial intelligence systems for the benefit of society and United States economic competitiveness.\n\n(d) Facility use and upgrades.\u2014In carrying out the program under subsection (a), the Secretary shall\u2014\n\n(1) make available high-performance computing infrastructure at national laboratories;\n\n(2) make any upgrades necessary to enhance the use of existing computing facilities for artificial intelligence systems, including upgrades to hardware;\n\n(3) establish new computing capabilities necessary to manage data and conduct high performance computing that enables the use of artificial intelligence systems; and\n\n(4) maintain and improve, as needed, networking infrastructure, data input and output mechanisms, and data analysis, storage, and service capabilities.\n\n(e) Ethics.\u2014\n\n(1) IN GENERAL.\u2014Not later than 18 months after the date of enactment of this Act, the Secretary shall amend grant proposal instructions to include a requirement for an ethics statement to be included as part of any proposal for funding prior to making the award. Such statement shall be considered by the Secretary in the review of proposals, taking into consideration any relevant input from the peer-reviewers for the proposal, and shall factor into award decisions as deemed necessary by the Secretary. Such statements may include, as appropriate\u2014\n\n(A) the potential societal benefits of the research;\n\n(B) any foreseeable or quantifiable risks to society, including how the research could enable products, technologies, or other outcomes that could intentionally or unintentionally cause significant societal harm; and\n\n(C) how technical or social solutions can mitigate such risks and, as appropriate, a plan to implement such mitigation measures.\n\n(2) GUIDANCE.\u2014The Secretary shall issue clear guidance on what constitutes risks as described in section (1)(B), and to the extent practical harmonize this policy with existing ethical policies or related requirements for human subjects.\n\n(3) ANNUAL REPORTS.\u2014The Secretary shall encourage awardees to update their ethics statements as appropriate as part of the annual reports required by all awardees under the grant terms and conditions.\n\n(f) Risk management.\u2014The Secretary shall review agency policies for risk management in artificial intelligence related projects and issue as necessary policies and principles that are consistent with the framework developed under section 301(b).\n\n(g) Data privacy and sharing.\u2014The Secretary shall review agency policies for data sharing with other public and private sector organizations and issue as necessary policies and principles that are consistent with the standards and guidelines submitted under section 301(c). In addition, the Secretary shall establish a streamlined mechanism for approving research projects or partnerships that require sharing sensitive public or private data with the Department.\n\n(h) Partnerships with other Federal agencies.\u2014The Secretary may request, accept, and provide funds from other Federal departments and agencies, State, United States territory, local, or Tribal government agencies, private sector for-profit entities, and nonprofit entities, to be available to the extent provided by appropriations Acts, to support a research project or partnership carried out under this section. The Secretary may not give any special consideration to any agency or entity in return for a donation.\n\n(i) Stakeholder engagement.\u2014In carrying out the activities authorized in this section, the Secretary shall\u2014\n\n(1) collaborate with a range of stakeholders including small businesses, institutes of higher education, industry, and the National Laboratories;\n\n(2) leverage the collective body of knowledge from existing artificial intelligence and machine learning research; and\n\n(3) engage with other Federal agencies, research communities, and potential users of information produced under this section.\n\n(j) Authorization of appropriations.\u2014There are authorized to be appropriated to the Department to carry out this section\u2014\n\n(1) $200,000,000 for fiscal year 2021;\n\n(2) $214,000,000 for fiscal year 2022;\n\n(3) $228,980,000 for fiscal year 2023;\n\n(4) $245,000,000 for fiscal year 2024; and\n\n(5) $262,160,000 for fiscal year 2025.\n\n(k) Definitions.\u2014In this section:\n\n(1) SECRETARY.\u2014The term \u201cSecretary\u201d means the Secretary of Energy.\n\n(2) DEPARTMENT.\u2014The term \u201cDepartment\u201d means the Department of Energy.\n\n(3) NATIONAL LABORATORY.\u2014The term \u201cnational laboratory\u201d has the meaning given such term in section 2 of the Energy Policy Act of 2005 (42 U.S.C. 15801).\n\n(4) ELIGIBLE ENTITIES.\u2014The term \u201celigible entities\u201d means\u2014\n\n(A) an institution of higher education;\n\n(B) a National Laboratory;\n\n(C) a Federal research agency;\n\n(D) a State research agency;\n\n(E) a nonprofit research organization;\n\n(F) a private sector entity; or\n\n(G) a consortium of 2 or more entities described in subparagraph (A) through (F).\n\n\n\n", "metadata": {"country": "USA", "year": "2020", "legally_binding": "No", "binding_proof": "", "date": "03/12/2020", "regulator": "the Senate and House of Representatives of the United States of America in Congress assembled", "type": "Act", "status": "enacted ", "language": "EN", "use_cases": "[1,2, 3, 4, 5, 6]"}}
{"_id": "686742b2e42c5bd68ce39c6e", "title": "California Consumer Privacy Act (CCPA)", "source": "https://leginfo.legislature.ca.gov/faces/codes_displayText.xhtml?division=3.&part=4.&lawCode=CIV&title=1.81.5", "text": "  \nCivil Code - CIV\nDIVISION 3. OBLIGATIONS [1427 - 3273.69]  ( Heading of Division 3 amended by Stats. 1988, Ch. 160, Sec. 14. )\nPART 4. OBLIGATIONS ARISING FROM PARTICULAR TRANSACTIONS [1738 - 3273.69]  ( Part 4 enacted 1872. )\n\nTITLE 1.81.5. California Consumer Privacy Act of 2018 [1798.100 - 1798.199.100]  ( Title 1.81.5 added by Stats. 2018, Ch. 55, Sec. 3. )\n\n1798.100.  General Duties of Businesses that Collect Personal Information\n(a) A business that controls the collection of a consumer\u2019s personal information shall, at or before the point of collection, inform consumers of the following:\n(1) The categories of personal information to be collected and the purposes for which the categories of personal information are collected or used and whether that information is sold or shared. A business shall not collect additional categories of personal information or use personal information collected for additional purposes that are incompatible with the disclosed purpose for which the personal information was collected without providing the consumer with notice consistent with this section.\n\n(2) If the business collects sensitive personal information, the categories of sensitive personal information to be collected and the purposes for which the categories of sensitive personal information are collected or used, and whether that information is sold or shared. A business shall not collect additional categories of sensitive personal information or use sensitive personal information collected for additional purposes that are incompatible with the disclosed purpose for which the sensitive personal information was collected without providing the consumer with notice consistent with this section.\n\n(3) The length of time the business intends to retain each category of personal information, including sensitive personal information, or if that is not possible, the criteria used to determine that period provided that a business shall not retain a consumer\u2019s personal information or sensitive personal information for each disclosed purpose for which the personal information was collected for longer than is reasonably necessary for that disclosed purpose.\n\n(b) A business that, acting as a third party, controls the collection of personal information about a consumer may satisfy its obligation under subdivision (a) by providing the required information prominently and conspicuously on the homepage of its internet website. In addition, if a business acting as a third party controls the collection of personal information about a consumer on its premises, including in a vehicle, then the business shall, at or before the point of collection, inform consumers as to the categories of personal information to be collected and the purposes for which the categories of personal information are used, and whether that personal information is sold, in a clear and conspicuous manner at the location.\n(c) A business\u2019 collection, use, retention, and sharing of a consumer\u2019s personal information shall be reasonably necessary and proportionate to achieve the purposes for which the personal information was collected or processed, or for another disclosed purpose that is compatible with the context in which the personal information was collected, and not further processed in a manner that is incompatible with those purposes.\n(d) A business that collects a consumer\u2019s personal information and that sells that personal information to, or shares it with, a third party or that discloses it to a service provider or contractor for a business purpose shall enter into an agreement with the third party, service provider, or contractor, that:\n(1) Specifies that the personal information is sold or disclosed by the business only for limited and specified purposes.\n\n(2) Obligates the third party, service provider, or contractor to comply with applicable obligations under this title and obligate those persons to provide the same level of privacy protection as is required by this title.\n\n(3) Grants the business rights to take reasonable and appropriate steps to help ensure that the third party, service provider, or contractor uses the personal information transferred in a manner consistent with the business\u2019 obligations under this title.\n\n(4) Requires the third party, service provider, or contractor to notify the business if it makes a determination that it can no longer meet its obligations under this title.\n\n(5) Grants the business the right, upon notice, including under paragraph (4), to take reasonable and appropriate steps to stop and remediate unauthorized use of personal information.\n\n(e) A business that collects a consumer\u2019s personal information shall implement reasonable security procedures and practices appropriate to the nature of the personal information to protect the personal information from unauthorized or illegal access, destruction, use, modification, or disclosure in accordance with Section 1798.81.5.\n(f) Nothing in this section shall require a business to disclose trade secrets, as specified in regulations adopted pursuant to paragraph (3) of subdivision (a) of Section 1798.185.\n(Amended November 3, 2020, by initiative Proposition 24, Sec. 4. Effective December 16, 2020. Operative January 1, 2023, pursuant to Sec. 31 of Proposition 24.)\n\n1798.105.  Consumers\u2019 Right to Delete Personal Information\n(a) A consumer shall have the right to request that a business delete any personal information about the consumer which the business has collected from the consumer.\n(b) A business that collects personal information about consumers shall disclose, pursuant to Section 1798.130, the consumer\u2019s rights to request the deletion of the consumer\u2019s personal information.\n(c) (1) A business that receives a verifiable consumer request from a consumer to delete the consumer\u2019s personal information pursuant to subdivision (a) of this section shall delete the consumer\u2019s personal information from its records, notify any service providers or contractors to delete the consumer\u2019s personal information from their records, and notify all third parties to whom the business has sold or shared the personal information to delete the consumer\u2019s personal information unless this proves impossible or involves disproportionate effort.\n(2) The business may maintain a confidential record of deletion requests solely for the purpose of preventing the personal information of a consumer who has submitted a deletion request from being sold, for compliance with laws or for other purposes, solely to the extent permissible under this title.\n\n(3) A service provider or contractor shall cooperate with the business in responding to a verifiable consumer request, and at the direction of the business, shall delete, or enable the business to delete and shall notify any of its own service providers or contractors to delete personal information about the consumer collected, used, processed, or retained by the service provider or the contractor. The service provider or contractor shall notify any service providers, contractors, or third parties who may have accessed personal information from or through the service provider or contractor, unless the information was accessed at the direction of the business, to delete the consumer\u2019s personal information unless this proves impossible or involves disproportionate effort. A service provider or contractor shall not be required to comply with a deletion request submitted by the consumer directly to the service provider or contractor to the extent that the service provider or contractor has collected, used, processed, or retained the consumer\u2019s personal information in its role as a service provider or contractor to the business.\n\n(d) A business, or a service provider or contractor acting pursuant to its contract with the business, another service provider, or another contractor, shall not be required to comply with a consumer\u2019s request to delete the consumer\u2019s personal information if it is reasonably necessary for the business, service provider, or contractor to maintain the consumer\u2019s personal information in order to:\n(1) Complete the transaction for which the personal information was collected, fulfill the terms of a written warranty or product recall conducted in accordance with federal law, provide a good or service requested by the consumer, or reasonably anticipated by the consumer within the context of a business\u2019 ongoing business relationship with the consumer, or otherwise perform a contract between the business and the consumer.\n\n(2) Help to ensure security and integrity to the extent the use of the consumer\u2019s personal information is reasonably necessary and proportionate for those purposes.\n\n(3) Debug to identify and repair errors that impair existing intended functionality.\n\n(4) Exercise free speech, ensure the right of another consumer to exercise that consumer\u2019s right of free speech, or exercise another right provided for by law.\n\n(5) Comply with the California Electronic Communications Privacy Act pursuant to Chapter 3.6 (commencing with Section 1546) of Title 12 of Part 2 of the Penal Code.\n\n(6) Engage in public or peer-reviewed scientific, historical, or statistical research that conforms or adheres to all other applicable ethics and privacy laws, when the business\u2019 deletion of the information is likely to render impossible or seriously impair the ability to complete such research, if the consumer has provided informed consent.\n\n(7) To enable solely internal uses that are reasonably aligned with the expectations of the consumer based on the consumer\u2019s relationship with the business and compatible with the context in which the consumer provided the information.\n\n(8) Comply with a legal obligation.\n\n(Amended November 3, 2020, by initiative Proposition 24, Sec. 5. Effective December 16, 2020. Operative January 1, 2023, pursuant to Sec. 31 of Proposition 24.)\n\n1798.106.  Consumers\u2019 Right to Correct Inaccurate Personal Information\n(a) A consumer shall have the right to request a business that maintains inaccurate personal information about the consumer to correct that inaccurate personal information, taking into account the nature of the personal information and the purposes of the processing of the personal information.\n(b) A business that collects personal information about consumers shall disclose, pursuant to Section 1798.130, the consumer\u2019s right to request correction of inaccurate personal information.\n(c) A business that receives a verifiable consumer request to correct inaccurate personal information shall use commercially reasonable efforts to correct the inaccurate personal information as directed by the consumer, pursuant to Section 1798.130 and regulations adopted pursuant to paragraph (7) of subdivision (a) of Section 1798.185.\n(Amended by Stats. 2024, Ch. 121, Sec. 1. (AB 3286) Effective January 1, 2025.)\n\n1798.110.  Consumers\u2019 Right to Know What Personal Information is Being Collected. Right to Access Personal Information\n(a) A consumer shall have the right to request that a business that collects personal information about the consumer disclose to the consumer the following:\n(1) The categories of personal information it has collected about that consumer.\n\n(2) The categories of sources from which the personal information is collected.\n\n(3) The business or commercial purpose for collecting, selling, or sharing personal information.\n\n(4) The categories of third parties to whom the business discloses personal information.\n\n(5) The specific pieces of personal information it has collected about that consumer.\n\n(b) A business that collects personal information about a consumer shall disclose to the consumer, pursuant to subparagraph (B) of paragraph (3) of subdivision (a) of Section 1798.130, the information specified in subdivision (a) upon receipt of a verifiable consumer request from the consumer, provided that a business shall be deemed to be in compliance with paragraphs (1) to (4), inclusive, of subdivision (a) to the extent that the categories of information and the business or commercial purpose for collecting, selling, or sharing personal information it would be required to disclose to the consumer pursuant to paragraphs (1) to (4), inclusive, of subdivision (a) is the same as the information it has disclosed pursuant to paragraphs (1) to (4), inclusive, of subdivision (c).\n(c) A business that collects personal information about consumers shall disclose, pursuant to subparagraph (B) of paragraph (5) of subdivision (a) of Section 1798.130:\n(1) The categories of personal information it has collected about consumers.\n\n(2) The categories of sources from which the personal information is collected.\n\n(3) The business or commercial purpose for collecting, selling, or sharing personal information.\n\n(4) The categories of third parties to whom the business discloses personal information.\n\n(5) That a consumer has the right to request the specific pieces of personal information the business has collected about that consumer.\n\n(Amended November 3, 2020, by initiative Proposition 24, Sec. 7. Effective December 16, 2020. Operative January 1, 2023, pursuant to Sec. 31 of Proposition 24.)\n\n1798.115.  Consumers\u2019 Right to Know What Personal Information is Sold or Shared and to Whom\n(a) A consumer shall have the right to request that a business that sells or shares the consumer\u2019s personal information, or that discloses it for a business purpose, disclose to that consumer:\n(1) The categories of personal information that the business collected about the consumer.\n\n(2) The categories of personal information that the business sold or shared about the consumer and the categories of third parties to whom the personal information was sold or shared, by category or categories of personal information for each category of third parties to whom the personal information was sold or shared.\n\n(3) The categories of personal information that the business disclosed about the consumer for a business purpose and the categories of persons to whom it was disclosed for a business purpose.\n\n(b) A business that sells or shares personal information about a consumer, or that discloses a consumer\u2019s personal information for a business purpose, shall disclose, pursuant to paragraph (4) of subdivision (a) of Section 1798.130, the information specified in subdivision (a) to the consumer upon receipt of a verifiable consumer request from the consumer.\n(c) A business that sells or shares consumers\u2019 personal information, or that discloses consumers\u2019 personal information for a business purpose, shall disclose, pursuant to subparagraph (C) of paragraph (5) of subdivision (a) of Section 1798.130:\n(1) The category or categories of consumers\u2019 personal information it has sold or shared, or if the business has not sold or shared consumers\u2019 personal information, it shall disclose that fact.\n\n(2) The category or categories of consumers\u2019 personal information it has disclosed for a business purpose, or if the business has not disclosed consumers\u2019 personal information for a business purpose, it shall disclose that fact.\n\n(d) A third party shall not sell or share personal information about a consumer that has been sold to, or shared with, the third party by a business unless the consumer has received explicit notice and is provided an opportunity to exercise the right to opt-out pursuant to Section 1798.120.\n(Amended November 3, 2020, by initiative Proposition 24, Sec. 8. Effective December 16, 2020. Operative January 1, 2023, pursuant to Sec. 31 of Proposition 24.)\n\n1798.120.  Consumers\u2019 Right to Opt Out of Sale or Sharing of Personal Information\n(a) (1) A consumer shall have the right, at any time, to direct a business that sells or shares personal information about the consumer to third parties not to sell or share the consumer\u2019s personal information. This right may be referred to as the right to opt out of sale or sharing.\n(2) A business to which another business transfers the personal information of a consumer as an asset that is part of a merger, acquisition, bankruptcy, or other transaction in which the transferee assumes control of all of, or part of, the transferor shall comply with a consumer\u2019s direction to the transferor made pursuant to this subdivision.\n\n(b) A business that sells consumers\u2019 personal information to, or shares it with, third parties shall provide notice to consumers, pursuant to subdivision (a) of Section 1798.135, that this information may be sold or shared and that consumers have the \u201cright to opt out\u201d of the sale or sharing of their personal information.\n(c) Notwithstanding subdivision (a), a business shall not sell or share the personal information of consumers if the business has actual knowledge that the consumer is less than 16 years of age, unless the consumer, in the case of consumers at least 13 years of age and less than 16 years of age, or the consumer\u2019s parent or guardian, in the case of consumers who are less than 13 years of age, has affirmatively authorized the sale or sharing of the consumer\u2019s personal information. A business that willfully disregards the consumer\u2019s age shall be deemed to have had actual knowledge of the consumer\u2019s age.\n(d) A business that has received direction from a consumer not to sell or share the consumer\u2019s personal information or, in the case of a minor consumer\u2019s personal information has not received consent to sell or share the minor consumer\u2019s personal information, shall be prohibited, pursuant to paragraph (4) of subdivision (c) of Section 1798.135, from selling or sharing the consumer\u2019s personal information after its receipt of the consumer\u2019s direction, unless the consumer subsequently provides consent, for the sale or sharing of the consumer\u2019s personal information.\n(Amended by Stats. 2024, Ch. 940, Sec. 1. (AB 1824) Effective January 1, 2025.)\n\n1798.121.  Consumers\u2019 Right to Limit Use and Disclosure of Sensitive Personal Information\n(a) A consumer shall have the right, at any time, to direct a business that collects sensitive personal information about the consumer to limit its use of the consumer\u2019s sensitive personal information to that use which is necessary to perform the services or provide the goods reasonably expected by an average consumer who requests those goods or services, to perform the services set forth in paragraphs (2), (4), (5), and (8) of subdivision (e) of Section 1798.140, and as authorized by regulations adopted pursuant to subparagraph (C) of paragraph (18) of subdivision (a) of Section 1798.185. A business that uses or discloses a consumer\u2019s sensitive personal information for purposes other than those specified in this subdivision shall provide notice to consumers, pursuant to subdivision (a) of Section 1798.135, that this information may be used, or disclosed to a service provider or contractor, for additional, specified purposes and that consumers have the right to limit the use or disclosure of their sensitive personal information.\n(b) A business that has received direction from a consumer not to use or disclose the consumer\u2019s sensitive personal information, except as authorized by subdivision (a), shall be prohibited, pursuant to paragraph (4) of subdivision (c) of Section 1798.135, from using or disclosing the consumer\u2019s sensitive personal information for any other purpose after its receipt of the consumer\u2019s direction unless the consumer subsequently provides consent for the use or disclosure of the consumer\u2019s sensitive personal information for additional purposes.\n(c) A service provider or contractor that assists a business in performing the purposes authorized by subdivision (a) may not use the sensitive personal information after it has received instructions from the business and to the extent it has actual knowledge that the personal information is sensitive personal information for any other purpose. A service provider or contractor is only required to limit its use of sensitive personal information received pursuant to a written contract with the business in response to instructions from the business and only with respect to its relationship with that business.\n(d) Sensitive personal information that is collected or processed without the purpose of inferring characteristics about a consumer is not subject to this section, as further defined in regulations adopted pursuant to subparagraph (C) of paragraph (18) of subdivision (a) of Section 1798.185, and shall be treated as personal information for purposes of all other sections of this act, including Section 1798.100.\n(Amended by Stats. 2024, Ch. 121, Sec. 2. (AB 3286) Effective January 1, 2025.)\n\n1798.125.  Consumers\u2019 Right of No Retaliation Following Opt Out or Exercise of Other Rights\n(a) (1) A business shall not discriminate against a consumer because the consumer exercised any of the consumer\u2019s rights under this title, including, but not limited to, by:\n(A) Denying goods or services to the consumer.\n\n(B) Charging different prices or rates for goods or services, including through the use of discounts or other benefits or imposing penalties.\n\n(C) Providing a different level or quality of goods or services to the consumer.\n\n(D) Suggesting that the consumer will receive a different price or rate for goods or services or a different level or quality of goods or services.\n\n(E) Retaliating against an employee, applicant for employment, or independent contractor, as defined in subparagraph (A) of paragraph (2) of subdivision (m) of Section 1798.145, for exercising their rights under this title.\n\n(2) Nothing in this subdivision prohibits a business, pursuant to subdivision (b), from charging a consumer a different price or rate, or from providing a different level or quality of goods or services to the consumer, if that difference is reasonably related to the value provided to the business by the consumer\u2019s data.\n\n(3) This subdivision does not prohibit a business from offering loyalty, rewards, premium features, discounts, or club card programs consistent with this title.\n\n(b) (1) A business may offer financial incentives, including payments to consumers as compensation, for the collection of personal information, the sale or sharing of personal information, or the retention of personal information. A business may also offer a different price, rate, level, or quality of goods or services to the consumer if that price or difference is reasonably related to the value provided to the business by the consumer\u2019s data.\n(2) A business that offers any financial incentives pursuant to this subdivision, shall notify consumers of the financial incentives pursuant to Section 1798.130.\n\n(3) A business may enter a consumer into a financial incentive program only if the consumer gives the business prior opt-in consent pursuant to Section 1798.130 that clearly describes the material terms of the financial incentive program, and which may be revoked by the consumer at any time. If a consumer refuses to provide opt-in consent, then the business shall wait for at least 12 months before next requesting that the consumer provide opt-in consent, or as prescribed by regulations adopted pursuant to Section 1798.185.\n\n(4) A business shall not use financial incentive practices that are unjust, unreasonable, coercive, or usurious in nature.\n\n(Amended November 3, 2020, by initiative Proposition 24, Sec. 11. Effective December 16, 2020. Operative January 1, 2023, pursuant to Sec. 31 of Proposition 24.)\n\n1798.130.  Notice, Disclosure, Correction, and Deletion Requirements\n(a) In order to comply with Sections 1798.100, 1798.105, 1798.106, 1798.110, 1798.115, and 1798.125, a business shall, in a form that is reasonably accessible to consumers:\n(1) (A) Make available to consumers two or more designated methods for submitting requests for information required to be disclosed pursuant to Sections 1798.110 and 1798.115, or requests for deletion or correction pursuant to Sections 1798.105 and 1798.106, respectively, including, at a minimum, a toll-free telephone number. A business that operates exclusively online and has a direct relationship with a consumer from whom it collects personal information shall only be required to provide an email address for submitting requests for information required to be disclosed pursuant to Sections 1798.110 and 1798.115, or for requests for deletion or correction pursuant to Sections 1798.105 and 1798.106, respectively.\n\n(B) If the business maintains an internet website, make the internet website available to consumers to submit requests for information required to be disclosed pursuant to Sections 1798.110 and 1798.115, or requests for deletion or correction pursuant to Sections 1798.105 and 1798.106, respectively.\n\n(2) (A) Disclose and deliver the required information to a consumer free of charge, correct inaccurate personal information, or delete a consumer\u2019s personal information, based on the consumer\u2019s request, within 45 days of receiving a verifiable consumer request from the consumer. The business shall promptly take steps to determine whether the request is a verifiable consumer request, but this shall not extend the business\u2019 duty to disclose and deliver the information, to correct inaccurate personal information, or to delete personal information within 45 days of receipt of the consumer\u2019s request. The time period to provide the required information, to correct inaccurate personal information, or to delete personal information may be extended once by an additional 45 days when reasonably necessary, provided the consumer is provided notice of the extension within the first 45-day period. The disclosure of the required information shall be made in writing and delivered through the consumer\u2019s account with the business, if the consumer maintains an account with the business, or by mail or electronically at the consumer\u2019s option if the consumer does not maintain an account with the business, in a readily useable format that allows the consumer to transmit this information from one entity to another entity without hindrance. The business may require authentication of the consumer that is reasonable in light of the nature of the personal information requested, but shall not require the consumer to create an account with the business in order to make a verifiable consumer request provided that if the consumer, has an account with the business, the business may require the consumer to use that account to submit a verifiable consumer request.\n\n(B) The disclosure of the required information shall cover the 12-month period preceding the business\u2019 receipt of the verifiable consumer request provided that, upon the adoption of a regulation pursuant to paragraph (8) of subdivision (a) of Section 1798.185, a consumer may request that the business disclose the required information beyond the 12-month period, and the business shall be required to provide that information unless doing so proves impossible or would involve a disproportionate effort. A consumer\u2019s right to request required information beyond the 12-month period, and a business\u2019 obligation to provide that information, shall only apply to personal information collected on or after January 1, 2022. Nothing in this subparagraph shall require a business to keep personal information for any length of time.\n\n(3) (A) A business that receives a verifiable consumer request pursuant to Section 1798.110 or 1798.115 shall disclose any personal information it has collected about a consumer, directly or indirectly, including through or by a service provider or contractor, to the consumer. A service provider or contractor shall not be required to comply with a verifiable consumer request received directly from a consumer or a consumer\u2019s authorized agent, pursuant to Section 1798.110 or 1798.115, to the extent that the service provider or contractor has collected personal information about the consumer in its role as a service provider or contractor. A service provider or contractor shall provide assistance to a business with which it has a contractual relationship with respect to the business\u2019 response to a verifiable consumer request, including, but not limited to, by providing to the business the consumer\u2019s personal information in the service provider or contractor\u2019s possession, which the service provider or contractor obtained as a result of providing services to the business, and by correcting inaccurate information or by enabling the business to do the same. A service provider or contractor that collects personal information pursuant to a written contract with a business shall be required to assist the business through appropriate technical and organizational measures in complying with the requirements of subdivisions (d) to (f), inclusive, of Section 1798.100, taking into account the nature of the processing.\n\n(B) For purposes of subdivision (b) of Section 1798.110:\n\n(i) To identify the consumer, associate the information provided by the consumer in the verifiable consumer request to any personal information previously collected by the business about the consumer.\n\n(ii) Identify by category or categories the personal information collected about the consumer for the applicable period of time by reference to the enumerated category or categories in subdivision (c) that most closely describes the personal information collected; the categories of sources from which the consumer\u2019s personal information was collected; the business or commercial purpose for collecting, selling, or sharing the consumer\u2019s personal information; and the categories of third parties to whom the business discloses the consumer\u2019s personal information.\n\n(iii) Provide the specific pieces of personal information obtained from the consumer in a format that is easily understandable to the average consumer, and to the extent technically feasible, in a structured, commonly used, machine-readable format that may also be transmitted to another entity at the consumer\u2019s request without hindrance. \u201cSpecific pieces of information\u201d do not include data generated to help ensure security and integrity or as prescribed by regulation. Personal information is not considered to have been disclosed by a business when a consumer instructs a business to transfer the consumer\u2019s personal information from one business to another in the context of switching services.\n\n(4) For purposes of subdivision (b) of Section 1798.115:\n\n(A) Identify the consumer and associate the information provided by the consumer in the verifiable consumer request to any personal information previously collected by the business about the consumer.\n\n(B) Identify by category or categories the personal information of the consumer that the business sold or shared during the applicable period of time by reference to the enumerated category in subdivision (c) that most closely describes the personal information, and provide the categories of third parties to whom the consumer\u2019s personal information was sold or shared during the applicable period of time by reference to the enumerated category or categories in subdivision (c) that most closely describes the personal information sold or shared. The business shall disclose the information in a list that is separate from a list generated for the purposes of subparagraph (C).\n\n(C) Identify by category or categories the personal information of the consumer that the business disclosed for a business purpose during the applicable period of time by reference to the enumerated category or categories in subdivision (c) that most closely describes the personal information, and provide the categories of persons to whom the consumer\u2019s personal information was disclosed for a business purpose during the applicable period of time by reference to the enumerated category or categories in subdivision (c) that most closely describes the personal information disclosed. The business shall disclose the information in a list that is separate from a list generated for the purposes of subparagraph (B).\n\n(5) Disclose the following information in its online privacy policy or policies if the business has an online privacy policy or policies and in any California-specific description of consumers\u2019 privacy rights, or if the business does not maintain those policies, on its internet website, and update that information at least once every 12 months:\n\n(A) A description of a consumer\u2019s rights pursuant to Sections 1798.100, 1798.105, 1798.106, 1798.110, 1798.115, and 1798.125 and two or more designated methods for submitting requests, except as provided in subparagraph (A) of paragraph (1) of subdivision (a).\n\n(B) For purposes of subdivision (c) of Section 1798.110:\n\n(i) A list of the categories of personal information it has collected about consumers in the preceding 12 months by reference to the enumerated category or categories in subdivision (c) that most closely describe the personal information collected.\n\n(ii) The categories of sources from which consumers\u2019 personal information is collected.\n\n(iii) The business or commercial purpose for collecting, selling, or sharing consumers\u2019 personal information.\n\n(iv) The categories of third parties to whom the business discloses consumers\u2019 personal information.\n\n(C) For purposes of paragraphs (1) and (2) of subdivision (c) of Section 1798.115, two separate lists:\n\n(i) A list of the categories of personal information it has sold or shared about consumers in the preceding 12 months by reference to the enumerated category or categories in subdivision (c) that most closely describe the personal information sold or shared, or if the business has not sold or shared consumers\u2019 personal information in the preceding 12 months, the business shall prominently disclose that fact in its privacy policy.\n\n(ii) A list of the categories of personal information it has disclosed about consumers for a business purpose in the preceding 12 months by reference to the enumerated category in subdivision (c) that most closely describes the personal information disclosed, or if the business has not disclosed consumers\u2019 personal information for a business purpose in the preceding 12 months, the business shall disclose that fact.\n\n(6) Ensure that all individuals responsible for handling consumer inquiries about the business\u2019 privacy practices or the business\u2019 compliance with this title are informed of all requirements in Sections 1798.100, 1798.105, 1798.106, 1798.110, 1798.115, 1798.125, and this section, and how to direct consumers to exercise their rights under those sections.\n\n(7) Use any personal information collected from the consumer in connection with the business\u2019 verification of the consumer\u2019s request solely for the purposes of verification and shall not further disclose the personal information, retain it longer than necessary for purposes of verification, or use it for unrelated purposes.\n\n(b) A business is not obligated to provide the information required by Sections 1798.110 and 1798.115 to the same consumer more than twice in a 12-month period.\n(c) The categories of personal information required to be disclosed pursuant to Sections 1798.100, 1798.110, and 1798.115 shall follow the definitions of personal information and sensitive personal information in Section 1798.140 by describing the categories of personal information using the specific terms set forth in subparagraphs (A) to (K), inclusive, of paragraph (1) of subdivision (v) of Section 1798.140 and by describing the categories of sensitive personal information using the specific terms set forth in paragraphs (1) to (9), inclusive, of subdivision (ae) of Section 1798.140.\n(Amended by Stats. 2024, Ch. 121, Sec. 3. (AB 3286) Effective January 1, 2025.)\n\n1798.135.  Methods of Limiting Sale, Sharing, and Use of Personal Information and Use of Sensitive Personal Information\n(a) A business that sells or shares consumers\u2019 personal information or uses or discloses consumers\u2019 sensitive personal information for purposes other than those authorized by subdivision (a) of Section 1798.121 shall, in a form that is reasonably accessible to consumers:\n(1) Provide a clear and conspicuous link on the business\u2019 internet homepages, titled \u201cDo Not Sell or Share My Personal Information,\u201d to an internet web page that enables a consumer, or a person authorized by the consumer, to opt out of the sale or sharing of the consumer\u2019s personal information.\n\n(2) Provide a clear and conspicuous link on the business\u2019 internet homepages, titled \u201cLimit the Use of My Sensitive Personal Information,\u201d that enables a consumer, or a person authorized by the consumer, to limit the use or disclosure of the consumer\u2019s sensitive personal information to those uses authorized by subdivision (a) of Section 1798.121.\n\n(3) At the business\u2019 discretion, utilize a single, clearly labeled link on the business\u2019 internet homepages, in lieu of complying with paragraphs (1) and (2), if that link easily allows a consumer to opt out of the sale or sharing of the consumer\u2019s personal information and to limit the use or disclosure of the consumer\u2019s sensitive personal information.\n\n(4) In the event that a business responds to opt-out requests received pursuant to paragraph (1), (2), or (3) by informing the consumer of a charge for the use of any product or service, present the terms of any financial incentive offered pursuant to subdivision (b) of Section 1798.125 for the retention, use, sale, or sharing of the consumer\u2019s personal information.\n\n(b) (1) A business shall not be required to comply with subdivision (a) if the business allows consumers to opt out of the sale or sharing of their personal information and to limit the use of their sensitive personal information through an opt-out preference signal sent with the consumer\u2019s consent by a platform, technology, or mechanism, based on technical specifications set forth in regulations adopted pursuant to paragraph (19) of subdivision (a) of Section 1798.185, to the business indicating the consumer\u2019s intent to opt out of the business\u2019 sale or sharing of the consumer\u2019s personal information or to limit the use or disclosure of the consumer\u2019s sensitive personal information, or both.\n(2) A business that allows consumers to opt out of the sale or sharing of their personal information and to limit the use of their sensitive personal information pursuant to paragraph (1) may provide a link to a web page that enables the consumer to consent to the business ignoring the opt-out preference signal with respect to that business\u2019 sale or sharing of the consumer\u2019s personal information or the use of the consumer\u2019s sensitive personal information for additional purposes provided that:\n\n(A) The consent web page also allows the consumer or a person authorized by the consumer to revoke the consent as easily as it is affirmatively provided.\n\n(B) The link to the web page does not degrade the consumer\u2019s experience on the web page the consumer intends to visit and has a similar look, feel, and size relative to other links on the same web page.\n\n(C) The consent web page complies with technical specifications set forth in regulations adopted pursuant to paragraph (19) of subdivision (a) of Section 1798.185.\n\n(3) A business that complies with subdivision (a) is not required to comply with subdivision (b). For the purposes of clarity, a business may elect whether to comply with subdivision (a) or subdivision (b).\n\n(c) A business that is subject to this section shall:\n(1) Not require a consumer to create an account or provide additional information beyond what is necessary in order to direct the business not to sell or share the consumer\u2019s personal information or to limit use or disclosure of the consumer\u2019s sensitive personal information.\n\n(2) Include a description of a consumer\u2019s rights pursuant to Sections 1798.120 and 1798.121, along with a separate link to the \u201cDo Not Sell or Share My Personal Information\u201d internet web page and a separate link to the \u201cLimit the Use of My Sensitive Personal Information\u201d internet web page, if applicable, or a single link to both choices, or a statement that the business responds to and abides by opt-out preference signals sent by a platform, technology, or mechanism in accordance with subdivision (b), in:\n\n(A) Its online privacy policy or policies if the business has an online privacy policy or policies.\n\n(B) Any California-specific description of consumers\u2019 privacy rights.\n\n(3) Ensure that all individuals responsible for handling consumer inquiries about the business\u2019 privacy practices or the business\u2019 compliance with this title are informed of all requirements in Sections 1798.120, 1798.121, and this section and how to direct consumers to exercise their rights under those sections.\n\n(4) For consumers who exercise their right to opt out of the sale or sharing of their personal information or limit the use or disclosure of their sensitive personal information, refrain from selling or sharing the consumer\u2019s personal information or using or disclosing the consumer\u2019s sensitive personal information and wait for at least 12 months before requesting that the consumer authorize the sale or sharing of the consumer\u2019s personal information or the use and disclosure of the consumer\u2019s sensitive personal information for additional purposes, or as authorized by regulations.\n\n(5) For consumers under 16 years of age who do not consent to the sale or sharing of their personal information, refrain from selling or sharing the personal information of the consumer under 16 years of age and wait for at least 12 months before requesting the consumer\u2019s consent again, or as authorized by regulations or until the consumer attains 16 years of age.\n\n(6) Use any personal information collected from the consumer in connection with the submission of the consumer\u2019s opt-out request solely for the purposes of complying with the opt-out request.\n\n(d) Nothing in this title shall be construed to require a business to comply with the title by including the required links and text on the homepage that the business makes available to the public generally, if the business maintains a separate and additional homepage that is dedicated to California consumers and that includes the required links and text, and the business takes reasonable steps to ensure that California consumers are directed to the homepage for California consumers and not the homepage made available to the public generally.\n(e) A consumer may authorize another person to opt out of the sale or sharing of the consumer\u2019s personal information and to limit the use of the consumer\u2019s sensitive personal information on the consumer\u2019s behalf, including through an opt-out preference signal, as defined in paragraph (1) of subdivision (b), indicating the consumer\u2019s intent to opt out, and a business shall comply with an opt-out request received from a person authorized by the consumer to act on the consumer\u2019s behalf, pursuant to regulations adopted by the Attorney General regardless of whether the business has elected to comply with subdivision (a) or (b). For purposes of clarity, a business that elects to comply with subdivision (a) may respond to the consumer\u2019s opt-out request consistently with Section 1798.125.\n(f) If a business communicates a consumer\u2019s opt-out request to any person authorized by the business to collect personal information, the person shall thereafter only use that consumer\u2019s personal information for a business purpose specified by the business, or as otherwise permitted by this title, and shall be prohibited from:\n(1) Selling or sharing the personal information.\n\n(2) Retaining, using, or disclosing that consumer\u2019s personal information.\n\n(A) For any purpose other than for the specific purpose of performing the services offered to the business.\n\n(B) Outside of the direct business relationship between the person and the business.\n\n(C) For a commercial purpose other than providing the services to the business.\n\n(g) A business that communicates a consumer\u2019s opt-out request to a person pursuant to subdivision (f) shall not be liable under this title if the person receiving the opt-out request violates the restrictions set forth in the title provided that, at the time of communicating the opt-out request, the business does not have actual knowledge, or reason to believe, that the person intends to commit such a violation. Any provision of a contract or agreement of any kind that purports to waive or limit in any way this subdivision shall be void and unenforceable.\n(Amended by Stats. 2024, Ch. 121, Sec. 4. (AB 3286) Effective January 1, 2025.)\n\n1798.140.  Definitions\nFor purposes of this title:\n(a) \u201cAdvertising and marketing\u201d means a communication by a business or a person acting on the business\u2019 behalf in any medium intended to induce a consumer to obtain goods, services, or employment.\n(b) \u201cAggregate consumer information\u201d means information that relates to a group or category of consumers, from which individual consumer identities have been removed, that is not linked or reasonably linkable to any consumer or household, including via a device. \u201cAggregate consumer information\u201d does not mean one or more individual consumer records that have been deidentified.\n(c) \u201cBiometric information\u201d means an individual\u2019s physiological, biological, or behavioral characteristics, including information pertaining to an individual\u2019s deoxyribonucleic acid (DNA), that is used or is intended to be used singly or in combination with each other or with other identifying data, to establish individual identity. Biometric information includes, but is not limited to, imagery of the iris, retina, fingerprint, face, hand, palm, vein patterns, and voice recordings, from which an identifier template, such as a faceprint, a minutiae template, or a voiceprint, can be extracted, and keystroke patterns or rhythms, gait patterns or rhythms, and sleep, health, or exercise data that contain identifying information.\n(d) \u201cBusiness\u201d means:\n(1) A sole proprietorship, partnership, limited liability company, corporation, association, or other legal entity that is organized or operated for the profit or financial benefit of its shareholders or other owners, that collects consumers\u2019 personal information, or on the behalf of which such information is collected and that alone, or jointly with others, determines the purposes and means of the processing of consumers\u2019 personal information, that does business in the State of California, and that satisfies one or more of the following thresholds:\n\n(A) As of January 1 of the calendar year, had annual gross revenues in excess of twenty-five million dollars ($25,000,000) in the preceding calendar year, as adjusted pursuant to subdivision (d) of Section 1798.199.95.\n\n(B) Alone or in combination, annually buys, sells, or shares the personal information of 100,000 or more consumers or households.\n\n(C) Derives 50 percent or more of its annual revenues from selling or sharing consumers\u2019 personal information.\n\n(2) Any entity that controls or is controlled by a business, as defined in paragraph (1), and that shares common branding with the business and with whom the business shares consumers\u2019 personal information. \u201cControl\u201d or \u201ccontrolled\u201d means ownership of, or the power to vote, more than 50 percent of the outstanding shares of any class of voting security of a business; control in any manner over the election of a majority of the directors, or of individuals exercising similar functions; or the power to exercise a controlling influence over the management of a company. \u201cCommon branding\u201d means a shared name, servicemark, or trademark that the average consumer would understand that two or more entities are commonly owned.\n\n(3) A joint venture or partnership composed of businesses in which each business has at least a 40 percent interest. For purposes of this title, the joint venture or partnership and each business that composes the joint venture or partnership shall separately be considered a single business, except that personal information in the possession of each business and disclosed to the joint venture or partnership shall not be shared with the other business.\n\n(4) A person that does business in California, that is not covered by paragraph (1), (2), or (3), and that voluntarily certifies to the California Privacy Protection Agency that it is in compliance with, and agrees to be bound by, this title.\n\n(e) \u201cBusiness purpose\u201d means the use of personal information for the business\u2019 operational purposes, or other notified purposes, or for the service provider or contractor\u2019s operational purposes, as defined by regulations adopted pursuant to paragraph (10) of subdivision (a) of Section 1798.185, provided that the use of personal information shall be reasonably necessary and proportionate to achieve the purpose for which the personal information was collected or processed or for another purpose that is compatible with the context in which the personal information was collected. Business purposes are:\n(1) Auditing related to counting ad impressions to unique visitors, verifying positioning and quality of ad impressions, and auditing compliance with this specification and other standards.\n\n(2) Helping to ensure security and integrity to the extent the use of the consumer\u2019s personal information is reasonably necessary and proportionate for these purposes.\n\n(3) Debugging to identify and repair errors that impair existing intended functionality.\n\n(4) Short-term, transient use, including, but not limited to, nonpersonalized advertising shown as part of a consumer\u2019s current interaction with the business, provided that the consumer\u2019s personal information is not disclosed to another third party and is not used to build a profile about the consumer or otherwise alter the consumer\u2019s experience outside the current interaction with the business.\n\n(5) Performing services on behalf of the business, including maintaining or servicing accounts, providing customer service, processing or fulfilling orders and transactions, verifying customer information, processing payments, providing financing, providing analytic services, providing storage, or providing similar services on behalf of the business.\n\n(6) Providing advertising and marketing services, except for cross-context behavioral advertising, to the consumer provided that, for the purpose of advertising and marketing, a service provider or contractor shall not combine the personal information of opted-out consumers that the service provider or contractor receives from, or on behalf of, the business with personal information that the service provider or contractor receives from, or on behalf of, another person or persons or collects from its own interaction with consumers.\n\n(7) Undertaking internal research for technological development and demonstration.\n\n(8) Undertaking activities to verify or maintain the quality or safety of a service or device that is owned, manufactured, manufactured for, or controlled by the business, and to improve, upgrade, or enhance the service or device that is owned, manufactured, manufactured for, or controlled by the business.\n\n(f) \u201cCollects,\u201d \u201ccollected,\u201d or \u201ccollection\u201d means buying, renting, gathering, obtaining, receiving, or accessing any personal information pertaining to a consumer by any means. This includes receiving information from the consumer, either actively or passively, or by observing the consumer\u2019s behavior.\n(g) \u201cCommercial purposes\u201d means to advance a person\u2019s commercial or economic interests, such as by inducing another person to buy, rent, lease, join, subscribe to, provide, or exchange products, goods, property, information, or services, or enabling or effecting, directly or indirectly, a commercial transaction.\n(h) \u201cConsent\u201d means any freely given, specific, informed, and unambiguous indication of the consumer\u2019s wishes by which the consumer, or the consumer\u2019s legal guardian, a person who has power of attorney, or a person acting as a conservator for the consumer, including by a statement or by a clear affirmative action, signifies agreement to the processing of personal information relating to the consumer for a narrowly defined particular purpose. Acceptance of a general or broad terms of use, or similar document, that contains descriptions of personal information processing along with other, unrelated information, does not constitute consent. Hovering over, muting, pausing, or closing a given piece of content does not constitute consent. Likewise, agreement obtained through use of dark patterns does not constitute consent.\n(i) \u201cConsumer\u201d means a natural person who is a California resident, as defined in Section 17014 of Title 18 of the California Code of Regulations, as that section read on September 1, 2017, however identified, including by any unique identifier.\n(j) (1) \u201cContractor\u201d means a person to whom the business makes available a consumer\u2019s personal information for a business purpose, pursuant to a written contract with the business, provided that the contract:\n(A) Prohibits the contractor from:\n\n(i) Selling or sharing the personal information.\n\n(ii) Retaining, using, or disclosing the personal information for any purpose other than for the business purposes specified in the contract, including retaining, using, or disclosing the personal information for a commercial purpose other than the business purposes specified in the contract, or as otherwise permitted by this title.\n\n(iii) Retaining, using, or disclosing the information outside of the direct business relationship between the contractor and the business.\n\n(iv) Combining the personal information that the contractor receives pursuant to a written contract with the business with personal information that it receives from or on behalf of another person or persons, or collects from its own interaction with the consumer, provided that the contractor may combine personal information to perform any business purpose as defined in regulations adopted pursuant to paragraph (9) of subdivision (a) of Section 1798.185, except as provided for in paragraph (6) of subdivision (e) and in regulations adopted by the California Privacy Protection Agency.\n\n(B) Includes a certification made by the contractor that the contractor understands the restrictions in subparagraph (A) and will comply with them.\n\n(C) Permits, subject to agreement with the contractor, the business to monitor the contractor\u2019s compliance with the contract through measures, including, but not limited to, ongoing manual reviews and automated scans and regular assessments, audits, or other technical and operational testing at least once every 12 months.\n\n(2) If a contractor engages any other person to assist it in processing personal information for a business purpose on behalf of the business, or if any other person engaged by the contractor engages another person to assist in processing personal information for that business purpose, it shall notify the business of that engagement, and the engagement shall be pursuant to a written contract binding the other person to observe all the requirements set forth in paragraph (1).\n\n(k) \u201cCross-context behavioral advertising\u201d means the targeting of advertising to a consumer based on the consumer\u2019s personal information obtained from the consumer\u2019s activity across businesses, distinctly branded internet websites, applications, or services, other than the business, distinctly branded internet website, application, or service with which the consumer intentionally interacts.\n(l) \u201cDark pattern\u201d means a user interface designed or manipulated with the substantial effect of subverting or impairing user autonomy, decisionmaking, or choice, as further defined by regulation.\n(m) \u201cDeidentified\u201d means information that cannot reasonably be used to infer information about, or otherwise be linked to, a particular consumer provided that the business that possesses the information:\n(1) Takes reasonable measures to ensure that the information cannot be associated with a consumer or household.\n\n(2) Publicly commits to maintain and use the information in deidentified form and not to attempt to reidentify the information, except that the business may attempt to reidentify the information solely for the purpose of determining whether its deidentification processes satisfy the requirements of this subdivision.\n\n(3) Contractually obligates any recipients of the information to comply with all provisions of this subdivision.\n\n(n) \u201cDesignated methods for submitting requests\u201d means a mailing address, email address, internet web page, internet web portal, toll-free telephone number, or other applicable contact information, whereby consumers may submit a request or direction under this title, and any new, consumer-friendly means of contacting a business, as approved by the Attorney General pursuant to Section 1798.185.\n(o) \u201cDevice\u201d means any physical object that is capable of connecting to the internet, directly or indirectly, or to another device.\n(p) \u201cHomepage\u201d means the introductory page of an internet website and any internet web page where personal information is collected. In the case of an online service, such as a mobile application, homepage means the application\u2019s platform page or download page, a link within the application, such as from the application configuration, \u201cAbout,\u201d \u201cInformation,\u2019\u2019 or settings page, and any other location that allows consumers to review the notices required by this title, including, but not limited to, before downloading the application.\n(q) \u201cHousehold\u201d means a group, however identified, of consumers who cohabitate with one another at the same residential address and share use of common devices or services.\n(r) \u201cInfer\u201d or \u201cinference\u201d means the derivation of information, data, assumptions, or conclusions from facts, evidence, or another source of information or data.\n(s) \u201cIntentionally interacts\u201d means when the consumer intends to interact with a person, or disclose personal information to a person, via one or more deliberate interactions, including visiting the person\u2019s internet website or purchasing a good or service from the person. Hovering over, muting, pausing, or closing a given piece of content does not constitute a consumer\u2019s intent to interact with a person.\n(t) \u201cNonpersonalized advertising\u201d means advertising and marketing that is based solely on a consumer\u2019s personal information derived from the consumer\u2019s current interaction with the business with the exception of the consumer\u2019s precise geolocation.\n(u) \u201cPerson\u201d means an individual, proprietorship, firm, partnership, joint venture, syndicate, business trust, company, corporation, limited liability company, association, committee, and any other organization or group of persons acting in concert.\n(v) (1) \u201cPersonal information\u201d means information that identifies, relates to, describes, is reasonably capable of being associated with, or could reasonably be linked, directly or indirectly, with a particular consumer or household. Personal information includes, but is not limited to, the following if it identifies, relates to, describes, is reasonably capable of being associated with, or could be reasonably linked, directly or indirectly, with a particular consumer or household:\n(A) Identifiers such as a real name, alias, postal address, unique personal identifier, online identifier, Internet Protocol address, email address, account name, social security number, driver\u2019s license number, passport number, or other similar identifiers.\n\n(B) Any personal information described in subdivision (e) of Section 1798.80.\n\n(C) Characteristics of protected classifications under California or federal law.\n\n(D) Commercial information, including records of personal property, products or services purchased, obtained, or considered, or other purchasing or consuming histories or tendencies.\n\n(E) Biometric information.\n\n(F) Internet or other electronic network activity information, including, but not limited to, browsing history, search history, and information regarding a consumer\u2019s interaction with an internet website application, or advertisement.\n\n(G) Geolocation data.\n\n(H) Audio, electronic, visual, thermal, olfactory, or similar information.\n\n(I) Professional or employment-related information.\n\n(J) Education information, defined as information that is not publicly available personally identifiable information as defined in the Family Educational Rights and Privacy Act (20 U.S.C. Sec. 1232g; 34 C.F.R. Part 99).\n\n(K) Inferences drawn from any of the information identified in this subdivision to create a profile about a consumer reflecting the consumer\u2019s preferences, characteristics, psychological trends, predispositions, behavior, attitudes, intelligence, abilities, and aptitudes.\n\n(L) Sensitive personal information.\n\n(2) (A) \u201cPersonal information\u201d does not include publicly available information or lawfully obtained, truthful information that is a matter of public concern.\n\n(B) (i) For purposes of this paragraph, \u201cpublicly available\u201d means any of the following:\n\n(I) Information that is lawfully made available from federal, state, or local government records.\n\n(II) Information that a business has a reasonable basis to believe is lawfully made available to the general public by the consumer or from widely distributed media.\n\n(III) Information made available by a person to whom the consumer has disclosed the information if the consumer has not restricted the information to a specific audience.\n\n(ii) \u201cPublicly available\u201d does not mean biometric information collected by a business about a consumer without the consumer\u2019s knowledge.\n\n(3) \u201cPersonal information\u201d does not include consumer information that is deidentified or aggregate consumer information.\n\n(4) \u201cPersonal information\u201d can exist in various formats, including, but not limited to, all of the following:\n\n(A) Physical formats, including paper documents, printed images, vinyl records, or video tapes.\n\n(B) Digital formats, including text, image, audio, or video files.\n\n(C) Abstract digital formats, including compressed or encrypted files, metadata, or artificial intelligence systems that are capable of outputting personal information.\n\n(w) \u201cPrecise geolocation\u201d means any data that is derived from a device and that is used or intended to be used to locate a consumer within a geographic area that is equal to or less than the area of a circle with a radius of 1,850 feet, except as prescribed by regulations.\n(x) \u201cProbabilistic identifier\u201d means the identification of a consumer or a consumer\u2019s device to a degree of certainty of more probable than not based on any categories of personal information included in, or similar to, the categories enumerated in the definition of personal information.\n(y) \u201cProcessing\u201d means any operation or set of operations that are performed on personal information or on sets of personal information, whether or not by automated means.\n(z) \u201cProfiling\u201d means any form of automated processing of personal information, as further defined by regulations pursuant to paragraph (15) of subdivision (a) of Section 1798.185, to evaluate certain personal aspects relating to a natural person and in particular to analyze or predict aspects concerning that natural person\u2019s performance at work, economic situation, health, personal preferences, interests, reliability, behavior, location, or movements.\n(aa) \u201cPseudonymize\u201d or \u201cPseudonymization\u201d means the processing of personal information in a manner that renders the personal information no longer attributable to a specific consumer without the use of additional information, provided that the additional information is kept separately and is subject to technical and organizational measures to ensure that the personal information is not attributed to an identified or identifiable consumer.\n(ab) \u201cResearch\u201d means scientific analysis, systematic study, and observation, including basic research or applied research that is designed to develop or contribute to public or scientific knowledge and that adheres or otherwise conforms to all other applicable ethics and privacy laws, including, but not limited to, studies conducted in the public interest in the area of public health. Research with personal information that may have been collected from a consumer in the course of the consumer\u2019s interactions with a business\u2019 service or device for other purposes shall be:\n(1) Compatible with the business purpose for which the personal information was collected.\n\n(2) Subsequently pseudonymized and deidentified, or deidentified and in the aggregate, such that the information cannot reasonably identify, relate to, describe, be capable of being associated with, or be linked, directly or indirectly, to a particular consumer, by a business.\n\n(3) Made subject to technical safeguards that prohibit reidentification of the consumer to whom the information may pertain, other than as needed to support the research.\n\n(4) Subject to business processes that specifically prohibit reidentification of the information, other than as needed to support the research.\n\n(5) Made subject to business processes to prevent inadvertent release of deidentified information.\n\n(6) Protected from any reidentification attempts.\n\n(7) Used solely for research purposes that are compatible with the context in which the personal information was collected.\n\n(8) Subjected by the business conducting the research to additional security controls that limit access to the research data to only those individuals as are necessary to carry out the research purpose.\n\n(ac) \u201cSecurity and integrity\u201d means the ability of:\n(1) Networks or information systems to detect security incidents that compromise the availability, authenticity, integrity, and confidentiality of stored or transmitted personal information.\n\n(2) Businesses to detect security incidents, resist malicious, deceptive, fraudulent, or illegal actions and to help prosecute those responsible for those actions.\n\n(3) Businesses to ensure the physical safety of natural persons.\n\n(ad) (1) \u201cSell,\u201d \u201cselling,\u201d \u201csale,\u201d or \u201csold,\u2019\u2019 means selling, renting, releasing, disclosing, disseminating, making available, transferring, or otherwise communicating orally, in writing, or by electronic or other means, a consumer\u2019s personal information by the business to a third party for monetary or other valuable consideration.\n(2) For purposes of this title, a business does not sell personal information when:\n\n(A) A consumer uses or directs the business to intentionally:\n\n(i) Disclose personal information.\n\n(ii) Interact with one or more third parties.\n\n(B) The business uses or shares an identifier for a consumer who has opted out of the sale of the consumer\u2019s personal information or limited the use of the consumer\u2019s sensitive personal information for the purposes of alerting persons that the consumer has opted out of the sale of the consumer\u2019s personal information or limited the use of the consumer\u2019s sensitive personal information.\n\n(C) The business transfers to a third party the personal information of a consumer as an asset that is part of a merger, acquisition, bankruptcy, or other transaction in which the third party assumes control of all or part of the business, provided that information is used or shared consistently with this title. If a third party materially alters how it uses or shares the personal information of a consumer in a manner that is materially inconsistent with the promises made at the time of collection, it shall provide prior notice of the new or changed practice to the consumer. The notice shall be sufficiently prominent and robust to ensure that existing consumers can easily exercise their choices consistently with this title. This subparagraph does not authorize a business to make material, retroactive privacy policy changes or make other changes in their privacy policy in a manner that would violate the Unfair and Deceptive Practices Act (Chapter 5 (commencing with Section 17200) of Part 2 of Division 7 of the Business and Professions Code).\n\n(ae) \u201cSensitive personal information\u201d means:\n(1) Personal information that reveals:\n\n(A) A consumer\u2019s social security, driver\u2019s license, state identification card, or passport number.\n\n(B) A consumer\u2019s account log-in, financial account, debit card, or credit card number in combination with any required security or access code, password, or credentials allowing access to an account.\n\n(C) A consumer\u2019s precise geolocation.\n\n(D) A consumer\u2019s racial or ethnic origin, citizenship or immigration status, religious or philosophical beliefs, or union membership.\n\n(E) The contents of a consumer\u2019s mail, email, and text messages unless the business is the intended recipient of the communication.\n\n(F) A consumer\u2019s genetic data.\n\n(G) (i) A consumer\u2019s neural data.\n\n(ii) \u201cNeural data\u201d means information that is generated by measuring the activity of a consumer\u2019s central or peripheral nervous system, and that is not inferred from nonneural information.\n\n(2) (A) The processing of biometric information for the purpose of uniquely identifying a consumer.\n\n(B) Personal information collected and analyzed concerning a consumer\u2019s health.\n\n(C) Personal information collected and analyzed concerning a consumer\u2019s sex life or sexual orientation.\n\n(3) Sensitive personal information that is \u201cpublicly available\u201d pursuant to paragraph (2) of subdivision (v) shall not be considered sensitive personal information or personal information.\n\n(af) \u201cService\u201d or \u201cservices\u201d means work, labor, and services, including services furnished in connection with the sale or repair of goods.\n(ag) (1) \u201cService provider\u201d means a person that processes personal information on behalf of a business and that receives from or on behalf of the business consumer\u2019s personal information for a business purpose pursuant to a written contract, provided that the contract prohibits the person from:\n(A) Selling or sharing the personal information.\n\n(B) Retaining, using, or disclosing the personal information for any purpose other than for the business purposes specified in the contract for the business, including retaining, using, or disclosing the personal information for a commercial purpose other than the business purposes specified in the contract with the business, or as otherwise permitted by this title.\n\n(C) Retaining, using, or disclosing the information outside of the direct business relationship between the service provider and the business.\n\n(D) Combining the personal information that the service provider receives from, or on behalf of, the business with personal information that it receives from, or on behalf of, another person or persons, or collects from its own interaction with the consumer, provided that the service provider may combine personal information to perform any business purpose as defined in regulations adopted pursuant to paragraph (9) of subdivision (a) of Section 1798.185, except as provided for in paragraph (6) of subdivision (e) of this section and in regulations adopted by the California Privacy Protection Agency. The contract may, subject to agreement with the service provider, permit the business to monitor the service provider\u2019s compliance with the contract through measures, including, but not limited to, ongoing manual reviews and automated scans and regular assessments, audits, or other technical and operational testing at least once every 12 months.\n\n(2) If a service provider engages any other person to assist it in processing personal information for a business purpose on behalf of the business, or if any other person engaged by the service provider engages another person to assist in processing personal information for that business purpose, it shall notify the business of that engagement, and the engagement shall be pursuant to a written contract binding the other person to observe all the requirements set forth in paragraph (1).\n\n(ah) (1) \u201cShare,\u201d \u201cshared,\u201d or \u201csharing\u201d means sharing, renting, releasing, disclosing, disseminating, making available, transferring, or otherwise communicating orally, in writing, or by electronic or other means, a consumer\u2019s personal information by the business to a third party for cross-context behavioral advertising, whether or not for monetary or other valuable consideration, including transactions between a business and a third party for cross-context behavioral advertising for the benefit of a business in which no money is exchanged.\n(2) For purposes of this title, a business does not share personal information when:\n\n(A) A consumer uses or directs the business to intentionally disclose personal information or intentionally interact with one or more third parties.\n\n(B) The business uses or shares an identifier for a consumer who has opted out of the sharing of the consumer\u2019s personal information or limited the use of the consumer\u2019s sensitive personal information for the purposes of alerting persons that the consumer has opted out of the sharing of the consumer\u2019s personal information or limited the use of the consumer\u2019s sensitive personal information.\n\n(C) The business transfers to a third party the personal information of a consumer as an asset that is part of a merger, acquisition, bankruptcy, or other transaction in which the third party assumes control of all or part of the business, provided that information is used or shared consistently with this title. If a third party materially alters how it uses or shares the personal information of a consumer in a manner that is materially inconsistent with the promises made at the time of collection, it shall provide prior notice of the new or changed practice to the consumer. The notice shall be sufficiently prominent and robust to ensure that existing consumers can easily exercise their choices consistently with this title. This subparagraph does not authorize a business to make material, retroactive privacy policy changes or make other changes in their privacy policy in a manner that would violate the Unfair and Deceptive Practices Act (Chapter 5 (commencing with Section 17200) of Part 2 of Division 7 of the Business and Professions Code).\n\n(ai) \u201cThird party\u201d means a person who is not any of the following:\n(1) The business with whom the consumer intentionally interacts and that collects personal information from the consumer as part of the consumer\u2019s current interaction with the business under this title.\n\n(2) A service provider to the business.\n\n(3) A contractor.\n\n(aj) \u201cUnique identifier\u201d or \u201cunique personal identifier\u201d means a persistent identifier that can be used to recognize a consumer, a family, or a device that is linked to a consumer or family, over time and across different services, including, but not limited to, a device identifier; an Internet Protocol address; cookies, beacons, pixel tags, mobile ad identifiers, or similar technology; customer number, unique pseudonym, or user alias; telephone numbers, or other forms of persistent or probabilistic identifiers that can be used to identify a particular consumer or device that is linked to a consumer or family. For purposes of this subdivision, \u201cfamily\u201d means a custodial parent or guardian and any children under 18 years of age over which the parent or guardian has custody.\n(ak) \u201cVerifiable consumer request\u201d means a request that is made by a consumer, by a consumer on behalf of the consumer\u2019s minor child, by a natural person or a person registered with the Secretary of State, authorized by the consumer to act on the consumer\u2019s behalf, or by a person who has power of attorney or is acting as a conservator for the consumer, and that the business can verify, using commercially reasonable methods, pursuant to regulations adopted by the Attorney General pursuant to paragraph (6) of subdivision (a) of Section 1798.185 to be the consumer about whom the business has collected personal information. A business is not obligated to provide information to the consumer pursuant to Sections 1798.110 and 1798.115, to delete personal information pursuant to Section 1798.105, or to correct inaccurate personal information pursuant to Section 1798.106, if the business cannot verify, pursuant to this subdivision and regulations adopted by the Attorney General pursuant to paragraph (6) of subdivision (a) of Section 1798.185, that the consumer making the request is the consumer about whom the business has collected information or is a person authorized by the consumer to act on such consumer\u2019s behalf.\n(Amended (as amended by Stats. 2024, Ch. 121, Sec. 5) by Stats. 2024, Ch. 887, Sec. 1.5. (SB 1223) Effective January 1, 2025.)\n\n1798.145.  Exemptions\n(a) (1) The obligations imposed on businesses by this title shall not restrict a business\u2019s ability to:\n(A) Comply with federal, state, or local laws or comply with a court order or subpoena to provide information.\n\n(B) Comply with a civil, criminal, or regulatory inquiry, investigation, subpoena, or summons by federal, state, or local authorities. Law enforcement agencies, including police and sheriff\u2019s departments, may direct a business pursuant to a law enforcement agency-approved investigation with an active case number not to delete a consumer\u2019s personal information, and, upon receipt of that direction, a business shall not delete the personal information for 90 days in order to allow the law enforcement agency to obtain a court-issued subpoena, order, or warrant to obtain a consumer\u2019s personal information. For good cause and only to the extent necessary for investigatory purposes, a law enforcement agency may direct a business not to delete the consumer\u2019s personal information for additional 90-day periods. A business that has received direction from a law enforcement agency not to delete the personal information of a consumer who has requested deletion of the consumer\u2019s personal information shall not use the consumer\u2019s personal information for any purpose other than retaining it to produce to law enforcement in response to a court-issued subpoena, order, or warrant unless the consumer\u2019s deletion request is subject to an exemption from deletion under this title.\n\n(C) Cooperate with law enforcement agencies concerning conduct or activity that the business, service provider, or third party reasonably and in good faith believes may violate federal, state, or local law.\n\n(D) (i) Cooperate with a government agency request for emergency access to a consumer\u2019s personal information if a natural person is at risk or danger of death or serious physical injury provided that:\n\n(I) The request is approved by a high-ranking agency officer for emergency access to a consumer\u2019s personal information.\n\n(II) The request is based on the agency\u2019s good faith determination that it has a lawful basis to access the information on a nonemergency basis.\n\n(III) The agency agrees to petition a court for an appropriate order within three days and to destroy the information if that order is not granted.\n\n(ii) For purposes of this subparagraph, a consumer accessing, procuring, or searching for services regarding contraception, pregnancy care, and perinatal care, including, but not limited to, abortion services, shall not constitute a natural person being at risk or danger of death or serious physical injury.\n\n(E) Exercise or defend legal claims.\n\n(F) Collect, use, retain, sell, share, or disclose consumers\u2019 personal information that is deidentified or aggregate consumer information.\n\n(G) Collect, sell, or share a consumer\u2019s personal information if every aspect of that commercial conduct takes place wholly outside of California. For purposes of this title, commercial conduct takes place wholly outside of California if the business collected that information while the consumer was outside of California, no part of the sale of the consumer\u2019s personal information occurred in California, and no personal information collected while the consumer was in California is sold. This paragraph shall not prohibit a business from storing, including on a device, personal information about a consumer when the consumer is in California and then collecting that personal information when the consumer and stored personal information is outside of California.\n\n(2) (A) This subdivision shall not apply if the consumer\u2019s personal information contains information related to accessing, procuring, or searching for services regarding contraception, pregnancy care, and perinatal care, including, but not limited to, abortion services.\n\n(B) This paragraph does not alter the use of aggregated or deidentified personal information consistent with a business purpose as defined in paragraphs (1), (2), (3), (4), (5), (7), or (8) of subdivision (e) of Section 1798.140, provided that the personal information is only retained in aggregated and deidentified form and is not sold or shared.\n\n(C) This paragraph does not alter the duty of a business to preserve or retain evidence pursuant to California or federal law in an ongoing civil proceeding.\n\n(b) The obligations imposed on businesses by Sections 1798.110, 1798.115, 1798.120, 1798.121, 1798.130, and 1798.135 shall not apply where compliance by the business with the title would violate an evidentiary privilege under California law and shall not prevent a business from providing the personal information of a consumer to a person covered by an evidentiary privilege under California law as part of a privileged communication.\n(c) (1) This title shall not apply to any of the following:\n(A) Medical information governed by the Confidentiality of Medical Information Act (Part 2.6 (commencing with Section 56) of Division 1) or protected health information that is collected by a covered entity or business associate governed by the privacy, security, and breach notification rules issued by the United States Department of Health and Human Services, Parts 160 and 164 of Title 45 of the Code of Federal Regulations, established pursuant to the Health Insurance Portability and Accountability Act of 1996 (Public Law 104-191) and the Health Information Technology for Economic and Clinical Health Act (Public Law 111-5).\n\n(B) A provider of health care governed by the Confidentiality of Medical Information Act (Part 2.6 (commencing with Section 56) of Division 1) or a covered entity governed by the privacy, security, and breach notification rules issued by the United States Department of Health and Human Services, Parts 160 and 164 of Title 45 of the Code of Federal Regulations, established pursuant to the Health Insurance Portability and Accountability Act of 1996 (Public Law 104-191), to the extent the provider or covered entity maintains patient information in the same manner as medical information or protected health information as described in subparagraph (A) of this section.\n\n(C) Personal information collected as part of a clinical trial or other biomedical research study subject to, or conducted in accordance with, the Federal Policy for the Protection of Human Subjects, also known as the Common Rule, pursuant to good clinical practice guidelines issued by the International Council for Harmonisation or pursuant to human subject protection requirements of the United States Food and Drug Administration, provided that the information is not sold or shared in a manner not permitted by this subparagraph, and, if it is inconsistent, that participants be informed of that use and provide consent.\n\n(2) For purposes of this subdivision, the definitions of \u201cmedical information\u201d and \u201cprovider of health care\u201d in Section 56.05 shall apply and the definitions of \u201cbusiness associate,\u201d \u201ccovered entity,\u201d and \u201cprotected health information\u201d in Section 160.103 of Title 45 of the Code of Federal Regulations shall apply.\n\n(d) (1) This title shall not apply to an activity involving the collection, maintenance, disclosure, sale, communication, or use of any personal information bearing on a consumer\u2019s creditworthiness, credit standing, credit capacity, character, general reputation, personal characteristics, or mode of living by a consumer reporting agency, as defined in subdivision (f) of Section 1681a of Title 15 of the United States Code, by a furnisher of information, as set forth in Section 1681s-2 of Title 15 of the United States Code, who provides information for use in a consumer report, as defined in subdivision (d) of Section 1681a of Title 15 of the United States Code, and by a user of a consumer report as set forth in Section 1681b of Title 15 of the United States Code.\n(2) Paragraph (1) shall apply only to the extent that such activity involving the collection, maintenance, disclosure, sale, communication, or use of such information by that agency, furnisher, or user is subject to regulation under the Fair Credit Reporting Act, Section 1681 et seq., Title 15 of the United States Code and the information is not collected, maintained, used, communicated, disclosed, or sold except as authorized by the Fair Credit Reporting Act.\n\n(3) This subdivision shall not apply to Section 1798.150.\n\n(e) This title shall not apply to personal information collected, processed, sold, or disclosed subject to the federal Gramm-Leach-Bliley Act (Public Law 106-102), and implementing regulations, or the California Financial Information Privacy Act (Division 1.4 (commencing with Section 4050) of the Financial Code), or the federal Farm Credit Act of 1971 (as amended in 12 U.S.C. 2001-2279cc and implementing regulations, 12 C.F.R. 600, et seq.). This subdivision shall not apply to Section 1798.150.\n(f) This title shall not apply to personal information collected, processed, sold, or disclosed pursuant to the Driver\u2019s Privacy Protection Act of 1994 (18 U.S.C. Sec. 2721 et seq.). This subdivision shall not apply to Section 1798.150.\n(g) (1) Section 1798.120 shall not apply to vehicle information or ownership information retained or shared between a new motor vehicle dealer, as defined in Section 426 of the Vehicle Code, and the vehicle\u2019s manufacturer, as defined in Section 672 of the Vehicle Code, if the vehicle information or ownership information is shared for the purpose of effectuating, or in anticipation of effectuating, a vehicle repair covered by a vehicle warranty or a recall conducted pursuant to Sections 30118 to 30120, inclusive, of Title 49 of the United States Code, provided that the new motor vehicle dealer or vehicle manufacturer with which that vehicle information or ownership information is shared does not sell, share, or use that information for any other purpose.\n(2) Section 1798.120 shall not apply to vessel information or ownership information retained or shared between a vessel dealer and the vessel\u2019s manufacturer, as defined in Section 651 of the Harbors and Navigation Code, if the vessel information or ownership information is shared for the purpose of effectuating, or in anticipation of effectuating, a vessel repair covered by a vessel warranty or a recall conducted pursuant to Section 4310 of Title 46 of the United States Code, provided that the vessel dealer or vessel manufacturer with which that vessel information or ownership information is shared does not sell, share, or use that information for any other purpose.\n\n(3) For purposes of this subdivision:\n\n(A) \u201cOwnership information\u201d means the name or names of the registered owner or owners and the contact information for the owner or owners.\n\n(B) \u201cVehicle information\u201d means the vehicle information number, make, model, year, and odometer reading.\n\n(C) \u201cVessel dealer\u201d means a person who is engaged, wholly or in part, in the business of selling or offering for sale, buying or taking in trade for the purpose of resale, or exchanging, any vessel or vessels, as defined in Section 651 of the Harbors and Navigation Code, and receives or expects to receive money, profit, or any other thing of value.\n\n(D) \u201cVessel information\u201d means the hull identification number, model, year, month and year of production, and information describing any of the following equipment as shipped, transferred, or sold from the place of manufacture, including all attached parts and accessories:\n\n(i) An inboard engine.\n\n(ii) An outboard engine.\n\n(iii) A stern drive unit.\n\n(iv) An inflatable personal floatation device approved under Section 160.076 of Title 46 of the Code of Federal Regulations.\n\n(h) Notwithstanding a business\u2019s obligations to respond to and honor consumer rights requests pursuant to this title:\n(1) A time period for a business to respond to a consumer for any verifiable consumer request may be extended by up to a total of 90 days where necessary, taking into account the complexity and number of the requests. The business shall inform the consumer of any such extension within 45 days of receipt of the request, together with the reasons for the delay.\n\n(2) If the business does not take action on the request of the consumer, the business shall inform the consumer, without delay and at the latest within the time period permitted of response by this section, of the reasons for not taking action and any rights the consumer may have to appeal the decision to the business.\n\n(3) If requests from a consumer are manifestly unfounded or excessive, in particular because of their repetitive character, a business may either charge a reasonable fee, taking into account the administrative costs of providing the information or communication or taking the action requested, or refuse to act on the request and notify the consumer of the reason for refusing the request. The business shall bear the burden of demonstrating that any verifiable consumer request is manifestly unfounded or excessive.\n\n(i) (1) A business that discloses personal information to a service provider or contractor in compliance with this title shall not be liable under this title if the service provider or contractor receiving the personal information uses it in violation of the restrictions set forth in the title, provided that, at the time of disclosing the personal information, the business does not have actual knowledge, or reason to believe, that the service provider or contractor intends to commit such a violation. A service provider or contractor shall likewise not be liable under this title for the obligations of a business for which it provides services as set forth in this title provided that the service provider or contractor shall be liable for its own violations of this title.\n(2) A business that discloses personal information of a consumer, with the exception of consumers who have exercised their right to opt out of the sale or sharing of their personal information, consumers who have limited the use or disclosure of their sensitive personal information, and minor consumers who have not opted in to the collection or sale of their personal information, to a third party pursuant to a written contract that requires the third party to provide the same level of protection of the consumer\u2019s rights under this title as provided by the business shall not be liable under this title if the third party receiving the personal information uses it in violation of the restrictions set forth in this title provided that, at the time of disclosing the personal information, the business does not have actual knowledge, or reason to believe, that the third party intends to commit such a violation.\n\n(j) This title shall not be construed to require a business, service provider, or contractor to:\n(1) Reidentify or otherwise link information that, in the ordinary course of business, is not maintained in a manner that would be considered personal information.\n\n(2) Retain any personal information about a consumer if, in the ordinary course of business, that information about the consumer would not be retained.\n\n(3) Maintain information in identifiable, linkable, or associable form, or collect, obtain, retain, or access any data or technology, in order to be capable of linking or associating a verifiable consumer request with personal information.\n\n(k) The rights afforded to consumers and the obligations imposed on the business in this title shall not adversely affect the rights and freedoms of other natural persons. A verifiable consumer request for specific pieces of personal information pursuant to Section 1798.110, to delete a consumer\u2019s personal information pursuant to Section 1798.105, or to correct inaccurate personal information pursuant to Section 1798.106, shall not extend to personal information about the consumer that belongs to, or the business maintains on behalf of, another natural person. A business may rely on representations made in a verifiable consumer request as to rights with respect to personal information and is under no legal requirement to seek out other persons that may have or claim to have rights to personal information, and a business is under no legal obligation under this title or any other provision of law to take any action under this title in the event of a dispute between or among persons claiming rights to personal information in the business\u2019s possession.\n(l) The rights afforded to consumers and the obligations imposed on any business under this title shall not apply to the extent that they infringe on the noncommercial activities of a person or entity described in subdivision (b) of Section 2 of Article I of the California Constitution.\n(m) (1) This title shall not apply to any of the following:\n(A) Personal information that is collected by a business about a natural person in the course of the natural person acting as a job applicant to, an employee of, owner of, director of, officer of, medical staff member of, or independent contractor of, that business to the extent that the natural person\u2019s personal information is collected and used by the business solely within the context of the natural person\u2019s role or former role as a job applicant to, an employee of, owner of, director of, officer of, medical staff member of, or an independent contractor of, that business.\n\n(B) Personal information that is collected by a business that is emergency contact information of the natural person acting as a job applicant to, an employee of, owner of, director of, officer of, medical staff member of, or independent contractor of, that business to the extent that the personal information is collected and used solely within the context of having an emergency contact on file.\n\n(C) Personal information that is necessary for the business to retain to administer benefits for another natural person relating to the natural person acting as a job applicant to, an employee of, owner of, director of, officer of, medical staff member of, or independent contractor of, that business to the extent that the personal information is collected and used solely within the context of administering those benefits.\n\n(2) For purposes of this subdivision:\n\n(A) \u201cIndependent contractor\u201d means a natural person who provides any service to a business pursuant to a written contract.\n\n(B) \u201cDirector\u201d means a natural person designated in the articles of incorporation as director, or elected by the incorporators and natural persons designated, elected, or appointed by any other name or title to act as directors, and their successors.\n\n(C) \u201cMedical staff member\u201d means a licensed physician and surgeon, dentist, or podiatrist, licensed pursuant to Division 2 (commencing with Section 500) of the Business and Professions Code and a clinical psychologist as defined in Section 1316.5 of the Health and Safety Code.\n\n(D) \u201cOfficer\u201d means a natural person elected or appointed by the board of directors to manage the daily operations of a corporation, including a chief executive officer, president, secretary, or treasurer.\n\n(E) \u201cOwner\u201d means a natural person who meets one of the following criteria:\n\n(i) Has ownership of, or the power to vote, more than 50 percent of the outstanding shares of any class of voting security of a business.\n\n(ii) Has control in any manner over the election of a majority of the directors or of individuals exercising similar functions.\n\n(iii) Has the power to exercise a controlling influence over the management of a company.\n\n(3) This subdivision shall not apply to subdivision (a) of Section 1798.100 or Section 1798.150.\n\n(4) This subdivision shall become inoperative on January 1, 2023.\n\n(n) (1) The obligations imposed on businesses by Sections 1798.100, 1798.105, 1798.106, 1798.110, 1798.115, 1798.121, 1798.130, and 1798.135 shall not apply to personal information reflecting a written or verbal communication or a transaction between the business and the consumer, where the consumer is a natural person who acted or is acting as an employee, owner, director, officer, or independent contractor of a company, partnership, sole proprietorship, nonprofit, or government agency and whose communications or transaction with the business occur solely within the context of the business conducting due diligence regarding, or providing or receiving a product or service to or from such company, partnership, sole proprietorship, nonprofit, or government agency.\n(2) For purposes of this subdivision:\n\n(A) \u201cIndependent contractor\u201d means a natural person who provides any service to a business pursuant to a written contract.\n\n(B) \u201cDirector\u201d means a natural person designated in the articles of incorporation as such or elected by the incorporators and natural persons designated, elected, or appointed by any other name or title to act as directors, and their successors.\n\n(C) \u201cOfficer\u201d means a natural person elected or appointed by the board of directors to manage the daily operations of a corporation, such as a chief executive officer, president, secretary, or treasurer.\n\n(D) \u201cOwner\u201d means a natural person who meets one of the following:\n\n(i) Has ownership of, or the power to vote, more than 50 percent of the outstanding shares of any class of voting security of a business.\n\n(ii) Has control in any manner over the election of a majority of the directors or of individuals exercising similar functions.\n\n(iii) Has the power to exercise a controlling influence over the management of a company.\n\n(3) This subdivision shall become inoperative on January 1, 2023.\n\n(o) (1) Sections 1798.105 and 1798.120 shall not apply to a commercial credit reporting agency\u2019s collection, processing, sale, or disclosure of business controller information to the extent the commercial credit reporting agency uses the business controller information solely to identify the relationship of a consumer to a business that the consumer owns or contact the consumer only in the consumer\u2019s role as the owner, director, officer, or management employee of the business.\n(2) For the purposes of this subdivision:\n\n(A) \u201cBusiness controller information\u201d means the name or names of the owner or owners, director, officer, or management employee of a business and the contact information, including a business title, for the owner or owners, director, officer, or management employee.\n\n(B) \u201cCommercial credit reporting agency\u201d has the meaning set forth in subdivision (b) of Section 1785.42.\n\n(C) \u201cOwner\u201d means a natural person that meets one of the following:\n\n(i) Has ownership of, or the power to vote, more than 50 percent of the outstanding shares of any class of voting security of a business.\n\n(ii) Has control in any manner over the election of a majority of the directors or of individuals exercising similar functions.\n\n(iii) Has the power to exercise a controlling influence over the management of a company.\n\n(D) \u201cDirector\u201d means a natural person designated in the articles of incorporation of a business as director, or elected by the incorporators and natural persons designated, elected, or appointed by any other name or title to act as directors, and their successors.\n\n(E) \u201cOfficer\u201d means a natural person elected or appointed by the board of directors of a business to manage the daily operations of a corporation, including a chief executive officer, president, secretary, or treasurer.\n\n(F) \u201cManagement employee\u201d means a natural person whose name and contact information is reported to or collected by a commercial credit reporting agency as the primary manager of a business and used solely within the context of the natural person\u2019s role as the primary manager of the business.\n\n(p) The obligations imposed on businesses in Sections 1798.105, 1798.106, 1798.110, and 1798.115 shall not apply to household data.\n(q) (1) This title does not require a business to comply with a verifiable consumer request to delete a consumer\u2019s personal information under Section 1798.105 to the extent the verifiable consumer request applies to a student\u2019s grades, educational scores, or educational test results that the business holds on behalf of a local educational agency, as defined in subdivision (d) of Section 49073.1 of the Education Code, at which the student is currently enrolled. If a business does not comply with a request pursuant to this section, it shall notify the consumer that it is acting pursuant to this exception.\n(2) This title does not require, in response to a request pursuant to Section 1798.110, that a business disclose on educational standardized assessment or educational assessment or a consumer\u2019s specific responses to the educational standardized assessment or educational assessment if consumer access, possession, or control would jeopardize the validity and reliability of that educational standardized assessment or educational assessment. If a business does not comply with a request pursuant to this section, it shall notify the consumer that it is acting pursuant to this exception.\n\n(3) For purposes of this subdivision:\n\n(A) \u201cEducational standardized assessment or educational assessment\u201d means a standardized or nonstandardized quiz, test, or other assessment used to evaluate students in or for entry to kindergarten and grades 1 to 12, inclusive, schools, postsecondary institutions, vocational programs, and postgraduate programs that are accredited by an accrediting agency or organization recognized by the State of California or the United States Department of Education, as well as certification and licensure examinations used to determine competency and eligibility to receive certification or licensure from a government agency or government certification body.\n\n(B) \u201cJeopardize the validity and reliability of that educational standardized assessment or educational assessment\u201d means releasing information that would provide an advantage to the consumer who has submitted a verifiable consumer request or to another natural person.\n\n(r) Sections 1798.105 and 1798.120 shall not apply to a business\u2019s use, disclosure, or sale of particular pieces of a consumer\u2019s personal information if the consumer has consented to the business\u2019s use, disclosure, or sale of that information to produce a physical item, including a school yearbook containing the consumer\u2019s photograph if:\n(1) The business has incurred significant expense in reliance on the consumer\u2019s consent.\n\n(2) Compliance with the consumer\u2019s request to opt out of the sale of the consumer\u2019s personal information or to delete the consumer\u2019s personal information would not be commercially reasonable.\n\n(3) The business complies with the consumer\u2019s request as soon as it is commercially reasonable to do so.\n\n(Amended by Stats. 2023, Ch. 567, Sec. 2. (AB 1194) Effective January 1, 2024. Subdivisions (m) and (n) inoperative January 1, 2023, by their own provisions.)\n\n1798.146.  (a) This title shall not apply to any of the following:\n(1) Medical information governed by the Confidentiality of Medical Information Act (Part 2.6 (commencing with Section 56) of Division 1) or protected health information that is collected by a covered entity or business associate governed by the privacy, security, and breach notification rules issued by the United States Department of Health and Human Services, Parts 160 and 164 of Title 45 of the Code of Federal Regulations, established pursuant to the federal Health Insurance Portability and Accountability Act of 1996 (Public Law 104-191) and the federal Health Information Technology for Economic and Clinical Health Act, Title XIII of the federal American Recovery and Reinvestment Act of 2009 (Public Law 111-5).\n\n(2) A provider of health care governed by the Confidentiality of Medical Information Act (Part 2.6 (commencing with Section 56) of Division 1) or a covered entity governed by the privacy, security, and breach notification rules issued by the United States Department of Health and Human Services, Parts 160 and 164 of Title 45 of the Code of Federal Regulations, established pursuant to the federal Health Insurance Portability and Accountability Act of 1996 (Public Law 104-191), to the extent the provider or covered entity maintains, uses, and discloses patient information in the same manner as medical information or protected health information as described in paragraph (1).\n\n(3) A business associate of a covered entity governed by the privacy, security, and data breach notification rules issued by the United States Department of Health and Human Services, Parts 160 and 164 of Title 45 of the Code of Federal Regulations, established pursuant to the federal Health Insurance Portability and Accountability Act of 1996 (Public Law 104-191) and the federal Health Information Technology for Economic and Clinical Health Act, Title XIII of the federal American Recovery and Reinvestment Act of 2009 (Public Law 111-5), to the extent that the business associate maintains, uses, and discloses patient information in the same manner as medical information or protected health information as described in paragraph (1).\n\n(4) (A) Information that meets both of the following conditions:\n\n(i) It is deidentified in accordance with the requirements for deidentification set forth in Section 164.514 of Part 164 of Title 45 of the Code of Federal Regulations.\n\n(ii) It is derived from patient information that was originally collected, created, transmitted, or maintained by an entity regulated by the Health Insurance Portability and Accountability Act, the Confidentiality Of Medical Information Act, or the Federal Policy for the Protection of Human Subjects, also known as the Common Rule.\n\n(B) Information that met the requirements of subparagraph (A) but is subsequently reidentified shall no longer be eligible for the exemption in this paragraph, and shall be subject to applicable federal and state data privacy and security laws, including, but not limited to, the Health Insurance Portability and Accountability Act, the Confidentiality Of Medical Information Act, and this title.\n\n(5) Information that is collected, used, or disclosed in research, as defined in Section 164.501 of Title 45 of the Code of Federal Regulations, including, but not limited to, a clinical trial, and that is conducted in accordance with applicable ethics, confidentiality, privacy, and security rules of Part 164 of Title 45 of the Code of Federal Regulations, the Federal Policy for the Protection of Human Subjects, also known as the Common Rule, good clinical practice guidelines issued by the International Council for Harmonisation, or human subject protection requirements of the United States Food and Drug Administration.\n\n(b) For purposes of this section, all of the following shall apply:\n(1) \u201cBusiness associate\u201d has the same meaning as defined in Section 160.103 of Title 45 of the Code of Federal Regulations.\n\n(2) \u201cCovered entity\u201d has the same meaning as defined in Section 160.103 of Title 45 of the Code of Federal Regulations.\n\n(3) \u201cIdentifiable private information\u201d has the same meaning as defined in Section 46.102 of Title 45 of the Code of Federal Regulations.\n\n(4) \u201cIndividually identifiable health information\u201d has the same meaning as defined in Section 160.103 of Title 45 of the Code of Federal Regulations.\n\n(5) \u201cMedical information\u201d has the same meaning as defined in Section 56.05.\n\n(6) \u201cPatient information\u201d shall mean identifiable private information, protected health information, individually identifiable health information, or medical information.\n\n(7) \u201cProtected health information\u201d has the same meaning as defined in Section 160.103 of Title 45 of the Code of Federal Regulations.\n\n(8) \u201cProvider of health care\u201d has the same meaning as defined in Section 56.05.\n\n(Added by Stats. 2020, Ch. 172, Sec. 2. (AB 713) Effective September 25, 2020.)\n\n1798.148.  (a) A business or other person shall not reidentify, or attempt to reidentify, information that has met the requirements of paragraph (4) of subdivision (a) of Section 1798.146, except for one or more of the following purposes:\n(1) Treatment, payment, or health care operations conducted by a covered entity or business associate acting on behalf of, and at the written direction of, the covered entity. For purposes of this paragraph, \u201ctreatment,\u201d \u201cpayment,\u201d \u201chealth care operations,\u201d \u201ccovered entity,\u201d and \u201cbusiness associate\u201d have the same meaning as defined in Section 164.501 of Title 45 of the Code of Federal Regulations.\n\n(2) Public health activities or purposes as described in Section 164.512 of Title 45 of the Code of Federal Regulations.\n\n(3) Research, as defined in Section 164.501 of Title 45 of the Code of Federal Regulations, that is conducted in accordance with Part 46 of Title 45 of the Code of Federal Regulations, the Federal Policy for the Protection of Human Subjects, also known as the Common Rule.\n\n(4) Pursuant to a contract where the lawful holder of the deidentified information that met the requirements of paragraph (4) of subdivision (a) of Section 1798.146 expressly engages a person or entity to attempt to reidentify the deidentified information in order to conduct testing, analysis, or validation of deidentification, or related statistical techniques, if the contract bans any other use or disclosure of the reidentified information and requires the return or destruction of the information that was reidentified upon completion of the contract.\n\n(5) If otherwise required by law.\n\n(b) In accordance with paragraph (4) of subdivision (a) of Section 1798.146, information reidentified pursuant this section shall be subject to applicable federal and state data privacy and security laws including, but not limited to, the Health Insurance Portability and Accountability Act, the Confidentiality of Medical Information Act, and this title.\n(c) Beginning January 1, 2021, any contract for the sale or license of deidentified information that has met the requirements of paragraph (4) of subdivision (a) of Section 1798.146, where one of the parties is a person residing or doing business in the state, shall include the following, or substantially similar, provisions:\n(1) A statement that the deidentified information being sold or licensed includes deidentified patient information.\n\n(2) A statement that reidentification, and attempted reidentification, of the deidentified information by the purchaser or licensee of the information is prohibited pursuant to this section.\n\n(3) A requirement that, unless otherwise required by law, the purchaser or licensee of the deidentified information may not further disclose the deidentified information to any third party unless the third party is contractually bound by the same or stricter restrictions and conditions.\n\n(d) For purposes of this section, \u201creidentify\u201d means the process of reversal of deidentification techniques, including, but not limited to, the addition of specific pieces of information or data elements that can, individually or in combination, be used to uniquely identify an individual or usage of any statistical method, contrivance, computer software, or other means that have the effect of associating deidentified information with a specific identifiable individual.\n(Added by Stats. 2020, Ch. 172, Sec. 3. (AB 713) Effective September 25, 2020.)\n\n1798.150.  Personal Information Security Breaches\n(a) (1) Any consumer whose nonencrypted and nonredacted personal information, as defined in subparagraph (A) of paragraph (1) of subdivision (d) of Section 1798.81.5, or whose email address in combination with a password or security question and answer that would permit access to the account is subject to an unauthorized access and exfiltration, theft, or disclosure as a result of the business\u2019 violation of the duty to implement and maintain reasonable security procedures and practices appropriate to the nature of the information to protect the personal information may institute a civil action for any of the following:\n(A) To recover damages in an amount not less than one hundred dollars ($100) and not greater than seven hundred and fifty ($750) per consumer per incident or actual damages, whichever is greater. The amounts in this subdivision shall be adjusted pursuant to subdivision (d) of Section 1798.199.95.\n\n(B) Injunctive or declaratory relief.\n\n(C) Any other relief the court deems proper.\n\n(2) In assessing the amount of statutory damages, the court shall consider any one or more of the relevant circumstances presented by any of the parties to the case, including, but not limited to, the nature and seriousness of the misconduct, the number of violations, the persistence of the misconduct, the length of time over which the misconduct occurred, the willfulness of the defendant\u2019s misconduct, and the defendant\u2019s assets, liabilities, and net worth.\n\n(b) Actions pursuant to this section may be brought by a consumer if, prior to initiating any action against a business for statutory damages on an individual or class-wide basis, a consumer provides a business 30 days\u2019 written notice identifying the specific provisions of this title the consumer alleges have been or are being violated. In the event a cure is possible, if within the 30 days the business actually cures the noticed violation and provides the consumer an express written statement that the violations have been cured and that no further violations shall occur, no action for individual statutory damages or class-wide statutory damages may be initiated against the business. The implementation and maintenance of reasonable security procedures and practices pursuant to Section 1798.81.5 following a breach does not constitute a cure with respect to that breach. No notice shall be required prior to an individual consumer initiating an action solely for actual pecuniary damages suffered as a result of the alleged violations of this title. If a business continues to violate this title in breach of the express written statement provided to the consumer under this section, the consumer may initiate an action against the business to enforce the written statement and may pursue statutory damages for each breach of the express written statement, as well as any other violation of the title that postdates the written statement.\n(c) The cause of action established by this section shall apply only to violations as defined in subdivision (a) and shall not be based on violations of any other section of this title. Nothing in this title shall be interpreted to serve as the basis for a private right of action under any other law. This shall not be construed to relieve any party from any duties or obligations imposed under other law or the United States or California Constitution.\n(Amended by Stats. 2024, Ch. 121, Sec. 6. (AB 3286) Effective January 1, 2025.)\n\n1798.155.  Administrative Enforcement\n(a) Any business, service provider, contractor, or other person that violates this title shall be liable for an administrative fine of not more than two thousand five hundred dollars ($2,500) for each violation or seven thousand five hundred dollars ($7,500) for each intentional violation or violations involving the personal information of consumers whom the business, service provider, contractor, or other person has actual knowledge are under 16 years of age, as adjusted pursuant to subdivision (d) of Section 1798.199.95, in an administrative enforcement action brought by the California Privacy Protection Agency.\n(b) Any administrative fine assessed for a violation of this title, and the proceeds of any settlement of an action brought pursuant to subdivision (a), shall be deposited in the Consumer Privacy Fund, created within the General Fund pursuant to subdivision (a) of Section 1798.160 with the intent to fully offset any costs incurred by the state courts, the Attorney General, and the California Privacy Protection Agency in connection with this title.\n(Amended by Stats. 2024, Ch. 121, Sec. 7. (AB 3286) Effective January 1, 2025.)\n\n1798.160.  Consumer Privacy Fund\n(a) A special fund to be known as the \u201cConsumer Privacy Fund\u201d is hereby created within the General Fund in the State Treasury, and is available upon appropriation by the Legislature first to offset any costs incurred by the state courts in connection with actions brought to enforce this title, the costs incurred by the California Privacy Protection Agency in carrying out its duties under this title, the costs incurred by the Attorney General in carrying out the Attorney General\u2019s duties under this title, and then for the purposes of establishing an investment fund in the State Treasury, with any earnings or interest from the fund to be deposited in the General Fund, and making grants to promote and protect consumer privacy, educate children in the area of online privacy, and fund cooperative programs with international law enforcement organizations to combat fraudulent activities with respect to consumer data breaches.\n(b) Funds transferred to the Consumer Privacy Fund shall be used exclusively as follows:\n(1) To offset any costs incurred by the state courts, the California Privacy Protection Agency, and the Attorney General in connection with this title.\n\n(2) After satisfying the obligations under paragraph (1), the remaining funds shall be allocated each fiscal year as follows:\n\n(A) Ninety-one percent shall be invested by the Treasurer in financial assets with the goal of maximizing long-term yields consistent with a prudent level of risk. The principal shall not be subject to transfer or appropriation, provided that any interest and earnings shall be transferred on an annual basis to the General Fund for appropriation by the Legislature for General Fund purposes.\n\n(B) Subject to subdivision (d), 9 percent shall be made available to the California Privacy Protection Agency for the purposes of making grants in California, with 3 percent allocated to each of the following grant recipients:\n\n(i) Nonprofit organizations to promote and protect consumer privacy.\n\n(ii) Nonprofit organizations and public agencies, including school districts, to educate children in the area of online privacy.\n\n(iii) State and local law enforcement agencies to fund cooperative programs with international law enforcement organizations to combat fraudulent activities with respect to consumer data breaches.\n\n(c) Funds in the Consumer Privacy Fund shall not be subject to appropriation or transfer by the Legislature for any other purpose.\n(d) (1) The California Privacy Protection Agency shall begin administering the grant program described in subparagraph (B) of paragraph (2) of subdivision (b) when the amount of grant funds available after all other distributions have been made in accordance with this section exceeds three hundred thousand dollars ($300,000).\n(2) In a fiscal year in which the amount of funds available for grants pursuant to subparagraph (B) of paragraph (2) of subdivision (b) are equal to or less than three hundred thousand dollars ($300,000), the funds shall remain in the Consumer Privacy Fund and that amount shall be reserved for future year appropriations for the purpose of making grants pursuant to subparagraph (B) of paragraph (2) of subdivision (b) until the total funds accrued for that purpose after all other distributions have been made exceeds three hundred thousand dollars ($300,000).\n\n(Amended by Stats. 2024, Ch. 121, Sec. 8. (AB 3286) Effective January 1, 2025.)\n\n1798.175.  Conflicting Provisions\nThis title is intended to further the constitutional right of privacy and to supplement existing laws relating to consumers\u2019 personal information, including, but not limited to, Chapter 22 (commencing with Section 22575) of Division 8 of the Business and Professions Code and Title 1.81 (commencing with Section 1798.80). The provisions of this title are not limited to information collected electronically or over the Internet, but apply to the collection and sale of all personal information collected by a business from consumers. Wherever possible, law relating to consumers\u2019 personal information should be construed to harmonize with the provisions of this title, but in the event of a conflict between other laws and the provisions of this title, the provisions of the law that afford the greatest protection for the right of privacy for consumers shall control.\n(Amended November 3, 2020, by initiative Proposition 24, Sec. 19. Effective December 16, 2020. Operative January 1, 2023, pursuant to Sec. 31 of Proposition 24.)\n\n1798.180.  Preemption\nThis title is a matter of statewide concern and supersedes and preempts all rules, regulations, codes, ordinances, and other laws adopted by a city, county, city and county, municipality, or local agency regarding the collection and sale of consumers\u2019 personal information by a business.\n(Amended November 3, 2020, by initiative Proposition 24, Sec. 20. Effective December 16, 2020. Operative January 1, 2023, pursuant to Sec. 31 of Proposition 24.)\n\n1798.185.  Regulations\n(a) On or before July 1, 2020, the Attorney General shall solicit broad public participation and adopt regulations to further the purposes of this title, including, but not limited to, the following areas:\n(1) Updating or adding categories of personal information to those enumerated in subdivision (c) of Section 1798.130 and subdivision (v) of Section 1798.140, and updating or adding categories of sensitive personal information to those enumerated in subdivision (ae) of Section 1798.140 in order to address changes in technology, data collection practices, obstacles to implementation, and privacy concerns.\n\n(2) Updating as needed the definitions of \u201cdeidentified\u201d and \u201cunique identifier\u201d to address changes in technology, data collection, obstacles to implementation, and privacy concerns, and adding, modifying, or deleting categories to the definition of designated methods for submitting requests to facilitate a consumer\u2019s ability to obtain information from a business pursuant to Section 1798.130. The authority to update the definition of \u201cdeidentified\u201d shall not apply to deidentification standards set forth in Section 164.514 of Title 45 of the Code of Federal Regulations, where such information previously was \u201cprotected health information\u201d as defined in Section 160.103 of Title 45 of the Code of Federal Regulations.\n\n(3) Establishing any exceptions necessary to comply with state or federal law, including, but not limited to, those relating to trade secrets and intellectual property rights, within one year of passage of this title and as needed thereafter, with the intention that trade secrets should not be disclosed in response to a verifiable consumer request.\n\n(4) Establishing rules and procedures for the following:\n\n(A) To facilitate and govern the submission of a request by a consumer to opt out of the sale or sharing of personal information pursuant to Section 1798.120 and to limit the use of a consumer\u2019s sensitive personal information pursuant to Section 1798.121 to ensure that consumers have the ability to exercise their choices without undue burden and to prevent business from engaging in deceptive or harassing conduct, including in retaliation against consumers for exercising their rights, while allowing businesses to inform consumers of the consequences of their decision to opt out of the sale or sharing of their personal information or to limit the use of their sensitive personal information.\n\n(B) To govern business compliance with a consumer\u2019s opt-out request.\n\n(C) For the development and use of a recognizable and uniform opt-out logo or button by all businesses to promote consumer awareness of the opportunity to opt out of the sale of personal information.\n\n(5) Establishing rules, procedures, and any exceptions necessary to ensure that the notices and information that businesses are required to provide pursuant to this title are provided in a manner that may be easily understood by the average consumer, are accessible to consumers with disabilities, and are available in the language primarily used to interact with the consumer, including establishing rules and guidelines regarding financial incentives within one year of passage of this title and as needed thereafter.\n\n(6) Establishing rules and procedures to further the purposes of Sections 1798.105, 1798.106, 1798.110, and 1798.115 and to facilitate a consumer\u2019s or the consumer\u2019s authorized agent\u2019s ability to delete personal information, correct inaccurate personal information pursuant to Section 1798.106, or obtain information pursuant to Section 1798.130, with the goal of minimizing the administrative burden on consumers, taking into account available technology, security concerns, and the burden on the business, to govern a business\u2019 determination that a request for information received from a consumer is a verifiable consumer request, including treating a request submitted through a password-protected account maintained by the consumer with the business while the consumer is logged into the account as a verifiable consumer request and providing a mechanism for a consumer who does not maintain an account with the business to request information through the business\u2019 authentication of the consumer\u2019s identity, within one year of passage of this title and as needed thereafter.\n\n(7) Establishing how often, and under what circumstances, a consumer may request a correction pursuant to Section 1798.106, including standards governing the following:\n\n(A) How a business responds to a request for correction, including exceptions for requests to which a response is impossible or would involve disproportionate effort, and requests for correction of accurate information.\n\n(B) How concerns regarding the accuracy of the information may be resolved.\n\n(C) The steps a business may take to prevent fraud.\n\n(D) If a business rejects a request to correct personal information collected and analyzed concerning a consumer\u2019s health, the right of a consumer to provide a written addendum to the business with respect to any item or statement regarding any such personal information that the consumer believes to be incomplete or incorrect. The addendum shall be limited to 250 words per alleged incomplete or incorrect item and shall clearly indicate in writing that the consumer requests the addendum to be made a part of the consumer\u2019s record.\n\n(8) Establishing the standard to govern a business\u2019 determination, pursuant to subparagraph (B) of paragraph (2) of subdivision (a) of Section 1798.130, that providing information beyond the 12-month period in a response to a verifiable consumer request is impossible or would involve a disproportionate effort.\n\n(9) Issuing regulations further defining and adding to the business purposes, including other notified purposes, for which businesses, service providers, and contractors may use consumers\u2019 personal information consistent with consumers\u2019 expectations, and further defining the business purposes for which service providers and contractors may combine consumers\u2019 personal information obtained from different sources, except as provided for in paragraph (6) of subdivision (e) of Section 1798.140.\n\n(10) Issuing regulations identifying those business purposes, including other notified purposes, for which service providers and contractors may use consumers\u2019 personal information received pursuant to a written contract with a business, for the service provider or contractor\u2019s own business purposes, with the goal of maximizing consumer privacy.\n\n(11) Issuing regulations to further define \u201cintentionally interacts,\u201d with the goal of maximizing consumer privacy.\n\n(12) Issuing regulations to further define \u201cprecise geolocation,\u201d including if the size defined is not sufficient to protect consumer privacy in sparsely populated areas or when the personal information is used for normal operational purposes, including billing.\n\n(13) Issuing regulations to define the term \u201cspecific pieces of information obtained from the consumer\u201d with the goal of maximizing a consumer\u2019s right to access relevant personal information while minimizing the delivery of information to a consumer that would not be useful to the consumer, including system log information and other technical data. For delivery of the most sensitive personal information, the regulations may require a higher standard of authentication provided that the agency shall monitor the impact of the higher standard on the right of consumers to obtain their personal information to ensure that the requirements of verification do not result in the unreasonable denial of verifiable consumer requests.\n\n(14) Issuing regulations requiring businesses whose processing of consumers\u2019 personal information presents significant risk to consumers\u2019 privacy or security, to:\n\n(A) Perform a cybersecurity audit on an annual basis, including defining the scope of the audit and establishing a process to ensure that audits are thorough and independent. The factors to be considered in determining when processing may result in significant risk to the security of personal information shall include the size and complexity of the business and the nature and scope of processing activities.\n\n(B) Submit to the California Privacy Protection Agency on a regular basis a risk assessment with respect to their processing of personal information, including whether the processing involves sensitive personal information, and identifying and weighing the benefits resulting from the processing to the business, the consumer, other stakeholders, and the public, against the potential risks to the rights of the consumer associated with that processing, with the goal of restricting or prohibiting the processing if the risks to privacy of the consumer outweigh the benefits resulting from processing to the consumer, the business, other stakeholders, and the public. Nothing in this section shall require a business to divulge trade secrets.\n\n(15) Issuing regulations governing access and opt-out rights with respect to a business\u2019 use of automated decisionmaking technology, including profiling and requiring a business\u2019 response to access requests to include meaningful information about the logic involved in those decisionmaking processes, as well as a description of the likely outcome of the process with respect to the consumer.\n\n(16) Issuing regulations to further define a \u201claw enforcement agency-approved investigation\u201d for purposes of the exception in subparagraph (B) of paragraph (1) of subdivision (a) of Section 1798.145.\n\n(17) Issuing regulations to define the scope and process for the exercise of the agency\u2019s audit authority, to establish criteria for selection of persons to audit, and to protect consumers\u2019 personal information from disclosure to an auditor in the absence of a court order, warrant, or subpoena.\n\n(18) (A) Issuing regulations to define the requirements and technical specifications for an opt-out preference signal sent by a platform, technology, or mechanism, to indicate a consumer\u2019s intent to opt out of the sale or sharing of the consumer\u2019s personal information and to limit the use or disclosure of the consumer\u2019s sensitive personal information. The requirements and specifications for the opt-out preference signal should be updated from time to time to reflect the means by which consumers interact with businesses, and should:\n\n(i) Ensure that the manufacturer of a platform or browser or device that sends the opt-out preference signal cannot unfairly disadvantage another business.\n\n(ii) Ensure that the opt-out preference signal is consumer-friendly, clearly described, and easy to use by an average consumer and does not require that the consumer provide additional information beyond what is necessary.\n\n(iii) Clearly represent a consumer\u2019s intent and be free of defaults constraining or presupposing that intent.\n\n(iv) Ensure that the opt-out preference signal does not conflict with other commonly used privacy settings or tools that consumers may employ.\n\n(v) Provide a mechanism for the consumer to selectively consent to a business\u2019 sale of the consumer\u2019s personal information, or the use or disclosure of the consumer\u2019s sensitive personal information, without affecting the consumer\u2019s preferences with respect to other businesses or disabling the opt-out preference signal globally.\n\n(vi) State that in the case of a page or setting view that the consumer accesses to set the opt-out preference signal, the consumer should see up to three choices, including:\n\n(I) Global opt out from sale and sharing of personal information, including a direction to limit the use of sensitive personal information.\n\n(II) Choice to \u201cLimit the Use of My Sensitive Personal Information.\u201d\n\n(III) Choice titled \u201cDo Not Sell/Do Not Share My Personal Information for Cross-Context Behavioral Advertising.\u201d\n\n(B) Issuing regulations to establish technical specifications for an opt-out preference signal that allows the consumer, or the consumer\u2019s parent or guardian, to specify that the consumer is less than 13 years of age or at least 13 years of age and less than 16 years of age.\n\n(C) Issuing regulations, with the goal of strengthening consumer privacy while considering the legitimate operational interests of businesses, to govern the use or disclosure of a consumer\u2019s sensitive personal information, notwithstanding the consumer\u2019s direction to limit the use or disclosure of the consumer\u2019s sensitive personal information, including:\n\n(i) Determining any additional purposes for which a business may use or disclose a consumer\u2019s sensitive personal information.\n\n(ii) Determining the scope of activities permitted under paragraph (8) of subdivision (e) of Section 1798.140, as authorized by subdivision (a) of Section 1798.121, to ensure that the activities do not involve health-related research.\n\n(iii) Ensuring the functionality of the business\u2019 operations.\n\n(iv) Ensuring that the exemption in subdivision (d) of Section 1798.121 for sensitive personal information applies to information that is collected or processed incidentally, or without the purpose of inferring characteristics about a consumer, while ensuring that businesses do not use the exemption for the purpose of evading consumers\u2019 rights to limit the use and disclosure of their sensitive personal information under Section 1798.121.\n\n(19) Issuing regulations to govern how a business that has elected to comply with subdivision (b) of Section 1798.135 responds to the opt-out preference signal and provides consumers with the opportunity subsequently to consent to the sale or sharing of their personal information or the use and disclosure of their sensitive personal information for purposes in addition to those authorized by subdivision (a) of Section 1798.121. The regulations should:\n\n(A) Strive to promote competition and consumer choice and be technology neutral.\n\n(B) Ensure that the business does not respond to an opt-out preference signal by:\n\n(i) Intentionally degrading the functionality of the consumer experience.\n\n(ii) Charging the consumer a fee in response to the consumer\u2019s opt-out preferences.\n\n(iii) Making any products or services not function properly or fully for the consumer, as compared to consumers who do not use the opt-out preference signal.\n\n(iv) Attempting to coerce the consumer to opt in to the sale or sharing of the consumer\u2019s personal information, or the use or disclosure of the consumer\u2019s sensitive personal information, by stating or implying that the use of the opt-out preference signal will adversely affect the consumer as compared to consumers who do not use the opt-out preference signal, including stating or implying that the consumer will not be able to use the business\u2019 products or services or that those products or services may not function properly or fully.\n\n(v) Displaying any notification or pop-up in response to the consumer\u2019s opt-out preference signal.\n\n(C) Ensure that any link to a web page or its supporting content that allows the consumer to consent to opt in:\n\n(i) Is not part of a popup, notice, banner, or other intrusive design that obscures any part of the web page the consumer intended to visit from full view or that interferes with or impedes in any way the consumer\u2019s experience visiting or browsing the web page or internet website the consumer intended to visit.\n\n(ii) Does not require or imply that the consumer must click the link to receive full functionality of any products or services, including the internet website.\n\n(iii) Does not make use of any dark patterns.\n\n(iv) Applies only to the business with which the consumer intends to interact.\n\n(D) Strive to curb coercive or deceptive practices in response to an opt-out preference signal but should not unduly restrict businesses that are trying in good faith to comply with Section 1798.135.\n\n(20) Review existing Insurance Code provisions and regulations relating to consumer privacy, except those relating to insurance rates or pricing, to determine whether any provisions of the Insurance Code provide greater protection to consumers than the provisions of this title. Upon completing its review, the agency shall adopt a regulation that applies only the more protective provisions of this title to insurance companies. For the purpose of clarity, the Insurance Commissioner shall have jurisdiction over insurance rates and pricing.\n\n(21) Harmonizing the regulations governing opt-out mechanisms, notices to consumers, and other operational mechanisms in this title to promote clarity and the functionality of this title for consumers.\n\n(b) The Attorney General may adopt additional regulations as necessary to further the purposes of this title.\n(c) The Attorney General shall not bring an enforcement action under this title until six months after the publication of the final regulations issued pursuant to this section or July 1, 2020, whichever is sooner.\n(d) Notwithstanding subdivision (a), the timeline for adopting final regulations required by the act adding this subdivision shall be July 1, 2022. Beginning the later of July 1, 2021, or six months after the agency provides notice to the Attorney General that it is prepared to begin rulemaking under this title, the authority assigned to the Attorney General to adopt regulations under this section shall be exercised by the California Privacy Protection Agency. Notwithstanding any other law, civil and administrative enforcement of the provisions of law added or amended by this act shall not commence until July 1, 2023, and shall only apply to violations occurring on or after that date. Enforcement of provisions of law contained in the California Consumer Privacy Act of 2018 amended by this act shall remain in effect and shall be enforceable until the same provisions of this act become enforceable.\n(Amended by Stats. 2024, Ch. 121, Sec. 9. (AB 3286) Effective January 1, 2025.)\n\n1798.190.  Anti-Avoidance\nA court or the agency shall disregard the intermediate steps or transactions for purposes of effectuating the purposes of this title:\n(a) If a series of steps or transactions were component parts of a single transaction intended from the beginning to be taken with the intention of avoiding the reach of this title, including the disclosure of information by a business to a third party in order to avoid the definition of sell or share.\n(b) If steps or transactions were taken to purposely avoid the definition of sell or share by eliminating any monetary or other valuable consideration, including by entering into contracts that do not include an exchange for monetary or other valuable consideration, but where a party is obtaining something of value or use.\n(Amended November 3, 2020, by initiative Proposition 24, Sec. 22. Effective December 16, 2020. Operative January 1, 2023, pursuant to Sec. 31 of Proposition 24.)\n\n1798.192.  Waiver\nAny provision of a contract or agreement of any kind, including a representative action waiver, that purports to waive or limit in any way rights under this title, including, but not limited to, any right to a remedy or means of enforcement, shall be deemed contrary to public policy and shall be void and unenforceable. This section shall not prevent a consumer from declining to request information from a business, declining to opt out of a business\u2019s sale of the consumer\u2019s personal information, or authorizing a business to sell or share the consumer\u2019s personal information after previously opting out.\n(Amended November 3, 2020, by initiative Proposition 24, Sec. 23. Effective December 16, 2020. Operative January 1, 2023, pursuant to Sec. 31 of Proposition 24.)\n\n1798.194.  This title shall be liberally construed to effectuate its purposes.\n(Added by Stats. 2018, Ch. 55, Sec. 3. (AB 375) Effective January 1, 2019. Section operative January 1, 2020, pursuant to Section 1798.198.)\n\n1798.196.  This title is intended to supplement federal and state law, if permissible, but shall not apply if such application is preempted by, or in conflict with, federal law or the United States or California Constitution.\n(Amended (as added by Stats. 2018, Ch. 55, Sec. 3) by Stats. 2018, Ch. 735, Sec. 15. (SB 1121) Effective September 23, 2018. Section operative January 1, 2020, pursuant to Section 1798.198.)\n\n1798.198.  (a) Subject to limitation provided in subdivision (b), and in Section 1798.199, this title shall be operative January 1, 2020.\n(b) This title shall become operative only if initiative measure No. 17-0039, The Consumer Right to Privacy Act of 2018, is withdrawn from the ballot pursuant to Section 9604 of the Elections Code.\n(Amended (as added by Stats. 2018, Ch. 55, Sec. 3) by Stats. 2018, Ch. 735, Sec. 16. (SB 1121) Effective September 23, 2018.)\n\n1798.199.  Notwithstanding Section 1798.198, Section 1798.180 shall be operative on the effective date of the act adding this section.\n(Added by Stats. 2018, Ch. 735, Sec. 17. (SB 1121) Effective September 23, 2018. Operative September 23, 2018.)\n\n1798.199.10.  (a) There is hereby established in state government the California Privacy Protection Agency, which is vested with full administrative power, authority, and jurisdiction to implement and enforce the California Consumer Privacy Act of 2018. The agency shall be governed by a five-member board, including the chairperson. The chairperson and one member of the board shall be appointed by the Governor. The Attorney General, Senate Rules Committee, and Speaker of the Assembly shall each appoint one member. These appointments should be made from among Californians with expertise in the areas of privacy, technology, and consumer rights.\n(b) The initial appointments to the agency shall be made within 90 days of the effective date of the act adding this section.\n(Added November 3, 2020, by initiative Proposition 24, Sec. 24.1. Effective December 16, 2020. Operative December 16, 2020, pursuant to Sec. 31 of Proposition 24.)\n\n1798.199.15.  Members of the agency board shall:\n(a) Have qualifications, experience, and skills, in particular in the areas of privacy and technology, required to perform the duties of the agency and exercise its powers.\n(b) Maintain the confidentiality of information which has come to their knowledge in the course of the performance of their tasks or exercise of their powers, except to the extent that disclosure is required by the Public Records Act.\n(c) Remain free from external influence, whether direct or indirect, and shall neither seek nor take instructions from another.\n(d) Refrain from any action incompatible with their duties and engaging in any incompatible occupation, whether gainful or not, during their term.\n(e) Have the right of access to all information made available by the agency to the chairperson.\n(f) Be precluded, for a period of one year after leaving office, from accepting employment with a business that was subject to an enforcement action or civil action under this title during the member\u2019s tenure or during the five-year period preceding the member\u2019s appointment.\n(g) Be precluded for a period of two years after leaving office from acting, for compensation, as an agent or attorney for, or otherwise representing, any other person in a matter pending before the agency if the purpose is to influence an action of the agency.\n(Added November 3, 2020, by initiative Proposition 24, Sec. 24.2. Effective December 16, 2020. Operative December 16, 2020, pursuant to Sec. 31 of Proposition 24.)\n\n1798.199.20.  Members of the agency board, including the chairperson, shall serve at the pleasure of their appointing authority but shall serve for no longer than eight consecutive years.\n(Added November 3, 2020, by initiative Proposition 24, Sec. 24.3. Effective December 16, 2020. Operative December 16, 2020, pursuant to Sec. 31 of Proposition 24.)\n\n1798.199.25.  For each day on which they engage in official duties, members of the agency board shall be compensated at the rate of one hundred dollars ($100), adjusted pursuant to subdivision (d) of Section 1798.199.95, and shall be reimbursed for expenses incurred in performance of their official duties.\n(Amended by Stats. 2024, Ch. 121, Sec. 10. (AB 3286) Effective January 1, 2025.)\n\n1798.199.30.  The agency board shall appoint an executive director who shall act in accordance with agency policies and regulations and with applicable law. The agency shall appoint and discharge officers, counsel, and employees, consistent with applicable civil service laws, and shall fix the compensation of employees and prescribe their duties. The agency may contract for services that cannot be provided by its employees.\n(Added November 3, 2020, by initiative Proposition 24, Sec. 24.5. Effective December 16, 2020. Operative December 16, 2020, pursuant to Sec. 31 of Proposition 24.)\n\n1798.199.35.  The agency board may delegate authority to the chairperson or the executive director to act in the name of the agency between meetings of the agency, except with respect to resolution of enforcement actions and rulemaking authority.\n(Added November 3, 2020, by initiative Proposition 24, Sec. 24.6. Effective December 16, 2020. Operative December 16, 2020, pursuant to Sec. 31 of Proposition 24.)\n\n1798.199.40.  The agency shall perform the following functions:\n(a) Administer, implement, and enforce through administrative actions this title.\n(b) On and after the later of July 1, 2021, or within six months of the agency providing the Attorney General with notice that it is prepared to assume rulemaking responsibilities under this title, adopt, amend, and rescind regulations pursuant to Section 1798.185 to carry out the purposes and provisions of the California Consumer Privacy Act of 2018, including regulations specifying recordkeeping requirements for businesses to ensure compliance with this title.\n(c) Through the implementation of this title, protect the fundamental privacy rights of natural persons with respect to the use of their personal information.\n(d) Promote public awareness and understanding of the risks, rules, responsibilities, safeguards, and rights in relation to the collection, use, sale, and disclosure of personal information, including the rights of minors with respect to their own information, and provide a public report summarizing the risk assessments filed with the agency pursuant to paragraph (14) of subdivision (a) of Section 1798.185 while ensuring that data security is not compromised.\n(e) Provide guidance to consumers regarding their rights under this title.\n(f) Provide guidance to businesses regarding their duties and responsibilities under this title and appoint a Chief Privacy Auditor to conduct audits of businesses to ensure compliance with this title pursuant to regulations adopted pursuant to paragraph (17) of subdivision (a) of Section 1798.185.\n(g) Provide technical assistance and advice to the Legislature, upon request, with respect to privacy-related legislation.\n(h) Monitor relevant developments relating to the protection of personal information and, in particular, the development of information and communication technologies and commercial practices.\n(i) Cooperate with other agencies with jurisdiction over privacy laws and with data processing authorities in California, other states, territories, and countries to ensure consistent application of privacy protections.\n(j) Establish a mechanism pursuant to which persons doing business in California that do not meet the definition of business set forth in paragraph (1), (2), or (3) of subdivision (d) of Section 1798.140 may voluntarily certify that they are in compliance with this title, as set forth in paragraph (4) of subdivision (d) of Section 1798.140, and make a list of those entities available to the public.\n(k) Solicit, review, and approve applications for grants to the extent funds are available pursuant to paragraph (2) of subdivision (b) of Section 1798.160.\n(l) Perform all other acts necessary or appropriate in the exercise of its power, authority, and jurisdiction and seek to balance the goals of strengthening consumer privacy while giving attention to the impact on businesses.\n(Amended by Stats. 2024, Ch. 121, Sec. 11. (AB 3286) Effective January 1, 2025.)\n\n1798.199.45.  (a) Upon the sworn complaint of any person or on its own initiative, the agency may investigate possible violations of this title relating to any business, service provider, contractor, or person. The agency may decide not to investigate a complaint or decide to provide a business with a time period to cure the alleged violation. In making a decision not to investigate or provide more time to cure, the agency may consider the following:\n(1) Lack of intent to violate this title.\n\n(2) Voluntary efforts undertaken by the business, service provider, contractor, or person to cure the alleged violation prior to being notified by the agency of the complaint.\n\n(b) (1) The agency shall notify in writing the person who made the complaint of the action, if any, the agency has taken or plans to take on the complaint, together with the reasons for that action or nonaction.\n(2) The written notification required by this subdivision shall not include information that is subject to law enforcement exemptions and privileges, including, but not limited to, confidential information related to an investigation and information that is privileged under the Evidence Code and the Government Code.\n\n(Amended by Stats. 2024, Ch. 121, Sec. 12. (AB 3286) Effective January 1, 2025.)\n\n1798.199.50.  No finding of probable cause to believe this title has been violated shall be made by the agency unless, at least 30 days prior to the agency\u2019s consideration of the alleged violation, the business, service provider, contractor, or person alleged to have violated this title is notified of the violation by service of process or registered mail with return receipt requested, provided with a summary of the evidence, and informed of their right to be present in person and represented by counsel at any proceeding of the agency held for the purpose of considering whether probable cause exists for believing the person violated this title. Notice to the alleged violator shall be deemed made on the date of service, the date the registered mail receipt is signed, or if the registered mail receipt is not signed, the date returned by the post office. A proceeding held for the purpose of considering probable cause shall be private unless the alleged violator files with the agency a written request that the proceeding be public.\n(Added November 3, 2020, by initiative Proposition 24, Sec. 24.9. Effective December 16, 2020. Operative December 16, 2020, pursuant to Sec. 31 of Proposition 24.)\n\n1798.199.55.  (a) When the agency determines there is probable cause for believing this title has been violated, it shall hold a hearing to determine if a violation has or violations have occurred. Notice shall be given and the hearing conducted in accordance with the Administrative Procedure Act (Chapter 5 (commencing with Section 11500), Part 1, Division 3, Title 2, Government Code). The agency shall have all the powers granted by that chapter. If the agency determines on the basis of the hearing conducted pursuant to this subdivision that a violation or violations have occurred, it shall issue an order that may require the violator to do all or any of the following:\n(1) Cease and desist violation of this title.\n\n(2) Subject to Section 1798.155, pay an administrative fine of up to two thousand five hundred dollars ($2,500) for each violation, or up to seven thousand five hundred dollars ($7,500) for each intentional violation and each violation involving the personal information of minor consumers to the Consumer Privacy Fund within the General Fund of the state. When the agency determines that no violation has occurred, it shall publish a declaration so stating.\n\n(b) If two or more persons are responsible for any violation or violations, they shall be jointly and severally liable.\n(Added November 3, 2020, by initiative Proposition 24, Sec. 24.10. Effective December 16, 2020. Operative December 16, 2020, pursuant to Sec. 31 of Proposition 24.)\n\n1798.199.60.  Whenever the agency rejects the decision of an administrative law judge made pursuant to Section 11517 of the Government Code, the agency shall state the reasons in writing for rejecting the decision.\n(Added November 3, 2020, by initiative Proposition 24, Sec. 24.11. Effective December 16, 2020. Operative December 16, 2020, pursuant to Sec. 31 of Proposition 24.)\n\n1798.199.65.  The agency may subpoena witnesses, compel their attendance and testimony, administer oaths and affirmations, take evidence and require by subpoena the production of any books, papers, records, or other items material to the performance of the agency\u2019s duties or exercise of its powers, including, but not limited to, its power to audit a business\u2019 compliance with this title.\n(Added November 3, 2020, by initiative Proposition 24, Sec. 24.12. Effective December 16, 2020. Operative December 16, 2020, pursuant to Sec. 31 of Proposition 24.)\n\n1798.199.70.  No administrative action brought pursuant to this title alleging a violation of any of the provisions of this title shall be commenced more than five years after the date on which the violation occurred.\n(a) The service of the probable cause hearing notice, as required by Section 1798.199.50, upon the person alleged to have violated this title shall constitute the commencement of the administrative action.\n(b) If the person alleged to have violated this title engages in the fraudulent concealment of the person\u2019s acts or identity, the five-year period shall be tolled for the period of the concealment. For purposes of this subdivision, \u201cfraudulent concealment\u201d means the person knows of material facts related to the person\u2019s duties under this title and knowingly conceals them in performing or omitting to perform those duties for the purpose of defrauding the public of information to which it is entitled under this title.\n(c) If, upon being ordered by a superior court to produce any documents sought by a subpoena in any administrative proceeding under this title, the person alleged to have violated this title fails to produce documents in response to the order by the date ordered to comply therewith, the five-year period shall be tolled for the period of the delay from the date of filing of the motion to compel until the date the documents are produced.\n(Added November 3, 2020, by initiative Proposition 24, Sec. 24.13. Effective December 16, 2020. Operative December 16, 2020, pursuant to Sec. 31 of Proposition 24.)\n\n1798.199.75.  (a) In addition to any other available remedies, the agency may bring a civil action and obtain a judgment in superior court for the purpose of collecting any unpaid administrative fines imposed pursuant to this title after exhaustion of judicial review of the agency\u2019s action. The action may be filed as a small claims, limited civil, or unlimited civil case depending on the jurisdictional amount. The venue for this action shall be in the county where the administrative fines were imposed by the agency. In order to obtain a judgment in a proceeding under this section, the agency shall show, following the procedures and rules of evidence as applied in ordinary civil actions, all of the following:\n(1) That the administrative fines were imposed following the procedures set forth in this title and implementing regulations.\n\n(2) That the defendant or defendants in the action were notified, by actual or constructive notice, of the imposition of the administrative fines.\n\n(3) That a demand for payment has been made by the agency and full payment has not been received.\n\n(b) A civil action brought pursuant to subdivision (a) shall be commenced within four years after the date on which the administrative fines were imposed.\n(Added November 3, 2020, by initiative Proposition 24, Sec. 24.14. Effective December 16, 2020. Operative December 16, 2020, pursuant to Sec. 31 of Proposition 24.)\n\n1798.199.80.  (a) If the time for judicial review of a final agency order or decision has lapsed, or if all means of judicial review of the order or decision have been exhausted, the agency may apply to the clerk of the court for a judgment to collect the administrative fines imposed by the order or decision, or the order as modified in accordance with a decision on judicial review.\n(b) The application, which shall include a certified copy of the order or decision, or the order as modified in accordance with a decision on judicial review, and proof of service of the order or decision, constitutes a sufficient showing to warrant issuance of the judgment to collect the administrative fines. The clerk of the court shall enter the judgment immediately in conformity with the application.\n(c) An application made pursuant to this section shall be made to the clerk of the superior court in the county where the administrative fines were imposed by the agency.\n(d) A judgment entered in accordance with this section has the same force and effect as, and is subject to all the provisions of law relating to, a judgment in a civil action and may be enforced in the same manner as any other judgment of the court in which it is entered.\n(e) The agency may bring an application pursuant to this section only within four years after the date on which all means of judicial review of the order or decision have been exhausted.\n(f) The remedy available under this section is in addition to those available under any other law.\n(Added November 3, 2020, by initiative Proposition 24, Sec. 24.15. Effective December 16, 2020. Operative December 16, 2020, pursuant to Sec. 31 of Proposition 24.)\n\n1798.199.85.  Any decision of the agency with respect to a complaint or administrative fine shall be subject to judicial review in an action brought by an interested party to the complaint or administrative fine and shall be subject to an abuse of discretion standard.\n(Added November 3, 2020, by initiative Proposition 24, Sec. 24.16. Effective December 16, 2020. Operative December 16, 2020, pursuant to Sec. 31 of Proposition 24.)\n\n1798.199.90.  (a) Any business, service provider, contractor, or other person that violates this title shall be subject to an injunction and liable for a civil penalty of not more than two thousand five hundred dollars ($2,500) for each violation or seven thousand five hundred dollars ($7,500) for each intentional violation and each violation involving the personal information of minor consumers, as adjusted pursuant to subdivision (d) of Section 1798.199.95, which shall be assessed and recovered in a civil action brought in the name of the people of the State of California by the Attorney General. The court may consider the good faith cooperation of the business, service provider, contractor, or other person in determining the amount of the civil penalty.\n(b) Any civil penalty recovered by an action brought by the Attorney General for a violation of this title, and the proceeds of any settlement of any said action, shall be deposited in the Consumer Privacy Fund.\n(c) The agency shall, upon request by the Attorney General, stay an administrative action or investigation under this title to permit the Attorney General to proceed with an investigation or civil action and shall not pursue an administrative action or investigation, unless the Attorney General subsequently determines not to pursue an investigation or civil action. The agency may not limit the authority of the Attorney General to enforce this title.\n(d) No civil action may be filed by the Attorney General under this section for any violation of this title after the agency has issued a decision pursuant to Section 1798.199.85 or an order pursuant to Section 1798.199.55 against that person for the same violation.\n(e) This section shall not affect the private right of action provided for in Section 1798.150.\n(Amended by Stats. 2024, Ch. 121, Sec. 13. (AB 3286) Effective January 1, 2025.)\n\n1798.199.95.  (a) There is hereby appropriated from the General Fund of the state to the agency the sum of five million dollars ($5,000,000) during the fiscal year 2020\u201321, and the sum of ten million dollars ($10,000,000) adjusted for cost-of-living changes, during each fiscal year thereafter, for expenditure to support the operations of the agency pursuant to this title. The expenditure of funds under this appropriation shall be subject to the normal administrative review given to other state appropriations. The Legislature shall appropriate those additional amounts to the commission and other agencies as may be necessary to carry out the provisions of this title.\n(b) The Department of Finance, in preparing the state budget and the Budget Act bill submitted to the Legislature, shall include an item for the support of this title that shall indicate all of the following:\n(1) The amounts to be appropriated to other agencies to carry out their duties under this title, which amounts shall be in augmentation of the support items of those agencies.\n\n(2) The additional amounts required to be appropriated by the Legislature to the agency to carry out the purposes of this title, as provided for in this section.\n\n(3) In parentheses, for informational purposes, the continuing appropriation during each fiscal year of ten million dollars ($10,000,000), adjusted for cost-of-living changes made pursuant to this section.\n\n(c) The Attorney General shall provide staff support to the agency until the agency has hired its own staff. The Attorney General shall be reimbursed by the agency for these services.\n(d) (1) On January 1, 2025, and on January 1 of any odd-numbered year thereafter, the California Privacy Protection Agency shall adjust the monetary thresholds in subparagraph (A) of paragraph (1) of subdivision (d) of Section 1798.140, subparagraph (A) of paragraph (1) of subdivision (a) of Section 1798.150, subdivision (a) of Section 1798.155, Section 1798.199.25, and subdivision (a) of Section 1798.199.90 to reflect any increase in the Consumer Price Index.\n(2) The agency shall use the Consumer Price Index (CPI) - California, All Items, All Urban Consumers percentage change from the previous two years\u2019 reports, published by the Department of Industrial Relations, Office of the Director\u2013Research. The agency shall apply the percentage change in the CPI for the August-to-August point in time of the prior two years. The increase in the thresholds shall be rounded to the nearest whole dollar.\n\n(3) The agency shall post the adjusted monetary thresholds on its internet website no later than January 15 of the year in which the adjustment becomes effective.\n\n(4) Notwithstanding any other law, adjustments to monetary thresholds and their publication on the agency\u2019s internet website pursuant to this subdivision are not subject to the rulemaking provisions of the Administrative Procedure Act (Chapter 3.5 (commencing with Section 11340) of Part 1 of Division 3 of Title 2 of the Government Code).\n\n(Amended by Stats. 2024, Ch. 121, Sec. 14. (AB 3286) Effective January 1, 2025.)\n\n1798.199.100.  The agency and any court, as applicable, shall consider the good faith cooperation of the business, service provider, contractor, or other person in determining the amount of any administrative fine or civil penalty for a violation of this title. A business shall not be required by the agency, a court, or otherwise to pay both an administrative fine and a civil penalty for the same violation.\n(Added November 3, 2020, by initiative Proposition 24, Sec. 24.19. Effective December 16, 2020. Operative December 16, 2020, pursuant to Sec. 31 of Proposition 24.)\n", "metadata": {"country": "USA", "year": "2021", "legally_binding": "yes", "binding_proof": "It is a California state law with enforcement authority granted to the California Attorney General and California Privacy Protection Agency (CPPA).", "date": " ", "regulator": "California Attorney General and California Privacy Protection Agency ", "type": "Act", "status": "enacted ", "language": "EN", "use_cases": "[1,2, 3, 4, 5, 6]"}}
{"_id": "68674448a8f60734255f3d1a", "title": "AV Policy Guidance 4.0", "source": "https://www.transportation.gov/sites/dot.gov/files/2020-02/EnsuringAmericanLeadershipAVTech4.pdf", "text": "  \nEnsuring American Leadership in Automated Vehicle Technologies\nAutomated Vehicles 4.0\n\nA Report by the\nNATIONAL SCIENCE & TECHNOLOGY COUNCIL\nand the\nUNITED STATES DEPARTMENT OF TRANSPORTATION\nJanuary 2020\nElaine L. Chao\nUnited States Secretary of Transportation\nMichael Kratsios\nUnited States Chief Technology Officer\nAS the world leader in technology, American innovation and ingenuity have historically transformed how we travel and\nconnect with one another. Under this Administration, President Donald J. Trump has stressed the importance of ensuring\nAmerica\u2019s continued leadership in emerging technologies, including Automated Vehicles (AVs). With the development\nof AVs, America has the potential to once again transform the future of transportation, while also increasing economic\ngrowth and overall productivity. AVs\u2014if developed properly- also have the potential to make our roadways safer by\nreducing crashes caused by human error, including crashes involving impaired or distracted drivers.\nThe release of Ensuring American Leadership in Automated Vehicle Technologies: Automated Vehicles 4.0 (AV 4.0) marks another\nmilestone in American innovation. The White House and the U.S. Department of Transportation (USDOT) developed AV 4.0\nto unify efforts in automated vehicles across 38 Federal departments, independent agencies, commissions, and Executive\nOffices of The President, providing high-level guidance to Federal agencies, innovators, and all stakeholders on the U.S.\nGovernment\u2019s posture towards AVs.\nThe USDOT is actively preparing for emerging technologies by engaging with new technologies to address legitimate\npublic concerns about safety, security, and privacy without hampering innovation. With the release of Automated Driving\nSystems 2.0: A Vision for Safety (ADS 2.0) in September 2017, the USDOT provided voluntary guidance to industry, as well as\ntechnical assistance and best practices to States, offering a path forward for the safe testing and integration of Automated\nDriving Systems. In October 2018, Preparing for the Future of Transportation: Automated Vehicles 3.0 (AV 3.0) introduced guiding\nprinciples for AV innovation for all surface transportation modes, and described the USDOT\u2019s strategy to address existing\nbarriers to potential safety benefits and progress.\nBuilding upon these efforts, AV 4.0 details 10 U.S. Government principles to protect users and communities, promote\nefficient markets, and to facilitate coordinated efforts to ensure a standardized Federal approach to American leadership\nin AVs. It also presents ongoing Administration efforts supporting AV technology growth and leadership, as well as\nopportunities for collaboration including Federal investments in the AV sector and resources for AV sector innovators.\nThe landscape for AV innovation is complex and evolving. While significant investments and achievements are being made\nby industry, academia, and nonprofit organizations, further development of the technology itself is needed. Therefore,\nthis Administration continues to evaluate its priorities for Federal research and development to ensure that investments\nadvance AV innovations without duplicating industry efforts.\nThe future of transportation holds tremendous promise to strengthen the U.S. economy and make life safer and more mobile\nfor all Americans. We look forward to continued efforts to ensure America leads the world in automated vehicle technologies.\nLetter from\nThe United States Secretary of Transportation\nand the United States Chief Technology Officer\nContents\nExecutive Summary 1\nI. Automated Vehicles 1\nPotential Benefits of Automated Vehicle Technology 2\nU.S. Government Automated Vehicle Technology Principles 3\nProtect Users and Communities 4\nPromote Efficient Markets 4\nFacilitate Coordinated Efforts 5\nII. Administration Efforts Supporting Automated Vehicle\nTechnology Growth and Leadership 6\nAdvanced Manufacturing 6\nArtificial Intelligence and Machine Learning 6\nConnected Vehicles and Spectrum 6\nSTEM Education 6\nSTEM Workforce 7\nSupply Chain Integration 7\nQuantum Information Science 7\nIII. U.S. Government Activities and Opportunities for\nCollaboration 8\nA. U.S. Government Investments in the Automated Vehicle Sector 8\nSafety 8\nEnsuring Mobility for All Americans 9\nFundamental Research 11\nSecurity and Cybersecurity 21\nInfrastructure 24\nSpectrum and Connectivity 25\nEconomics and Workforce Research 27\nB. U.S. Government Enabling Activities in the Automated Vehicle Sector 27\nFostering Collaboration with Government 27\nVoluntary Consensus Standards and Other Guidance 29\nRegulatory Authority and Automated Vehicles 30\nTaxation, Trade, and Intellectual Property 31\nEnvironmental Quality 34\nCompetition, Privacy, and Market Transparency 35\nC. U.S. Government Resources for Automated Vehicle Sector Innovators 36\nFederal Laboratories Test Beds and Technology Transfer 36\nSmall Business Administration Resources 36\nUnited States Patent and Trademark Office\u2019s Inventor and Entrepreneur Resources 37\nUSAspending.gov 37\nAdditional U.S. Government Resources 37\nIV. Conclusion 37\nV. Appendix A \u2013 U.S. Government Resources 38\nVI. Appendix B \u2013 U.S. Government AV Contacts 42\nVII. Appendix C \u2013 Automated Vehicle Fast Track Action\nCommittee 43\nVIII.Appendix D \u2013 Development and Writing Team 44\nIX. Appendix E \u2013 Acronyms 46\nAbout the National Science and Technology Council 51\nAbout the Office of Science and Technology Policy 51\nAbout this Document 51\nCopyright Information 51\nAutomated Vehicles \u2014 1\nExecutive Summary\nThe United States Government is committed to fostering surface transportation innovations to ensure the United States\nleads the world in automated vehicle (AV) technology development and integration while prioritizing safety, security,\nand privacy and safeguarding the freedoms enjoyed by Americans. The U.S. Government recognizes the value of industry\nleadership in the research, development, and integration of AV innovations. Such innovation requires appropriate oversight\nby the Government to ensure safety, open markets, allocation of scarce public resources, and protection of the public\ninterest. Realizing the full potential of AVs will require collaboration and information sharing among stakeholders from\nindustry, State, local, tribal, and territorial governments, academia, not-for-profit organizations, standards development\norganizations (SDO), and the Federal Government.\nAV 4.0 presents a unifying posture to inform collaborative efforts in automated vehicles for all stakeholders and outlines\npast and current Federal Government efforts to address these areas of concern. AV 4.0 establishes U.S. Government\nprinciples that consist of three core interests, each of which is comprised of several sub-areas.\nI. Protect Users and Communities\n 1. Prioritize Safety\n 2. Emphasize Security and Cybersecurity\n 3. Ensure Privacy and Data Security\n 4. Enhance Mobility and Accessibility\nII. Promote Efficient Markets\n 5. Remain Technology Neutral\n 6. Protect American Innovation and Creativity\n 7. Modernize Regulations\nIII. Facilitate Coordinated Efforts\n 8. Promote Consistent Standards and Policies\n 9. Ensure a Consistent Federal Approach\n 10. Improve Transportation System-Level Effects\nWhile AV 4.0 cannot practically address all areas related to AVs, our intent is to facilitate and guide future efforts in a safe\nand consistent way in order to embolden AV innovators and entrepreneurs and enable the public.\nI. Automated Vehicles\nThe United States Government is committed to fostering surface transportation innovations to ensure the United States\nleads the world in automated vehicle (AV) technology development and integration while prioritizing safety, security,\nand privacy and safeguarding the freedoms enjoyed by Americans. The U.S. Government recognizes the value of industry\nleadership in the research, development, and integration of AV innovations. Such innovation requires appropriate oversight\nby the Government to ensure safety, open markets, allocation of scarce public resources, and protection of the public\ninterest. Realizing the full potential of AVs will require collaboration and information sharing among stakeholders from\nindustry, State, local, tribal, and territorial governments, academia, not-for-profit organizations, standards development\norganizations (SDO), and the Federal Government.\nThis document is not intended to be an exhaustive catalog of Federal efforts, roles, or responsibilities. Rather, it outlines\ncertain past and current Federal efforts, and compiles available key resources for innovators and entrepreneurs in the\nsurface transportation AV domain. Our purpose is to document a sample of U.S. Government investments and resources\nrelated to AVs in order to support American leadership in AV and AV-related research and development (R&D).\n 2 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nAs such, the U.S. Government AV principles outlined here may align to a greater or lesser extent with any given Federal\nagency\u2019s mission and areas of responsibilities. They are not intended to define the extent of concerns, but rather to inform\nefforts to work together in the AV domain.\nPotential Benefits of Automated Vehicle Technology\nThere are many potential benefits to increasing R&D efforts for AV technology and furthering its broad adoption and\nuse in the U.S. surface transportation system. Potential benefits to the American public could include improved safety\nand a reduction in roadway fatalities; improved quality of life, access, and mobility for all citizens; lower energy usage;\nand improved supply chain management.1\n Today\u2019s Advanced Driver Assistance Systems (ADAS) that help vehicles avoid\ncollisions form the building blocks for tomorrow\u2019s Automated Driving Systems (ADS). Advances in these technologies can\nreduce roadway crashes, fatalities, and injuries and assist the USDOT in \u201cmanaging safety risks along the path to the full\ncommercial integration of AV technology.\u201d2\nThe National Highway Traffic Safety Administration (NHTSA) has highlighted four main areas of potential benefit with regard\nto AVs: safety, economic and societal benefits, efficiency and convenience, and mobility.3\n AVs also have great potential\nbenefit for improving public safety on roadways. NHTSA\u2019s Fatality Analysis Reporting System report of traffic fatalities for\n2018 found that 36,560 people died from motor vehicle crashes in the U.S.4\n By eliminating the possibility of human error or\npoor human choices (e.g., impairment or distraction) while driving, ADS has enormous potential to save lives and reduce\nthe economic burden associated with crashes.\nThe potential economic and societal benefits of AVs could also be substantial, including increased economic productivity\nand efficiency, reduced commuting time, and even the potential reduction of the environmental impact of conventional\nsurface vehicles while increasing overall system energy efficiency.5\n In addition, adoption of AVs may provide mobility to\ncitizens who currently face transportation challenges, increasing their access to jobs and services and their ability to live\nindependently.6\nAVs also have strong potential for increased benefits in more specialized operational design domains (ODD) such as,\nthe agricultural domain, automated tractors and farm equipment have the potential to allow American farmers to track\nmultiple vehicles and monitor field operations remotely. In addition, continued improvements in sensor technologies and\nsoftware increasingly will allow equipment to operate in more complex environments and make precise observational\ndecisions, deploying herbicides only when weeds are detected, for example.7\n In the arena of commercial freight transport,\nAVs have the potential to safely haul freight long distances, which could decrease long-haul transport times and improve\n1 U.S. Congressional Research Service. Autonomous Vehicles: Emerging Policy Issues (IF10658 VERSION 3; May 23, 2017), by Bill Canis. https://crsreports.\ncongress.gov/product/pdf/IF/IF10658\n2 Chao, Elaine L. \u201cAV 3.0 Roll Out remarks by USDOT Secretary of Transportation Elaine L. Chao\u201d https://www.transportation.gov/briefing-room/av-30-\nroll-out\n3 National Highway Traffic Safety Administration. Automated Vehicles for Safety. https://www.nhtsa.gov/technology-innovation/automatedvehicles#topic-benefits\n4 National Highway Traffic Safety Administration. Automated Vehicles for Safety. https://www.nhtsa.gov/technology-innovation/automatedvehicles#topic-benefits\n5 Groshen, Erica, John Paul Macduffie, Susan Helper, and Charles Carson. 2018. America\u2019s Workforce and the Self-Driving Future: Realizing Productivity\nGains and Spurring Economic Growth. Washington, DC: Securing America\u2019s Future Energy. https://avworkforce.secureenergy.org/wp-content/\nuploads/2018/06/Americas-Workforce-and-the-Self-Driving-Future_Realizing-Productivity-Gains-and-Spurring-Economic-Growth.pdf\n6 For more information, see the following NSTC report: https://www.whitehouse.gov/wp-content/uploads/2019/03/Emerging-Tech-to-SupportAging-2019.pdf\n7 McMahon, Karen. 2018. \u201cAutomated Farm Equipment Poised to Transform Production Practices.\u201d http://www.syngenta-us.com/thrive/research/\nautomated-farm-equipment.html\nAutomated Vehicles \u2014 3\nsupply chain management efficiencies. AV technology also has the potential to dramatically reduce congestion\u2014one of the\nhighest costs for freight movement\u2014and to enable platooning technology that can reduce energy costs.8\nGiven that ADS are still currently in the R&D phase and not available for consumer purchase, data on collision rates for ADS\nunder real-world conditions are limited at this time and a standardized vocabulary and methodology for evaluating and\nregulating their safety is still being developed by NHTSA, State regulators, and other stakeholders.9\n However, numerous\ntechnologies that are related to ADS, such as automatic emergency braking, lane departure warning, and adaptive cruise\ncontrol, are already being incorporated into conventional vehicles and their effect on collision rates can be evaluated.\nAVs hold enormous potential to promote the independence, economic opportunities, and social well-being of older\nAmericans and persons with disabilities by offering independent mobility for daily activities. Reducing transportation\nrelated obstacles would enable new employment opportunities for individuals with disabilities and could save billions\nannually in healthcare expenditures from missed medical appointments.10 Ensuring that AVs will meet the needs of\nAmericans of all abilities will require carefully thought-out inclusive design to ensure widespread usability and market\npotential for persons with all types of disabilities\u2014visual, auditory, cognitive, mobility, and others.11\nThe introduction of AVs in the coming decades has the potential to substantially affect many sectors of daily life. The U.S.\nGovernment\u2019s deliberate and forward engagement of all stakeholders\u2014including industry, government, the workforce,\nand the public\u2014could help fulfill the potential for AVs to improve the quality of life for all Americans and grow the U.S.\neconomy.\nU.S. Government Automated Vehicle Technology Principles\nUSDOT, through Preparing for the Future of Transportation: Automated Vehicles 3.0,12 developed principles that encompassed\nthe equities of USDOT. In order for the American public to fully reap the individual, societal, and economic benefits of AV\ntechnology, the National Science and Technology Council\u2019s (NSTC) Automated Vehicle Fast Track Action Committee (AV\nFTAC) expanded upon USDOT\u2019s principles and adopted a total of 10 principles to protect users and communities, promote\nefficient markets, and facilitate coordinated efforts. Together, these principles will foster research, development, and\nintegration of AVs in the United States and guide consistent policy across the U.S. Government.\nThe U.S. Government will be proactive about AVs and will provide guidance, best practices, conduct research and pilot\nprograms, and other assistance to help stakeholders plan and make the investments needed for a dynamic and flexible\nfuture for all Americans. We will also prepare for complementary technologies that enhance the benefits of AVs, such as\ncommunications between vehicles and the surrounding environment, but will not assume universal implementation of\nany particular approach.\n8 DOE, Office of Energy Efficiency & Renewable Energy, Platooning Trucks to Cut Cost and Improve Efficiency. https://www.energy.gov/eere/articles/\nplatooning-trucks-cut-cost-and-improve-efficiency\n9 Fraade-Blanar, Laura, Marjory S. Blumenthal, James M. Anderson, and Nidhi Kalra. 2018. Measuring Automated Vehicle Safety: Forging a Framework.\nSanta Monica, CA: RAND Corporation. https://www.rand.org/pubs/research_reports/RR2662.html\n10 Claypool, Henry, Amitai Bin-Nun, and Jeffrey Gerlach. 2017. Self-Driving Cars: The Impact on People with Disabilities. Boston, MA: Ruderman Family\nFoundation. https://rudermanfoundation.org/wp-content/uploads/2017/08/Self-Driving-Cars-The-Impact-on-People-with-Disabilities_FINAL.pdf\n11 Bierstedt, Jane et al., 2014, \u201cEffects of Next-Generation Vehicles on Travel Demand and Highway Capacity,\u201d Princeton University. https://www.\nfehrandpeers.com/wp-content/uploads/2015/07/FP_Think_Next_Gen_Vehicle_White_Paper_FINAL.pdf\n12 Preparing for the Future of Transportation: Automated Vehicle 3.0, USDOT. https://www.transportation.gov/sites/dot.gov/files/docs/policy-initiatives/\nautomated-vehicles/320711/preparing-future-transportation-automated-vehicle-30.pdf\n 4 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nI. Protect Users and Communities\nAVs have the potential to improve physical safety for vehicle operators and occupants, pedestrians, bicyclists, motorcyclists,\nand other travelers sharing the road. To realize these benefits, we must attend to the public\u2019s safety, security, and privacy.\n1. Prioritize Safety\nThe U.S. Government will lead efforts to facilitate the safe integration of AV technologies, address potential safety risks,\nenhance the life-saving potential of AVs, and strengthen public confidence in these emerging technologies. The U.S.\nGovernment will also enforce existing laws to ensure entities do not make deceptive claims or mislead the public about\nthe performance capabilities and limitations of AV technologies including, for example, deceptive claims relating to\nvehicle safety or performance.\n2. Emphasize Security and Cybersecurity\nThe U.S. Government will support the design and implementation of secure AV technologies, the systems on which\nthey rely, and the functions that they support to adequately safeguard against the threats to security and public safety\nposed by criminal or other malicious use of AVs and related services. The U.S. Government will work with developers,\nmanufacturers, integrators, and service providers of AVs and AV services to ensure the successful prevention, mitigation,\nand investigation of crimes and security threats targeting or exploiting AVs, while safeguarding privacy, civil rights, and\ncivil liberties. These efforts include the development and promotion of physical and cybersecurity standards and best\npractices across all data mediums and domains of the transportation system to deter, detect, protect, respond, and\nsafely recover from known and evolving risks.\n3. Ensure Privacy and Data Security\nThe U.S. Government will use a holistic, risk-based approach to protect the security of data and the public\u2019s privacy as AV\ntechnologies are designed and integrated. This will include protecting driver and passenger data as well as the data of\npassive third-parties\u2014such as pedestrians about whom AVs may collect data\u2014from privacy risks such as unauthorized\naccess, collection, use, or sharing.\n4. Enhance Mobility and Accessibility\nThe U.S. Government embraces the freedom of the open road, which includes the freedom for Americans to drive their\nown vehicles. The U.S. Government envisions an environment in which AVs operate alongside conventional, manually\ndriven vehicles and other road users; therefore, the U.S. Government will protect the ability of consumers to make the\nmobility choices that best suit their needs. The U.S. Government will support AV technologies that enhance freedom by\nproviding additional options for consumers to access goods and services, allowing individuals to live and work in places\nthat fit their families\u2019 needs and expanding access to safe, affordable, accessible, and independent mobility options to\nall people, including those with disabilities and older Americans.\nII. Promote Efficient Markets\nAVs offer a dynamic area for R&D. To promote rapid development of the technologies underlying AVs, the U.S. Government\nwill promote market efforts for American investment and innovation.\n5. Remain Technology Neutral\nThe U.S. Government will adopt\u2014and promote the adoption on an international level of\u2014flexible, technology-neutral\npolicies that will allow the public, not the Federal Government or foreign governments, to choose the most economically\nefficient and effective transportation and mobility solutions. \nAutomated Vehicles \u2014 5\n6. Protect American Innovation and Creativity\nThe U.S. Government will continue to advance pro-growth policies to protect our economic prosperity and innovative\ncompetitiveness, promote new engines of growth, and to prioritize America\u2019s innovative and creative capacity in all\nsectors, including AVs. The U.S. Government will continue to promote sensitive emerging technologies through the\nprotection and enforcement of intellectual property rights\u2014patents, trademarks, copyrights, and trade secrets\u2014technical\ndata, and sensitive proprietary communications and will continue to work to prevent other nations from gaining unfair\nadvantage at the expense of American innovators.\n7. Modernize Regulations\nThe U.S. Government will modernize or eliminate outdated regulations that unnecessarily impede the development of\nAVs\u2014or that do not address critical safety, mobility, and accessibility needs\u2014to encourage a consistent regulatory and\noperational environment. In doing so, it will promote regulatory consistency among State, local, tribal and territorial, and\ninternational laws and regulations so that AVs can operate seamlessly nationwide and internationally. When regulation\nis needed, the U.S. Government will seek rules, both at home and abroad, that are as performance-based and nonprescriptive as possible and do not discriminate against American technologies, products, or services.\nIII. Facilitate Coordinated Efforts\nAVs touch upon areas of concern to Federal, State, local, tribal, and territorial governments, while also directly affecting\ninternational cooperation. This complex governance environment offers opportunities for collaboration, facilitation, and\ninformation sharing.\n8. Promote Consistent Standards and Policies\nThe U.S. Government will prioritize participation in and advocate abroad for voluntary consensus standards and evidencebased and data driven regulations. The U.S. Government will engage State, local, tribal and territorial authorities as\nwell as industry to promote the development and implementation of voluntary consensus standards, advance policies\nsupporting the integration of AVs throughout the transportation system, and seek harmonized technical standards and\nregulatory policies with international partners.\n9. Ensure a Consistent Federal Approach\nThe U.S. Government will proactively facilitate coordination of AV research, regulations, and policies across the Federal\nGovernment to ensure maximum effectiveness and leverage inter-agency resources. The U.S. Government will ensure all\nFederal dollars used for automated and connected vehicle research, grants, and any other Federal funding opportunities\nwill comply with Executive Order 13788 (Buy American and Hire American), Executive Order 13881 (Maximizing Use\nof American-Made Goods, Products, and Materials), and all current laws, regulations, and Executive orders to ensure\nAmerican growth and leadership in AV technology.\n10. Improve Transportation System-Level Effects\nThe U.S. Government will focus on opportunities to improve transportation system-level performance, efficiency, and\neffectiveness while avoiding negative transportation system-level effects from AV technologies.\n 6 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nII. Administration Efforts Supporting Automated Vehicle\nTechnology Growth and Leadership\nThe Administration has prioritized the development of AVs, including them as part of the Fiscal Year (FY) 2021 Administration\nResearch and Development Budget Priorities.13, 14\nThe Administration, through the NSTC and the White House Office of Science and Technology Policy (OSTP), has convened\nworkshops and published strategy documents to inform efforts in a number of building blocks for AV technology growth,\noutlined below. Moreover, the U.S. Government addresses a wide range of concerns related to AVs from conceptualization,\nthrough R&D, to support of commercialization. A sample of those efforts is provided here to outline these broad investments.\nAdvanced Manufacturing\nThe NSTC released A Strategy for American Leadership in Advanced Manufacturing in October 2018, which presents the\nAdministration\u2019s vision for American leadership in advanced manufacturing across industrial sectors to ensure national\nsecurity and economic prosperity.15 Advanced manufacturing offers the promise of increasing productivity and efficiency\nfor existing product types, as well as allowing for entirely new production methods.\nArtificial Intelligence and Machine Learning\nOn February 11, 2019, President Donald J. Trump signed Executive Order 13840 Maintaining American Leadership in Artificial\nIntelligence (AI), which launched the American AI Initiative. This initiative implements a whole-of-government national\nstrategy in collaboration and engagement with the private sector, academia, the public, and like-minded international\npartners. It directs Federal agencies to pursue a multipronged approach to advance AI, including: promoting sustained\nAI R&D investment, enhancing access to high-quality cyberinfrastructure and data, removing barriers to AI innovation,\nproviding education and training opportunities to prepare the American workforce for AI, and fostering an international\nenvironment favorable to American AI innovation.\nConnected Vehicles and Spectrum\nIn June 2018, the Federal Communications Commission (FCC) released the Facilitate America's Superiority in 5G Technology\nPlan (also known as the 5G FAST Plan). This plan includes three key components: (1) pushing more spectrum into the\nmarketplace; (2) updating infrastructure policy; and (3) modernizing outdated regulations.16 High-speed communications\nsupport Vehicle-to-Vehicle (V2V) and Vehicle-to-Everything (V2X) environment data exchange. Such data exchange allows\nAVs to receive and contribute data beyond their on-board sensors\u2019 physical range. Wireless technologies that complement\nthe capabilities of automated vehicle technologies are a priority of the current administration.17\nSTEM Education\nAVs are an application of a variety of contributing and complementary technologies, including advanced manufacturing,\nhigh-speed communications technologies, advanced computational capabilities, computer vision, advanced sensors,\ndata science, machine learning, and artificial intelligence. As such, education in science, technology, engineering, and\nmathematics (STEM) and computer science plays a critical role in these technological advancements. The NSTC released\n13 \u201cAdditional R&D is needed to safely and efficiently integrate autonomous driving systems and unmanned aircraft systems (UAS), including urban air\nmobility aircraft, onto our roadways and into the national airspace. Specifically, agencies should prioritize R&D to lower barriers to the deployment of\nautonomous vehicles and to develop operating standards and a traffic management system for UAS\u201d (M-18-22, July 2018).\n14 https://www.whitehouse.gov/wp-content/uploads/2019/08/FY-21-RD-Budget-Priorities.pdf\n15 For the full text, see https://www.whitehouse.gov/wp-content/uploads/2018/10/Advanced-Manufacturing-Strategic-Plan-2018.pdf\n16 The FCC\u2019s 5G FAST Plan. https://www.fcc.gov/5G\n17 Emerging Technologies and Their Expected Impact on Non-Federal Spectrum Demand, https://www.whitehouse.gov/wp-content/uploads/2019/05/\nEmerging-Technologies-and-Impact-on-Non-Federal-Spectrum-Demand-Report-May-2019.pdf\nAdministration Efforts Supporting Automated Vehicle Technology Growth and Leadership \u2014 7\nCharting a Course for Success: America\u2019s Strategy for STEM Education in December 2018, which sets out a Federal strategy for\nthe next 5 years based on a vision for a future in which all Americans have lifelong access to high-quality STEM education,\nand the United States is a global leader in STEM literacy, innovation, and employment.18\nSTEM Workforce\nAdvances in innovation are dependent on a vibrant, scientifically literate workforce. Federal STEM strategy encourages\nexpansion of educator-employer partnerships that promote work-based learning experiences to offer powerful, relevant\nways to ensure that STEM learning is authentic and engaging and that learners are prepared to succeed. The July 19,\n2018, Executive Order Establishing the President\u2019s National Council for the American Worker created the Council to develop\nrecommendations for the President on policy and strategy related to the American workforce, building upon the June 2017\nPresidential Executive Order Expanding Apprenticeships in America intended to promote the development of apprenticeship\nprograms by third parties and to prioritize the use of apprenticeships by Federal agencies.19\nSupply Chain Integration\nThe May 15, 2019, Executive Order on Securing the Information and Communications Technology and Services Supply Chain\nbanned any new acquisition, importation, transfer, installation, dealing in, or use of any information and communications\ntechnology or service (transaction) by any person subject to the jurisdiction of the United States of any products or services\nfrom a foreign-owned company or foreign person subject to a determination by the Secretary of Commerce, in consultation\nwith the heads of other departments and agencies.20\nQuantum Information Science\nThe NSTC released the National Strategic Overview for Quantum Information Science in September 2018, which lays out\na visible, systematic, national approach to quantum information research and development.21 Congress passed and the\nPresident signed into law the National Quantum Initiative Act in December 2018, which, among other activities, established\nthe Subcommittee on Quantum Information Science within NSTC, and the National Quantum Initiative Advisory\nCommittee. The Advisory Committee advises the President and the Subcommittee on the national quantum program\nand trends and developments in quantum information science and technology.22 In addition, the economic and national\nsecurity implications of quantum science are highlighted by additional coordination and funding in the National Defense\nAuthorization Act of 2018.23 Sensors, optimization, and security are areas where overlaps exist between the R&D interests\nfor AVs and quantum information science. For example, the Global Positioning System (GPS) is a well-developed example\nof how quantum technologies, in this case atomic clocks in space, have revolutionized navigation. Additional sensors based\non quantum technologies are transforming inertial navigation, a key backup technology to GPS. At the same time, new\napproaches for solving challenging multi-vehicle scheduling and optimization of machine learning systems may benefit\nfrom developments in quantum computing. Finally, the cybersecurity of automated platforms will require appropriate\nstandards that are resistant to attack from a quantum computer, as covered in the National Institute of Standards and\nTechnology (NIST) cybersecurity framework.24\n18 For the full text, see https://www.whitehouse.gov/wp-content/uploads/2018/12/STEM-Education-Strategic-Plan-2018.pdf\n19 For the full text, see https://www.whitehouse.gov/presidential-actions/3245/; https://www.whitehouse.gov/presidential-actions/executive-orderestablishing-presidents-national-council-american-worker/\n20 For the full text, see https://www.whitehouse.gov/presidential-actions/executive-order-securing-information-communications-technology-servicessupply-chain/\n21 National Strategic Overview for Quantum Information Science. https://www.whitehouse.gov/wp-content/uploads/2018/09/National-StrategicOverview-for-Quantum-Information-Science.pdf\n22 Public Law No: 115-368 (12/21/2018) National Quantum Initiative Act.\n23 https://www.congress.gov/bill/115th-congress/house-bill/2810\n24 NIST Cybersecurity Framework. https://www.nist.gov/cyberframework\n 8 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nIII. U.S. Government Activities and Opportunities for\nCollaboration\nThe U.S. Government has invested in the development of foundational and complementary technologies for AVs to advance\nnovel science and technology and provide support to innovators and entrepreneurs bringing technological advances\nto market. This continued investment will ensure public safety in a rapidly changing technological landscape, promote\ngreater economic productivity and more efficient consumption of available resources, protect intellectual property, and\nsafeguard the privacy of individuals and the security of the Nation.\nA. U.S. Government Investments in the Automated Vehicle Sector\nThe U.S. Government is actively funding AV R&D and investing in the development of technologies to enable and complement\nan efficient transition toward a transportation system in which AVs and conventional surface vehicles operate seamlessly\nand safely. These investment areas include safety, mobility, security and cybersecurity, infrastructure, and connectivity.\nSafety\nSafety is a key component for the development of a transportation system that efficiently and effectively incorporates\nAVs. The U.S. Government prioritizes safety for vehicle operators\u2014including low-speed vehicles, motorcycles, passenger\nvehicles, medium-duty vehicles, and heavy-duty commercial motor vehicles (CMVs), such as large trucks and buses\u2014and\nvehicle occupants, pedestrians, bicyclists, and all other road users.\nDepartment of Transportation\nUSDOT\u2019s mission is to ensure our Nation has the safest, most efficient, and modern transportation system in the\nworld, which improves the quality of life for all American people and communities, from rural to urban, and increases\nthe productivity and competitiveness of American workers and businesses. As a steward of the Nation\u2019s roadway\ntransportation system, the Federal Government plays a significant role in facilitating the safe and effective integration\nof AVs into the existing transportation system, alongside conventional vehicles, pedestrians, bicyclists, motorcyclists,\nand other road users. Furthermore, USDOT is provided with significant research, regulatory, and enforcement authority\nto protect the safety of the American public pertaining to various aspects of AVs, to include establishing manufacturing,\nperformance, and operational standards and supporting research that explores societal implications and interactions\nas AVs development and testing matures and eventually integration becomes increasingly common. Key modal agencies\nthat are most relevant to surface transportation AVs are NHTSA, Federal Motor Carrier Safety Administration (FMCSA),\nFederal Transit Administration (FTA), and Federal Highway Administration (FHWA):\n\u2022 NHTSA\u2019s mission is to save lives, prevent injuries, and reduce the economic costs of road traffic crashes through\neducation, research, safety standards, and enforcement activity. NHTSA sets and enforces safety performance\nstandards for motor vehicles and motor vehicle equipment, identifying safety defects, and through the development\nand delivery of effective highway safety programs for State and local jurisdictions.\n\u2022 FMCSA\u2019s mission is to reduce crashes, injuries, and fatalities involving large trucks and buses. FMCSA partners with\nindustry, safety advocates, and State and local governments to keep the Nation\u2019s roads safe and improve CMV safety\nthrough regulation, education, enforcement, research, and technology.\n\u2022 FTA provides financial and technical assistance to local public transit systems, including buses, subways, light rail, commuter\nrail, trolleys, and ferries. FTA also oversees safety measures and helps develop next-generation technology research.\n U.S. Government Activities and Opportunities for Collaboration \u2014 9\n\u2022 FHWA is responsible for providing stewardship over the construction, maintenance, and preservation of the Nation\u2019s\nhighways, bridges, and tunnels. Through research and technical assistance, the FHWA supports its partners in Federal,\nState, and local agencies to accelerate innovation and improve safety and mobility.\nNational Transportation Safety Board\nThe National Transportation Safety Board (NTSB) was established to determine the cause of certain crashes and to apply\nthe lessons discovered in each investigation through recommendations to prevent future crashes. The NTSB selects and\nprioritizes highway safety investigations by the likelihood of gaining new knowledge. It has been focusing considerable\nresources on crashes involving AV control systems. The NTSB investigates crashes of vehicles under automated control\nand applies systemic lessons from other modes of transportation where human control has been replaced with\nautomation in human-centric environments.\nFor the foreseeable future, motorists are expected to have many options for transportation, including shared AVs and\nAVs for personal use. The NTSB\u2019s work to investigate and prevent crashes could enhance public confidence by providing\nan accurate public perception that failures are taken seriously and corrected. This confidence, in turn, will help support\nmore accurate public understanding of AV technology.\nThe NTSB will also continue to advocate favorable action on recommendations germane to AVs and their building\nblocks, such as promoting the use of collision avoidance systems that confer a proven safety benefit and high potential\nto improve safety.\nEnsuring Mobility for All Americans\nFreedom of mobility is fundamental to the American way of life. AVs\u2014whether passenger vehicles or State, local, and\nprivate transportation systems\u2014have the potential to expand access and ease of movement and travel, particularly for\npeople with limited mobility due to disability, injury, or age. Therefore, the U.S. Government is dedicated to ensuring that\nAVs are designed to offer independent mobility for daily activities as well as promote economic opportunities and overall\nsocial well-being for all Americans.\nDepartment of Health and Human Services\nThe National Institute on Disability, Independent Living, and Rehabilitation Research (NIDILRR) is the primary research\narm of the Administration for Community Living (ACL) within the Department of Health and Human Services (HHS). Its\nmission is to generate new knowledge and promote its effective use to improve the abilities of individuals with disabilities\nto perform activities of their choice in the community, and to expand society\u2019s capacity to provide full opportunities and\naccommodations for citizens with disabilities.\nDepartment of the Interior\nThe National Park Service (NPS) in the Department of the Interior (DOI) is dedicated to conserving the natural and\ncultural resources and values of the NPS for the enjoyment, education, and inspiration of this and future generations.\nNPS sees AV opportunities in the near future as potential mobility aids in key locations. Exploration of AV technology\nwill provide contexts to learn how it can be integrated into NPS operations, what hurdles exist for future automation\nopportunities, and how automation will best fit within the agency\u2019s mission. Currently, NPS is establishing program and\ntechnical connections with USDOT for support of information on technical and programmatic opportunities regarding\nAVs, support for information gathering, and potential pilot testing at National Park sites.\nUSDOT hosted the Access and Mobility for All Summit to raise\nawareness of USDOT and government-wide efforts to improve\naccess and mobility for persons with disabilities, older adults,\nand individuals of low income and identify priority Federal\nand non-Federal activities and innovations that can provide\nmore efficient, affordable, and accessible vehicles and\nmobility services such as transit and ridesharing.\nThe following announcements were made by Secretary Elaine\nL. Chao during this summit:\n1. Up to $40 Million for a Complete Trip Deployment\nSolicitation\n2. $5 million in cash prizes for a planned Inclusive Design\nChallenge\n3. Notice of Funding Opportunity for FTA\u2019s FY 2020\nMobility for All Pilot Program\n4. A strategic plan for the Coordinating Council on Access\nand Mobility (CCAM)\nFor reference: (https://www.transportation.gov/accessibility)\n 10 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nDepartment of Justice\nThe Department of Justice (DOJ) enforces regulations under the Americans with Disabilities Act (ADA) that ensure equal\naccess to private transportation systems for persons with disabilities. DOJ also investigates complaints regarding disability\ndiscrimination in public transportation that it receives directly or that are referred by USDOT. The precise applicability of the\nADA\u2019s regulations and DOJ\u2019s role will depend on the type of AV at issue, who is providing or using it, and how the vehicle\nis being used. However, covered entities that choose to adopt AVs would need to do so in compliance with the ADA.\nDepartment of Transportation\nUSDOT encourages AV developers and operatorsto work\nproactively with the disability community to support\nefforts that focus on the array of accommodations\nneeded for different types of disabilities and ways to\nimprove mobility as a whole. 25\nNHTSA has the authority to set performance\nrequirements for adaptive motor vehicle equipment\nand develop exemptions that permit the modification\nof motor vehicles used by persons with disabilities.26\nAdditionally, ADA regulations require accessible,\ntimely public transportation service for passengers\nwith disabilities, including wheelchair users.27 FTA\nworks to ensure nondiscriminatory and integrated\nmobility services in support of FTA\u2019s mission to\nenhance the social and economic quality of life for\nall Americans.28 Additionally, USDOT\u2019s Accessible\nTransportation Technologies Research Initiative29\n(ATTRI) is a joint USDOT initiative, co-led by the FHWA,\nFTA, and the Intelligent Transportation Systems\nJoint Program Office30 (ITS JPO), with support from\nNIDILRR and other Federal partners. The ATTRI\nProgram is leading efforts to develop and implement\ntransformative applications to improve mobility\noptions for all travelers, particularly those with\ndisabilities.\nNational Council on Disability\nThe National Council on Disability (NCD) is an independent Federal agency comprised of Presidential and congressional\nappointees. Pursuant to its statutory mandate, 29 U.S.C. \u00a7 781, the Council is charged with reviewing Federal laws,\n25 https://www.transportation.gov/accessibility\n26 https://one.nhtsa.gov/cars/rules/adaptive/index.html\n27 https://www.fmcsa.dot.gov/regulations/americans-disabilities-act-reporting-and-other-requirements-over-road-bus-companies\n28 https://www.transit.dot.gov/regulations-and-guidance/civil-rights-ada/americans-disabilities-act\n29 https://www.its.dot.gov/research_areas/attri/index.htm\n30 https://www.its.dot.gov/automated_vehicle/avr_plan.htm\nA new generation of automated high clearance tractor\nis being equipped for crop field-based trait analyses\nwith an array of sensors for use by breeders at the USDA\nAgricultural Research Service (ARS) Arid Land Agricultural\nResearch Center (ALARC) in Maricopa, AZ. This technology\nwill replace the human piloted sensor platform shown\nbelow that is tasked with analyzing wheat for multiple traits\nsimultaneously. (Photo credit: USDA)\n U.S. Government Activities and Opportunities for Collaboration \u2014 11\nregulations, programs, and policies affecting persons with disabilities to assess the effectiveness of such laws,\nregulations, programs, and policies in meeting the needs of individuals with disabilities, and making recommendations\nto the President, Congress, officials of Federal agencies, and other Federal entities regarding ways to better promote\nequal opportunity, economic self-sufficiency, independent living, and inclusion and integration into all aspects of society\nfor Americans with disabilities.\nThe NCD provided policy recommendations on the advantages of AVs for persons with disabilities in its 2015 publication:\nSelf-Driving Cars: Mapping Access to a Technology Revolution.\n31 The report explores the emerging revolution in automobile\ntechnology and the promise it holds for persons with disabilities, as well as the obstacles the disability community faces.\nU.S. Access Board\nThe U.S. Access Board is an independent Federal agency that promotes equality for persons with disabilities through\nleadership in accessible design and the development of accessibility guidelines and standards. While the Access Board\ndoes not have rulemaking authority in the area of AVs, the agency has hosted presentations by USDOT and the Department\nof Labor (DOL) on issues related to ensuring AV accessibility for individuals with disabilities and has provided technical\nassistance on making AVs accessible to them. In addition, the Board has a Frontiers Committee that engages partners\non many aspects of AVs and released the 2018 Final Rule on Section 508 for access to technology procured and used by\nthe U.S. Government.\nFundamental Research\nThe U.S. Government fosters research, development,\nand integration of AVs and supports many ongoing and\nfuture Federal investments. Advancing AV innovation and\nexpanding the potential role of AVs in daily life requires\nthoughtful and effective design, research, demonstration,\ntesting, and validation. Numerous Federal agencies\ncarry out or support academic research on AVs and\ncomplementary technologies.\nDepartment of Agriculture\nThe U.S. Department of Agriculture (USDA) conducts\nresearch on AVs related to agricultural production and\nprocessing. The research areas include unmanned\nground vehicles (UGV), and autosteer equipment. The\nUSDA is heavily involved in the design and development\nof numerous AVs, supporting technologies and tools\nfor precision agriculture and for crop breeding such as:\nsensor development, lighting systems, voice response\nsystems, predictive modeling, AI/machine learning, rapid\nresponse control systems, robotics, big data analytics,\nand best management practice decision support tools.\n31 https://www.ncd.gov/publications/2015/self-driving-cars-mapping-access-technology-revolution\n 12 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nThe USDA\u2019s research includes a focus on developing AV tools and systems that decrease labor requirements for managing\nanimals in ranching operations.\nRobotics is another primary research area. Much of this research is funded through USDA\u2019s National Institute of Food\nand Agriculture\u2019s (NIFA) contribution to the National Robotics Initiative 2.0.32 These robotics-centered projects include\nprecision pollination, precision grazing, precision orchard harvesting, precision herbicide application, livestock health\nmonitoring, plant phenotyping, and cooperative human-robotic networks for agricultural applications.\nA new generation of automated high clearance tractor is being equipped for crop field-based trait analyses with an array\nof sensors for use by breeders at the USDA Agricultural Research Service (ARS) Arid Land Agricultural Research Center\n(ALARC) in Maricopa, AZ. This technology will replace the human piloted sensor platform shown below that is tasked with\nanalyzing wheat for multiple traits simultaneously.\nDepartment of Defense\nAutonomy plays a major role in the Department of Defense\u2019s (DoD) military missions, and its role in future military\nmissions will likely expand as the technology continues to develop. The DoD\u2019s R&D for military purposes contributes\nto R&D for civilian applications of AVs as well. The role of autonomy within the DoD is not to directly replace humans,\nbut rather to extend and complement human capabilities in a number of ways. The DoD\u2019s investments in autonomy\nfocus on developing systems that will facilitate performing complex military missions in dynamic environments with\nthe right balance of warfighter involvement. Increased investment in autonomy will enhance joint warfighter capability\nin hazardous and degraded environments, heighten speed of action, and provide scalability beyond human capability.\nAutonomy is not a single-threaded R&D program, but rather a collection of smaller programs and demonstrations.\nThe DoD is pursuing advanced technology development programs as well as several other efforts to conduct\nfundamental research. For example, the Automated Ground Resupply program also investigates improved operations\nof manned platforms through the application of a wide variety of sensing and autonomy technologies developed for\nunmanned systems. These include maneuver and tactical behavior algorithms, driver assistance techniques, autonomy\nkits, teleoperation, advanced navigation and planning, vehicle self-protection, local situational awareness, advanced\nperception, vehicle and pedestrian safety, active safety, and robotic command and control.\nThe DoD has a wide-ranging effort to improve the sensors and networking technologies for autonomous platforms. This\nincludes efforts in improving relative navigation through improvements in the GPS and inertial navigation systems driven\nby advances in quantum science. This also covers new approaches to active and passive sensing, such as improved Light\nDetection and Ranging (LIDAR) and sensor arrays for better situational awareness.\nIn another example, the Combat Vehicle Robotics (CoVeR) program researches, designs, and develops technologies\nthat enable scalable integration of multi-domain teamed robotic and automated system capabilities supporting Army\ncombat formations. It also investigates, researches, and evaluates ground vehicle technologies for both military and\ncommercial applications in collaboration with industry, universities, and other government agencies. The Research in\nVehicle Mobility program is working to develop human cognitive models to represent behavioral dynamics to work sideby-side with control algorithms in a semi-automated robotic system engaged in extreme mobility scenarios, thereby\nreplacing the need for real human-in-the-loop assessments.\nThe DoD aims to field a Joint Force architecture by 2030 that will fully integrate robotic and automated systems,\nsupplementing and augmenting manned systems and forces in an attempt to counter threats from adversaries across\nmultiple domains. However, humans must remain in the loop and play an oversight role, with the ability to activate or\n32 https://www.nsf.gov/funding/pgm_summ.jsp?pims_id=503641\n U.S. Government Activities and Opportunities for Collaboration \u2014 13\ndeactivate system functions as necessary. The DoD is developing multiple vehicle demonstration programs in support\nof its 2030 Joint Force architecture goal and to improve DoD\u2019s Non-Tactical Vehicle (NTV) mobility options. Examples\ninclude:\n\u2022 High Mobility Multipurpose Wheeled Vehicle (HMMWV) Autonomy: This effort will develop a cost-effective upgrade to\nthe existing HMMWV platform that will enable drive-by-wire control. Converting the vehicle controls from mechanical\nlinkages to electronic actuation will enable connection to computers for autonomous operation, as well as to process,\ncommunicate, and store diagnostic/sensor data for use in localization and maintenance functions.\n\u2022 Off Road Autonomy: This effort will look at several new techniques for executing off road autonomy built onto the\ncurrent Army ground autonomy architecture. This effort focuses on developing new path planning and perception\ntechniques with the intent of increasing reliability and performance for off-road unmanned maneuver systems for\nRobotics Combat Vehicle (RCV) and other platforms.\n\u2022 Situational Awareness in Dynamic Environments: This research investigates and establishes the components\nrequired for embodied intelligent ground robotic systems to achieve understanding of dynamic, highly unstructured\nenvironment to support reasoning over time and space given multi-modal sensory input.\n\u2022 NTV Automated Shuttle Pilot: Marine Corps Installations Command (MCICOM) and Army Headquarters are sponsoring\na 3-month automated non-tactical shuttle pilot on Joint Base Myer Henderson Hall. This industry-led pilot facilitates\nan opportunity for the Army's Engineering Research and Development Center (ERDC) to shadow the performers in\norder to create future automated shuttle programs on other military installations.\nDepartment of Energy\nThe Energy Efficient Mobility Systems program at the U.S. Department of Energy (DOE) is conducting fundamental\nresearch to understand the transportation \u201csystem level\u201d impact from connected and automated vehicle technologies.\nDOE researchers are creating and using large-scale agent-based models to simulate current and future mobility\ntechnologies and services, including transportation network companies (TNCs), public transit systems, and other modes\nfor transporting freight and people. These models will allow users to better understand the second and third order\nimpacts from adding a technology like AVs (e.g., induced traffic congestion due to \u201cempty\u201d AV miles or new patterns for\nland use and development) or to compare the system-wide impacts of different technologies (e.g., traffic flow impacts\nof SAE Level 4 versus Level 5 ADS-equipped vehicle33, congestion impacts of personally-owned AVs compared to fleetowned mobility service AVs).\nDOE is also using its unique High Performance Computing34 (HPC) and AI capabilities at the National Laboratories to\ndevelop methods to use AVs or connectivity to anticipate and reduce or prevent congestion. Projects are underway\nutilizing roadway and vehicle data from the Los Angeles and Chattanooga metropolitan areas. Although in its early\nstages, as more data from AVs becomes available and HPC capability increases, it will increasingly become possible to\noptimize traffic flow, and reduce costs.\nDOE is also studying how to fundamentally extend computing capability, which will likely be needed to safely operate\nSAE Level 5 ADS-equipped vehicle in a real-world, consumer-acceptable package. Given the amount of computational\ncapability necessary and the size, weight, and power constraints on a motor vehicle, dramatic improvements in the\nenergy efficiency, performance, and cost of the underlying computer systems will be needed.\nBecause transportation accounts for nearly one-third of the energy used in the United States, technologies such as AVs,\nwhich could reduce energy use associated with driving, play valuable roles in America\u2019s energy future. DOE\u2019s role with\n33 https://www.sae.org/news/2019/01/sae-updates-j3016-automated-driving-graphic\n34 https://www.energy.gov/science/initiatives/high-performance-computing\n 14 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nrespect to AVs is to develop technologies, tools, and insights that enhance the affordability, effectiveness, and energy\nefficiency of the overall transportation system. DOE leads the multi-agency 21st Century Truck Partnership35 (21CTP).\nThis public/private partnership includes DoD, USDOT, the Environmental Protection Agency (EPA), and DOE, along with\nindustry partners. This non-funded research partnership focuses on pre-competitive information exchange across four\ntechnical focus areas: internal combustion engines, electrified powertrains, operational efficiency, and safety. AVs and\nrelated mobility technologies are key parts of 21CTP\u2019s Freight Operational Efficiency and Safety technical teams. DOE also\nfunds the SuperTruck II initiative36, a competitive funding opportunity initiated in FY 2016 aimed at developing innovative,\ncost-effective technologies that can double the freight efficiency of Class 8 trucks. Automation and connectivity are\namong the technologies being considered by the five teams selected for cost-shared financial assistance awards.\nWith respect to the development of AVs for personal use, the DOE Vehicle Technologies Office (VTO) and the Advanced\nResearch Projects Agency-Energy37 (ARPA-E) have made numerous cost-shared financial assistance awards focused on\nautomated and connected vehicles and efficient mobility. VTO also had a recent Funding Opportunity Announcement\n(FOA) for mobility research (~$7 million) that included AV projects.38\nARPA-E\u2019s NEXTCAR (Next-Generation Energy Technologies for Connected and Automated On-Road Vehicles) Program\n39provided approximately $32 million in FY 2016 for 11 projects to use connected and AV technologies to improve vehiclelevel fuel efficiency through improvements in vehicle dynamics and powertrain controls.\nA 2019 DOE award will build on the progress of NEXTCAR by adapting a NEXTCAR AV algorithm for use in a SAE Level 4\nADS-equipped vehicle. The project will also implement an infrastructure-based solution that offloads computing from\nthe vehicles to roadside units for centralized perception processing at intersections that can be utilized by any connected\nvehicle. This project aims to reduce system-level energy consumption by 15%.\nA second 2019 DOE financial assistance award will develop deep-learning algorithms for AVs that smooth mixed highway\ntraffic (human-driven and automated vehicles) and reduce system-wide energy consumption by 10% through just 5% AV\npenetration. In 2018, DOE awarded over $26 million to 18 projects that will bring together key stakeholders in partnerships\nto provide data on the impact of mobility services and solutions through real-world testing (evaluation/assessment) and\nvalidation. The data, analysis, and insights from this work will fill critical information gaps to inform mobility research\nneeds, as well as near- and long-term transportation planning that maximizes energy efficiency and affordability.\nIn 2018, DOE made $5 million in financial assistance awards to demonstrate the real-world application of Class 8 Truck\nPlatooning to identify remaining roadblocks to practical application of commercial AV technology. The DoD U.S. Army\nFutures Command is a major participant in one of the projects. This builds on experimental work on which DOE and\nFHWA have collaborated for a number of years, proving the capability and energy savings from heavy truck platooning.\nIn 2017, VTO financial assistance awards funding to the Virginia Tech Transportation Institute (VTTI), University of\nCalifornia\u2013Riverside, and Clemson University to conduct research that evaluates energy savings benefits from connected\nand automated vehicles. The Clemson University project is developing anticipative and predictive AV control algorithms\nand building a novel vehicle-in-the-loop testbed to demonstrate energy savings of 10% AVs in traffic that includes both\nautomated and human-driven vehicles.\n35 https://www.energy.gov/eere/vehicles/21st-century-truck-partnership\n36 https://www.energy.gov/articles/energy-department-announces-137-million-investment-commercial-and-passenger-vehicle\n37 https://arpa-e.energy.gov/\n38 https://www.energy.gov/articles/doe-announces-59-million-and-43-projects-accelerate-advanced-vehicle-technologies-research\n https://www.energy.gov/eere/vehicles/downloads/fiscal-year-2019-advanced-vehicle-technologies-research-selections\n39 https://arpa-e.energy.gov/?q=arpa-e-programs/nextcar\nThe U.S. Government has funded various research projects\non accessible transportation technologies. Recently, FHWA\nand NIDILRR has funded a project on ATTRI: Assessment of\nRelevant Research, which was conducted by The Robotics\nInstitute at Carnegie Mellon University. This report highlights\nthe potential That Automated Vehicles hold for travelers with\ndisabilities.\n(For reference: https://www.ri.cmu.edu/wp-content/\nuploads/2017/04/3_ATTRI_ARR_2017-04.pdf)\n U.S. Government Activities and Opportunities for Collaboration \u2014 15\nDepartment of Health and Human Services\nNIDILRR\u2019s Rehabilitation Engineering Research Center\non Physical Access and Transportation at Carnegie\nMellon University is researching potential reference\ndesigns and vehicle interior concepts intended to\npromote and facilitate the accessibility of AVs for persons\nwith disabilities. This center is also conducting R&D\nto generate new knowledge about how AVs can help\naddress transportation barriers that are experienced by\npersons with disabilities in the first or last mile of a trip.\nNIDILRR\u2019s Research Project on Optimizing Accessible\nPublic Transportation, at the State University of New York\u2013Buffalo, is generating new knowledge about innovative\nsecurement systems for wheelchair users in transit buses and paratransit vehicles. This project includes research into the\nramifications of introducing automated securement systems for wheelchair users in automated transit vehicles. In order\nto provide community input into the R&D process, NIDILRR\u2019s Rehabilitation Research and Training Center on Community\nLiving Policy collected data from persons with disabilities and other critical stakeholders to inform recommendations\nfor a future research and standards/architecture development effort for fully accessible and fully automated vehicles.\nThe National Institute for Occupational Safety and Health (NIOSH) Strategic Plan, FYs 2019\u20132023, prioritizes research on\nthe health effects of AVs for truck, bus, and taxi drivers. It also prioritizes research on injury risks associated with new jobs\nthat may be created by automation and on potential stress and fatigue consequences of automation.\nNIOSH is conducting simulator-based research that will lead to recommendations for the capabilities of automation\nsensors and driver-vehicle interfaces used in heavy trucks (for example, the minimum time required for sensors to issue\na warning in time for the driver to safely re-assume control of the vehicle).\nDepartment of Homeland Security\nThe Department of Homeland Security (DHS) Science and Technology (S&T) Directorate conducts R&D on a range of\ntechnologies related to AVs, focusing on understanding their potential utility and vulnerabilities.40 Examples of DHS AV\nR&D include operating an AV test bed, spoofing protection for global navigation satellite systems, analytics for evaluating\nperformance of ADAS, and using AI and machine learning for automated systems.\nResearch examples include:\n\u2022 DHS\u2019s Homeland Security Systems Engineering and Development Institute (HSSEDI) is a Federally Funded Research\nand Development Center (FFRDC) in the process of developing an open-architecture platform to develop and\nevaluate AV technology. The purpose is to have an environment to demonstrate multi-agent autonomy, cybersecurity\nchallenges, and communications architectures applicable to potential future networked, unmanned systems. This\neffort will develop the next generation of AV test bed.\n\u2022 Since the need for resilient positioning, navigation, and timing will only increase with the advent of AVs, DHS\u2019s HSSEDI\nFFRDC is studying methods of spoofing protection for global navigation satellite systems.\n\u2022 Active safety and driver assistance systems can potentially save lives and avoid crashes, but usage and safety\nperformance of the systems remains poorly understood. DHS\u2019s HSSEDI FFRDC is researching analytics for evaluating\nperformance of ADAS.\n40 https://www.dhs.gov/science-and-technology/technology-foraging\nCARMAsm is a research program designed to develop concepts\nfor cooperative driving automation that address common\ntraffic situations, and test and evaluate resulting applications.\nCARMAsm enables ADS to navigate more safely and efficiently\nwith other vehicles and roadway infrastructure though\ncommunication and cooperation. CARMAsm aims to accelerate\nmarket readiness and the integration of cooperative\nautomated driving systems, while advancing safety, security,\ndata, and artificial intelligence. FHWA is conducting this\nwork using open source software to encourage national and\ninternational collaboration and participation by a community\nof engineers and researchers in public, private and non-profit\nsectors. (Photo credit: FHWA)\n(For reference: https://cms7.fhwa.dot.gov/research/researchprograms/operations/carma-overview)\n 16 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nDepartment of Justice\nDOJ\u2019s National Institute of Justice (NIJ) awarded $50,000 to Purdue University to identify vulnerabilities of AVs\u2019 computer\nsystems to cyber threats and to develop measures to counter those threats. NIJ also provided funding to RAND Corporation\nto host a workshop on AVs in July 2019 with the Police Executive Research Forum (PERF). The workshop highlighted\nand explored specific public safety scenarios involving AVs that have been or will be faced by law enforcement, ranging\nfrom routine police interactions with specific individual vehicles (e.g., traffic stop, accident report) as well as small- or\nlarge-scale emergency situations that may require interaction with large numbers of vehicles at once (e.g., detours,\nevacuations).\nDepartment of Transportation\nSeveral USDOT modal administrations are conducting\na wide array of research and demonstration projects\nrelated to surface transportation AVs.\n\u2022 FHWA is:\n\u2015 Investigating different roadway/automated\ndriving scenarios with a focus on the data\nand systems that will be needed to enable\nADS to exchange data to successfully navigate\nchallenging roadway scenarios.\n\u2015 Developing new modeling and simulation\ncapabilities to analyze the impact of connected\nand automated vehicles (CAVs) on the highway\nsystem, including developing new traffic\nsimulation algorithms that incorporate CAVs and\nconducting case studies to analyze impacts of CAV\ntechnologies on traffic flow and operations.\n\u2015 Pursuing an update of the Manual on Uniform\nTraffic Control Devices (MUTCD). The upcoming\nnew edition will propose updated technical\nprovisions to reflect advances in technologies and\noperational practices; incorporate recent trends\nand innovations; and set the stage for ADS as\nthose continue to take shape.\n\u2015 Funding grants for through the annual $60\nmillion Advanced Transportation and Congestion\nManagement Technologies Deployment (ATCMTD)\nprogram.41 The Fixing America\u2019s Surface Transportation Act (FAST Act) established ATCMTD to make\ncompetitive grants for the development of model deployment sites for large scale installation and operation\nof advanced transportation technologies to improve safety, efficiency, system performance, and infrastructure\nreturn on investment.\n41 https://www.fhwa.dot.gov/fastact/factsheets/advtranscongmgmtfs.cfm\n U.S. Government Activities and Opportunities for Collaboration \u2014 17\n\u2022 FMCSA is:\n\u2015 Conducting research to increase understanding of the human factors and address specific areas such as driver\nreadiness, the human-machine interface (HMI), adaptation to advanced technologies, and communication with\nothers outside the vehicle.\n\u2015 Researching safety performance of critical items such as sensors, brakes, and tires in AV CMV operations, truck\nplatooning, emergency response, and roadside inspections.\n\u2015 Conducting research to ensure that the CMV industry is adequately equipped and able to prevent or respond to\ncyber threats.\n\u2022 FTA is:\n\u2015 Conducting research to assess both user acceptance and human factors design considerations for high-priority\ntransit automation use cases involving passengers, bus operators, and other transit users to apply and conduct\npractical research in demonstrations and to identify and study potential customer acceptance issues associated\nwith fully driverless operations due to perceived security issues or distrust of technology.\n\u2015 Developing non-binding guidance, based on earlier research results and demonstration findings, on Federal\nfunding programs that may be relevant to transit automation investments.\n\u2015 Working to produce a practical reference guide for transit agencies covering key transition areas, such as vehicle\nmaintenance; human factors, labor, and training issues; customer communications; maintaining consistency in\nthe passenger experience; and transit service planning.\n\u2015 Exploring the potential transferability of AV technologies and capabilities from light and commercial vehicles to\nbus transit.42\n\u2015 Launching a series of seven demonstrations, organized by use case categories, in real-world transit environments\nas defined in the FTA Strategic Transit Automation Research (STAR) Plan.43 The demonstrations will create a testbed\nfor study of technical issues, user acceptance, operational and maintenance costs, and institutional issues, and\nwill further assess needs for standards development to ensure interoperability.\n\u2022 NHTSA is:\n\u2015 Researching unintended regulatory barriers. Historically, the Federal Motor Vehicle Safety Standards (FMVSS) have\nbeen based on the concept of a human operating the vehicle. With the introduction of ADS, the driving tasks are\nincreasingly shifted to the vehicle. The absence of a human driver creates opportunities for vehicle manufacturers\nto design new vehicle architectures that may remove driving controls, change seating configurations, and\nestablishing new interfaces for occupants.\n\u2015 NHTSA has published non-binding guidance to support the automotive industry and other key stakeholders as\nthey consider and design best practices for the testing and safe integration of Automated Driving Systems, along\nwith technical assistance to States and Best Practices for Legislatures.44\n\u2015 Researching alternative metrics and safety assessment models. This research will identify the methods, metrics,\nand tools to assess how well the ADS perform at a system level to avoid crashes including system performance and\nbehavior relative to the system\u2019s ODD and stated Object and Event Detection and Response (OEDR) capabilities.\nResearch will be conducted to explore the functional performance and safety benefits of ADS implementations.\nResearch also will be performed to study the feasibility and methods to assess normal driving capabilities of\nan ADS. The dynamic driving tasks (previously undertaken by the human driver) as behavioral competencies\n42 Transferability of Automation Technologies https://www.transit.dot.gov/sites/fta.dot.gov/files/docs/research-innovation/118161/transit-busautomation-project-transferability-automation-technologies-final-report-fta-report-no.pdf\n43 https://www.transit.dot.gov/sites/fta.dot.gov/files/docs/research-innovation/114661/strategic-transit-automation-research-report-no-0116_0.pdf\n44 https://www.nhtsa.gov/press-releases/us-dot-releases-new-automated-driving-systems-guidance\n 18 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nor maneuvers that can be measured and tested much in the way a human driver is evaluated to ensure driving\ncompetency.\n\u2015 Researching functional safety and ADS subsystems. The safe operation and reliable performance of ADS are\ncritical to public acceptance and successful integration of future ADS. As the dynamic driving tasks are transferred\nfrom the human driver to the ADS, human sensing and cognition functions are essentially being relegated to the\nmachine through a collection of integrated hardware and software subsystems. Accordingly, methods and tools\nare necessary to assess the functional safety of ADS subsystems and their building block components.\n\u2015 Researching occupant protection45 in alternative vehicle designs. Vehicle crash mechanics and occupant restraint\nsystems are not directly affected by vehicle automation. However, occupant behavior and the enhanced sensor\nsystems will affect priorities for a vehicle\u2019s safety in the event of a crash.\n\u2015 Researching human factors for ADS Vehicles, for example, vehicles that are designed in a manner where it can\nbe operated by both a driver and an ADS (e.g., dual-mode), involving control handoff between drivers and ADS\nin certain circumstances. A driver\u2019s readiness to resume control in SAE Level 3 ADS-equipped vehicle is critical to\nsafety. Driver engagement with the ADS is influenced by several issues, including the human-machine interface,\nthe driver\u2019s experience and training with the system, and other situation-specific factors that affect behavioral\nresponses.\n\u2015 Researching accessibility considerations in ADS vehicles. ADS vehicles are expected to provide mobility options not\npreviously afforded to persons with disabilities, regardless of cognitive, physical, or even the degree of condition.\nResearch has been initiated to explore the information needs of persons with disabilities and how these needs\ncould be implemented effectively within a HMI.\n\u2015 Conducting cybersecurity research to promote a layered approach to cybersecurity by focusing on a vehicle\u2019s\nentry points, both wireless and wired, which could be potentially vulnerable to a cyber-attack. A layered approach\nto vehicle cybersecurity reduces the possibility of a successful vehicle cyber-attack, and mitigates the potential\nconsequences of a successful intrusion. NHTSA has published non-binding guidance to the automotive industry\nfor improving motor vehicle cybersecurity,46 which it is currently working on updating.\n\u2022 Office of the Secretary of Transportation (OST) announced:\n\u2015 $60 million in Federal grant funding for a competitive grant program that awarded 8 recipients for ADS\ndemonstrations. 47\n\u2015 A planned Inclusive Design Challenge48, which will make up to $5 million in cash prizes available to innovators who\ndesign solutions to enable accessible automated vehicles. USDOT aims to increase availability and decrease cost\nof aftermarket modifiers that improve accessibility of vehicles today and spark development for future automated\nvehicles.\nNational Aeronautics and Space Administration\nWhile the National Aeronautics and Space Administration\u2019s (NASA) mission relates to space and aviation, in service\nof that mission NASA is developing and maturing a broad range of technologies that are also relevant to surface AVs.\nThese technologies are primarily described by the \u201cRobotics and Autonomous Systems\u201d Technology Roadmap.49 NASA\u2019s\ninvestment in this area includes work in sensing and perception, mobility, manipulation, human-system integration,\n45 https://www.nhtsa.gov/research-data/crashworthiness\n46 NHTSA, Cybersecurity Best Practices for Modern Vehicles. https://www.nhtsa.gov/sites/nhtsa.dot.gov/files/documents/sae2017chatipoglu_0.pdf\n47 https://www.transportation.gov/av/grants\n48 https://www.transportation.gov/accessibility\n49 For the full text, see https://www.nasa.gov/offices/oct/home/roadmaps\nNASA develops and deploys a wide range of operator interfaces to remotely monitor and supervise space robots, including planetary\nrovers that drive autonomously in uncertain environments. These interfaces, such as the NASA open-source \u201cVisual Environment\nfor Remote and Virtual Exploration (VERVE)\u201d, are used to visualize robot sensor data, telemetry, and remote environments as well as\nto interactively handle contingencies and exceptions. Numerous AV companies are currently developing similar systems to support\nmonitoring and supervision of AV services (delivery, taxi, etc.).\n(For reference: https://software.nasa.gov/software/ARC-16457-1A, https://ntrs.nasa.gov/search.jsp?R=20140013445)\n U.S. Government Activities and Opportunities for Collaboration \u2014 19\nsystem-level autonomy, autonomous rendezvous and docking, and systems engineering. Autonomy (both system- and\nsubsystem-level), cognition, and machine learning are integral parts that span all sub-areas, including object, event, and\nactivity recognition; robot navigation; dexterous manipulation; intent recognition and reaction; and rendezvous and\ndocking.\nNASA develops and deploys a wide range of operator interfaces to remotely monitor and supervise space robots, including\nplanetary rovers that drive autonomously in uncertain environments. These interfaces, such as the NASA open-source\n\"Visual Environment for Remote and Virtual Exploration (VERVE)\u201d, are used to visualize robot sensor data, telemetry,\nand remote environments as well as to interactively handle contingencies and exceptions. Numerous AV companies are\ncurrently developing similar systems to support monitoring and supervision of AV services (delivery, taxi, etc.).\nNASA\u2019s technology investments (including internal projects and external awards) can be tracked and analyzed using\nTechPort, a web-based, publicly available, software system that serves as NASA\u2019s integrated technology data source.50\nResearch products are archived in NASA Technical Reports Server (NTRS), which provides access to scientific and technical\ninformation (STI) created or funded by NASA including conference papers, journal articles, meeting papers, patents,\n50 For the full text, see https://techport.nasa.gov\n 20 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nresearch reports, images, movies, and technical videos.51 Technologies with foreseeable application beyond aviation,\nspace, and planetary exploration include development of higher resolution 3D range imaging sensors allowing an AV\nto perceive the surrounding landscape, map-based position estimation for navigation by surface vehicles, natural and\nhuman-made object recognition algorithms, improved routing and optimization techniques, and adaptive autonomous\nsurface navigation systems.\nNational Science Foundation\nThe National Science Foundation (NSF) supports the development of AVs, as well as analysis of the potential benefits\nand challenges of their introduction into the current transportation system through a variety of programs, primarily in\nthe Computer and Information Science and Engineering (CISE); Engineering (ENG); and Social, Behavioral, and Economic\nSciences (SBE) Directorates.\nNSF funds basic research in the three broad categories of sensing, reasoning, and acting.\n\u2022 Basic research in sensing may include improved computer vision, radar, LIDAR, mapping, and other sensing\nmodalities, as well as sensor fusion.\n\u2022 Basic research in reasoning may include real-time machine learning, perception and localization, safety guarantees\nfor control in uncertain environments, and multi-objective optimization under constraints.\n\u2022 Basic research in action may include ensuring the safety of the AV occupants as well as other road users\u2014bicyclists\nand pedestrians, trajectory and path planning, vehicle dynamics, model-predictive control, and blended control.\nIn addition, NSF funds basic research and workshops to address communication issues between AVs, social issues\nsurrounding the adoption of AVs, and a future transportation system that incorporates surface AVs. As part of NSF\u2019s\nbroad portfolio of basic research in communications, infrastructure, and human factors, NSF funds basic research and\nworkshops in:\n\u2022 Communications including spectrum research for V2V and V2I communication,\n\u2022 Security of AV systems\n\u2022 How human responses to sharing roads with AVs can help to foster trust in automated technology.\n\u2022 The relationship between user privacy and the architecture of AV sharing services.\n\u2022 How the emergence of automated trucks affects the trucking workforce and the U.S. economy.\n\u2022 How repurposing time currently taken up by driving can enhance economic productivity and worker wellbeing\nU.S. Postal Service\nThe U.S. Postal Service (USPS) operates the largest civil agency fleet of vehicles in the country with well over 200,000\nvehicles. The use of AVs offers an opportunity for USPS to improve operational efficiency and enhance the safety of postal\nworkers and the public. USPS\u2019s use of advanced technology to improve efficiency is part of the charter that recreated the\norganization in the early 1970s. USPS is conducting three AV demonstration programs:\n\u2022 Automated Rural Delivery Vehicle (Zippy) Program:52 The program created a prototype in conjunction with the\nUniversity of Michigan to identify current capabilities and value of AVs.\n\u2022 Request for Information (RFI) for Autonomous Vehicle Capability:53 USPS issued an RFI on an advanced automated\ndelivery vehicle program to produce a mail delivery vehicle for improved productivity and to evaluate current AV\ncapabilities and individual sensor technologies. The USPS received numerous responses and is developing programs\n51 https://ntrs.nasa.gov/\n52 https://www.uspsoig.gov/sites/default/files/document-library-files/2017/RARC-WP-18-001.pdf\n53 https://www.fbo.gov/spg/USPS/SSP/PhPMSC/RFI-USPS-AVC/listing.html\n U.S. Government Activities and Opportunities for Collaboration \u2014 21\nto pursue targeted research on automated technology for its vehicles. In addition to the research projects, USPS\nwill be exploring partnerships with industry leaders to leverage its vast fleet that drives to every door, every day at\ntypically low speeds to deliver the Nation\u2019s mail.\n\u2022 Automated Semi-Truck: This is an automated tractor-trailer proof of concept program operating (with safety engineer\nand driver present) on defined routes between major distribution centers in the southwest United States. USPS\nrecently completed a pilot program that included five round trips between Dallas, Texas and Phoenix, Arizona. All of\nthe automated trips were either on time or early to the respective facilities.\nSecurity and Cybersecurity\nSecurity and cybersecurity are critical for the development of a transportation system that safely and effectively incorporates\nAVs. High degrees of connectivity and automation increase the need to protect vehicle control systems and secure sensitive\ninformation. In addition, most AV manufacturers have indicated that their vehicles will use electric motors and therefore\nwill need to be plugged into the grid and connected through charging equipment. In consideration of potential increases\nto the critical technologies for both vehicles and the wider critical infrastructure, the U.S. Government is dedicated to\nproviding a secure AV environment.\nDepartment of Energy\nDOE has deep cybersecurity expertise through its national laboratories. Vehicle-related cybersecurity research to date\nhas focused on plug-in electric vehicles and the interconnections between vehicles, charging equipment, buildings,\nand the grid. However, a more holistic vehicle cyber threat assessment, including AVs, is being undertaken by Sandia\nNational Laboratory to understand whether additional research is needed.\nDepartment of Homeland Security\nThe DHS\u2019s Cybersecurity and Infrastructure Security Agency (CISA) also has deep cybersecurity expertise and leads the\nnational effort to defend critical infrastructure against today\u2019s threats, while working with partners across all levels of\ngovernment and in the private sector to secure against the evolving risks of tomorrow. CISA's integrated operations center\nprovides 24x7 cyber situational awareness, analysis, incident response, and cyber defense capabilities to the Federal\nGovernment; State, local, tribal and territorial governments; the private sector, and international partners. CISA provides\ncybersecurity tools, incident response services, and assessment capabilities to safeguard the networks that support the\nessential operations of Federal civilian departments and agencies. CISA coordinates security and resilience efforts using\ntrusted partnerships across the private and public sectors and delivers training, technical assistance, and assessments\nto Federal stakeholders as well as to infrastructure owners and operators nationwide. CISA provides consolidated allhazards risk analysis for U.S. critical infrastructure through the National Risk Management Center (NRMC).\nDepartment of Justice\nDOJ focuses on enforcing Federal law, ensuring public safety, and protecting national security. DOJ\u2019s security and\ncybersecurity interests in AV integration into our transportation system include:\n\u2022 Enforcing the Law in Cyberspace: The computer systems involved in operating and communicating with AVs make\nthe vehicles potential targets of domestic or international criminals. DOJ investigates and prosecutes criminal\nexploitation of computer systems and works with interagency, State and local, and international partners to mitigate\npublic safety and national security threats in cyberspace. In that regard, it is important to DOJ and its law enforcement\npartners that AV computer systems employ adequate cybersecurity measures to combat criminal exploitation by\ncybercriminals. It is also imperative that the data in those systems necessary to investigate crime be accessible to law\nenforcement officials, upon appropriate authorization.\n 22 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\n\u2022 Supply Chain Security: To mitigate supply chain risks to sensitive technologies, such as AVs, posed by foreign\nadversaries, DOJ\u2014as well as NHTSA\u2014evaluates proposed foreign acquisitions of U.S. businesses through the\nCommittee on Foreign Investment in the United States (CFIUS).\n\u2022 Research and Development of Best Practices for Law Enforcement: Within DOJ, NIJ is the lead Federal agency in\nresearching the application of technology to and for criminal justice purposes. NIJ not only funds research related to\nthe impact of AVs on law enforcement, but also seeks to evaluate and disseminate best practices for protecting officer\nsafety from any threats posed by AVs. Additionally, NIJ engages with State, local, tribal, and territorial law enforcement\npartners to identify their operational requirements relating to AVs and interacts with developers, manufacturers, and\nvendors of law enforcement technology to address those requirements.\n\u2022 Federal Law Enforcement Use of Automated Vehicles: In the future, law enforcement agencies within DOJ may seek\nto leverage AV technology to increase their law enforcement capabilities while improving officer safety, potentially\nreducing costs, and ensuring the protection of privacy, civil rights, and civil liberties.\nDepartment of Transportation\nThe National Traffic and Motor Vehicle Safety Act54 provides NHTSA with broad authority over motor vehicle and motor\nvehicle equipment. Congress created this broad authority for the purpose of reducing traffic crashes, deaths, and injuries\nresulting from traffic crashes.55 Three key components of NHTSA\u2019s authority are its ability to develop and establish safety\nstandards, to enforce the prohibition against covered parties making inoperative aspects of vehicles or motor vehicle\nequipment installed in compliance with a safety standard, and to take action to protect the public against noncompliance\nand defects that pose unreasonable risks to motor vehicle safety. NHTSA\u2019s broad authority allows the agency to remain\nnimble and responsive in the face of ever-changing technological advances, including those related to cybersecurity.\nWhile \u201cdata security\u201d and \u201cprivacy\u201d are important considerations within the context of vehicles and cybersecurity,\nthe specific possibility of software vulnerabilities and other threats or risks potentially causing a crash or safety\ndegradation to motor vehicles or motor vehicle equipment is the primary concern for NHTSA. NHTSA has established\na Vehicle Cybersecurity Response Process for Incidents Involving Safety-Critical Systems. During a significant incident,\ncoordination will be handled through DHS\u2019s National Cybersecurity & Communications Integration Center (NCCIC), with\nNHTSA having an information/advisory role and performing its statutory responsibility under the Safety Act.\nWhile cybersecurity is a critical issue for NHTSA, the emphasis for addressing cybersecurity ultimately must be with the\nindustry, which must be the primary mover and leader in this field. The agency has taken several other concrete steps\nto prepare for the eventuality of an automotive cyber incident that affects safety. In order to encourage industry to face\nthis emerging issue, NHTSA has issued non-binding best practices.56 Also, in 2015, the Industry formed the Automotive\nInformation Sharing and Analysis Center57 (Auto-ISAC) as an industry led clearinghouse to share cybersecurity information.\nThe Auto-ISAC is one of the few ISACs formed prior to a sector incident. In July 2016, the Auto ISAC published its own set\nof best practices to the public.\nWhile general consumer privacy is an important secondary concern for NHTSA, the agency works with Federal Trade\nCommission (FTC), which has primary jurisdiction over privacy issues not related to motor vehicle safety.\n54 (49 U.S.C. chapter 301) (\u201cSafety Act\u201d)\n55 49 U.S.C. \u00a7 30101\n56 NHTSA, Cybersecurity Best Practices for Modern Vehicles. https://www.nhtsa.gov/sites/nhtsa.dot.gov/files/documents/sae2017chatipoglu_0.pdf\n57 https://www.automotiveisac.com/\n U.S. Government Activities and Opportunities for Collaboration \u2014 23\nNational Institute of Standards and Technology\nThe NIST National Cybersecurity Center of Excellence58 (NCCoE) conducts research to accelerate the deployment and\nuse of secure, standards-based risk management solutions. NCCoE is a collaborative hub where industry organizations,\ngovernment agencies, and academic institutions work together to address businesses\u2019 most pressing cybersecurity\nissues. It is the responsibility of AV developers, vehicle manufacturers, parts suppliers, and all stakeholders who support\ntransportation to follow best practices, and industry standards, for managing cyber risks in the design, integration,\ntesting, and deployment of AV. The Federal Government will promote the NIST Cybersecurity Framework\u2014already a de\nfacto common measure for cybersecurity in industry\u2014for AV stakeholders. 59\nNIST\u2019s draft publication for Core Cybersecurity Feature Baseline for Securable Internet of Things (IoT) Devices: A Starting\nPoint for IoT Device Manufacturers60 is intended to help IoT device manufacturers understand the cybersecurity risks\ntheir customers face. Many IoT devices are the result of the convergence of cloud computing, mobile computing,\nembedded systems, big data, low-price hardware, and other technological advances. IoT devices can provide computing\nfunctionality, data storage, and network connectivity for equipment that previously lacked them, enabling new\nefficiencies and technological capabilities for the equipment, such as remote access for monitoring, configuration, and\ntroubleshooting.61 The draft NIST publication defines a core baseline of cybersecurity features that any manufacturers may\nvoluntarily adopt for IoT devices they produce, and also provides information on how they can identify and implement\nthe features most appropriate for their customers. This publication can be used as a resource by AV innovators to better\nunderstand cybersecurity risks to their customers and provides a core baseline of cybersecurity features that can be used\nfor potential IoT devices embedded in AVs.\nNational Security Council\nThe National Security Council62 team, with the departments and agencies, enables the President to plan and execute\nintegrated national security strategies to protect American citizens and the homeland while prioritizing national\ninterests and values. These national security strategies are informed by the National Security Strategy (2017)63 and\nits four pillars: (1) Protect the American people, the homeland, and the American way of life; (2) Promote American\nprosperity; (3) Preserve peace through strength; and (4) Advance American influence. The U.S. Government will prioritize\nthe transportation sector as one of seven sectors to prioritize cyber risk-reduction activities. The U.S. Government will\nprioritize emerging technologies critical to economic growth and security, such as AV technologies. The U.S. Government\nwill also promote and protect its National Security Innovation Base, defined as the American network of knowledge,\ncapabilities, and people that turns ideas into innovations, transforms discoveries into successful commercial products\nand companies, and protects and enhances the American way of life.\n58 National Institute of Standards and Technology. National Cybersecurity Center of Excellence. https://www.nccoe.nist.gov/\n59 NIST Cybersecurity Framework. https://www.nist.gov/cyberframework\n60 NIST 8259 draft publication for Core Cybersecurity Feature Baseline for Securable Internet of Things (IoT) Devices: A Starting Point for IoT Device\nManufacturers. https://nvlpubs.nist.gov/nistpubs/ir/2019/NIST.IR.8259-draft.pdf\n61 NISTIR 8228 Considerations for Managing Internet of Things (IoT) Cybersecurity and Privacy Risks. Page IV. https://nvlpubs.nist.gov/nistpubs/ir/2019/\nNIST.IR.8228.pdf\n62 https://www.whitehouse.gov/nsc/\n63 National Security Strategy of the United States of America. https://www.whitehouse.gov/wp-content/uploads/2017/12/NSS-Final-12-18-2017-0905.pdf\n 24 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nInfrastructure\nAcross the U.S. Government, many agencies are invested in diverse infrastructure R&D that will allow for American\nentrepreneurship and innovation. This research explores both utilizing current infrastructure and exploring new\ninfrastructure to maximize the potential of AVs.\nDepartment of Energy\nDOE\u2019s national laboratories have access to the world\u2019s fastest HPC facilities, as well as expertise in AI and big data\nanalytics. DOE has developed high-performance computing infrastructure for modeling and simulating AV software for\nperception, planning, and control. DOE\u2019s work in this area related to automation falls into two main areas: (1) efforts\nto optimize transportation systems to reduce congestion and improve throughput, and (2) developing improved AI or\ncomputing needed for AVs.\nAs an application of this computing infrastructure, Oak Ridge National Lab is working closely with a vehicle manufacturer\nto use advanced AI software (e.g., Multi-node Evolutionary Neural Networks for Deep Learning\u2014MENNDL)64 to reduce the\ndevelopment time and improve the performance of AV software for perception, planning, and control.\nThe DOE System Modeling for Accelerated Research in Transportation65 (SMART Mobility) national laboratory consortium\nwas created in 2016 to produce new knowledge, insights, and understanding about the future of mobility. The consortium\nis developing modeling and simulation tools that scale from the vehicle/traveler level to the city/regional level, and\nincorporates new and emerging mobility technologies and services. These modeling efforts include estimates of land use\nchanges and charging infrastructure demand using UrbanSimw and EVI-Pro through an iterative closed-loop simulation\nwith regional agent-based models (POLARIS and BEAM). The agent-based models provide information on travel time,\ncost, distance, and other factors by travel mode and time-of-day that are then utilized to simulate future population\nshifts, employment, market penetration of electric vehicles, and electric vehicle charging demand.\nThe research community, local governments and transportation planners, and other Federal agencies can use the\ntools to understand the outcomes of future mobility scenarios in terms of energy consumption, affordability, time and\nconvenience, and access to opportunities. The first phase of SMART Mobility will be completed at the end of FY 2019 with\na comprehensive set of modeling and simulation tools that, in combination, can fully model current and potential future\nstates of a large metropolitan area. A broad range of new mobility technologies and services, including different levels\nand effectiveness of automation, will be included.\nDepartment of Transportation\nFHWA is responsible for providing stewardship over the construction, maintenance, and preservation of the Nation\u2019s\nhighways, bridges, and tunnels. Through research66 and technical assistance, the FHWA supports its partners in Federal,\nState, and local agencies to accelerate innovation and improve safety and mobility. FHWA facilitates uniformity in traffic\ncontrol devices through its MUTCD.\nAs of early 2019, there are 89 connected vehicle deployments67 that are either planned or deployed around the country,\nand the number is growing rapidly. Based in part on the insights afforded by FHWA\u2019s National Dialogue, FHWA will\n64 https://www.ornl.gov/division/csmd/projects/multi-node-evolutionary-neural-networks-deep-learning-menndl\n65 https://www.energy.gov/eere/vehicles/energy-efficient-mobility-systems\n66 https://highways.dot.gov/research/research-and-development/research-programs\n67 Map of Connected Vehicle (CV) Deployments in the U.S. https://www.transportation.gov//sites/dot.gov/files/docs/research-and-technology/345996/\ncv-deployment-locationsusamapnodetails-2.pdf\n U.S. Government Activities and Opportunities for Collaboration \u2014 25\nfacilitate the development of a national roadway automation integration readiness strategy. The strategy will define a\nflexible framework for coordinated planning among State and local transportation agencies, and with ADS developers.\nFHWA\u2014in partnership with FMCSA\u2014awarded contracts to three teams to develop detailed proposals for a field test\nof truck platoons. The field tests will collect technical and operational data related to the vehicles, environment, and\ndrivers to assess safety, efficiency, and mobility impacts of truck platoons on the transportation system. In addition,\nFHWA is conducting research to better understand the impacts truck platoons may have on roadway infrastructure, e.g.,\npavement and bridges.\nFHWA\u2014in coordination with the ITS JPO\u2014is supporting a Work Zone Data Exchange68 (WZDx) initiative for AVs. Accurate\nand up-to-date information about dynamic conditions occurring on the roads\u2014such as work zones\u2014can help AVs\nnavigate safely and efficiently. The WZDx initiative seeks to set the foundation for development of other data set that will\nfacilitate AV integration in to our Nation\u2019s roadway systems.\nSpectrum and Connectivity\nAs AVs become more prevalent on American roads, access to spectrum cooperation and connectivity may become\nincreasingly important. Therefore, the U.S. Government will focus on the use and management on this important spectrum.\nDepartment of Energy\nDOE-sponsored research has shown that in addition to safety benefits, connectivity can be a significant enabler to\nreducing congestion on our roadways. Congestion increases fuel consumption and comes at a significant economic\ncost to businesses, causing delays for consumers, increasing emissions, and contributing to fatalities and injuries.\nConnectivity also enables vehicles to drive more efficiently in a range of settings\u2014including on freeways, arterial roads,\nwhen merging, and at intersections\u2014saving significant amounts of fuel/energy. These benefits require complementary\ntechnologies such as vehicle-to-vehicle and vehicle-to-infrastructure connectivity that has very high bandwidth and low\nlatency.\nDepartment of Homeland Security\nIn July 2019, DHS\u2019s CISA released a risk and resilience note providing an overview of risks introduced by 5G adoption in\nthe United States.69 It highlights a number of risk management mitigations including ensuring robust security capabilities\nfor 5G applications and services.\nDepartment of Transportation\nUSDOT is collaborating with public and private partners, including State and local governments, vehicle and device\nmanufacturers, and academia, to advance connected vehicle development and implementation. ITS JPO is working\nwith modal administrations within USDOT to coordinate and foster the advancement of connected vehicle technologies.\nSignificant progress has already been made in testing connected vehicle technologies and applications in real-world\nsituations. USDOT\u2019s Connected Vehicle Safety Pilot Program70 provided large amounts of valuable data on how these\ntechnologies, applications, and systems perform in the hands of everyday drivers. USDOT strongly supports preserving\nthe ability for transportation safety applications to function in the 5.9GHz Safety Band.71\n68 https://github.com/usdot-jpo-ode/jpo-wzdx/blob/master/README.md\n69 https://www.dhs.gov/sites/default/files/publications/19_0731_cisa_5th-generation-mobile-networks-overview.pdf\n70 https://www.its.dot.gov/pilots/pilots_overview.htm\n71 https://www.transportation.gov/content/safety-band\n 26 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nFederal Communications Commission and National Telecommunications and Information Administration\nThe FCC is the United States\u2019 primary authority for communications law, regulation, and technological innovation and is\nresponsible for management of the electromagnetic spectrum (i.e., the radio airwaves) that is vital to nearly all facets of\nthe modern economy.\nThe FCC works with colleagues in the National Telecommunications and Information Administration (NTIA), a part of the\nDepartment of Commerce (DOC), on spectrum matters affecting Federal Government users. NTIA is the executive branch\nagency that is principally responsible for advising the President on telecommunications and information policy issues.\nNTIA\u2019s programs and policymaking focus largely on expanding broadband internet access and adoption in America,\nexpanding the use of spectrum by all users, and ensuring that the internet remains an engine for continued innovation\nand economic growth.\nMany of the technologies central to enabling vehicle function, added-value features, and driver comfort require spectrum\naccess to function. These include, for example, radars and the transmission of data from cameras used for safety and\ndriver assistance features; GPS for navigation; toll tags, tire pressure monitors, garage door openers, and key fobs that\naid and augment the driving experience; stolen vehicle recovery systems that help locate and recover vehicles; and\nradios (satellite and terrestrial) and Bluetooth/Wi-Fi connections that provide entertainment and in-cabin connectivity.\nToday\u2019s vehicles incorporate or make use of a wide range and increasing number of spectrum-dependent technologies.\nThey must have the capability to integrate a multitude of services and devices to operate most effectively and provide\nthe functions and features that drivers want. Areas where the FCC has seen particular interest include radar technologies\n(such as those in the 76-81 GHz band that is reserved for vehicular applications), vehicle-to-vehicle and vehicle-toinfrastructure communications protocols and increasingly widespread network connectivity that will be enabled by\nubiquitous terrestrial 5G systems. Through its general spectrum management policies and rules, the FCC creates an\nenvironment that permits the development and deployment of communications technologies, including those used in\nvehicles, while leaving it to innovators to create and integrate those technologies.\nThe FCC focuses primarily on preventing harmful interference between competing uses while relying on flexible rules that\nenable innovative devices and services to develop and deploy. This core principle is well suited to the fast-moving world\nof AV technologies. We expect that developers of technologies and applications will draw increasingly on the different\nspectrum authorization mechanisms that the FCC offers\u2014whether through use of various frequencies that are assigned\nto specific users through licensing or for use by the general public without a specific license, or a combination of both.\nThe FCC will continue efforts to ensure that its policies promote the type of modern approach to spectrum management\nthat affords maximum flexibility to all innovators\u2014including those who are working to advance AVs in the United States.\nNTIA\u2019s Institute for Telecommunication Sciences (ITS) staff monitor C-V2X and 5G communications technology\nspecifications development activities through observation at 3GPP Working Group meetings and plenary sessions at\ninternational or domestic settings to identify how each input might affect transportation. This includes the identification\nof significant shifts to specifications that arise due to technology innovations that come through the working groups. The\n5G use cases 3GPP is targeting are focused on remote driving, automated driving, sensing, and platooning.\nNational Institute of Standards and Technology\nNIST, part of the Department of Commerce, advances industrial competitiveness by furthering measurement science,\nstandards, and technology in ways that enhance economic security and improve quality of life. The National Advanced\nSpectrum and Communications Test Network (NASCTN) is a multi-agency partnership headquartered at and led by NIST\nthat organizes a national network of Federal, academic, and commercial test facilities to provide testing, modeling,\nand analysis necessary to develop and deploy spectrum-sharing technologies and inform future spectrum policy and \n U.S. Government Activities and Opportunities for Collaboration \u2014 27\nregulations. NASCTN's mission is to provide robust test processes and validated measurement data necessary to increase\naccess to the spectrum by both Federal agencies and non-Federal spectrum users.\nNIST also conducts metrology research related to AVs, including the development of measurement techniques, test\nprotocols, calibration services, modeling and simulation techniques that will help with predicting and testing certain\nconnectivity aspects, such as signal propagation, wireless co-existence, and antenna performance as well as minimize\nradio interference in crowded airwaves. These tools are critical for reliable communications among connected vehicles,\nroadway infrastructure, and central control centers, and thus generate confidence in the safety of connected vehicles.\nEconomics and Workforce Research\nComplementary to the U.S. Government\u2019s role in advancing AV innovation and technology, the DOC, HHS, DOL, and\nUSDOT are collaborating in support of research on the Impact of Automated Vehicle Technologies on (Professional Drivers)\nWorkforce.72\nDOL\u2019s Bureau of Labor Statistics (BLS) is currently conducting a literature review that summarizes and synthesizes economic\ntheory on the interaction between labor and capital in the workplace and how this is affected by new technologies such as\nautomation, digitization, and AI. This review will be the basis for developing a comprehensive list of constructs that need\nto be measured to allow researchers to determine the effect of these new technologies on the workforce.\nFTA is researching economics and workforce considerations associated with AVs, including:\n\u2022 Analyzing labor and workforce-related considerations with transit bus automation for non-driving tasks of bus\noperations (e.g., management of bus yard operations).\n\u2022 Researching the availability and costs of automation-related systems and products with an emphasis on the U.S.\ndomestic bus market.\n\u2022 Developing methods and tools that transit agencies can use to assess the business case for investing in bus automation.\n\u2022 Studying the potential impacts of automation-related changes to transit service patterns, such as an increase in pointto-point service using smaller vehicles.\nB. U.S. Government Enabling Activities in the Automated Vehicle Sector\nThe U.S. Government is actively pursuing a range of regulatory and non-regulatory activities that will enable the\nadoption of AVs, with the overall goal to facilitate the safe and full integration of AV technologies into the national surface\ntransportation system. Integration would help realize the great potential AV technologies have for enhancing public safety,\nmaking systems more efficient, and facilitating economic vitality.\nFostering Collaboration with Government\nOutreach to Non-Federal Stakeholders\nThe Federal Government uses the Federal Register73 to make it easier for citizens and communities to understand the\nregulatory process and to participate in Government decision-making. Many Federal agencies are also reaching out\nto stakeholders in State, local, tribal and territorial governments, in industry, and elsewhere as part of the activities\ndescribed above. These outreach activities are often conducted in collaboration with multiple Federal entities.\n72 https://www.transportation.gov/av/workforce\n73 https://www.federalregister.gov/\n 28 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nFor example, through a series of listening sessions and online dialogues, most co-hosted with USDOT, the DOL\u2019s Office\nof Disability Employment Policy (ODEP) has engaged Federal agencies, academic researchers, original equipment\nmanufacturers (OEMs), TNCs, State legislators, and disability advocates in a conversation about the role of the Federal\nGovernment in ensuring that AVs will be accessible to persons with mobility, sensory, and cognitive disabilities once\ndeployed. The data from these events and meetings will be used in the development of Federal and State policy\nrecommendations.\nDOE\u2019s SMART Mobility Lab Consortium has convened an external Executive Advisory Board of 12 prominent experts in\na broad range of sectors impacting AVs, including manufacturing, transit, delivery, mobility, regulatory, technology,\nacademia, and non-governmental organizations. The board advises the SMART Consortium, providing feedback on the\nConsortium\u2019s research portfolio, advising on industry needs and trends, and making recommendations for improving\nthe quality, relevance, and impact of the SMART Mobility Consortium\u2019s research and development.\nUSDOT has lead numerous public events and published various public notices on the topic of AV to ensure the widest\npossible outreach to non-Federal stakeholders. These public events74 and public notices75 are compiled at an USDOT AV\ncentral webpage. 76\nUSDOT has supported industry efforts to ensure public access to accurate and clear information about ADAS and ADS\ncan encourage their safe use and adoption. In July 2019, USDOT brought together a diverse group of stakeholders77 to\ndiscuss current issues around communication, terminology, and language regarding AVs and how it influences consumer\nperception of AV technologies. Additionally, during the Automated Vehicle Symposium, also in July 2019, a panel\ndiscussion was held on Steps Towards Putting the Public Safety Community at Ease with Advanced Vehicle Technologies.\n78\nCities and local communities manage much of the transportation system within which AVs will operate. They have been\nasking how they should prepare for this new technology. EPA and DOE have been engaging with these communities\nto understand their needs and develop tools and information they can use to help consider potential environmental\nimpacts of increasing AV operation.\nThe FTC and NHTSA co-hosted a public workshop in 201779 to explore privacy and security issues related to AVs. FTC staff\nissued a paper summarizing the important themes from the panelist discussions during the full-day workshop.\nNIST hosted a workshop on Consensus Safety Measurement Methodologies for ADS-Equipped Vehicles80 in June 2019\nin collaboration with USDOT. This workshop\u2019s objectives was to identify and develop criteria that should be satisfied\nfor any approach to automated vehicle decision-making safety, to review existing or proposed methodologies for\nthe establishing safety requirements and safety measurement approaches, to identify gaps and key challenges, and\nto explore opportunities for progress, including identifying alternative methodologies that should be considered. The\nworkshop report81 can be found through NIST Special Publication 1900-320.\n74 https://www.transportation.gov/av/events\n75 https://www.transportation.gov/av/publicnotices\n76 https://www.transportation.gov/AV\n77 www.transportation.gov/av/communications\n78 AVS 2019: Steps Toward Putting Public Safety Community at Ease with Advanced Vehicle Technologies, https://youtu.be/oeh6u7JqgrY\n79 https://www.ftc.gov/system/files/documents/reports/connected-cars-workshop-federal-trade-commission-staff-perspective/staff_perspective_\nconnected_cars_0.pdf\n80 https://www.nist.gov/news-events/events/2019/06/consensus-safety-measurement-methodologies-ads-equipped-vehicles\n81 https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1900-320.pdf\n U.S. Government Activities and Opportunities for Collaboration \u2014 29\nTrans-Federal Coordination\nIn addition to working with non-Federal stakeholders, several agencies lead activities intended to foster interagency\ncoordination and the development of unified Federal approaches to AVs. For example, The General Services\nAdministration\u2019s (GSA) Office of Government Policy promotes interagency collaboration through various committees\nand councils, including the Federal Fleet Policy Council82 (FEDFLEET). FEDFLEET provides a mechanism for coordinating\nFederal vehicle management programs and policies, and analyzing the impact of current and proposed regulations,\nlaws, Executive orders, and international agreements. It is composed of representatives of Federal agencies that operate\nFederal motor vehicle fleets.\nVoluntary Consensus Standards and Other Guidance\nThe U.S. Government will promote voluntary consensus standards as a mechanism to encourage increased investment\nand bring cost-effective innovation to the market more quickly. Voluntary consensus standards can be validated by testing\nprotocols, are supported by private-sector conformity assessment schemes, and offer flexibility and responsiveness to\nthe rapid pace of innovation. Furthermore, many SDOs utilize existing processes that allow industry participation in the\ndevelopment of voluntary consensus standards.\nDepartment of Health and Human Services\nIn other voluntary standards-setting efforts, NIOSH served on the subcommittee convened by the American Society of\nSafety Professionals (ASSP) and National Safety Council, which developed the American National Standards Institute\n(ANSI)/ASSP Z15.3 technical report, Management Practices for the Safe Operation of Partially and Fully Automated Motor\nVehicles.\n83 The report is intended to help organizations develop policies, procedures, and management processes to\ncontrol risks associated with the operation of AVs.\nDepartment of Homeland Security\nIn another Federal collaboration, in March 2019, DHS\u2019s U.S. Customs and Border Protection (CBP) authored six vehicle\ncybersecurity threat scenarios for inclusion in USDOT\u2019s Volpe Center\u2019s upcoming \u201cGovernment Fleet Manager\u2019s Guide\nto Medium and Heavy Truck Cybersecurity Best Practices\u201d that have applicability to AVs. CBP also collaborates with\nUSDOT through its participation in the Government Cybersecurity Vehicle Steering Committee and the Commercial\nTruck Cybersecurity Working Group.\nDepartment of Transportation\nIn 2017, NHTSA provided voluntary guidance through Automated Driving Systems 2.0: A Vision for Safety (ADS 2.0). ADS\n2.084 revised and streamlined to emphasize the voluntary nature of the guidelines\u2013no compliance requirement or\nenforcement mechanism. ADS 2.0 focuses on the New Operating Guidance on SAE Level 3 and above Automated Driving\nSystems. Additionally, ADS 2.0 clarifies that assessments are not subject to Federal approval and that there is no waiting\nperiod or delay to begin testing or deployment. Furthermore, it revises priority safety elements, focusing on 12 aspects\nthat are ready for implementation in the near term. Elements involving privacy, ethical considerations, registration, and\nthe sharing of data beyond crash data remain important and are areas for further discussion and research.\n82 https://www.gsa.gov/policy-regulations/policy/vehicle-management-policy/-councils/federal-fleet-policy-council-fedfleet-enrollment\n83 https://www.assp.org/news-and-articles/2019/06/25/automated-vehicles-addressing-challenges-and-opportunities\n84 https://www.nhtsa.gov/sites/nhtsa.dot.gov/files/documents/13069a-ads2.0_090617_v9a_tag.pdf\n 30 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nIn 2018, USDOT presented further voluntary guidance for AV development across all surface modes through Preparing\nfor the Future of Transportation: Automated Vehicles 3.0 (AV 3.0).85 AV 3.0\u2014developed with input from a diverse set of\nstakeholder engagements throughout the Nation\u2014builds upon ADS 2.0, further expanding the scope to all surface onroad transportation systems. AV 3.0 is structured around three key areas: 1) Advancing multi-modal safety, 2) Reducing\npolicy uncertainty, and 3) Outlining a process for working with USDOT.\nUSDOT\u2019s Volpe National Transportation Systems Center and NCCoE collaborated with three Connected Vehicle (CV)\nPilots (Wyoming, New York, and Florida) and the University of Michigan Transportation Research Institute (UMTRI) to\ndevelop the CV Pilot Cybersecurity Framework Profile and conduct a privacy risk analysis. This included applying the\nNIST Privacy Risk Assessment Methodology (PRAM) to UMTRI\u2019s Ann Arbor Connected Vehicle Test Environment (AACVTE)\nresearch implementation. This research resulted in a Cybersecurity Framework Profile in 2018.86\nNational Institute of Standards and Technology\nNIST supports the development and use of measurement science in voluntary consensus standards, conformity\nassessment, and related tools. This work is enabling the development, deployment and assurance of ADS. NIST\u2019s\nCyber-Physical Systems Program is developing methods for measuring AV trustworthiness (safety, security, resilience,\nreliability, and privacy) to support performance measurements for ADS. The goal is to enhance existing methods for\nvalidating vehicle trustworthiness\u2014for example to support new modeling and simulation capabilities in ADS-equipped\nvehicles.\nRegulatory Authority and Automated Vehicles\nDepartment of Transportation\nUSDOT\u2019s modal administrations regulate aspects of AVs. For more details, please refer to the Safety, and Security and\nCybersecurity sections, above.\nGeneral Services Administration\nThe GSA develops Federal motor vehicle management regulations, issues guidance on Federal fleet operations, and\nprovides reports on the Federal fleet, which was estimated as 644,545 non-tactical vehicles in FY2018.87 Federal regulations\non fleet management include requirements regarding agencies\u2019 acquisition, use, and disposal of motor vehicles, and\ncover home-to-work transportation, among other requirements. The GSA Office of Government-wide Policy (OGP) also\nissues guidance to help agencies manage their motor vehicle fleets effectively. Guidance includes bulletins on various\naspects of fleet management, including fleet management information systems, and methodologies for determining the\noptimal fleet size for agency fleets. GSA OGP will consider guidance for how to integrate AVs into Federal fleets.\nOffice of Management and Budget\nThe Office of Information and Regulatory Affairs (OIRA)88 is a Federal office established by Congress within the Office\nof Management and Budget (OMB), which is an agency within the Executive Office of the President. OIRA reviews draft\nproposed and final regulations under Executive Order 12866 from Federal agencies, including USDOT. OIRA also reviews\nFederal agencies\u2019 collections of information from the public under the Paperwork Reduction Act, and develops and\n85 https://www.transportation.gov/av/3\n86 https://www.its.dot.gov/presentations/trb2018/TRB_NIST_CSF_Project.pdf\n87 https://www.gsa.gov/policy-regulations/policy/vehicle-management-policy/federal-fleet-report\n88 https://www.whitehouse.gov/omb/information-regulatory-affairs/\n U.S. Government Activities and Opportunities for Collaboration \u2014 31\noversees the implementation of government-wide policies in the areas of information policy, privacy, and statistical and\nscience policy.\nTaxation, Trade, and Intellectual Property\nTax Incentives for AV Research\nTo ensure American leadership and growth in AV technology, the U.S. Government offers attractive tax incentives for AV\ninnovators and entrepreneurs to conduct AV R&D in the United States.\nDepartment of the Treasury\nThe Department of the Treasury and the Internal Revenue Service (IRS) promote innovation in the AV industry through\npublication of administrative rules and other guidance on current Federal income tax law incentives. Taxpayers can\nimmediately expense the cost of research and developmental activities that are experimental in nature with the purpose\nof eliminating uncertainty when developing or improving a product. Qualifying activities may include developing a\npatent and inventing technologies to improve the fuel efficiency of AVs or to enhance driver experiences with AVs. A\nFederal income tax credit of up to 20% of the eligible spending for research and developmental activities is also available.\nTaxpayers may also immediately expense the cost of qualified business property purchased after September 27, 2017\nand before January 1, 2023. Additionally, AV innovators can immediately expense the cost of purchasing new or used\nmanufacturing equipment, the AVs they operate or lease, and computer hardware and software. Understanding that\nAV companies may have more operating expenses than revenues in their early years of business, the tax code allows\nthe carryover of net operating losses to offset 80% of taxable income generated in future years. The indefinite carryover\nof net operating losses to future years ensures the benefit of the operating expenses will be utilized when a company\ngenerates profits. Taxpayers may immediately expense start-up and organizational costs of up to $5,000 (for each\ncategory) in the year the business begins operations. The $5,000 deduction is reduced by the amount of the start-up or\norganizational costs that exceeds $50,000; the remainder of the costs may be deducted over a 180-month period. The\nstart-up costs include any amounts paid in connection with creating an active trade or business or investigating the\ncreation or acquisition of an active trade or business. Organizational costs include the cost of creating a corporation or\npartnership.\nTax incentives are available to promote domestic manufacturing for export, including AVs. U.S. corporations have a\nreduced U.S. Federal income tax rate through a 37.5% deduction for their directly earned foreign-derived intangible\nincome (FDII) for the 2018 through 2025 tax years (reduced to 21.875% thereafter). The FDII deduction is akin to an\nInnovation Box tax regime designed to incentivize American corporations to maintain U.S.-based operations and\nintangibles while exporting more goods and services to foreign markets. The FDII deduction is provided for all exportrelated income in excess of a fixed return on tangible assets to incentivize all U.S. export-based operations. An \u201cinterest\ncharge domestic international sales corporation\u201d (IC-DISC) can be utilized to eliminate the Federal corporate income tax\non foreign sales of tangible goods that are manufactured or produced in the United States. The earnings from the IC-DISC\nare taxed only when they are distributed to its shareholders, and usually at a 20% tax rate for qualified dividends. Unlike\nthe FDII deduction, the IC-DISC rules require a substantial amount of U.S. activity in manufacturing or producing the sold\ngood, and thus this regime specifically incentivizes U.S. production for export.\nTrade Promotion Related to AVs\nThe U.S. Government will ensure American AV innovators have fair access to foreign markets. The U.S. Government\nwill seek rules, both at home and abroad, that are as performance-based and non-prescriptive as possible and do not\ndiscriminate against U.S. technologies, products, or services. \n 32 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nDepartment of State\nWith respect to international trade promotion for AVs, the mission of the Department of State\u2019s Bureau of Economic\nand Business Affairs is to advance America\u2019s prosperity and other national interests by supporting American business\noverseas; fostering good governance through economic transparency, accountability and sustainability; and fostering\ninclusive economic growth and prosperity. The Bureau of Economic and Business Affairs is the Department\u2019s lead\nbureau on economic engagement, international trade, transportation and telecommunications policy, and commercial\nadvocacy.\nDepartment of Transportation\nThe USDOT\u2019s Office of International Transportation and Trade provides departmental leadership on international\nmultimodal transportation and trade policies and initiatives, including technical assistance and cooperation programs,\nas well as trade facilitation and advocacy activities. The office provides the Secretary of Transportation with information\nand analysis to aid in developing international transportation policy and other international responsibilities.\nThese include exchanging technical information with foreign counterparts, facilitating open and liberalized global\ntransportation markets, reducing technical barriers to trade in the transportation sector and resolving market access\nissues created by other countries\u2019 standards and regulations. The office also represents the Department in global\ntransportation organizations and trade fora. It conducts in-depth analysis and provides policy recommendations to\naddress emerging and ongoing international transportation issues, and in consultation with the Department\u2019s operating\nadministrations, it also develops the Department\u2019s positions on the negotiation or implementation of international\ntrade agreement provisions affecting transport.\nInternational Trade Administration\nThe International Trade Administration (ITA) within the United States Department of Commerce promotes United States\nexports of nonagricultural U.S. services and goods. ITA is working with U.S. regulators and industry to collaborate\nwith foreign partners while the technology is still being developed to attain convergent technical specifications and\nrequirements that enable trade and continued U.S. exports because regulatory divergence acts to unnecessarily raise\ncosts while also restricting road vehicle trade. ITA has found that it is much easier to achieve convergent standards and\nregulations if work begins prior to their initial development to bridge differences prior to investments being made. ITA\ncan also work with smaller technology developers to both find foreign buyers and to help protect intellectual property.\nOffice of Trade and Manufacturing Policy\nThe Office of Trade and Manufacturing Policy (OTMP) was created by Executive order within the Executive Office of the\nPresident (EOP) in 2017.89 One of OTMP\u2019s primary roles is to support the ability of the United States to manufacture\nproducts, particularly technologically advanced products such as AVs, domestically. This can be done through a variety\nof policy options, including trade policies and government procurement programs (such as \u201cBuy American\u201d preference\nprograms). OTMP has a particular focus on the nexus of economic and national security issues, and works closely with\nthe DoD and other agencies on defense procurement policies, which may include purchase commitments and loan\nguarantees for production capabilities with critical defense implications.\nOffice of the U.S. Trade Representative\nThe Office of the U.S. Trade Representative90 (USTR) is responsible for developing and coordinating U.S. international\ntrade, commodity, and direct investment policy, and overseeing trade negotiations with other countries. USTR\u2019s role\n89 https://www.whitehouse.gov/presidential-actions/presidential-executive-order-establishment-office-trade-manufacturing-policy/\n90 https://ustr.gov/\n U.S. Government Activities and Opportunities for Collaboration \u2014 33\nin transportation automation is to engage with trading partners as appropriate to pursue fair and reciprocal market\naccess abroad for U.S.-developed and U.S.-manufactured transportation automation-related technologies, vehicles,\nand services. This includes protecting U.S. transportation automation-related intellectual property internationally and\nworking with trading partners to shape regulatory environments abroad so that they do not discriminate against U.S.\ntechnologies, products, or services.\nIntellectual Property Protection\nThe U.S. Government will continue to promote sensitive emerging technologies through the protection and enforcement\nof intellectual property rights\u2014patents, trademarks, copyrights, and trade secrets\u2014technical data, and sensitive\nproprietary communications and will continue to work to prevent other nations from gaining unfair advantage at the\nexpense of American innovators.\nOffice of the U.S. Intellectual Property Enforcement Coordinator\nThe Office of the U.S. Intellectual Property Enforcement Coordinator (IPEC)91 in the Executive Office of the President\ncoordinates and develops policy and strategy to promote innovation and creativity, and ensures effective intellectual\nproperty protection and enforcement, domestically and abroad, with respect to all forms of intellectual property. As is\nthe case for other critical technologies, AV technology will rely heavily on intellectual property in the form of patents,\ntrade secrets, copyrighted software, and trademarked goods. For the United States to successfully adopt this technology,\nthe intellectual property of American innovators\u2014and the safety of the American public\u2014will both need to be protected.\nIn this regard, establishing and maintaining secure supply chains for AV technologies will be essential for protecting\nsafety, security, and intellectual property.\nDepartment of Justice\nDOJ, through the Computer Crime and Intellectual Property Section (CCIPS) in its Criminal Division, as well as through\nits National Security Division, executes national strategies in combating intellectual property crimes\u2014including those\ninvolving AV technology\u2014worldwide. DOJ attorneys prevent, investigate, and prosecute intellectual crimes by working\nwith other government agencies, the private sector, academic institutions, and foreign counterparts. These attorneys\nwork to improve the domestic and international infrastructure (legal, technological, and operational) to pursue\ncriminals most effectively. They also regularly run complex investigations, resolve unique legal and investigative issues\nraised by emerging computer and telecommunications technologies; litigate cases; provide litigation support to other\nprosecutors; train Federal, State, and local law enforcement personnel; comment on and propose legislation; and initiate\nand participate in international efforts to combat computer and intellectual property crime.\nUnited States Patent and Trademark Office\nThe United States Patent and Trademark Office (USPTO) is the Federal agency responsible for issuing patents and\nregistering trademarks.92 The agency\u2019s mission is to foster innovation, competitiveness, and economic growth,\ndomestically and abroad. It does this through a three-pronged approach:\n\u2022 delivering high quality and timely examinations of patent and trademark applications;\n\u2022 guiding domestic and international intellectual property policy; and\n\u2022 delivering IP information and education worldwide.\n91 https://www.whitehouse.gov/omb/office-u-s-intellectual-property-enforcement-coordinator-ipec/\n92 USPTO provides access to patent and trademark information through its searchable databases, which along with other useful information may be\nfound at: https://www.uspto.gov/learning-and-resources/inventors-entrepreneurs-resources. To facilitate searching patent documents, they are\nindexed or classified into classes and subclasses. For automated vehicles, the most relevant international classifications are: B60W, B60T, G01S, G05D,\nand G08G.\n 34 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nInnovators and entrepreneurs in the AV field should be aware of USPTO, as securing a patent, trademark, or both serves\nnot only to afford them important legal rights, but also to help preserve the United States\u2019 technological edge, which\nis key to our current and future competitiveness in AV technologies. In particular, a patent grants a property right to an\ninventor providing the exclusive right to exclude others from \u201cmaking, using, offering for sale, or selling\u201d an invention\nin the United States, or for importing a patent-protected invention into the United States. Generally, patent rights for\nan invention will last for a term of 20 years from the date on which the application was filed in the United States. A\ntrademark is a word, name, symbol, or device that is used in trade in goods to indicate the source of the goods and to\ndistinguish them from the goods of others. Trademark rights may be used to prevent others from using a confusingly\nsimilar mark, but not to prevent others from making the same goods or from selling the same goods or services under a\nclearly different mark. Trademarks that are used in interstate or foreign commerce may be registered with USPTO. U.S.\npatents and trademarks are open to applicants around the world, and provide the aforementioned rights within the\nborders of the United States.\nEnvironmental Quality\nThe U.S. Government will focus on opportunities to improve transportation system-level efficiency, while avoiding negative\ntransportation system-level environmental impacts from AV technologies.\nCouncil on Environmental Quality\nCouncil on Environment Quality (CEQ)93 was created by the National Environmental Policy Act (NEPA) and is a Federal\nagency located within the Executive Office of the President. CEQ oversees NEPA implementation through regulations\nand guidance. The development and implementation of AV-related technology and infrastructure may require Federal\npermits or other authorizations that would trigger a NEPA analysis. CEQ would support Federal agencies as they\nundertake the NEPA process for AV-related projects.\nCEQ also houses the Office of Federal Sustainability94 (OFS), which coordinates policy across the Federal Government\nto promote energy and environmental sustainability in Federal operations. OFS implements Executive Order 13834\nwhich directs Federal agencies to manage their operations to optimize energy and environmental performance, reduce\nwaste, and cuts costs, which includes vehicles. In order to meet statutory requirements for petroleum reductions and\noptimize efficiency, some agencies have decided to implement telematics as well as EV infrastructure to manage their\nfleets. The development and implementation of AV-related technology and infrastructure would require consideration\nof the existing use of telematics and electric vehicles in the Federal fleet to ensure coordination and interoperability.\nOFS assists Federal agencies that decide to use AV technology to meet their statutory requirements related to vehicles\nin a manner that increases efficiency, optimizes performance, eliminates unnecessary use of resources, and protects the\nenvironment.\nEnvironmental Protection Agency\nAs the Federal Government\u2019s lead regulator for clean air and other environmental programs, EPA is charged with developing\nrules and policies to ensure its public health goals are met. All vehicles offered for sale in the U.S., for example, must\nreceive an EPA certificate of conformity before introduction to the market. Automobile manufacturers must demonstrate\ncompliance with environmental regulations over a wide range of operating conditions and test procedures.\n93 https://www.whitehouse.gov/ceq/\n94 https://www.sustainability.gov/\n U.S. Government Activities and Opportunities for Collaboration \u2014 35\nThe introduction of ADS technologies could modify how these vehicles operate under these test conditions requiring\nupdates in testing to provide a complete environmental profile. EPA\u2019s National Vehicle and Fuel Emissions Laboratory\nhas begun to monitor, measure, and assess ADS and ADAS vehicle technology improvements and innovations, so that\npolicy actions targeted toward ADS and ADAS performance that impact fuel economy (as regulated by NHTSA), energy\nconsumption, tailpipe emissions, and vehicle activity profiles account for and have the latest, best technical information\navailable.\nEPA provides the Federal Government\u2019s official measured testing for tailpipe emission, fuel economy, and consumer\ninformation. As AVs come to market those tests must accurately account for ADS and ADAS, which may mean developing\nand employing special test methods. As appropriate, EPA will update vehicle testing regulations to address unique AV\noperational considerations that may arise. As data become known, EPA will also incorporate into vehicle performance\nmodels and policy tools the benefits (reductions) or dis-benefits (increases) in emissions and energy consumption\nassociated with ADS and ADAS performance on auto-emissions compliance requirements.\nCompetition, Privacy, and Market Transparency\nThe U.S. Government will ensure the security of data and the public\u2019s privacy as AV technologies are designed and\nintegrated. The U.S. Government will enforce existing laws to ensure entities do not make deceptive claims or mislead the\npublic about AVs technologies or publicly traded AV technology companies.\nDepartment of Justice\nThe DOJ is the executive branch agency charged with promoting and protecting competition for the benefit of American\nconsumers. DOJ enforces the antitrust laws so that markets for innovative technologies, such as those related to AVs, are\ndynamic, competitive, and free of collusion. For example, DOJ is charged with prosecuting criminal antitrust conduct,\nsuch as price fixing, bid rigging, and market allocation agreements that have no economic benefit and harm competition\nand innovation in dynamic markets. In addition, DOJ interacts with industry, including as to the role of antitrust\nenforcement to promote innovation in the standard-setting context, emphasizing open, balanced, and competitive\nprocesses. Free market competition enabled by the DOJ\u2019s enforcement will support innovation and consumer welfare in\nemerging markets for automated vehicles.\nFederal Trade Commission\nThe FTC is the Nation\u2019s principal consumer protection agency. The FTC enforces Section 5 of the FTC Act, 15 U.S.C. \u00a7\n45, which prohibits unfair or deceptive acts or practices in or affecting commerce. In the AV context, the FTC could, for\nexample, use its Section 5 authority to take action against a company that makes deceptive claims about the performance\ncapabilities or limitations of AVs or their component systems. The FTC could also use its Section 5 authority to take action\nagainst a company that makes deceptive claims with respect to consumer data that is collected, used, or maintained in\nconnection with automated or connected vehicles or that has inadequate privacy or security practices. The FTC uses\na variety of measures\u2014such as policy initiatives, including issuing reports or holding workshops, and consumer and\nbusiness education efforts\u2014to protect consumers.\nSecurities and Exchange Commission\nThe U.S. Securities and Exchange Commission\u2019s (SEC) mission is to protect investors, maintain fair, orderly, and efficient\nmarkets, and facilitate capital formation. The laws and rules that govern the securities industry in the United States derive\nfrom a simple and straightforward concept: all investors, whether large institutions or private individuals, should have\naccess to certain basic facts about an investment prior to buying it, and so long as they hold it. To achieve this, the SEC\nrequires public companies (e.g., publicly traded AV technology companies) to disclose meaningful financial and other \n 36 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\ninformation to the public. This provides a common pool of knowledge for all investors to use to judge for themselves\nwhether to buy, sell, or hold a particular security. Only through the steady flow of timely, comprehensive, and accurate\ninformation can people make sound investment decisions. The SEC oversees the key participants in the securities world,\nincluding securities exchanges, securities brokers and dealers, investment advisors, and mutual funds. Here the SEC is\nconcerned primarily with promoting the disclosure of important market-related information, maintaining fair dealing,\nand protecting against fraud. Crucial to the SEC's effectiveness in each of these areas is its enforcement authority. Typical\ninfractions SEC may pursue include insider trading, accounting fraud, and providing false or misleading information\nabout securities and the companies that issue them.\nC. U.S. Government Resources for Automated Vehicle Sector Innovators\nThe role of the U.S. Government is to create an environment in which innovators can iterate new technologies to meet\nmarket needs. As such, the U.S. Government has resources available to support AV innovators.\nFederal Laboratories Test Beds and Technology Transfer\nLeveraging the Federal Government\u2019s investments in R&D for societal benefit necessarily involves the transfer of technologies\ncreated with Federal money to the open market. The Federal Laboratory Consortium for Technology Transfer (FLC) is a\nnationwide network of over 300 Federal laboratories, agencies, and research centers that fosters commercialization best\npractice strategies and opportunities for accelerating Federal technologies from out of the laboratories and into the\nmarketplace.95 The FLC\u2019s mission is to promote, educate, and facilitate Federal technology transfer (T2) among its member\nlaboratories and institutions so they can reach their commercialization goals, and create social and economic impacts\nwith new innovative technologies. One of the FLC\u2019s growing service initiatives is the Technology Focus Area (TFA) program.\nTFA provides an annual spotlight on a specific technology that addresses a public need and supports Federal laboratories\u2019\nresearch and technology transfer missions as well as government-wide economic development goals. The TFA for\nAutomated Systems (AS) program is designed to facilitate commercialization activity by cultivating valuable connections\nbetween Federal laboratories and innovators. Through the TFA AS program, the FLC provides innovators with a dedicated\nonline platform for identifying relevant AS Federal laboratory technologies, intellectual property, programs, and expertise.\nThe program serves as a pathway of introduction for innovators to access the Federal resources and contacts they need to\nestablish T2 relationships and agreements for accelerating their R&D.\nSmall Business Administration Resources\nThe U.S. Small Business Administration (SBA) helps Americans start, build, and grow businesses. It provides access to\ncapital through an array of financing mechanisms, free counseling and low-cost training for both new entrepreneurs and\nestablished small businesses, facilitates access to contracts with Federal agencies and departments, and advocates on\nbehalf of small businesses with government policy makers. SBA offers detailed guides for planning, launching, managing,\nand growing a business96 as well as District Offices that can provide assistance focused on particular local conditions.97\nSBA provides policy guidance and leadership for the Small Business Innovation Research (SBIR) and Small Business\nTechnology Transfer (STTR) Programs,98 coordinating across 11 Federal agencies and departments to help innovative\n95 https://www.federallabs.org/flcbusiness\n96 https://www.sba.gov/business-guide\n97 https://www.sba.gov/local-assistance\n98 http://www.sbir.gov\nConclusion \u2014 37\nsmall businesses meet Federal R&D needs and commercialize those innovations. SBA assists small businesses interested\nin pursuing SBIR/STTR opportunities across the Federal Government through outreach, training resources, and by helping\nentrepreneurs connect to local resources.\nSBA offers a wide variety of courses designed to help entrepreneurs research, plan, and turn ideas into businesses.99 Training\nincludes the Emerging Leaders Initiative, an intensive program that provides free entrepreneurship education and training\nfor executives of small, poised-for-growth companies that are potential job creators in America\u2019s underserved cities.100\nThe NSF I-CorpsTM program prepares scientists and engineers to extend their focus beyond the university laboratory and\naccelerates the economic and societal benefits of NSF-funded, basic-research projects that are ready to move toward\ncommercialization.\nUnited States Patent and Trademark Office\u2019s Inventor and Entrepreneur Resources\nUSPTO maintains a website101 linking to resources related to protecting intellectual property (IP) and ensuring innovators\nunderstand how and when to register their IP. Information on the IP lifecycle as well as legal resources are available to\nenable innovators to best protect their efforts.\nUSAspending.gov\nUSAspending.gov102 is the official source for spending data for the U.S. Government. Its mission is to show the American\npublic what the U.S. Government spends every year and how it spends the money. You can follow the money from the\ncongressional appropriations to the Federal agencies and down to local communities and businesses. AV innovators and\nentrepreneurs could use this as a resource to identify potential U.S. Government funding opportunities.\nAdditional U.S. Government Resources\nA list of all other known U.S. Government AV relevant resources available to AV innovators and entrepreneurs can be\nfound in Appendix A. If AV innovators and entrepreneurs have questions directed at specific components inside the U.S.\nGovernment, a contact list can be found in Appendix B.\nIV. Conclusion\nThe White House OSTP encourages a future in which the United States is a global leader in AV technology. The U.S.\nGovernment offers AV innovators and entrepreneurs an ideal environment to develop and integrate AV technology\nwhile prioritizing safety, security, and privacy for users and communities; promoting efficient markets; and facilitating\ncoordinated research efforts nationwide. In preparation for emerging and innovative AV technology, the U.S. Government\nwill provide policies, guidance, and best practices; conduct appropriate research and pilot programs; and offer necessary\nassistance to help plan for and invest in a dynamic and flexible future for all Americans.\n99 https://www.sba.gov/learning-center\n100 https://www.sba.gov/about-sba/organization/sba-initiatives#section-header-14\n101 USPTO Inventor and entrepreneur resources, https://www.uspto.gov/learning-and-resources/inventors-entrepreneurs-resources\n102 https://www.usaspending.gov/#/\n 38 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nV. Appendix A \u2013 U.S. Government Resources\nCouncil on Environmental Quality\n\u2022 Office of Federal Sustainability: https://www.sustainability.gov/resources.html\nDepartment of Agriculture\n\u2022 National Robotics Initiative 2.0: Ubiquitous Collaboration Robots (NRI-2.0): https://nifa.usda.gov/fundingopportunity/national-robotics-initiative-realization-co-robots-acting-direct-support\nDepartment of Energy\n\u2022 Vehicle Technologies Office: https://www.energy.gov/eere/vehicles/vehicle-technologies-office\n\u2022 Vehicle Technologies Office Annual Merit Review and Peer Evaluations: https://www.energy.gov/eere/vehicles/\nannual-merit-review-presentations\n\u2022 Vehicle Technologies Office reports and publications: https://www.energy.gov/eere/vehicles/reports-and-publication\ns?TechArea=Energy+Efficient+Mobility+Systems\n\u2022 DOE\u2019s Technology Commercialization Fund: https://www.energy.gov/technologytransitions/services/technologycommercialization-fund\n\u2015 Technology Commercialization Fund (TCF) is a nearly $20 million funding opportunity that leverages R&D funding\nin the Department\u2019s applied energy programs to mature promising energy technologies with the potential for high\nimpact. TCF was created by the Energy Policy Act of 2005 and catalyzes the commercial impact of the Department\u2019s\nportfolio of research, development, demonstration, and deployment activities. TCF funds are matched with funds\nfrom private partners to promote promising energy technologies for commercial purposes.\nDepartment of Defense\n\u2022 Defense Technical Information Center: https://discover.dtic.mil/products-services/\nDepartment of Health and Human Services\n\u2022 NIOSH Center for Motor Vehicle Safety Strategic Plan for Research and Prevention, 2014-2018: https://www.cdc.gov/\nniosh/docs/2014-122/pdfs/2014-122.pdf (note: An updated plan is under development and will be posted on the NIOSH\ndocket for public comment.)\n\u2022 NIOSH Strategic Plan: FYs 2019\u22122023 prioritizes research on the safety impacts of automated and connected vehicles\nand ADAS for truck, bus, and taxi drivers. In addition, the NIOSH plan prioritizes research on injury risks associated with\nnew jobs that may be created by automation, and on potential stress and fatigue consequences of automation. (See\nIntermediate Goals 6.14 and 7.8.) https://www.cdc.gov/niosh/about/strategicplan/\n\u2022 NIDILRR\u2019s Rehabilitation Engineering Research Center on Physical Access and Transportation: https://acl.gov/sites/\ndefault/files/about-acl/2019-01/NIDILRR%20LRP-2018-2023-Final.pdf\n\u2022 NIDILRR\u2019s research Project on Optimizing Accessible Public Transportation: https://acl.gov/sites/default/files/aboutacl/2019-01/NIDILRR%20LRP-2018-2023-Final.pdf\nDepartment of Homeland Security\n\u2022 DHS Science and Technology Directorate\n\u2015 Critical Infrastructure and Resilience: https://www.dhs.gov/science-and-technology/critical-infrastructure-andresilience#\n\u2015 Cybersecurity: https://www.dhs.gov/science-and-technology/cybersecurity\n\u2022 DHS CISA, Cyber Storm: Securing Cyber Space\n\u2015 https://www.dhs.gov/cisa/cyber-storm-securing-cyber-space\nAppendix A \u2013 U.S. Government Resources \u2014 39\nDepartment of Labor\n\u2015 Office of Disability Employment Policy: https://www.dol.gov/odep/topics/Transportation.htm\nDepartment of Transportation\n\u2022 Access and Mobility for All Summit: https://www.transportation.gov/accessibility\n\u2022 Coordinating Council on Access and Mobility (CCAM) Strategic Plan 2019-2022: https://www.transit.dot.gov/sites/fta.\ndot.gov/files/docs/regulations-and-guidance/ccam/about/134436/ccam-strategic-plan-2019-2022.pdf\n\u2022 Mobility for All Pilot Program Grants: https://www.transit.dot.gov/funding/grants/grant-programs/mobility-all-pilotprogram-grants\n\u2022 USDOT Automated Vehicles Activities: https://www.transportation.gov/AV\n\u2022 USDOT Research HUB 2.0: https://researchhub.bts.gov/\n\u2022 USDOT Repository & Open Science Access Portal: https://rosap.ntl.bts.gov/welcome\n\u2022 USDOT/BTS National Transportation Library: https://ntl.bts.gov/\n\u2022 USDOT/FTA Transit Automation Activities: https://www.transit.dot.gov/automation-research\nFederal Communication Commission\n\u2022 FCC Reports & Research: https://www.fcc.gov/reports-research\n\u2022 Office of Engineering and Technology (OET): https://www.fcc.gov/engineering-technology\n\u2022 Wireless Telecommunications Bureau: https://www.fcc.gov/wireless-telecommunications\n\u2022 Dedicated Short Range Communications (DSRC) Service: https://www.fcc.gov/wireless/bureau-divisions/mobilitydivision/dedicated-short-range-communications-dsrc-service\nFederal Laboratory Consortium for Technology Transfer\n\u2022 FLC Business: https://www.federallabs.org/flcbusiness\nNational Aeronautics and Space Administration\n\u2022 NASA TechPort: https://techport.nasa.gov/home\n\u2022 NTRS: https://ntrs.nasa.gov/\nNational Council on Disability\n\u2022 Self-Driving Cars: Mapping Access to a Technology Revolution: https://www.ncd.gov/sites/default/files/NCD_\nAutomatedVehiclesReport_508-PDF.pdf\nNational Institute of Standards and Technology\n\u2022 Cyber-Physical System: https://www.nist.gov/el/cyber-physical-systems\n\u2022 Mobility Performance of Robotics Systems: https://www.nist.gov/programs-projects/mobility-performance-roboticsystems\n\u2022 Communication Technology research: https://www.nist.gov/programs-projects/5g-beyond\n\u2022 National Advanced Spectrum and Communication Test Network: https://www.nist.gov/communications-technologylaboratory/nasctn\n\u2022 Applied Research \u2013 Cybersecurity and Privacy in Connected vehicles: https://www.nccoe.nist.gov/\n\u2022 NIST Cybersecurity Framework: https://www.nist.gov/cyberframework\n\u2022 NIST Privacy Framework: https://www.nist.gov/privacy-framework\n\u2022 U.S. Leadership in AI: A Plan for Federal Engagement in Developing Technical Standards and Related Tools. https://\nwww.nist.gov/document/report-plan-federal-engagement-developing-technical-standards-and-related-tools\n 40 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\n\u2022 An Independent Measurement System for Testing Automotive Crash Warning Systems: http://ws680.nist.gov/\npublication/get_pdf.cfm?pub_id=901038\n\u2022 Objective Test and Performance Measurement of Automotive Crash Warning Systems: http://ws680.nist.gov/\npublication/get_pdf.cfm?pub_id=823603\n\u2022 Performance Evaluation of Integrated Vehicle-Based Safety System: http://ws680.nist.gov/publication/get_pdf.\ncfm?pub_id=823587\n\u2022 NIST Work in Support of Army Research Labs and DARPA Autonomous Vehicles for Military Operations (e.g., scouting)\n\u2015 4D/RCS Version 2.0: A Reference Model Architecture for Unmanned Vehicle Systems: http://ws680.nist.gov/\npublication/get_pdf.cfm?pub_id=821823\n\u2015 Intelligent Vehicle Systems: A 4D RCS Approach https://books.google.com/books/about/Intelligent_Vehicle_\nSystems.html?id=A84mXxcNjlwC\n\u2022 NIST Work in Support of DARPA Mobile Autonomous Robots (MARS) and follow-on Programs to develop the\nfoundations for a robotic chauffeur type of capability:\n\u2015 Identifying Sensory Processing Requirements for an On-Road Driving Application of 4D/RCS https://www.nist.gov/\nnode/683826\n\u2015 How task analysis can be used to derive and organize the knowledge for the control of AVs https://www.nist.gov/\nnode/705571\n\u2015 Achieving Intelligent Performance in Autonomous Driving: https://www.nist.gov/node/705951\n\u2015 PRIDE: A Framework for Performance Evaluation of Intelligent Vehicles in Dynamic, On-Road Environments: https://\nwww.nist.gov/node/761331\n\u2022 Framework for Defining and Measuring Autonomy Levels (Autonomy Levels for Unmanned Systems):\n\u2015 Autonomy Levels for Unmanned Systems (ALFUS) Framework Volume II: Framework Models Initial Version http://\nws680.nist.gov/publication/get_pdf.cfm?pub_id=823618\nNational Science Foundation\n\u2022 NSF Award Search: https://nsf.gov/awardsearch/advancedSearch.jsp\n\u2022 NSF Public Access Repository (NSF-PAR): https://par.nsf.gov/\nNational Transportation Safety Board\n\u2022 Completed Investigations:\n\u2015 Collision Between a Car Operating with Automated Vehicle Control Systems and a Tractor-Semitrailer Truck Near\nWilliston, Florida - May 7, 2016, https://www.ntsb.gov/investigations/AccidentReports/Pages/HAR1702.aspx\n\u2015 Low-Speed Collision Between Truck-Tractor and Autonomous Shuttle, Las Vegas, Nevada, November 8, 2017, https://\nwww.ntsb.gov/investigations/pages/HWY18FH001.aspx\n\u2015 Collision Between Vehicle Controlled by Developmental Automated Driving System and Pedestrian , Tempe, Arizona,\nMarch 18, 2018, https://www.ntsb.gov/investigations/AccidentReports/Reports/HAR1903.pdf\n\u2022 Ongoing Investigations:\n\u2015 Rear-End Collision Between a Passenger Car Operating with Advanced Driver Assistance Systems and a Stationary\nFire Truck, Culver City, California, January 22, 2018, https://www.ntsb.gov/investigations/pages/HWY18FH004.aspx\n\u2015 Passenger Car Operating with Advanced Driver Assistance Systems Collided with Roadway Barrier, Mountain View,\nCalifornia, March 23, 2018, https://www.ntsb.gov/investigations/pages/HWY18FH011.aspx\n\u2015 Collision Between a Passenger Car Operating with Advanced Driver Assistance Systems and Combination Vehicle at\nan Intersection, Delray Beach, Florida, March 1, 2019, https://www.ntsb.gov/investigations/pages/HWY19FH008.aspx\nAppendix A \u2013 U.S. Government Resources \u2014 41\n\u2022 Significant recommendations:\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-17-037\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-17-038\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-17-039\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-17-040\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-17-041\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-17-042\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-17-043\n\u2022 Recommendations for collision avoidance systems:\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-15-004\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-15-005\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-15-006\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-15-007\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-15-008\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-15-009\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-18-008\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-18-019\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-18-029\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-18-043\n\u2015 https://www.ntsb.gov/investigations/AccidentReports/_layouts/ntsb.recsearch/Recommendation.aspx?Rec=H-18-044\nUnited States Patent and Trademark Office\n\u2022 USPTO patent search database: https://www.uspto.gov/patents-application-process/search-patents\n\u2022 USPTO Inventor and entrepreneur resources: https://uspto.gov/learning-and-resources/inventors-entrepreneursresources\n\u2022 USPTO Inventors Assistance Center: 800-786-9199; 517-272-1000; TTY: 800-877-8339\nUnited States Access Board\n\u2022 https://www.access-board.gov/guidelines-and-standards/transportation\n 42 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nVI. Appendix B \u2013 U.S. Government AV Contacts\nOrganization Email\nDHS STMCSTasking@hq.dhs.gov\nDoD osd.pentagon.ousd.r-e.mbx.autonomy@mail.mil\nDOE EEMS@ee.doe.gov\nDOI feedback@ios.doi.gov\nDOJ automated.vehicles@usdoj.gov\nEPA OTAQ@epa.gov\nFLC support@FederalLabs.org\nGSA Vehicle.Policy@gsa.gov\nNASA Autonomous-Vehicles@mail.nasa.gov\nNCD ncd@ncd.gov\nNIST inquiry@nist.gov\nNSF info@nsf.gov\nNTSB Correspondence@ntsb.gov\nUnited States Access Board info@access-board.gov\nUSDA askUSDA@usda.gov\nUSDOT\nautomation@dot.gov\nTransitAutomation@dot.gov\nav_info_nhtsa@dot.gov\nUSPS vehicletechnology@usps.gov\nUSPTO HelpAAU@uspto.gov\nAppendix C \u2013 Automated Vehicle Fast Track Action Committee \u2014 43\nVII. Appendix C \u2013 Automated Vehicle Fast Track Action\nCommittee\nChair\nMichael Kratsios\nUnited States Chief Technology Officer\nMembers\nSujeesh Kurup Sudarsana Kurup\nEOP/OSTP Liaison\nVishal Amin\nEOP/IPEC\nBrooks Bentley\nEOP/NSC\nMichael Berube\nDOE\nMark Champoux\nDOJ\nDavid Connolly\nEOP/OMB\nKarin Ferriter\nDOC/USPTO\nFinch Fulton\nUSDOT\nChazeman Jackson\nHHS\nDouglas Kinkoph\nDOC/NTIA\nJulius Knapp\nFCC\nTom McDermott\nDHS\nBart Meroney\nDOC/ITA\nJon Montgomery\nNASA\nWayne Nickols\nDoD\nJames Olthoff\nDOC/NIST\nAndrew Smith\nFTC \n 44 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nVIII. Appendix D \u2013 Development and Writing Team\nDepartment of\nCommerce\nNational Institutes of Standards and\nTechnology\nHeather Evans\nChris Greer\nAjit Jillavenkatesa\nTim McBride\nElena Messina\nAl Wavering\nNational Telecommunications\nand Information Administration\nCharles Cooper\nDerek Khlopin\nDouglas Kinkoph\nUnited States Patent and Trade\nMark Office\nKarin Ferriter\nChristian Hannon\nMolly Stech\nInternational Trade\nAdministration\nElizabeth Clark\nAnne Driscoll\nScott Kennedy\nBart Meroney\nDale Tasharski\nAndy Parris\nHolly Vineyard\nDepartment of\nEducation\nJean Morrow\nDepartment of Energy\nDavid Anderson\nMichael Berube\nErin Boyd\nHeather Croteau\nPrasad Gupte\nRachael Nealer\nDepartment of Defense\nBrandon Newell\nWayne Nickols\nDepartment of Health\nand Human Services\nDawn Castillo\nHongwei Hsiao\nChazeman Jackson\nJennifer E. Lincoln\nStephanie Pratt\nWilliam (Karl) Sieber\nDepartment of\nHomeland Security\nMark Fleming\nChristian Van Ginder\nJonathan Murphy\nTed Sobel\nPeter W. Tortorell, Jr.\nJeremiah B. Wells\nDepartment of Justice\nMike Buchwald\nMark Champoux\nMakan Delrahim\nJennifer Dixton\nBrendan Groves\nDaniel Haar\nAarash A. Haghighat\nChris Hardee\nJoseph Heaps\nLionel Kennedy\nDavid Knight\nDavid Lawrence\nDavid Mudd\nBrian H. Pandya\nKimberley Raleigh\nSujit Raman\nWilliam Rinner\nColin T. Ross\nSteven Schuetz\nAnthony M. Shults\nMick Stawasz\nJoy Welan\nDepartment of Labor\nKristen Monaco\nMichael Reardon\nLindsey Teel\nNathan Uldricks\nKim Vitelli\nDepartment of State\nVanessa Guest\nMegan Walklet-Tighe\nDepartment of\nTransportation\nNational Highway Traffic\nSafety Administration\nSara Bennett\nJonathan Morrison\nDorothy Jo (Dee) Williams\nFederal Highway Administration\nCarl Andersen\nValerie Briggs\nBrian Cronin\nJohn Harding\nTaylor Lochrane\nHeather Rose\nDale Thompson\nAppendix D \u2013 Development and Writing Team \u2014 45\nFederal Transit Administration\nDanyell Diggs\nJustin John\nSteve Mortensen\nGwo-Wei Torng\nFederal Motor Carrier Safety\nAdministration\nJeff Loftus\nNicole Michelle\nJonathan Mueller\nKelly Regal\nOffice of the Secretary of\nTransportation\nJulie Abraham\nJohn Augustine\nNicole Baker\nLily Ballengee\nTed Boll\nDavid Carter\nTony Choi\nTrish Fritz\nFinch Fulton\nDiana Furchtgott-Roth\nAriel Gold\nTimothy Mullins\nSteve Polzin\nSujeesh Kurup Sudarsana Kurup\nDepartment of the\nTreasury\nWendy Friese\nDavid Kautter\nKrishna Vallabhaneni\nJames Wang\nEnvironmental Protection\nAgency\nAlexander Dominguez\nMatt Brusstar\nDavid Haugen\nKarl Simon\nFederal Communications\nCommission\nPaul Jackson\nIra Keltz\nJulius Knapp\nPaul Murray\nAspasia Paroutsas\nJamison Prime\nRonald E. Williams\nFederal Laboratory\nConsortium for\nTechnology Transfer\nJohn Dement\nKevin Barquinero\nDenise Wainer\nFederal Trade\nCommission\nMark Eichorn\nPeder Magee\nManeesha Mithal\nAndrew Smith\nGeneral Services\nAdministration\nAlexander Kurien\nPatrick McConnell\nJim Vogelsinger\nNational Aeronautics and\nSpace Administration\nB. Danette Allen\nTerrence Fong\nNational Council on\nDisability\nRebecca Cokley\nJoan Durocher\nLisa Grubb\nGeraldine-Drake Hawkins\nRobyn Powell\nNeil Romano\nJeff Rosen\nAnne Sommers\nClyde Terry\nNational Science\nFoundation\nDawn Marie Tilbury\nLloyd Whitman\nNational Transportation\nSafety Board\nSteve Blackistone\nJoseph Schmoll\nChristopher Wallace\nSmall Business\nAdministration\nJennifer Shieh\nJohn R. Williams\nSecurities and Exchange\nCommission\nJessica Leonardo\nHolli Heiles Pandol\nUnited States Access\nBoard\nJuliet Shoultz\nScott Windley\nUnited States Department\nof Agriculture\nMichael Buser\nRichard Derksen\nSteven Thomson\nUnited States Postal\nService\nScott R. Bombaugh\nDon E. Crone\nRod Sallay\n 46 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nIX. Appendix E \u2013 Acronyms\nAcronym Meaning\n21CTP 21st Century Truck Partnership\nAACVTE UMTRI\u2019s Ann Arbor Connected Vehicle Test Environment\nACL Administration for Community Living\nADA Americans with Disabilities Act\nADAS Advanced Driver Assistance Systems\nADS Automated Driving Systems\nAI Artificial Intelligence\nALARC Arid Land Agricultural Research Center\nANSI American National Standards Institute\nARPA-E DOE Advanced Research Projects Agency-Energy\nARS USDA Agricultural Research Service\nAS Automated System\nASSP American Society of Safety Professionals\nATCMTD Advanced Transportation and Congestion Management Technologies Deployment\nATTRI Accessible Transportation Technologies Research Initiative\nAV Automated Vehicles\nAVFTAC Automated Vehicle Fast Track Action Committee\nBLS United States Bureau of Labor Statistics\nCAV Connected and Automated Vehicle\nCBP Customs and Border Protection\nCEQ Council on Environmental Quality\nCFIUS Committee on Foreign Investment in the United States\nCISA DHS Cybersecurity and Infrastructure Security Agency\nCISE NSF Directorate for Computer and Information Science and Engineering\nCMV Commercial Motor Vehicle\nCoVeR Combat Vehicle Robotics\nCV Connected Vehicle\nDHS Department of Homeland Security\nDOC Department of Commerce\nDoD Department of Defense\nAppendix E \u2013 Acronyms \u2014 47\nAcronym Meaning\nDOE Department of Energy\nDOI Department of the Interior\nDOJ Department of Justice\nDOL Department of Labor\nDOS U.S. State Department\nDSRC Dedicated Short Range Communication\nED Department of Education\nENG NSF Directorate for Engineering\nEOP Executive Office of the President\nEPA Environmental Protection Agency\nERDC Army's Engineering Research and Development Center\nFAST Act Fixing America\u2019s Surface Transportation Act\nFCC Federal Communications Commission\nFDII Foreign-derived intangible income\nFEDFLEET Federal Fleet Policy Council\nFFRDC Federally Funded Research and Development Center\nFHWA Federal Highway Administration\nFLC Federal Laboratory Consortium for Technology Transfer\nFMCSA Federal Motor Carrier Safety Administration\nFMVSS Federal Motor Vehicle Safety Standards\nFOA Funding Opportunity Announcement\nFTA Federal Transit Administration\nFTAC Fast Track Action Committee\nFTC Federal Trade Commission\nFY Fiscal Year\nGPS Global Positioning System\nGSA General Services Administration\nHHS Department of Health and Human Services\nHMI Human-Machine Interface\nHMMWV High Mobility Multipurpose Wheeled Vehicle\nHPC High performance computing\nHSSEDI Homeland Security Systems Engineering and Development Institute\nIC-DISC Interest charge domestic international sales corporation\n 48 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nAcronym Meaning\nIoT Internet of Things\nIP Intellectual Property\nIPEC Intellectual Property Enforcement Coordinator\nIRS Internal Revenue Service\nITA International Trade Administration\nITS NTIA Institute for Telecommunications Sciences\nITS JPO Intelligent Transportation Systems Joint Program Office\nLIDAR Light Detection and Ranging\nMCICOM Marine Corps Installations Command\nMENNDL Multi-node Evolutionary Neural Networks for Deep Learning\nMUTCD Manual on Uniform Traffic Control Devices\nNASA National Aeronautics and Space Administration\nNASCTN National Advanced Spectrum and Communications Test Network\nNCCoE NIST National Cybersecurity Center of Excellence\nNCD National Council on Disability\nNEPA National Environmental Policy Act\nNEXTCAR Next-Generation Energy Technologies for Connected and Automated On-Road Vehicles\nNHTSA National Highway Traffic Safety Administration\nNIDILRR National Institute on Disability, Independent Living, and Rehabilitation Research\nNIFA National Institute of Food and Agriculture\nNIJ National Institute of Justice\nNIOSH National Institute for Occupational Safety and Health\nNIST National Institute of Standards and Technology\nNPS National Park Service\nNRMC National Risk Management Center\nNSC National Security Council\nNSF National Science Foundation\nNSTC National Science and Technology Council\nNTIA National Telecommunications and Information Administration\nNTRS NASA Technical Reports Server\nNTSB National Transportation Safety Board\nNTV Non-Tactical Vehicle\nODD Operational Design Domain\nAppendix E \u2013 Acronyms \u2014 49\nAcronym Meaning\nODEP DOL Office of Disability Employment Policy\nOEDR Object and Event Detection and Response\nOEM Original Equipment Manufacturers\nOFS Office of Federal Sustainability\nOGP GSA Office of Government-wide Policy\nOIRA Office of Information and Regulatory Affairs\nOMB Office of Management and Budget\nOST Office of the Secretary of Transportation\nOSTP Office of Science and Technology Policy\nOTMP Office of Trade and Manufacturing Policy\nPERF Police Executive Research Forum\nPRAM NIST Privacy Risk Assessment Methodology\nR&D Research and Development\nRCV Robotics Combat Vehicle\nRFI Request for Information\nS&T Science and Technology\nSBA Small Business Administration\nSBE NSF Directorate for Social, Behavioral, and Economic Sciences\nSBIR Small Business Innovation Research\nSDO Standards Development Organization\nSEC Securities and Exchange Commission\nSMART DOE System Modeling for Accelerated Research in Transportation\nSTAR FTA Strategic Transit Automation Research\nSTEM Science, Technology, Engineering, and Mathematics\nSTI Scientific and Technical Information\nSTTR Small Business Technology Transfer\nT2 Technology Transfer\nTCF DOE Technology Commercialization Fund\nTFA Technology Focus Area\nTNC Transportation Network Company\nUGV Unmanned Ground Vehicles\nUMTRI University of Michigan Transportation Research Institute\nUSDA United States Department of Agriculture\n 50 ENSURING AMERICAN LEADERSHIP IN AUTOMATED VEHICLE TECHNOLOGIES: AUTOMATED VEHICLES 4.0\nAcronym Meaning\nUSDOT United States Department of Transportation\nUSPS United States Postal Service\nUSPTO United States Patent and Trademark Office\nUSTR United States Trade Representative\nV2V Vehicle-to-Vehicle\nV2X Vehicle-to-Everything\nVERVE Visual Environment for Remote and Virtual Exploration\nVTO DOE Vehicle Technologies Office\nVTTI Virginia Tech Transportation Institute\nWZDx Work Zone Data Exchange\n51\nAbout the National Science and Technology Council\nThe National Science and Technology Council (NSTC) is the principal means by which the Executive Branch coordinates\nscience and technology policy across the diverse entities that make up the Federal research and development enterprise.\nA primary objective of the NSTC is to ensure science and technology policy decisions and programs are consistent with\nthe President's stated goals. The NSTC prepares research and development strategies that are coordinated across Federal\nagencies aimed at accomplishing multiple national goals. The work of the NSTC is organized under committees that oversee\nsubcommittees and working groups focused on different aspects of science and technology. More information is available\nat http://www.whitehouse.gov/ostp/nstc.\nAbout the Office of Science and Technology Policy\nThe Office of Science and Technology Policy (OSTP) was established by the National Science and Technology Policy,\nOrganization, and Priorities Act of 1976 to provide the President and others within the Executive Office of the President\nwith advice on the scientific, engineering, and technological aspects of the economy, national security, homeland security,\nhealth, foreign relations, the environment, and the technological recovery and use of resources, among other topics. OSTP\nleads interagency science and technology policy coordination efforts, assists the Office of Management and Budget with\nan annual review and analysis of Federal research and development budgets, and serves as a source of scientific and\ntechnological analysis and judgment for the President with respect to major policies, plans, and programs of the Federal\nGovernment. More information is available at http://www.whitehouse.gov/ostp.\nAbout this Document\nThis document presents the United States Government\u2019s posture for surface transportation automated vehicles (AV) based\non a vision in which American innovators are global leaders in AV technology, integrating this technology in the United\nStates and around the world in a safe and secure manner. As Automated Driving Systems (ADS) come into fruition over the\ncoming years and decades, this document is intended to provide AV innovators a single, high-level reference document to\nnavigate the U.S. Government. The scope of this document is limited to surface transportation AVs and does not include\nmaritime, railway, or aviation concerns.\nThis document is the result of extensive input from relevant stakeholders across 38 Federal departments, independent\nagencies, commissions, and Executive Offices of The President.\nCopyright Information\nThis document is a work of the U.S. Government and is in the public domain (see 17 U.S.C. \u00a7 105). Subject to the stipulations\nbelow, it may be distributed and copied with acknowledgment to OSTP. Copyrights to graphics included in this document\nare reserved by the original copyright holders or their assignees and are used here under the government\u2019s license and\nby permission. Requests to use any images must be made to the provider identified in the image credits or to OSTP if no\nprovider is identified. Published in the United States of America, 2020.\n\n\n\n", "metadata": {"country": "USA", "year": "2020", "legally_binding": "no", "binding_proof": " ", "date": " ", "regulator": " ", "type": "Guidance", "status": "enacted ", "language": "EN", "use_cases": "[1,2, 3, 4, 5, 6]"}}
{"_id": "686744b3a8f60734255f3d1b", "title": "St. Louis Ordinance on the City's Use of Surveillance Technology", "source": "https://www.stlouis-mo.gov/government/city-laws/upload/legislative//Ordinances/BOAPdf/BB815FS%20Ord%20No%2071842.pdf", "text": "ORDINANCE 71842\nBOARD BILL NUMBER 185 FLOOR SUBSTITUTE INTRODUCED BY ALDERMAN\nALDRIDGE\nCOSPONSORS: PRESIDENT MEGAN GREEN/ ALDERMAN BRET NARAYAN/\nALDERMAN SHANE COHN/ ALDERWOMAN DANIELA VELAZQUEZ/\nALDERWOMAN ALSIHA SONNIER\nAn ordinance setting forth regulations for the use of surveillance technology by the City of St.\nLouis; requiring surveillance technology usage and specific technologies be approved by the Board\nof Aldermen after the required public hearing, before any such surveillance technology may be\nused and plans may be put into practice; and containing a severability clause and emergency clause.\nWHEREAS, the use of surveillance technology is becoming increasingly common, and\nWHEREAS, these technologies include various types and sizes of cameras, internet surveillance\nprogramming, listening devices, phone monitoring systems, and other technologies; and\nWHEREAS, recognizing the profound impact of artificial intelligence on surveillance, there is an\nimperative need for comprehensive regulations and robust oversight mechanisms to safeguard\nprivacy, mitigate potential misuse, and ensure ethical and responsible deployment of AI-powered\nsurveillance technologies; and\nWHEREAS, several studies have shown that surveillance technologies are developing faster than\nthe laws to govern them, resulting in an imbalance between governance and the use of these\ntechnologies and causing numerous cities across the country to enact new and/or revised statutes\nto ensure the civil rights and liberties of their citizens where the lawful use of surveillance\ntechnology is approved by their local legislature; and\nWHEREAS, numerous community groups have expressed concerns that surveillance technology\nposes a threat to reproductive freedom, and the privacy of people of color; and\nPage 1 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n18\nPage 2 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 WHEREAS, the Mayor signed Executive Order 78 on February 23, 2024, created Surveillance\n2 Transparency guidelines which this board bill intends to build upon.\n3 BE IT ORDAINED BY THE CITY OF ST. LOUIS AS FOLLOWS:\n4 SECTION ONE. Definitions\n5 1. \u201cArtificial Intelligence\u201d means a machine-based system that can, for a given set of human6 defined objectives, make predictions, recommendations, or decisions influencing real or\n7 virtual environments. Artificial intelligence systems use machine- and human-based inputs\n8 to perceive real and virtual environments; abstract such perceptions into models through\n9 analysis in an automated manner; and use model inference to formulate options for\n10 information or action. This definition shall comply with the meaning outlined in 15 U.S.C.\n11 9401(3).\n12 2. \u201cCity Entity\u201d means any agency, department, bureau, unit, or commission of the City of St.\n13 Louis or any person or entity acting on behalf of any agency, department, bureau, unit, or\n14 commission of the City of St. Louis. A Special Tax District shall not be considered a City\n15 Entity.\n16 3. \u201cCommittee\u201d means a committee to which, pursuant to the Rules of the Board of\n17 Aldermen, bills affecting matters that are subject to this Ordinance are assigned.\n18 4. \u201cDiscrimination\u201d means the disparate treatment or consideration of, or making a distinction\n19 in favor or against a person based on the characteristics, real or perceived, for which\n20 discriminatory treatment is prohibited under the laws and regulations of the United States,\n21 the State of Missouri, and the Charter and ordinances of the City of St. Louis, which shall\n22 include the following characteristics; race, religion, national origin, age, sex, sexual \nPage 3 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 orientation, gender identity, pregnancy, familial status, disability, veteran status and\n2 genetic status.\n3 5. \u201cDisparate Impact\" means an adverse effect that is disproportionately experienced by\n4 individuals having traits, characteristics, or status as to which discrimination is prohibited\n5 under the Constitution or any laws of the United States, under the constitution or any law\n6 of the state of Missouri, or the Charter or any ordinance of the City of St. Louis.\n7 6. \u201cExigent circumstances\u201d means an emergency involving imminent danger of death or\n8 serious physical injury to any person that requires the immediate use of Surveillance\n9 Technology or the information it provides.\n10 7. \u201cNew surveillance technology\u201d shall mean any type of surveillance technology, the\n11 acquisition of which was not previously approved by the Board of Aldermen pursuant to\n12 the requirements of this ordinance. A surveillance technology is not considered a new\n13 surveillance technology where its capabilities and functionality do not differ in any\n14 significant way from a previously approved version of an equivalent surveillance\n15 technology.\n16 8. \u201cSurveillance Data\u201d means any information or data collected, captured, recorded, retained,\n17 processed, intercepted, analyzed, or shared by surveillance technology.\n18 9. \u201cSurveillance Technology'' shall mean any electronic surveillance device, hardware, or\n19 software that is capable of collecting, capturing, recording, retaining, processing,\n20 intercepting, analyzing, monitoring, or sharing audio, visual, digital, location, thermal, \nPage 4 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 biometric, behavioral, or similar information or communications specifically associated\n2 with, or capable of being associated with, any specific individual or group; or any system,\n3 device, or vehicle that is equipped with an electronic surveillance device, hardware, or\n4 software has the principal or an intended purpose of monitoring activities, behavior, or\n5 changing conditions to influence, manage, monitor, or protect the safety and welfare of\n6 individuals or groups, or to aid in the prevention of criminal activity or the investigation of\n7 suspected criminal activity. Surveillance technology includes but is not limited to these or\n8 their successor technologies: (a) international mobile subscriber identity (IMSI) catchers\n9 and other cell site simulators; (b) automatic license plate readers; (c) closed-circuit\n10 television cameras; (d) biometric surveillance technology, including facial, voice, iris, and\n11 gait-recognition software and databases; (e) mobile DNA capture technology; (f) gunshot\n12 detection and location hardware and services; (g) x-ray vans; (h) video and audio\n13 monitoring and/or recording technology, such as surveillance cameras, wide-angle\n14 cameras, and wearable body cameras; (i) surveillance enabled or capable light bulbs or\n15 light fixtures; (j) social media monitoring software; (k) through-the-wall radar or similar\n16 imaging technology; (l) passive scanners of radio networks; (m) long-range Bluetooth and\n17 other wireless-scanning devices; (n) radio-frequency I.D. (RFID) scanners; (o) software\n18 designed to integrate or analyze data from surveillance technology, including surveillance\n19 target tracking and predictive policing software. and (p) technology that includes Artificial\n20 Intelligence to deploy, direct, execute, analyze, or engage in surveillance. The enumeration\n21 of surveillance technology examples in this subsection shall not be interpreted as an\n22 endorsement or approval of their use by any city entity; \u201cSurveillance technology\u201d does \nPage 5 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 not include the following unless they have been equipped with, or are modified to become\n2 or include, a surveillance technology as defined herein: a. Routine office hardware (such\n3 as televisions, computers, and printers) that are in widespread public use and will not be\n4 used for any surveillance or surveillance related functions; b. Parking Ticket Devices\n5 (PTD); c. Surveillance devices that cannot record or transmit audio or video or be remotely\n6 accessed, such as image stabilizing binoculars, night vision goggles, or similar imaging\n7 devices; d. City Entity databases that do not and will not contain any data or other\n8 information collected, captured, recorded, retained, processed, intercepted, or analyzed by\n9 surveillance technology including but not limited to databases containing private\n10 healthcare information required under the Health Insurance Portability and Accountability\n11 Act (HIPAA), disease outbreak management systems and e. Manually operated\n12 technological devices that are used primarily for internal city entity communications and\n13 are not designed to surreptitiously collect surveillance data, such as radios, tablets, city14 issued cell phones, and email systems.\n15 10. \u201cViewpoint-based\" shall mean targeted at any community or group or their members\n16 because of their exercise of rights protected under the First Amendment of the United\n17 States Constitution.\n18 SECTION TWO. Board of Aldermen Approval Mandatory\n19 A. A City Entity must obtain Board of Aldermen approval \u2013 in the form of a resolution that shall\n20 be introduced to the full Board of Aldermen, referred to the relevant Committee, and thereafter\n21 voted on by the Committee subsequent to a mandatory, properly-noticed, germane, hearing at \nPage 6 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 which the public is afforded a fair and adequate opportunity to provide online, written, and oral\n2 testimony, as referenced in Section (3)(F) prior to engaging in any of the following:\n3 1. Accepting funds for a new surveillance technology, including but not limited to grant\n4 funding, or accepting state or federal funds or in-kind or other donations;\n5 2. Acquiring, borrowing, or sharing surveillance technology, including the surveillance data\n6 therefrom, whether or not that acquisition is made through the exchange of monies or other\n7 consideration;\n8 3. Using new or existing surveillance technology for a purpose or in a manner not previously\n9 approved pursuant to this ordinance, or exceeding a quantitative limit as outlined within\n10 the Surveillance Use Plan previously approved by the Board of Aldermen in accordance\n11 with this ordinance, including the acquisition or sharing of surveillance data therefrom; or\n12 4. Soliciting proposals for or entering into an agreement with any other person or entity, by\n13 way of a Request for a Proposal (RFP), to acquire, share, or otherwise use surveillance\n14 technology or surveillance data.\n15 B. Nothing in this Section shall be deemed to prohibit:\n16 1. A city law enforcement entity, in the course of a specific, active criminal investigation,\n17 from securing surveillance data from a non-city entity pursuant to a judicially-issued\n18 probable cause warrant, from receiving surveillance data voluntarily provided for no\n19 monetary or other consideration by a non-city entity or an individual not acting in their\n20 capacity as an employee or agent of a City Entity, or from allowing an individual not acting\n21 in their capacity as an employee or agent of a city entity to review but not possess \nPage 7 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 surveillance data in possession of the city law enforcement entity; or\n2 2. Any city entity from responding to a valid and lawful request for government records\n3 pursuant to Chapter 610 of the Revised Statutes of Missouri (the \u201cMissouri Sunshine\n4 Law\u201d).\n5 C. In the event a City Entity operates an approved real-time crime center (RTCC) jointly with other\n6 counties or municipalities, nothing in this Act shall be deemed to restrict the RTCC's receipt or\n7 sharing of surveillance data from or with non-City Entity operators, or its use of surveillance\n8 technologies to analyze or process non-city entity-provided data for the benefit of non-city entities.\n9 Rather, with respect to jointly operated RTCCs, this Act shall only prohibit city entities from (1)\n10 providing, receiving, or reviewing surveillance data that was collected produced by, or derived\n11 from a surveillance technology that has not been approved by the Board of Alderman pursuant to\n12 this Act, and (2) permitting or allowing City Entity-provided data to be analyzed or processed\n13 using a surveillance technology that has not been approved by the Board of Alderman pursuant to\n14 this Act.\n15 D. Once approval for a Surveillance Technology Use Plan has been obtained, it applies throughout\n16 the procurement or budgeting process.\n17 SECTION THREE. Surveillance Use Plan (\u201cSUP\u201d) and Timing of Review, Hearings, and Votes\n18 A. As a part of the process of seeking Board of Aldermen approval pursuant to Section 2, a\n19 City Entity shall submit to the Board of Aldermen and make publicly available a Surveillance Use\n20 Plan concerning the surveillance technology at issue. No approval of the acquisition or use of\n21 surveillance technology by a City Entity pursuant to Section 2 shall be permitted without the Board \nPage 8 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 of Aldermen's express approval of the related Surveillance Use Plan. The Board of Aldermen may\n2 request review and recommendations from the Civil Rights Enforcement Agency (CREA),\n3 Division of Civilian Oversight, the Information Technology Department, the City Counselor\u2019s\n4 Office, or a functionally equivalent City organization prior to voting on a surveillance technology\n5 approval resolution and related Surveillance Use Plan.\n6 1. Resolutions and related Surveillance Use Plans for the approval of new surveillance\n7 technologies may only be submitted to the Board of Aldermen between September 1 through\n8 January 15.\n9 B. Prior to a vote on the resolution containing a Surveillance Use Plan, the Committee may\n10 request revisions be made by the submitting City Entity as outlined in Section 3(C), to be\n11 considered as amendments at the next regularly scheduled or specially called Committee meeting.\n12 C. Upon submission of the SUP to the clerk of the Board of Alderman and the respective\n13 Committee chair, The President of the Board of Alderman shall assign the resolution with the SUP\n14 attached to the Committee. The President of the Board shall make these assignments in a timely\n15 manner, so as they may be announced by the clerk, no later than the second, subsequent regular\n16 meeting that the resolution was introduced.\n17 1. Pursuant to Section 3 (E), the resolution and the initial SUP shall be publicly noticed for\n18 21 days before a Committee hearing is held to discuss the resolution and the SUP. The Committee\n19 hearing, at which the opportunity for public testimony shall be required, shall be held within 14\n20 days of the expiration of the public notice period.\n21 2. After public testimony is taken on the resolution and the SUP pursuant to Sections\n22 3(C)(1) and (10), the Committee shall take a vote on the resolution and SUP within 14 days, unless \nPage 9 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 the Committee requests additional information from the City Entity or makes or requests changes\n2 to the resolution or SUP.\n3 3. If the Committee requests more information from the City Entity or changes to the\n4 resolution or SUP, the City Entity shall have a maximum of 30 days to submit the requested\n5 information and changes and to provide the Committee with comments on the proposed changes\n6 to the resolution or SUP. The City Entity may request an extension beyond 30 days by sending\n7 such request to the Chair of the Committee and the Clerk of the Board with the date that the City\n8 Entity will provide the requested information, documentation, or changes.\n9 4. Upon receipt of the information, changes, and/or comments provided by the City Entity,\n10 the Committee shall make the provided information, changes, and comments available to the\n11 public, at a designated page on the City website.\n12 5. The Committee shall call a hearing within 14 days to review the information, changes,\n13 and/or comments provided by the City Entity and take public testimony.\n14 6. After public testimony is taken on the resolution and SUP pursuant to Section 3(C)(5)\n15 and (10), the Committee shall take a vote on the resolution and SUP within 14 days.\n16 7. If the resolution and SUP are approved by the Committee, the resolution and SUP shall\n17 advance to the full Board of Aldermen for a final vote, which shall be taken within 30 days.\n18 8. If the resolution and SUP are not approved by either the Committee or the full Board of\n19 Aldermen:\n20 a. Any existing contract involving a surveillance technology that was not approved for use\n21 pursuant to this ordinance may continue to be honored in accordance with the terms of the contract\n22 and any ongoing criminal investigation utilizing said technology may continue until the \nPage 10 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 investigation has concluded, but immediately cease once that investigation ends. However, the\n2 Surveillance Technology shall not be used in future investigations upon the disapproval of the\n3 Board of Alderman.\n4 c. The surveillance technology that was not approved may not be used, even if funds have\n5 been allocated for its acquisition, use, operation, or maintenance, including by the Board of\n6 Estimate and Apportionment.\n7 9. Weekdays on which the Board of Aldermen is in recess, and weekend days following a\n8 Friday on which the Board of Aldermen is in recess, shall not count toward the time periods\n9 in Section 3(C) that pertain to Committee or Board of Aldermen hearings and votes.\n10 10. All resolutions covered by this ordinance shall be properly noticed pursuant to Chapter\n11 610 of the Revised Statutes of Missouri (\u201cMissouri Sunshine Law\u201d) before a committee\n12 hearing is held to discuss the resolution. Public testimony shall be required at all hearings\n13 mandated under Section 3(C) if members of the public appear to give testimony or submit\n14 written testimony.\n15 D. Surveillance Use Plan: A Surveillance Use Plan submitted pursuant to this Section shall be a\n16 publicly released, legally enforceable written report that includes, at a minimum, the following:\n17 1. General Description: Information describing the surveillance technology and how it works,\n18 including product descriptions from manufacturers.\n19 2. Purpose: What specific purpose(s) the surveillance technology is intended to advance.\n20 3. Authorized Use(s): For what specific capabilities and uses of the surveillance technology\n21 is authorization being sought, including amounts to be acquired and deployed, expected \nPage 11 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 geographic areas and durations, organizational partnerships, and Memorandums of\n2 Understanding (MOUs) and:\n3 a. What legal and procedural rules will govern each authorized use, including where\n4 an application of Surveillance Technology requires a warrant;\n5 b. What potential uses of the surveillance technology will be expressly prohibited; and\n6 c. How and under what circumstances will surveillance data that was collected,\n7 captured, recorded, or intercepted by the surveillance technology be analyzed and\n8 reviewed.\n9 4. Deployment: If the surveillance technology will not be uniformly deployed or targeted\n10 throughout the city, what factors will be used to determine the specific geographic\n11 targeting, and what measures will be taken to ensure such targeting is racially and\n12 economically neutral.\n13 5. Cost: The fiscal impact of the surveillance technology, including costs of technology\n14 acquisition, operation, maintenance, personnel, and data storage, as well as all sources of\n15 funding and donations.\n16 6. Discriminatory Impact Avoidance: What specific, affirmative measures will be\n17 implemented to safeguard the public from the potential discriminatory impacts of the\n18 technology, including without limitation what measures will be used to avoid biases in\n19 surveillance targeting and data collection.\n20 7. Data Collection: \nPage 12 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 a. What types of surveillance data will be collected, captured, recorded, intercepted,\n2 or retained by the surveillance technology;\n3 b. What surveillance data may be inadvertently collected during the authorized uses\n4 of the surveillance technology, and what measures will be taken to minimize the\n5 inadvertent collection of data; and\n6 c. How inadvertently collected surveillance data will be expeditiously identified and\n7 deleted.\n8 d. How the City Entity will ensure that, when it retains surveillance data, such\n9 retention will be in compliance with Section Three(D)(9) of this ordinance, and\n10 that when it collects surveillance data, it (1) shall not collect surveillance data\n11 concerning an individual where there is no reasonable suspicion that the individual\n12 is involved in criminal conduct or activity and the information is relevant to that\n13 criminal conduct or activity and (2) shall not collect criminal intelligence\n14 information about the political, religious or social views, associations, or activities\n15 of any individual or any group, association, corporation, business, partnership, or\n16 other organization unless such information directly relates to criminal conduct or\n17 activity and there is reasonable suspicion that the subject of the information is\n18 involved in criminal conduct or activity.\n19 8. Data Protection: What safeguards will be used to protect surveillance data from\n20 unauthorized access, including encryption and access control mechanisms, and what\n21 protocols will be put in place to authorize access and monitor who has access. \nPage 13 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 9. Data Retention: What rules and procedures will govern the retention and deletion of\n2 surveillance data, including how it will be ensured that the schedule for retaining and\n3 deleting data aligns with the guidelines specified in RSMo 109.200-109.310 and how data\n4 collected by the City Entity as a result of the use of surveillance technology shall be stored\n5 in a manner such that it cannot be modified, destroyed, accessed or purged contrary to the\n6 Missouri Police Clerks Records Retention Schedule.\n7 10. Surveillance Data Sharing: If a city entity is seeking authorization to share access to\n8 surveillance technology or surveillance data with any other persons, city entities, or\n9 governmental entities, it shall detail:\n10 a. Which persons, city entities, or other governmental entities will be approved for (i)\n11 surveillance technology sharing, and for (ii) surveillance data sharing;\n12 b. How such sharing is necessary for the stated purpose and use of the surveillance\n13 technology;\n14 c. How will it ensure any person, city entity, or other governmental entity approved\n15 for access to the surveillance technology or surveillance data complies with the\n16 applicable Surveillance Use Plan and does not further disclose the surveillance data\n17 to unauthorized persons and entities; and\n18 11. Demands for Access to Surveillance Data: What legal standard must be met by government\n19 entities or third parties seeking or demanding access to surveillance data.\n20 12. Training: What training procedures will be implemented to ensure compliance with this\n21 ordinance, the Revised Code of the City of St. Louis, and applicable federal and state laws \nPage 14 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 and regulations.\n2 13. Auditing and Oversight: What mechanisms will be implemented to ensure the Surveillance\n3 Use Plan is followed, including what independent or non-independent persons or entities\n4 will be given oversight authority, and what legally enforceable sanctions will be put in\n5 place for violations of the Plan.\n6 14. Complaints: What procedures will be put in place by which members of the public can\n7 register complaints or concerns, or submit questions about the deployment or use of a\n8 specific surveillance technology, and how the city entity will ensure each question and\n9 complaint is responded to in a timely manner.\n10 E. In no event will access to surveillance technology be permitted to investigate, analyze, review,\n11 or gather information solely concerning any action or speech protected by the First Amendment to\n12 the United States Constitution. Additionally, in no event will access to surveillance technology be\n13 permitted to investigate, analyze, review, or gather information protected under HIPAA.\n14 F. The Committee hearing required pursuant to Section 2 may not be held until the required\n15 Surveillance Use Plan has been available to the public, at a designated page on the City website,\n16 for a period of at least twenty-one (21) calendar days.\n17 G. Open Records: All complete and unredacted Surveillance Technology Use Plans shall be\n18 considered \u201copen records\u201d as permitted under the Missouri Sunshine Law.\n19 H. Exceptions: Unless limitations are set forth in the Surveillance Technology Use Plan, the\n20 acquisition of additional units of Surveillance Technology, or the replacement of existing\n21 technology with like-kind units shall not be considered a modification to a Plan requiring approval \nPage 15 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 subject to the approval procedures of this ordinance.\n2 SECTION FOUR. Review of Preexisting Uses Mandatory\n3 No later than one hundred fifty (150) days following the effective date of this ordinance, any City\n4 Entity seeking to continue the use of any surveillance technology that was in use prior to the\n5 effective date of this ordinance, or the sharing of surveillance data therefrom, must commence a\n6 Board of Aldermen approval process in accordance with Section 2, and upon receipt of the required\n7 resolution and SUP, the Board of Aldermen must initiate the approval review process in\n8 accordance with the procedures and timelines set forth in Section 3. During this review process,\n9 the City Entity may continue the use of the Surveillance Technology, until the technology is\n10 approved or rejected during the review process in accordance with Section 3.\n11 SECTION FIVE. Lead Entity Identification\n12 If more than one city entity will have access to the surveillance technology or surveillance data, a\n13 lead city entity shall be identified. The lead city entity shall be responsible for maintaining the\n14 surveillance technology and ensuring compliance with all related laws, regulations, and protocols.\n15 SECTION SIX. Standard for Approval\n16 The Board of Aldermen shall only approve a request to fund, acquire, or use a surveillance\n17 technology if it determines the benefits of the surveillance technology outweigh its costs, that the\n18 proposal will safeguard civil liberties and civil rights, and that the uses and deployments of the\n19 surveillance technology will not be based upon discriminatory or viewpoint-based factors or have\n20 a disparate impact on any community or group. During such analysis, the Board of Alderman shall\n21 decide on the approval of surveillance technology based on their compliance with the requirements\n22 of this ordinance, notwithstanding the potential availability of third-party funding. To assist the \nPage 16 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 public in participating in such an analysis, all approved Surveillance Use Plans shall be made\n2 available to the public, at a designated page on the relevant city entity's public website, for as long\n3 as the related surveillance technology remains in use. Approval for the funding, acquisition, and/or\n4 use of a surveillance technology by the Board of Aldermen, where the risk of potential\n5 discriminatory impacts on civil liberties or civil rights has been identified in the Surveillance Use\n6 Plan, shall not be interpreted as an acquiescence to such impacts, but rather as an acknowledgment\n7 that a risk of such impacts exists and must be proactively avoided.\n8 SECTION SEVEN. Annual Surveillance Reports\n9 A. For each Surveillance Technology approved pursuant to this ordinance, the lead City Entity\n10 must submit an annual report detailing its use during the preceding calendar year to the Clerk of\n11 the Board of Aldermen and Chair of the respective Committee on or before February 28th of each\n12 year. All annual surveillance reports shall be considered an \u201copen record\u201d under the Missouri\n13 Sunshine Law as permitted by law and shall be posted on the city entity\u2019s website within five (5)\n14 days of submission for at least one calendar year.\n15 B. All annual surveillance reports shall contain the following information:\n16 1. A summary of how the surveillance technology was used, including frequency of use,\n17 numbers deployed, and duration of use;\n18 2. Whether and how often collected surveillance data was shared with and received from any\n19 external persons or entities, the name(s) of any recipient or entity, the type(s) of data\n20 disclosed, under what legal standard(s) the information was disclosed, and the justification\n21 for the disclosure(s);\nPage 17 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 3. Where applicable, a breakdown of where the surveillance technology was deployed\n2 geographically, by individual census tract as defined in the relevant year by the United\n3 States Census Bureau, ward boundary, neighborhood boundary, or St. Louis Metropolitan\n4 Police Department district as applicable.\n5 4. A breakdown of how many Surveillance Technology deployments were utilized in pursuit\n6 of a crime/an active criminal investigation, and the classification of the offense.\n7 5. The number of Surveillance Technology requests submitted by Alderpersons per ward.\n8 6. A summary of complaints or concerns that were received about the surveillance technology\n9 with no identifying personal information;\n10 7. The results of any internal audits, any information about violations of the Surveillance Use\n11 Plan, and any actions taken in response;\n12 8. A good faith effort of an analysis of any discriminatory, disparate, and other adverse\n13 impacts the use of the technology may have had on the public\u2019s civil rights and civil\n14 liberties, including but not limited to those guaranteed by the First, Fourth, and Fourteenth\n15 Amendment to the United States Constitution; and\n16 9. For the preceding fiscal year, an annual budget spending report detailing, by line item, all\n17 expenditures on Surveillance Technologies and the specific sources of funding or\n18 resources, both internal and external, for Surveillance Technologies.\n19 10. Total annual costs for the surveillance technology, including personnel and other ongoing\n20 costs, and what source of funding will fund the technology in the coming year.\nPage 18 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 11. For purposes of this section, \u201cexternal persons and entities\u201d shall not include specifically\n2 identifying persons acting in their individual capacities.\n3 SECTION EIGHT. Remedies; Discipline; Whistleblower Protections; Exclusionary Rule;\n4 Deletion/Destruction Requirement\n5 A. Unless prohibited by state law, federal law, the Missouri Constitution, or the Missouri Supreme\n6 Court rules and procedures, any violation of this ordinance, including but not limited to funding,\n7 acquiring, or utilizing surveillance technology that has not been approved pursuant to this\n8 ordinance or utilizing surveillance technology in a manner or for a purpose that has not been\n9 approved pursuant to this ordinance, constitutes an injury and any person may institute any and all\n10 available civil legal proceedings, including but not limited to actions for damages in any court of\n11 competent jurisdiction to enforce this ordinance.\n12 B. Unless prohibited by state law, federal law, the Missouri Constitution, or the Missouri Supreme\n13 Court rules and procedures, a court shall award costs and reasonable attorneys\u2019 fees to the plaintiff\n14 who if they are the prevailing party in an action brought to enforce this ordinance.\n15 C. City employees or agents, except in response to a declared municipal, state, or federal state\n16 of emergency, shall not use any surveillance technology except in a manner consistent with\n17 policies approved pursuant to the terms of this ordinance.\n18 D. Should an employee or agent of a City Entity violate any provisions of this Act, the City\n19 Entity shall take appropriate disciplinary action against the employee or agent, subject to and in\n20 accordance with the provisions of the RSMo. 590.502, RSMo. 84.341, Civil Service Rule IX, and\n21 all applicable Department of Personnel Regulations. \nPage 19 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 E. Whistleblower protections: In accordance with provisions of Civil Service Rule IX, Chapter\n2 15.14 of the City Code, and all applicable Department of Personnel Regulations, No City Entity\n3 or anyone acting on behalf of a City Entity may take or fail to take, or threaten to take or fail to\n4 take, a personnel action with respect to any employee or applicant for employment, including but\n5 not limited to discriminating with respect to compensation, terms, conditions, access to\n6 information, restrictions on due process rights, privileges of employment, or civil or criminal\n7 liability, because the employee or applicant was perceived to, about to, or assisted in any lawful\n8 disclosure of information concerning the funding, acquisition, or use of a surveillance technology\n9 or surveillance data to any relevant city agency, city law enforcement, prosecutorial, or\n10 investigatory office, or Alderman, based upon a good faith belief that the disclosure evidenced a\n11 violation of this ordinance.\n12 F. Exclusionary Rule; Deletion/Destruction Requirement: Unless prohibited by state law, federal\n13 law, the Missouri Constitution, the Missouri Supreme Court rules and procedures:\n14 1. Any data or other information created or collected in contravention of this ordinance, and\n15 any data or information derived therefrom, shall be immediately deleted and destroyed, and may\n16 not:\n17 a. Be offered as evidence by any City government entity, agency, department, prosecutorial\n18 office, or any other subdivision thereof, in any criminal or civil action or proceeding against any\n19 member of the public, except as evidence of the violation of this ordinance; or\n20 b. Be voluntarily provided to another person or entity for use as evidence or for any other\n21 purpose.\nPage 20 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 2. Notwithstanding the above, if, upon the discovery of data or other information that was\n2 created or collected in contravention of this ordinance, it appears such data or information may be\n3 material to the defense in a criminal prosecution, a copy of the relevant, potentially material data\n4 or other information shall be turned over to the defendant before it is deleted and destroyed, except\n5 where prohibited by local, state, or federal law.\n6 G. Nothing in this ordinance, this section, or the administration or application thereof shall be\n7 construed to create a right of action between private parties.\n8 SECTION NINE. Use of unapproved surveillance technology in exigent circumstances.\n9 A. A City Entity may temporarily acquire, or temporarily use, surveillance technology in exigent\n10 circumstances without following the provisions of this ordinance provided that the City Entity\n11 does all of the following:\n12 1. Use the surveillance technology to solely respond to the exigent circumstances;\n13 2. Cease using the surveillance technology within 30 calendar days, or when the exigent\n14 circumstances end, whichever is sooner. If an exigent circumstance lasts longer than 30 days, the\n15 City Entity shall request an extension of no more than 30 days from the Board of Aldermen.\n16 Multiple extensions may be individually requested if exigent circumstances so require;\n17 3. Keep and maintain only data related to the exigent circumstances and dispose of any\n18 data that is not relevant to an ongoing investigation, unless its retention is:\n19 a. Necessary to address the exigent circumstance;\n20 b. Authorized by a court based on a finding of probable cause to believe the\n21 information constitutes evidence of a crime; or\n22 c. Otherwise required by law;\nPage 21 of 21\nBoard Bill Number 185\nFloor Substitute\nAldridge\nDecember 8, 2023\n1 4. Not disclose to any third party any information acquired during exigent circumstances\n2 unless such disclosure is:\n3 a. Authorized by a court based on a finding of probable cause to believe the\n4 information constitutes evidence of a crime; or\n5 b. Otherwise required by law; and\n6 5. Within 45 days of the conclusion of the exigent circumstances submit a written report to\n7 the Board of Aldermen identifying the exigent circumstances and the surveillance technology\n8 acquisition and/or use;\n9 B. Any surveillance technology temporarily acquired in exigent circumstances shall not be used\n10 following the end of exigent circumstances unless approved by the Board of Aldermen pursuant\n11 to Section 3.\n12 SECTION TEN. Severability\n13 The provisions of this are severable. If any part of this ordinance, or the application of this\n14 ordinance to any person or circumstance, is held invalid, the remainder of this ordinance, including\n15 the application of such part or provisions to other persons or circumstances, shall not be affected\n16 by such holding and shall continue to have force and effect.\n17 SECTION ELEVEN. Effective Date\n18 This ordinance shall go into effect on July 1, 2024. ", "metadata": {"country": "USA", "year": "2023", "legally_binding": "yes", "binding_proof": "ordinance ", "date": "12/08/2023 ", "regulator": " ", "type": "ordinance", "status": "enacted ", "language": "EN", "use_cases": "[1,2, 3, 4, 5, 6]"}}
{"_id": "686748d0a8f60734255f3d22", "title": "NIST AI Risk Management Framework (RMF 1.0)", "source": "https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-1.pdf", "text": "  \nNIST AI 100-1\nArtificial Intelligence Risk Management\nFramework (AI RMF 1.0)\nNIST AI 100-1\nArtificial Intelligence Risk Management\nFramework (AI RMF 1.0)\nThis publication is available free of charge from:\nhttps://doi.org/10.6028/NIST.AI.100-1\nJanuary 2023\nU.S. Department of Commerce\nGina M. Raimondo, Secretary\nNational Institute of Standards and Technology\nLaurie E. Locascio, NIST Director and Under Secretary of Commerce for Standards and Technology\nCertain commercial entities, equipment, or materials may be identified in this document in order to describe\nan experimental procedure or concept adequately. Such identification is not intended to imply recommendation or endorsement by the National Institute of Standards and Technology, nor is it intended to imply that\nthe entities, materials, or equipment are necessarily the best available for the purpose.\nThis publication is available free of charge from: https://doi.org/10.6028/NIST.AI.100-1\nUpdate Schedule and Versions\nThe Artificial Intelligence Risk Management Framework (AI RMF) is intended to be a living document.\nNIST will review the content and usefulness of the Framework regularly to determine if an update is appropriate; a review with formal input from the AI community is expected to take place no later than 2028. The\nFramework will employ a two-number versioning system to track and identify major and minor changes. The\nfirst number will represent the generation of the AI RMF and its companion documents (e.g., 1.0) and will\nchange only with major revisions. Minor revisions will be tracked using \u201c.n\u201d after the generation number\n(e.g., 1.1). All changes will be tracked using a Version Control Table which identifies the history, including\nversion number, date of change, and description of change. NIST plans to update the AI RMF Playbook\nfrequently. Comments on the AI RMF Playbook may be sent via email to AIframework@nist.gov at any time\nand will be reviewed and integrated on a semi-annual basis.\nTable of Contents\nExecutive Summary 1\nPart 1: Foundational Information 4\n1 Framing Risk 4\n1.1 Understanding and Addressing Risks, Impacts, and Harms 4\n1.2 Challenges for AI Risk Management 5\n1.2.1 Risk Measurement 5\n1.2.2 Risk Tolerance 7\n1.2.3 Risk Prioritization 7\n1.2.4 Organizational Integration and Management of Risk 8\n2 Audience 9\n3 AI Risks and Trustworthiness 12\n3.1 Valid and Reliable 13\n3.2 Safe 14\n3.3 Secure and Resilient 15\n3.4 Accountable and Transparent 15\n3.5 Explainable and Interpretable 16\n3.6 Privacy-Enhanced 17\n3.7 Fair \u2013 with Harmful Bias Managed 17\n4 Effectiveness of the AI RMF 19\nPart 2: Core and Profiles 20\n5 AI RMF Core 20\n5.1 Govern 21\n5.2 Map 24\n5.3 Measure 28\n5.4 Manage 31\n6 AI RMF Profiles 33\nAppendix A: Descriptions of AI Actor Tasks from Figures 2 and 3 35\nAppendix B: How AI Risks Differ from Traditional Software Risks 38\nAppendix C: AI Risk Management and Human-AI Interaction 40\nAppendix D: Attributes of the AI RMF 42\nList of Tables\nTable 1 Categories and subcategories for the GOVERN function. 22\nTable 2 Categories and subcategories for the MAP function. 26\nTable 3 Categories and subcategories for the MEASURE function. 29\nTable 4 Categories and subcategories for the MANAGE function. 32\ni\nNIST AI 100-1 AI RMF 1.0\nList of Figures\nFig. 1 Examples of potential harms related to AI systems. Trustworthy AI systems\nand their responsible use can mitigate negative risks and contribute to benefits for people, organizations, and ecosystems. 5\nFig. 2 Lifecycle and Key Dimensions of an AI System. Modified from OECD\n(2022) OECD Framework for the Classification of AI systems \u2014 OECD\nDigital Economy Papers. The two inner circles show AI systems\u2019 key dimensions and the outer circle shows AI lifecycle stages. Ideally, risk management efforts start with the Plan and Design function in the application\ncontext and are performed throughout the AI system lifecycle. See Figure 3\nfor representative AI actors. 10\nFig. 3 AI actors across AI lifecycle stages. See Appendix A for detailed descriptions of AI actor tasks, including details about testing, evaluation, verification, and validation tasks. Note that AI actors in the AI Model dimension\n(Figure 2) are separated as a best practice, with those building and using the\nmodels separated from those verifying and validating the models. 11\nFig. 4 Characteristics of trustworthy AI systems. Valid & Reliable is a necessary\ncondition of trustworthiness and is shown as the base for other trustworthiness characteristics. Accountable & Transparent is shown as a vertical box\nbecause it relates to all other characteristics. 12\nFig. 5 Functions organize AI risk management activities at their highest level to\ngovern, map, measure, and manage AI risks. Governance is designed to be\na cross-cutting function to inform and be infused throughout the other three\nfunctions. 20\nPage ii\nNIST AI 100-1 AI RMF 1.0\nExecutive Summary\nArtificial intelligence (AI) technologies have significant potential to transform society and\npeople\u2019s lives \u2013 from commerce and health to transportation and cybersecurity to the environment and our planet. AI technologies can drive inclusive economic growth and support\nscientific advancements that improve the conditions of our world. AI technologies, however, also pose risks that can negatively impact individuals, groups, organizations, communities, society, the environment, and the planet. Like risks for other types of technology, AI\nrisks can emerge in a variety of ways and can be characterized as long- or short-term, highor low-probability, systemic or localized, and high- or low-impact.\nThe AI RMF refers to an AI system as an engineered or machine-based system that\ncan, for a given set of objectives, generate outputs such as predictions, recommendations, or decisions influencing real or virtual environments. AI systems are designed\nto operate with varying levels of autonomy (Adapted from: OECD Recommendation\non AI:2019; ISO/IEC 22989:2022).\nWhile there are myriad standards and best practices to help organizations mitigate the risks\nof traditional software or information-based systems, the risks posed by AI systems are in\nmany ways unique (See Appendix B). AI systems, for example, may be trained on data that\ncan change over time, sometimes significantly and unexpectedly, affecting system functionality and trustworthiness in ways that are hard to understand. AI systems and the contexts\nin which they are deployed are frequently complex, making it difficult to detect and respond\nto failures when they occur. AI systems are inherently socio-technical in nature, meaning\nthey are influenced by societal dynamics and human behavior. AI risks \u2013 and benefits \u2013\ncan emerge from the interplay of technical aspects combined with societal factors related\nto how a system is used, its interactions with other AI systems, who operates it, and the\nsocial context in which it is deployed.\nThese risks make AI a uniquely challenging technology to deploy and utilize both for organizations and within society. Without proper controls, AI systems can amplify, perpetuate,\nor exacerbate inequitable or undesirable outcomes for individuals and communities. With\nproper controls, AI systems can mitigate and manage inequitable outcomes.\nAI risk management is a key component of responsible development and use of AI systems. Responsible AI practices can help align the decisions about AI system design, development, and uses with intended aim and values. Core concepts in responsible AI emphasize human centricity, social responsibility, and sustainability. AI risk management can\ndrive responsible uses and practices by prompting organizations and their internal teams\nwho design, develop, and deploy AI to think more critically about context and potential\nor unexpected negative and positive impacts. Understanding and managing the risks of AI\nsystems will help to enhance trustworthiness, and in turn, cultivate public trust.\nPage 1\nNIST AI 100-1 AI RMF 1.0\nSocial responsibility can refer to the organization\u2019s responsibility \u201cfor the impacts\nof its decisions and activities on society and the environment through transparent\nand ethical behavior\u201d (ISO 26000:2010). Sustainability refers to the \u201cstate of the\nglobal system, including environmental, social, and economic aspects, in which the\nneeds of the present are met without compromising the ability of future generations\nto meet their own needs\u201d (ISO/IEC TR 24368:2022). Responsible AI is meant to\nresult in technology that is also equitable and accountable. The expectation is that\norganizational practices are carried out in accord with \u201cprofessional responsibility,\u201d\ndefined by ISO as an approach that \u201caims to ensure that professionals who design,\ndevelop, or deploy AI systems and applications or AI-based products or systems,\nrecognize their unique position to exert influence on people, society, and the future\nof AI\u201d (ISO/IEC TR 24368:2022).\nAs directed by the National Artificial Intelligence Initiative Act of 2020 (P.L. 116-283),\nthe goal of the AI RMF is to offer a resource to the organizations designing, developing,\ndeploying, or using AI systems to help manage the many risks of AI and promote trustworthy and responsible development and use of AI systems. The Framework is intended to be\nvoluntary, rights-preserving, non-sector-specific, and use-case agnostic, providing flexibility to organizations of all sizes and in all sectors and throughout society to implement the\napproaches in the Framework.\nThe Framework is designed to equip organizations and individuals \u2013 referred to here as\nAI actors \u2013 with approaches that increase the trustworthiness of AI systems, and to help\nfoster the responsible design, development, deployment, and use of AI systems over time.\nAI actors are defined by the Organisation for Economic Co-operation and Development\n(OECD) as \u201cthose who play an active role in the AI system lifecycle, including organizations and individuals that deploy or operate AI\u201d [OECD (2019) Artificial Intelligence in\nSociety\u2014OECD iLibrary] (See Appendix A).\nThe AI RMF is intended to be practical, to adapt to the AI landscape as AI technologies\ncontinue to develop, and to be operationalized by organizations in varying degrees and\ncapacities so society can benefit from AI while also being protected from its potential\nharms.\nThe Framework and supporting resources will be updated, expanded, and improved based\non evolving technology, the standards landscape around the world, and AI community experience and feedback. NIST will continue to align the AI RMF and related guidance with\napplicable international standards, guidelines, and practices. As the AI RMF is put into\nuse, additional lessons will be learned to inform future updates and additional resources.\nThe Framework is divided into two parts. Part 1 discusses how organizations can frame\nthe risks related to AI and describes the intended audience. Next, AI risks and trustworthiness are analyzed, outlining the characteristics of trustworthy AI systems, which include\nPage 2\nNIST AI 100-1 AI RMF 1.0\nvalid and reliable, safe, secure and resilient, accountable and transparent, explainable and\ninterpretable, privacy enhanced, and fair with their harmful biases managed.\nPart 2 comprises the \u201cCore\u201d of the Framework. It describes four specific functions to help\norganizations address the risks of AI systems in practice. These functions \u2013 GOVERN,\nMAP, MEASURE, and MANAGE \u2013 are broken down further into categories and subcategories. While GOVERN applies to all stages of organizations\u2019 AI risk management processes and procedures, the MAP, MEASURE, and MANAGE functions can be applied in AI\nsystem-specific contexts and at specific stages of the AI lifecycle.\nAdditional resources related to the Framework are included in the AI RMF Playbook,\nwhich is available via the NIST AI RMF website:\nhttps://www.nist.gov/itl/ai-risk-management-framework.\nDevelopment of the AI RMF by NIST in collaboration with the private and public sectors is directed and consistent with its broader AI efforts called for by the National AI\nInitiative Act of 2020, the National Security Commission on Artificial Intelligence recommendations, and the Plan for Federal Engagement in Developing Technical Standards and\nRelated Tools. Engagement with the AI community during this Framework\u2019s development\n\u2013 via responses to a formal Request for Information, three widely attended workshops,\npublic comments on a concept paper and two drafts of the Framework, discussions at multiple public forums, and many small group meetings \u2013 has informed development of the AI\nRMF 1.0 as well as AI research and development and evaluation conducted by NIST and\nothers. Priority research and additional guidance that will enhance this Framework will be\ncaptured in an associated AI Risk Management Framework Roadmap to which NIST and\nthe broader community can contribute.\nPage 3\nNIST AI 100-1 AI RMF 1.0\nPart 1: Foundational Information\n1. Framing Risk\nAI risk management offers a path to minimize potential negative impacts of AI systems,\nsuch as threats to civil liberties and rights, while also providing opportunities to maximize\npositive impacts. Addressing, documenting, and managing AI risks and potential negative\nimpacts effectively can lead to more trustworthy AI systems.\n1.1 Understanding and Addressing Risks, Impacts, and Harms\nIn the context of the AI RMF, risk refers to the composite measure of an event\u2019s probability\nof occurring and the magnitude or degree of the consequences of the corresponding event.\nThe impacts, or consequences, of AI systems can be positive, negative, or both and can\nresult in opportunities or threats (Adapted from: ISO 31000:2018). When considering the\nnegative impact of a potential event, risk is a function of 1) the negative impact, or magnitude of harm, that would arise if the circumstance or event occurs and 2) the likelihood of\noccurrence (Adapted from: OMB Circular A-130:2016). Negative impact or harm can be\nexperienced by individuals, groups, communities, organizations, society, the environment,\nand the planet.\n\u201cRisk management refers to coordinated activities to direct and control an organization with regard to risk\u201d (Source: ISO 31000:2018).\nWhile risk management processes generally address negative impacts, this Framework offers approaches to minimize anticipated negative impacts of AI systems and identify opportunities to maximize positive impacts. Effectively managing the risk of potential harms\ncould lead to more trustworthy AI systems and unleash potential benefits to people (individuals, communities, and society), organizations, and systems/ecosystems. Risk management\ncan enable AI developers and users to understand impacts and account for the inherent limitations and uncertainties in their models and systems, which in turn can improve overall\nsystem performance and trustworthiness and the likelihood that AI technologies will be\nused in ways that are beneficial.\nThe AI RMF is designed to address new risks as they emerge. This flexibility is particularly\nimportant where impacts are not easily foreseeable and applications are evolving. While\nsome AI risks and benefits are well-known, it can be challenging to assess negative impacts\nand the degree of harms. Figure 1 provides examples of potential harms that can be related\nto AI systems.\nAI risk management efforts should consider that humans may assume that AI systems work\n\u2013 and work well \u2013 in all settings. For example, whether correct or not, AI systems are\noften perceived as being more objective than humans or as offering greater capabilities\nthan general software.\nPage 4\nNIST AI 100-1 AI RMF 1.0\nFig. 1. Examples of potential harms related to AI systems. Trustworthy AI systems and their\nresponsible use can mitigate negative risks and contribute to benefits for people, organizations, and\necosystems.\n1.2 Challenges for AI Risk Management\nSeveral challenges are described below. They should be taken into account when managing\nrisks in pursuit of AI trustworthiness.\n1.2.1 Risk Measurement\nAI risks or failures that are not well-defined or adequately understood are difficult to measure quantitatively or qualitatively. The inability to appropriately measure AI risks does not\nimply that an AI system necessarily poses either a high or low risk. Some risk measurement\nchallenges include:\nRisks related to third-party software, hardware, and data: Third-party data or systems\ncan accelerate research and development and facilitate technology transition. They also\nmay complicate risk measurement. Risk can emerge both from third-party data, software or\nhardware itself and how it is used. Risk metrics or methodologies used by the organization\ndeveloping the AI system may not align with the risk metrics or methodologies uses by\nthe organization deploying or operating the system. Also, the organization developing\nthe AI system may not be transparent about the risk metrics or methodologies it used. Risk\nmeasurement and management can be complicated by how customers use or integrate thirdparty data or systems into AI products or services, particularly without sufficient internal\ngovernance structures and technical safeguards. Regardless, all parties and AI actors should\nmanage risk in the AI systems they develop, deploy, or use as standalone or integrated\ncomponents.\nTracking emergent risks: Organizations\u2019 risk management efforts will be enhanced by\nidentifying and tracking emergent risks and considering techniques for measuring them.\nPage 5\nNIST AI 100-1 AI RMF 1.0\nAI system impact assessment approaches can help AI actors understand potential impacts\nor harms within specific contexts.\nAvailability of reliable metrics: The current lack of consensus on robust and verifiable\nmeasurement methods for risk and trustworthiness, and applicability to different AI use\ncases, is an AI risk measurement challenge. Potential pitfalls when seeking to measure\nnegative risk or harms include the reality that development of metrics is often an institutional endeavor and may inadvertently reflect factors unrelated to the underlying impact. In\naddition, measurement approaches can be oversimplified, gamed, lack critical nuance, become relied upon in unexpected ways, or fail to account for differences in affected groups\nand contexts.\nApproaches for measuring impacts on a population work best if they recognize that contexts\nmatter, that harms may affect varied groups or sub-groups differently, and that communities\nor other sub-groups who may be harmed are not always direct users of a system.\nRisk at different stages of the AI lifecycle: Measuring risk at an earlier stage in the AI\nlifecycle may yield different results than measuring risk at a later stage; some risks may\nbe latent at a given point in time and may increase as AI systems adapt and evolve. Furthermore, different AI actors across the AI lifecycle can have different risk perspectives.\nFor example, an AI developer who makes AI software available, such as pre-trained models, can have a different risk perspective than an AI actor who is responsible for deploying\nthat pre-trained model in a specific use case. Such deployers may not recognize that their\nparticular uses could entail risks which differ from those perceived by the initial developer.\nAll involved AI actors share responsibilities for designing, developing, and deploying a\ntrustworthy AI system that is fit for purpose.\nRisk in real-world settings: While measuring AI risks in a laboratory or a controlled\nenvironment may yield important insights pre-deployment, these measurements may differ\nfrom risks that emerge in operational, real-world settings.\nInscrutability: Inscrutable AI systems can complicate risk measurement. Inscrutability\ncan be a result of the opaque nature of AI systems (limited explainability or interpretability), lack of transparency or documentation in AI system development or deployment, or\ninherent uncertainties in AI systems.\nHuman baseline: Risk management of AI systems that are intended to augment or replace\nhuman activity, for example decision making, requires some form of baseline metrics for\ncomparison. This is difficult to systematize since AI systems carry out different tasks \u2013 and\nperform tasks differently \u2013 than humans.\nPage 6\nNIST AI 100-1 AI RMF 1.0\n1.2.2 Risk Tolerance\nWhile the AI RMF can be used to prioritize risk, it does not prescribe risk tolerance. Risk\ntolerance refers to the organization\u2019s or AI actor\u2019s (see Appendix A) readiness to bear the\nrisk in order to achieve its objectives. Risk tolerance can be influenced by legal or regulatory requirements (Adapted from: ISO GUIDE 73). Risk tolerance and the level of risk that\nis acceptable to organizations or society are highly contextual and application and use-case\nspecific. Risk tolerances can be influenced by policies and norms established by AI system owners, organizations, industries, communities, or policy makers. Risk tolerances are\nlikely to change over time as AI systems, policies, and norms evolve. Different organizations may have varied risk tolerances due to their particular organizational priorities and\nresource considerations.\nEmerging knowledge and methods to better inform harm/cost-benefit tradeoffs will continue to be developed and debated by businesses, governments, academia, and civil society.\nTo the extent that challenges for specifying AI risk tolerances remain unresolved, there may\nbe contexts where a risk management framework is not yet readily applicable for mitigating\nnegative AI risks.\nThe Framework is intended to be flexible and to augment existing risk practices\nwhich should align with applicable laws, regulations, and norms. Organizations\nshould follow existing regulations and guidelines for risk criteria, tolerance, and\nresponse established by organizational, domain, discipline, sector, or professional\nrequirements. Some sectors or industries may have established definitions of harm or\nestablished documentation, reporting, and disclosure requirements. Within sectors,\nrisk management may depend on existing guidelines for specific applications and\nuse case settings. Where established guidelines do not exist, organizations should\ndefine reasonable risk tolerance. Once tolerance is defined, this AI RMF can be used\nto manage risks and to document risk management processes.\n1.2.3 Risk Prioritization\nAttempting to eliminate negative risk entirely can be counterproductive in practice because\nnot all incidents and failures can be eliminated. Unrealistic expectations about risk may\nlead organizations to allocate resources in a manner that makes risk triage inefficient or\nimpractical or wastes scarce resources. A risk management culture can help organizations\nrecognize that not all AI risks are the same, and resources can be allocated purposefully.\nActionable risk management efforts lay out clear guidelines for assessing trustworthiness\nof each AI system an organization develops or deploys. Policies and resources should be\nprioritized based on the assessed risk level and potential impact of an AI system. The extent\nto which an AI system may be customized or tailored to the specific context of use by the\nAI deployer can be a contributing factor.\nPage 7\nNIST AI 100-1 AI RMF 1.0\nWhen applying the AI RMF, risks which the organization determines to be highest for the\nAI systems within a given context of use call for the most urgent prioritization and most\nthorough risk management process. In cases where an AI system presents unacceptable\nnegative risk levels \u2013 such as where significant negative impacts are imminent, severe harms\nare actually occurring, or catastrophic risks are present \u2013 development and deployment\nshould cease in a safe manner until risks can be sufficiently managed. If an AI system\u2019s\ndevelopment, deployment, and use cases are found to be low-risk in a specific context, that\nmay suggest potentially lower prioritization.\nRisk prioritization may differ between AI systems that are designed or deployed to directly\ninteract with humans as compared to AI systems that are not. Higher initial prioritization\nmay be called for in settings where the AI system is trained on large datasets comprised of\nsensitive or protected data such as personally identifiable information, or where the outputs\nof the AI systems have direct or indirect impact on humans. AI systems designed to interact\nonly with computational systems and trained on non-sensitive datasets (for example, data\ncollected from the physical environment) may call for lower initial prioritization. Nonetheless, regularly assessing and prioritizing risk based on context remains important because\nnon-human-facing AI systems can have downstream safety or social implications.\nResidual risk \u2013 defined as risk remaining after risk treatment (Source: ISO GUIDE 73) \u2013\ndirectly impacts end users or affected individuals and communities. Documenting residual\nrisks will call for the system provider to fully consider the risks of deploying the AI product\nand will inform end users about potential negative impacts of interacting with the system.\n1.2.4 Organizational Integration and Management of Risk\nAI risks should not be considered in isolation. Different AI actors have different responsibilities and awareness depending on their roles in the lifecycle. For example, organizations\ndeveloping an AI system often will not have information about how the system may be\nused. AI risk management should be integrated and incorporated into broader enterprise\nrisk management strategies and processes. Treating AI risks along with other critical risks,\nsuch as cybersecurity and privacy, will yield a more integrated outcome and organizational\nefficiencies.\nThe AI RMF may be utilized along with related guidance and frameworks for managing\nAI system risks or broader enterprise risks. Some risks related to AI systems are common\nacross other types of software development and deployment. Examples of overlapping risks\ninclude: privacy concerns related to the use of underlying data to train AI systems; the energy and environmental implications associated with resource-heavy computing demands;\nsecurity concerns related to the confidentiality, integrity, and availability of the system and\nits training and output data; and general security of the underlying software and hardware\nfor AI systems.\nPage 8\nNIST AI 100-1 AI RMF 1.0\nOrganizations need to establish and maintain the appropriate accountability mechanisms,\nroles and responsibilities, culture, and incentive structures for risk management to be effective. Use of the AI RMF alone will not lead to these changes or provide the appropriate\nincentives. Effective risk management is realized through organizational commitment at\nsenior levels and may require cultural change within an organization or industry. In addition, small to medium-sized organizations managing AI risks or implementing the AI RMF\nmay face different challenges than large organizations, depending on their capabilities and\nresources.\n2. Audience\nIdentifying and managing AI risks and potential impacts \u2013 both positive and negative \u2013 requires a broad set of perspectives and actors across the AI lifecycle. Ideally, AI actors will\nrepresent a diversity of experience, expertise, and backgrounds and comprise demographically and disciplinarily diverse teams. The AI RMF is intended to be used by AI actors\nacross the AI lifecycle and dimensions.\nThe OECD has developed a framework for classifying AI lifecycle activities according to\nfive key socio-technical dimensions, each with properties relevant for AI policy and governance, including risk management [OECD (2022) OECD Framework for the Classification\nof AI systems \u2014 OECD Digital Economy Papers]. Figure 2 shows these dimensions,\nslightly modified by NIST for purposes of this framework. The NIST modification highlights the importance of test, evaluation, verification, and validation (TEVV) processes\nthroughout an AI lifecycle and generalizes the operational context of an AI system.\nAI dimensions displayed in Figure 2 are the Application Context, Data and Input, AI\nModel, and Task and Output. AI actors involved in these dimensions who perform or\nmanage the design, development, deployment, evaluation, and use of AI systems and drive\nAI risk management efforts are the primary AI RMF audience.\nRepresentative AI actors across the lifecycle dimensions are listed in Figure 3 and described\nin detail in Appendix A. Within the AI RMF, all AI actors work together to manage risks\nand achieve the goals of trustworthy and responsible AI. AI actors with TEVV-specific\nexpertise are integrated throughout the AI lifecycle and are especially likely to benefit from\nthe Framework. Performed regularly, TEVV tasks can provide insights relative to technical,\nsocietal, legal, and ethical standards or norms, and can assist with anticipating impacts and\nassessing and tracking emergent risks. As a regular process within an AI lifecycle, TEVV\nallows for both mid-course remediation and post-hoc risk management.\nThe People & Planet dimension at the center of Figure 2 represents human rights and the\nbroader well-being of society and the planet. The AI actors in this dimension comprise\na separate AI RMF audience who informs the primary audience. These AI actors may include trade associations, standards developing organizations, researchers, advocacy groups,\nPage 9\nNIST AI 100-1 AI RMF 1.0\nFig. 2. Lifecycle and Key Dimensions of an AI System. Modified from OECD (2022) OECD\nFramework for the Classification of AI systems \u2014 OECD Digital Economy Papers. The two inner\ncircles show AI systems\u2019 key dimensions and the outer circle shows AI lifecycle stages. Ideally,\nrisk management efforts start with the Plan and Design function in the application context and are\nperformed throughout the AI system lifecycle. See Figure 3 for representative AI actors.\nenvironmental groups, civil society organizations, end users, and potentially impacted individuals and communities. These actors can:\n\u2022 assist in providing context and understanding potential and actual impacts;\n\u2022 be a source of formal or quasi-formal norms and guidance for AI risk management;\n\u2022 designate boundaries for AI operation (technical, societal, legal, and ethical); and\n\u2022 promote discussion of the tradeoffs needed to balance societal values and priorities\nrelated to civil liberties and rights, equity, the environment and the planet, and the\neconomy.\nSuccessful risk management depends upon a sense of collective responsibility among AI\nactors shown in Figure 3. The AI RMF functions, described in Section 5, require diverse\nperspectives, disciplines, professions, and experiences. Diverse teams contribute to more\nopen sharing of ideas and assumptions about the purposes and functions of technology \u2013\nmaking these implicit aspects more explicit. This broader collective perspective creates\nopportunities for surfacing problems and identifying existing and emergent risks.\nPage 10\nNIST AI 100-1 AI RMF 1.0 Fig. 3. AI actors across AI lifecycle stages. See Appendix A for detailed descriptions of AI actor tasks, including details about testing, evaluation, verification, and validation tasks. Note that AI actors in the AI Model dimension (Figure 2) are separated as a best practice, with those building and using the models separated from those verifying and validating the models.\nPage 11\nNIST AI 100-1 AI RMF 1.0\n3. AI Risks and Trustworthiness\nFor AI systems to be trustworthy, they often need to be responsive to a multiplicity of criteria that are of value to interested parties. Approaches which enhance AI trustworthiness\ncan reduce negative AI risks. This Framework articulates the following characteristics of\ntrustworthy AI and offers guidance for addressing them. Characteristics of trustworthy AI\nsystems include: valid and reliable, safe, secure and resilient, accountable and transparent, explainable and interpretable, privacy-enhanced, and fair with harmful bias\nmanaged. Creating trustworthy AI requires balancing each of these characteristics based\non the AI system\u2019s context of use. While all characteristics are socio-technical system attributes, accountability and transparency also relate to the processes and activities internal\nto an AI system and its external setting. Neglecting these characteristics can increase the\nprobability and magnitude of negative consequences.\nFig. 4. Characteristics of trustworthy AI systems. Valid & Reliable is a necessary condition of\ntrustworthiness and is shown as the base for other trustworthiness characteristics. Accountable &\nTransparent is shown as a vertical box because it relates to all other characteristics.\nTrustworthiness characteristics (shown in Figure 4) are inextricably tied to social and organizational behavior, the datasets used by AI systems, selection of AI models and algorithms\nand the decisions made by those who build them, and the interactions with the humans who\nprovide insight from and oversight of such systems. Human judgment should be employed\nwhen deciding on the specific metrics related to AI trustworthiness characteristics and the\nprecise threshold values for those metrics.\nAddressing AI trustworthiness characteristics individually will not ensure AI system trustworthiness; tradeoffs are usually involved, rarely do all characteristics apply in every setting, and some will be more or less important in any given situation. Ultimately, trustworthiness is a social concept that ranges across a spectrum and is only as strong as its weakest\ncharacteristics.\nWhen managing AI risks, organizations can face difficult decisions in balancing these characteristics. For example, in certain scenarios tradeoffs may emerge between optimizing for\ninterpretability and achieving privacy. In other cases, organizations might face a tradeoff\nbetween predictive accuracy and interpretability. Or, under certain conditions such as data\nsparsity, privacy-enhancing techniques can result in a loss in accuracy, affecting decisions\nPage 12\nNIST AI 100-1 AI RMF 1.0\nabout fairness and other values in certain domains. Dealing with tradeoffs requires taking into account the decision-making context. These analyses can highlight the existence\nand extent of tradeoffs between different measures, but they do not answer questions about\nhow to navigate the tradeoff. Those depend on the values at play in the relevant context and\nshould be resolved in a manner that is both transparent and appropriately justifiable.\nThere are multiple approaches for enhancing contextual awareness in the AI lifecycle. For\nexample, subject matter experts can assist in the evaluation of TEVV findings and work\nwith product and deployment teams to align TEVV parameters to requirements and deployment conditions. When properly resourced, increasing the breadth and diversity of\ninput from interested parties and relevant AI actors throughout the AI lifecycle can enhance opportunities for informing contextually sensitive evaluations, and for identifying\nAI system benefits and positive impacts. These practices can increase the likelihood that\nrisks arising in social contexts are managed appropriately.\nUnderstanding and treatment of trustworthiness characteristics depends on an AI actor\u2019s\nparticular role within the AI lifecycle. For any given AI system, an AI designer or developer\nmay have a different perception of the characteristics than the deployer.\nTrustworthiness characteristics explained in this document influence each other.\nHighly secure but unfair systems, accurate but opaque and uninterpretable systems,\nand inaccurate but secure, privacy-enhanced, and transparent systems are all undesirable. A comprehensive approach to risk management calls for balancing tradeoffs\namong the trustworthiness characteristics. It is the joint responsibility of all AI actors to determine whether AI technology is an appropriate or necessary tool for a\ngiven context or purpose, and how to use it responsibly. The decision to commission\nor deploy an AI system should be based on a contextual assessment of trustworthiness characteristics and the relative risks, impacts, costs, and benefits, and informed\nby a broad set of interested parties.\n3.1 Valid and Reliable\nValidation is the \u201cconfirmation, through the provision of objective evidence, that the requirements for a specific intended use or application have been fulfilled\u201d (Source: ISO\n9000:2015). Deployment of AI systems which are inaccurate, unreliable, or poorly generalized to data and settings beyond their training creates and increases negative AI risks and\nreduces trustworthiness.\nReliability is defined in the same standard as the \u201cability of an item to perform as required,\nwithout failure, for a given time interval, under given conditions\u201d (Source: ISO/IEC TS\n5723:2022). Reliability is a goal for overall correctness of AI system operation under the\nconditions of expected use and over a given period of time, including the entire lifetime of\nthe system.\nPage 13\nNIST AI 100-1 AI RMF 1.0\nAccuracy and robustness contribute to the validity and trustworthiness of AI systems, and\ncan be in tension with one another in AI systems.\nAccuracy is defined by ISO/IEC TS 5723:2022 as \u201ccloseness of results of observations,\ncomputations, or estimates to the true values or the values accepted as being true.\u201d Measures of accuracy should consider computational-centric measures (e.g., false positive and\nfalse negative rates), human-AI teaming, and demonstrate external validity (generalizable\nbeyond the training conditions). Accuracy measurements should always be paired with\nclearly defined and realistic test sets \u2013 that are representative of conditions of expected use\n\u2013 and details about test methodology; these should be included in associated documentation. Accuracy measurements may include disaggregation of results for different data\nsegments.\nRobustness or generalizability is defined as the \u201cability of a system to maintain its level\nof performance under a variety of circumstances\u201d (Source: ISO/IEC TS 5723:2022). Robustness is a goal for appropriate system functionality in a broad set of conditions and\ncircumstances, including uses of AI systems not initially anticipated. Robustness requires\nnot only that the system perform exactly as it does under expected uses, but also that it\nshould perform in ways that minimize potential harms to people if it is operating in an\nunexpected setting.\nValidity and reliability for deployed AI systems are often assessed by ongoing testing or\nmonitoring that confirms a system is performing as intended. Measurement of validity,\naccuracy, robustness, and reliability contribute to trustworthiness and should take into consideration that certain types of failures can cause greater harm. AI risk management efforts\nshould prioritize the minimization of potential negative impacts, and may need to include\nhuman intervention in cases where the AI system cannot detect or correct errors.\n3.2 Safe\nAI systems should \u201cnot under defined conditions, lead to a state in which human life,\nhealth, property, or the environment is endangered\u201d (Source: ISO/IEC TS 5723:2022). Safe\noperation of AI systems is improved through:\n\u2022 responsible design, development, and deployment practices;\n\u2022 clear information to deployers on responsible use of the system;\n\u2022 responsible decision-making by deployers and end users; and\n\u2022 explanations and documentation of risks based on empirical evidence of incidents.\nDifferent types of safety risks may require tailored AI risk management approaches based\non context and the severity of potential risks presented. Safety risks that pose a potential\nrisk of serious injury or death call for the most urgent prioritization and most thorough risk\nmanagement process.\nPage 14\nNIST AI 100-1 AI RMF 1.0\nEmploying safety considerations during the lifecycle and starting as early as possible with\nplanning and design can prevent failures or conditions that can render a system dangerous.\nOther practical approaches for AI safety often relate to rigorous simulation and in-domain\ntesting, real-time monitoring, and the ability to shut down, modify, or have human intervention into systems that deviate from intended or expected functionality.\nAI safety risk management approaches should take cues from efforts and guidelines for\nsafety in fields such as transportation and healthcare, and align with existing sector- or\napplication-specific guidelines or standards.\n3.3 Secure and Resilient\nAI systems, as well as the ecosystems in which they are deployed, may be said to be resilient if they can withstand unexpected adverse events or unexpected changes in their environment or use \u2013 or if they can maintain their functions and structure in the face of internal\nand external change and degrade safely and gracefully when this is necessary (Adapted\nfrom: ISO/IEC TS 5723:2022). Common security concerns relate to adversarial examples,\ndata poisoning, and the exfiltration of models, training data, or other intellectual property\nthrough AI system endpoints. AI systems that can maintain confidentiality, integrity, and\navailability through protection mechanisms that prevent unauthorized access and use may\nbe said to be secure. Guidelines in the NIST Cybersecurity Framework and Risk Management Framework are among those which are applicable here.\nSecurity and resilience are related but distinct characteristics. While resilience is the ability to return to normal function after an unexpected adverse event, security includes resilience but also encompasses protocols to avoid, protect against, respond to, or recover\nfrom attacks. Resilience relates to robustness and goes beyond the provenance of the data\nto encompass unexpected or adversarial use (or abuse or misuse) of the model or data.\n3.4 Accountable and Transparent\nTrustworthy AI depends upon accountability. Accountability presupposes transparency.\nTransparency reflects the extent to which information about an AI system and its outputs is\navailable to individuals interacting with such a system \u2013 regardless of whether they are even\naware that they are doing so. Meaningful transparency provides access to appropriate levels\nof information based on the stage of the AI lifecycle and tailored to the role or knowledge\nof AI actors or individuals interacting with or using the AI system. By promoting higher\nlevels of understanding, transparency increases confidence in the AI system.\nThis characteristic\u2019s scope spans from design decisions and training data to model training, the structure of the model, its intended use cases, and how and when deployment,\npost-deployment, or end user decisions were made and by whom. Transparency is often\nnecessary for actionable redress related to AI system outputs that are incorrect or otherwise\nlead to negative impacts. Transparency should consider human-AI interaction: for examPage 15\nNIST AI 100-1 AI RMF 1.0\nple, how a human operator or user is notified when a potential or actual adverse outcome\ncaused by an AI system is detected. A transparent system is not necessarily an accurate,\nprivacy-enhanced, secure, or fair system. However, it is difficult to determine whether an\nopaque system possesses such characteristics, and to do so over time as complex systems\nevolve.\nThe role of AI actors should be considered when seeking accountability for the outcomes of\nAI systems. The relationship between risk and accountability associated with AI and technological systems more broadly differs across cultural, legal, sectoral, and societal contexts.\nWhen consequences are severe, such as when life and liberty are at stake, AI developers\nand deployers should consider proportionally and proactively adjusting their transparency\nand accountability practices. Maintaining organizational practices and governing structures\nfor harm reduction, like risk management, can help lead to more accountable systems.\nMeasures to enhance transparency and accountability should also consider the impact of\nthese efforts on the implementing entity, including the level of necessary resources and the\nneed to safeguard proprietary information.\nMaintaining the provenance of training data and supporting attribution of the AI system\u2019s\ndecisions to subsets of training data can assist with both transparency and accountability.\nTraining data may also be subject to copyright and should follow applicable intellectual\nproperty rights laws.\nAs transparency tools for AI systems and related documentation continue to evolve, developers of AI systems are encouraged to test different types of transparency tools in cooperation with AI deployers to ensure that AI systems are used as intended.\n3.5 Explainable and Interpretable\nExplainability refers to a representation of the mechanisms underlying AI systems\u2019 operation, whereas interpretability refers to the meaning of AI systems\u2019 output in the context\nof their designed functional purposes. Together, explainability and interpretability assist\nthose operating or overseeing an AI system, as well as users of an AI system, to gain\ndeeper insights into the functionality and trustworthiness of the system, including its outputs. The underlying assumption is that perceptions of negative risk stem from a lack of\nability to make sense of, or contextualize, system output appropriately. Explainable and\ninterpretable AI systems offer information that will help end users understand the purposes\nand potential impact of an AI system.\nRisk from lack of explainability may be managed by describing how AI systems function,\nwith descriptions tailored to individual differences such as the user\u2019s role, knowledge, and\nskill level. Explainable systems can be debugged and monitored more easily, and they lend\nthemselves to more thorough documentation, audit, and governance.\nPage 16\nNIST AI 100-1 AI RMF 1.0\nRisks to interpretability often can be addressed by communicating a description of why\nan AI system made a particular prediction or recommendation. (See \u201cFour Principles of\nExplainable Artificial Intelligence\u201d and \u201cPsychological Foundations of Explainability and\nInterpretability in Artificial Intelligence\u201d found here.)\nTransparency, explainability, and interpretability are distinct characteristics that support\neach other. Transparency can answer the question of \u201cwhat happened\u201d in the system. Explainability can answer the question of \u201chow\u201d a decision was made in the system. Interpretability can answer the question of \u201cwhy\u201d a decision was made by the system and its\nmeaning or context to the user.\n3.6 Privacy-Enhanced\nPrivacy refers generally to the norms and practices that help to safeguard human autonomy,\nidentity, and dignity. These norms and practices typically address freedom from intrusion,\nlimiting observation, or individuals\u2019 agency to consent to disclosure or control of facets of\ntheir identities (e.g., body, data, reputation). (See The NIST Privacy Framework: A Tool\nfor Improving Privacy through Enterprise Risk Management.)\nPrivacy values such as anonymity, confidentiality, and control generally should guide choices\nfor AI system design, development, and deployment. Privacy-related risks may influence\nsecurity, bias, and transparency and come with tradeoffs with these other characteristics.\nLike safety and security, specific technical features of an AI system may promote or reduce\nprivacy. AI systems can also present new risks to privacy by allowing inference to identify\nindividuals or previously private information about individuals.\nPrivacy-enhancing technologies (\u201cPETs\u201d) for AI, as well as data minimizing methods such\nas de-identification and aggregation for certain model outputs, can support design for\nprivacy-enhanced AI systems. Under certain conditions such as data sparsity, privacyenhancing techniques can result in a loss in accuracy, affecting decisions about fairness\nand other values in certain domains.\n3.7 Fair \u2013 with Harmful Bias Managed\nFairness in AI includes concerns for equality and equity by addressing issues such as harmful bias and discrimination. Standards of fairness can be complex and difficult to define because perceptions of fairness differ among cultures and may shift depending on application.\nOrganizations\u2019 risk management efforts will be enhanced by recognizing and considering\nthese differences. Systems in which harmful biases are mitigated are not necessarily fair.\nFor example, systems in which predictions are somewhat balanced across demographic\ngroups may still be inaccessible to individuals with disabilities or affected by the digital\ndivide or may exacerbate existing disparities or systemic biases.\nPage 17\nNIST AI 100-1 AI RMF 1.0\nBias is broader than demographic balance and data representativeness. NIST has identified\nthree major categories of AI bias to be considered and managed: systemic, computational\nand statistical, and human-cognitive. Each of these can occur in the absence of prejudice,\npartiality, or discriminatory intent. Systemic bias can be present in AI datasets, the organizational norms, practices, and processes across the AI lifecycle, and the broader society\nthat uses AI systems. Computational and statistical biases can be present in AI datasets\nand algorithmic processes, and often stem from systematic errors due to non-representative\nsamples. Human-cognitive biases relate to how an individual or group perceives AI system information to make a decision or fill in missing information, or how humans think\nabout purposes and functions of an AI system. Human-cognitive biases are omnipresent\nin decision-making processes across the AI lifecycle and system use, including the design,\nimplementation, operation, and maintenance of AI.\nBias exists in many forms and can become ingrained in the automated systems that help\nmake decisions about our lives. While bias is not always a negative phenomenon, AI systems can potentially increase the speed and scale of biases and perpetuate and amplify\nharms to individuals, groups, communities, organizations, and society. Bias is tightly associated with the concepts of transparency as well as fairness in society. (For more information about bias, including the three categories, see NIST Special Publication 1270, Towards\na Standard for Identifying and Managing Bias in Artificial Intelligence.)\nPage 18\nNIST AI 100-1 AI RMF 1.0\n4. Effectiveness of the AI RMF\nEvaluations of AI RMF effectiveness \u2013 including ways to measure bottom-line improvements in the trustworthiness of AI systems \u2013 will be part of future NIST activities, in\nconjunction with the AI community.\nOrganizations and other users of the Framework are encouraged to periodically evaluate\nwhether the AI RMF has improved their ability to manage AI risks, including but not limited to their policies, processes, practices, implementation plans, indicators, measurements,\nand expected outcomes. NIST intends to work collaboratively with others to develop metrics, methodologies, and goals for evaluating the AI RMF\u2019s effectiveness, and to broadly\nshare results and supporting information. Framework users are expected to benefit from:\n\u2022 enhanced processes for governing, mapping, measuring, and managing AI risk, and\nclearly documenting outcomes;\n\u2022 improved awareness of the relationships and tradeoffs among trustworthiness characteristics, socio-technical approaches, and AI risks;\n\u2022 explicit processes for making go/no-go system commissioning and deployment decisions;\n\u2022 established policies, processes, practices, and procedures for improving organizational accountability efforts related to AI system risks;\n\u2022 enhanced organizational culture which prioritizes the identification and management\nof AI system risks and potential impacts to individuals, communities, organizations,\nand society;\n\u2022 better information sharing within and across organizations about risks, decisionmaking processes, responsibilities, common pitfalls, TEVV practices, and approaches\nfor continuous improvement;\n\u2022 greater contextual knowledge for increased awareness of downstream risks;\n\u2022 strengthened engagement with interested parties and relevant AI actors; and\n\u2022 augmented capacity for TEVV of AI systems and associated risks.\nPage 19\nNIST AI 100-1 AI RMF 1.0\nPart 2: Core and Profiles\n5. AI RMF Core\nThe AI RMF Core provides outcomes and actions that enable dialogue, understanding, and\nactivities to manage AI risks and responsibly develop trustworthy AI systems. As illustrated in Figure 5, the Core is composed of four functions: GOVERN, MAP, MEASURE,\nand MANAGE. Each of these high-level functions is broken down into categories and subcategories. Categories and subcategories are subdivided into specific actions and outcomes.\nActions do not constitute a checklist, nor are they necessarily an ordered set of steps.\nFig. 5. Functions organize AI risk management activities at their highest level to govern, map,\nmeasure, and manage AI risks. Governance is designed to be a cross-cutting function to inform\nand be infused throughout the other three functions.\nRisk management should be continuous, timely, and performed throughout the AI system\nlifecycle dimensions. AI RMF Core functions should be carried out in a way that reflects\ndiverse and multidisciplinary perspectives, potentially including the views of AI actors outside the organization. Having a diverse team contributes to more open sharing of ideas and\nassumptions about purposes and functions of the technology being designed, developed,\nPage 20\nNIST AI 100-1 AI RMF 1.0\ndeployed, or evaluated \u2013 which can create opportunities to surface problems and identify\nexisting and emergent risks.\nAn online companion resource to the AI RMF, the NIST AI RMF Playbook, is available\nto help organizations navigate the AI RMF and achieve its outcomes through suggested\ntactical actions they can apply within their own contexts. Like the AI RMF, the Playbook\nis voluntary and organizations can utilize the suggestions according to their needs and\ninterests. Playbook users can create tailored guidance selected from suggested material\nfor their own use and contribute their suggestions for sharing with the broader community.\nAlong with the AI RMF, the Playbook is part of the NIST Trustworthy and Responsible AI\nResource Center.\nFramework users may apply these functions as best suits their needs for managing\nAI risks based on their resources and capabilities. Some organizations may choose\nto select from among the categories and subcategories; others may choose and have\nthe capacity to apply all categories and subcategories. Assuming a governance structure is in place, functions may be performed in any order across the AI lifecycle as\ndeemed to add value by a user of the framework. After instituting the outcomes in\nGOVERN, most users of the AI RMF would start with the MAP function and continue to MEASURE or MANAGE. However users integrate the functions, the process\nshould be iterative, with cross-referencing between functions as necessary. Similarly, there are categories and subcategories with elements that apply to multiple\nfunctions, or that logically should take place before certain subcategory decisions.\n5.1 Govern\nThe GOVERN function:\n\u2022 cultivates and implements a culture of risk management within organizations designing, developing, deploying, evaluating, or acquiring AI systems;\n\u2022 outlines processes, documents, and organizational schemes that anticipate, identify,\nand manage the risks a system can pose, including to users and others across society\n\u2013 and procedures to achieve those outcomes;\n\u2022 incorporates processes to assess potential impacts;\n\u2022 provides a structure by which AI risk management functions can align with organizational principles, policies, and strategic priorities;\n\u2022 connects technical aspects of AI system design and development to organizational\nvalues and principles, and enables organizational practices and competencies for the\nindividuals involved in acquiring, training, deploying, and monitoring such systems;\nand\n\u2022 addresses full product lifecycle and associated processes, including legal and other\nissues concerning use of third-party software or hardware systems and data.\nPage 21\nNIST AI 100-1 AI RMF 1.0\nGOVERN is a cross-cutting function that is infused throughout AI risk management and\nenables the other functions of the process. Aspects of GOVERN, especially those related to\ncompliance or evaluation, should be integrated into each of the other functions. Attention\nto governance is a continual and intrinsic requirement for effective AI risk management\nover an AI system\u2019s lifespan and the organization\u2019s hierarchy.\nStrong governance can drive and enhance internal practices and norms to facilitate organizational risk culture. Governing authorities can determine the overarching policies that\ndirect an organization\u2019s mission, goals, values, culture, and risk tolerance. Senior leadership sets the tone for risk management within an organization, and with it, organizational\nculture. Management aligns the technical aspects of AI risk management to policies and\noperations. Documentation can enhance transparency, improve human review processes,\nand bolster accountability in AI system teams.\nAfter putting in place the structures, systems, processes, and teams described in the GOVERN function, organizations should benefit from a purpose-driven culture focused on risk\nunderstanding and management. It is incumbent on Framework users to continue to execute the GOVERN function as knowledge, cultures, and needs or expectations from AI\nactors evolve over time.\nPractices related to governing AI risks are described in the NIST AI RMF Playbook. Table\n1 lists the GOVERN function\u2019s categories and subcategories.\nTable 1: Categories and subcategories for the GOVERN function.\nGOVERN 1:\nPolicies, processes,\nprocedures, and\npractices across the\norganization related\nto the mapping,\nmeasuring, and\nmanaging of AI\nrisks are in place,\ntransparent, and\nimplemented\neffectively.\nGOVERN 1.1: Legal and regulatory requirements involving AI\nare understood, managed, and documented.\nGOVERN 1.2: The characteristics of trustworthy AI are integrated into organizational policies, processes, procedures, and\npractices.\nGOVERN 1.3: Processes, procedures, and practices are in place\nto determine the needed level of risk management activities based\non the organization\u2019s risk tolerance.\nGOVERN 1.4: The risk management process and its outcomes are\nestablished through transparent policies, procedures, and other\ncontrols based on organizational risk priorities.\nCategories Subcategories\nContinued on next page\nPage 22\nNIST AI 100-1 AI RMF 1.0\nTable 1: Categories and subcategories for the GOVERN function. (Continued)\nGOVERN 1.5: Ongoing monitoring and periodic review of the\nrisk management process and its outcomes are planned and organizational roles and responsibilities clearly defined, including\ndetermining the frequency of periodic review.\nGOVERN 1.6: Mechanisms are in place to inventory AI systems\nand are resourced according to organizational risk priorities.\nGOVERN 1.7: Processes and procedures are in place for decommissioning and phasing out AI systems safely and in a manner that does not increase risks or decrease the organization\u2019s\ntrustworthiness.\nGOVERN 2:\nAccountability\nstructures are in\nplace so that the\nappropriate teams\nand individuals are\nempowered,\nresponsible, and\ntrained for mapping,\nmeasuring, and\nmanaging AI risks.\nGOVERN 2.1: Roles and responsibilities and lines of communication related to mapping, measuring, and managing AI risks are\ndocumented and are clear to individuals and teams throughout\nthe organization.\nGOVERN 2.2: The organization\u2019s personnel and partners receive\nAI risk management training to enable them to perform their duties and responsibilities consistent with related policies, procedures, and agreements.\nGOVERN 2.3: Executive leadership of the organization takes responsibility for decisions about risks associated with AI system\ndevelopment and deployment.\nGOVERN 3:\nWorkforce diversity,\nequity, inclusion,\nand accessibility\nprocesses are\nprioritized in the\nmapping,\nmeasuring, and\nmanaging of AI\nrisks throughout the\nlifecycle.\nGOVERN 3.1: Decision-making related to mapping, measuring,\nand managing AI risks throughout the lifecycle is informed by a\ndiverse team (e.g., diversity of demographics, disciplines, experience, expertise, and backgrounds).\nGOVERN 3.2: Policies and procedures are in place to define and\ndifferentiate roles and responsibilities for human-AI configurations and oversight of AI systems.\nGOVERN 4:\nOrganizational\nteams are committed\nto a culture\nGOVERN 4.1: Organizational policies and practices are in place\nto foster a critical thinking and safety-first mindset in the design,\ndevelopment, deployment, and uses of AI systems to minimize\npotential negative impacts.\nCategories Subcategories\nContinued on next page\nPage 23\nNIST AI 100-1 AI RMF 1.0\nTable 1: Categories and subcategories for the GOVERN function. (Continued)\nthat considers and\ncommunicates AI\nrisk.\nGOVERN 4.2: Organizational teams document the risks and potential impacts of the AI technology they design, develop, deploy,\nevaluate, and use, and they communicate about the impacts more\nbroadly.\nGOVERN 4.3: Organizational practices are in place to enable AI\ntesting, identification of incidents, and information sharing.\nGOVERN 5:\nProcesses are in\nplace for robust\nengagement with\nrelevant AI actors.\nGOVERN 5.1: Organizational policies and practices are in place\nto collect, consider, prioritize, and integrate feedback from those\nexternal to the team that developed or deployed the AI system\nregarding the potential individual and societal impacts related to\nAI risks.\nGOVERN 5.2: Mechanisms are established to enable the team\nthat developed or deployed AI systems to regularly incorporate\nadjudicated feedback from relevant AI actors into system design\nand implementation.\nGOVERN 6: Policies\nand procedures are\nin place to address\nAI risks and benefits\narising from\nthird-party software\nand data and other\nsupply chain issues.\nGOVERN 6.1: Policies and procedures are in place that address\nAI risks associated with third-party entities, including risks of infringement of a third-party\u2019s intellectual property or other rights.\nGOVERN 6.2: Contingency processes are in place to handle\nfailures or incidents in third-party data or AI systems deemed to\nbe high-risk.\nCategories Subcategories\n5.2 Map\nThe MAP function establishes the context to frame risks related to an AI system. The AI\nlifecycle consists of many interdependent activities involving a diverse set of actors (See\nFigure 3). In practice, AI actors in charge of one part of the process often do not have full\nvisibility or control over other parts and their associated contexts. The interdependencies\nbetween these activities, and among the relevant AI actors, can make it difficult to reliably\nanticipate impacts of AI systems. For example, early decisions in identifying purposes and\nobjectives of an AI system can alter its behavior and capabilities, and the dynamics of deployment setting (such as end users or impacted individuals) can shape the impacts of AI\nsystem decisions. As a result, the best intentions within one dimension of the AI lifecycle\ncan be undermined via interactions with decisions and conditions in other, later activities.\nPage 24\nNIST AI 100-1 AI RMF 1.0\nThis complexity and varying levels of visibility can introduce uncertainty into risk management practices. Anticipating, assessing, and otherwise addressing potential sources of\nnegative risk can mitigate this uncertainty and enhance the integrity of the decision process.\nThe information gathered while carrying out the MAP function enables negative risk prevention and informs decisions for processes such as model management, as well as an\ninitial decision about appropriateness or the need for an AI solution. Outcomes in the\nMAP function are the basis for the MEASURE and MANAGE functions. Without contextual knowledge, and awareness of risks within the identified contexts, risk management is\ndifficult to perform. The MAP function is intended to enhance an organization\u2019s ability to\nidentify risks and broader contributing factors.\nImplementation of this function is enhanced by incorporating perspectives from a diverse\ninternal team and engagement with those external to the team that developed or deployed\nthe AI system. Engagement with external collaborators, end users, potentially impacted\ncommunities, and others may vary based on the risk level of a particular AI system, the\nmakeup of the internal team, and organizational policies. Gathering such broad perspectives can help organizations proactively prevent negative risks and develop more trustworthy AI systems by:\n\u2022 improving their capacity for understanding contexts;\n\u2022 checking their assumptions about context of use;\n\u2022 enabling recognition of when systems are not functional within or out of their intended context;\n\u2022 identifying positive and beneficial uses of their existing AI systems;\n\u2022 improving understanding of limitations in AI and ML processes;\n\u2022 identifying constraints in real-world applications that may lead to negative impacts;\n\u2022 identifying known and foreseeable negative impacts related to intended use of AI\nsystems; and\n\u2022 anticipating risks of the use of AI systems beyond intended use.\nAfter completing the MAP function, Framework users should have sufficient contextual\nknowledge about AI system impacts to inform an initial go/no-go decision about whether\nto design, develop, or deploy an AI system. If a decision is made to proceed, organizations\nshould utilize the MEASURE and MANAGE functions along with policies and procedures\nput into place in the GOVERN function to assist in AI risk management efforts. It is incumbent on Framework users to continue applying the MAP function to AI systems as context,\ncapabilities, risks, benefits, and potential impacts evolve over time.\nPractices related to mapping AI risks are described in the NIST AI RMF Playbook. Table\n2 lists the MAP function\u2019s categories and subcategories.\nPage 25\nNIST AI 100-1 AI RMF 1.0\nTable 2: Categories and subcategories for the MAP function.\nMAP 1: Context is\nestablished and\nunderstood.\nMAP 1.1: Intended purposes, potentially beneficial uses, contextspecific laws, norms and expectations, and prospective settings in\nwhich the AI system will be deployed are understood and documented. Considerations include: the specific set or types of users\nalong with their expectations; potential positive and negative impacts of system uses to individuals, communities, organizations,\nsociety, and the planet; assumptions and related limitations about\nAI system purposes, uses, and risks across the development or\nproduct AI lifecycle; and related TEVV and system metrics.\nMAP 1.2: Interdisciplinary AI actors, competencies, skills, and\ncapacities for establishing context reflect demographic diversity\nand broad domain and user experience expertise, and their participation is documented. Opportunities for interdisciplinary collaboration are prioritized.\nMAP 1.3: The organization\u2019s mission and relevant goals for AI\ntechnology are understood and documented.\nMAP 1.4: The business value or context of business use has been\nclearly defined or \u2013 in the case of assessing existing AI systems\n\u2013 re-evaluated.\nMAP 1.5: Organizational risk tolerances are determined and\ndocumented.\nMAP 1.6: System requirements (e.g., \u201cthe system shall respect\nthe privacy of its users\u201d) are elicited from and understood by relevant AI actors. Design decisions take socio-technical implications into account to address AI risks.\nMAP 2:\nCategorization of\nthe AI system is\nperformed.\nMAP 2.1: The specific tasks and methods used to implement the\ntasks that the AI system will support are defined (e.g., classifiers,\ngenerative models, recommenders).\nMAP 2.2: Information about the AI system\u2019s knowledge limits\nand how system output may be utilized and overseen by humans\nis documented. Documentation provides sufficient information\nto assist relevant AI actors when making decisions and taking\nsubsequent actions.\nCategories Subcategories\nContinued on next page\nPage 26\nNIST AI 100-1 AI RMF 1.0\nTable 2: Categories and subcategories for the MAP function. (Continued)\nMAP 2.3: Scientific integrity and TEVV considerations are identified and documented, including those related to experimental\ndesign, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct\nvalidation.\nMAP 3: AI\ncapabilities, targeted\nusage, goals, and\nexpected benefits\nand costs compared\nwith appropriate\nbenchmarks are\nunderstood.\nMAP 3.1: Potential benefits of intended AI system functionality\nand performance are examined and documented.\nMAP 3.2: Potential costs, including non-monetary costs, which\nresult from expected or realized AI errors or system functionality\nand trustworthiness \u2013 as connected to organizational risk tolerance \u2013 are examined and documented.\nMAP 3.3: Targeted application scope is specified and documented based on the system\u2019s capability, established context, and\nAI system categorization.\nMAP 3.4: Processes for operator and practitioner proficiency\nwith AI system performance and trustworthiness \u2013 and relevant\ntechnical standards and certifications \u2013 are defined, assessed, and\ndocumented.\nMAP 3.5: Processes for human oversight are defined, assessed,\nand documented in accordance with organizational policies from\nthe GOVERN function.\nMAP 4: Risks and\nbenefits are mapped\nfor all components\nof the AI system\nincluding third-party\nsoftware and data.\nMAP 4.1: Approaches for mapping AI technology and legal risks\nof its components \u2013 including the use of third-party data or software \u2013 are in place, followed, and documented, as are risks of infringement of a third party\u2019s intellectual property or other rights.\nMAP 4.2: Internal risk controls for components of the AI system, including third-party AI technologies, are identified and\ndocumented.\nMAP 5: Impacts to\nindividuals, groups,\ncommunities,\norganizations, and\nsociety are\ncharacterized.\nMAP 5.1: Likelihood and magnitude of each identified impact\n(both potentially beneficial and harmful) based on expected use,\npast uses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed\nor deployed the AI system, or other data are identified and\ndocumented.\nCategories Subcategories\nContinued on next page\nPage 27\nNIST AI 100-1 AI RMF 1.0\nTable 2: Categories and subcategories for the MAP function. (Continued)\nMAP 5.2: Practices and personnel for supporting regular engagement with relevant AI actors and integrating feedback about\npositive, negative, and unanticipated impacts are in place and\ndocumented.\nCategories Subcategories\n5.3 Measure\nThe MEASURE function employs quantitative, qualitative, or mixed-method tools, techniques, and methodologies to analyze, assess, benchmark, and monitor AI risk and related\nimpacts. It uses knowledge relevant to AI risks identified in the MAP function and informs\nthe MANAGE function. AI systems should be tested before their deployment and regularly while in operation. AI risk measurements include documenting aspects of systems\u2019\nfunctionality and trustworthiness.\nMeasuring AI risks includes tracking metrics for trustworthy characteristics, social impact,\nand human-AI configurations. Processes developed or adopted in the MEASURE function\nshould include rigorous software testing and performance assessment methodologies with\nassociated measures of uncertainty, comparisons to performance benchmarks, and formalized reporting and documentation of results. Processes for independent review can improve\nthe effectiveness of testing and can mitigate internal biases and potential conflicts of interest.\nWhere tradeoffs among the trustworthy characteristics arise, measurement provides a traceable basis to inform management decisions. Options may include recalibration, impact\nmitigation, or removal of the system from design, development, production, or use, as well\nas a range of compensating, detective, deterrent, directive, and recovery controls.\nAfter completing the MEASURE function, objective, repeatable, or scalable test, evaluation,\nverification, and validation (TEVV) processes including metrics, methods, and methodologies are in place, followed, and documented. Metrics and measurement methodologies\nshould adhere to scientific, legal, and ethical norms and be carried out in an open and transparent process. New types of measurement, qualitative and quantitative, may need to be\ndeveloped. The degree to which each measurement type provides unique and meaningful\ninformation to the assessment of AI risks should be considered. Framework users will enhance their capacity to comprehensively evaluate system trustworthiness, identify and track\nexisting and emergent risks, and verify efficacy of the metrics. Measurement outcomes will\nbe utilized in the MANAGE function to assist risk monitoring and response efforts. It is incumbent on Framework users to continue applying the MEASURE function to AI systems\nas knowledge, methodologies, risks, and impacts evolve over time.\nPage 28\nNIST AI 100-1 AI RMF 1.0\nPractices related to measuring AI risks are described in the NIST AI RMF Playbook. Table\n3 lists the MEASURE function\u2019s categories and subcategories.\nTable 3: Categories and subcategories for the MEASURE function.\nMEASURE 1:\nAppropriate\nmethods and metrics\nare identified and\napplied.\nMEASURE 1.1: Approaches and metrics for measurement of AI\nrisks enumerated during the MAP function are selected for implementation starting with the most significant AI risks. The risks\nor trustworthiness characteristics that will not \u2013 or cannot \u2013 be\nmeasured are properly documented.\nMEASURE 1.2: Appropriateness of AI metrics and effectiveness\nof existing controls are regularly assessed and updated, including\nreports of errors and potential impacts on affected communities.\nMEASURE 1.3: Internal experts who did not serve as front-line\ndevelopers for the system and/or independent assessors are involved in regular assessments and updates. Domain experts,\nusers, AI actors external to the team that developed or deployed\nthe AI system, and affected communities are consulted in support\nof assessments as necessary per organizational risk tolerance.\nMEASURE 2: AI\nsystems are\nevaluated for\ntrustworthy\ncharacteristics.\nMEASURE 2.1: Test sets, metrics, and details about the tools used\nduring TEVV are documented.\nMEASURE 2.2: Evaluations involving human subjects meet applicable requirements (including human subject protection) and\nare representative of the relevant population.\nMEASURE 2.3: AI system performance or assurance criteria\nare measured qualitatively or quantitatively and demonstrated\nfor conditions similar to deployment setting(s). Measures are\ndocumented.\nMEASURE 2.4: The functionality and behavior of the AI system and its components \u2013 as identified in the MAP function \u2013 are\nmonitored when in production.\nMEASURE 2.5: The AI system to be deployed is demonstrated\nto be valid and reliable. Limitations of the generalizability beyond the conditions under which the technology was developed\nare documented.\nCategories Subcategories\nContinued on next page\nPage 29\nNIST AI 100-1 AI RMF 1.0\nTable 3: Categories and subcategories for the MEASURE function. (Continued)\nMEASURE 2.6: The AI system is evaluated regularly for safety\nrisks \u2013 as identified in the MAP function. The AI system to be deployed is demonstrated to be safe, its residual negative risk does\nnot exceed the risk tolerance, and it can fail safely, particularly if\nmade to operate beyond its knowledge limits. Safety metrics reflect system reliability and robustness, real-time monitoring, and\nresponse times for AI system failures.\nMEASURE 2.7: AI system security and resilience \u2013 as identified\nin the MAP function \u2013 are evaluated and documented.\nMEASURE 2.8: Risks associated with transparency and accountability \u2013 as identified in the MAP function \u2013 are examined and\ndocumented.\nMEASURE 2.9: The AI model is explained, validated, and documented, and AI system output is interpreted within its context \u2013\nas identified in the MAP function \u2013 to inform responsible use and\ngovernance.\nMEASURE 2.10: Privacy risk of the AI system \u2013 as identified in\nthe MAP function \u2013 is examined and documented.\nMEASURE 2.11: Fairness and bias \u2013 as identified in the MAP\nfunction \u2013 are evaluated and results are documented.\nMEASURE 2.12: Environmental impact and sustainability of AI\nmodel training and management activities \u2013 as identified in the\nMAP function \u2013 are assessed and documented.\nMEASURE 2.13: Effectiveness of the employed TEVV metrics and processes in the MEASURE function are evaluated and\ndocumented.\nMEASURE 3:\nMechanisms for\ntracking identified\nAI risks over time\nare in place.\nMEASURE 3.1: Approaches, personnel, and documentation are\nin place to regularly identify and track existing, unanticipated,\nand emergent AI risks based on factors such as intended and actual performance in deployed contexts.\nMEASURE 3.2: Risk tracking approaches are considered for\nsettings where AI risks are difficult to assess using currently\navailable measurement techniques or where metrics are not yet\navailable.\nCategories Subcategories\nContinued on next page\nPage 30\nNIST AI 100-1 AI RMF 1.0\nTable 3: Categories and subcategories for the MEASURE function. (Continued)\nMEASURE 3.3: Feedback processes for end users and impacted\ncommunities to report problems and appeal system outcomes are\nestablished and integrated into AI system evaluation metrics.\nMEASURE 4:\nFeedback about\nefficacy of\nmeasurement is\ngathered and\nassessed.\nMEASURE 4.1: Measurement approaches for identifying AI risks\nare connected to deployment context(s) and informed through\nconsultation with domain experts and other end users. Approaches are documented.\nMEASURE 4.2: Measurement results regarding AI system trustworthiness in deployment context(s) and across the AI lifecycle\nare informed by input from domain experts and relevant AI actors to validate whether the system is performing consistently as\nintended. Results are documented.\nMEASURE 4.3: Measurable performance improvements or declines based on consultations with relevant AI actors, including affected communities, and field data about contextrelevant risks and trustworthiness characteristics are identified\nand documented.\nCategories Subcategories\n5.4 Manage\nThe MANAGE function entails allocating risk resources to mapped and measured risks on\na regular basis and as defined by the GOVERN function. Risk treatment comprises plans to\nrespond to, recover from, and communicate about incidents or events.\nContextual information gleaned from expert consultation and input from relevant AI actors\n\u2013 established in GOVERN and carried out in MAP \u2013 is utilized in this function to decrease\nthe likelihood of system failures and negative impacts. Systematic documentation practices\nestablished in GOVERN and utilized in MAP and MEASURE bolster AI risk management\nefforts and increase transparency and accountability. Processes for assessing emergent risks\nare in place, along with mechanisms for continual improvement.\nAfter completing the MANAGE function, plans for prioritizing risk and regular monitoring\nand improvement will be in place. Framework users will have enhanced capacity to manage the risks of deployed AI systems and to allocate risk management resources based on\nassessed and prioritized risks. It is incumbent on Framework users to continue to apply\nthe MANAGE function to deployed AI systems as methods, contexts, risks, and needs or\nexpectations from relevant AI actors evolve over time.\nPage 31\nNIST AI 100-1 AI RMF 1.0\nPractices related to managing AI risks are described in the NIST AI RMF Playbook. Table\n4 lists the MANAGE function\u2019s categories and subcategories.\nTable 4: Categories and subcategories for the MANAGE function.\nMANAGE 1: AI\nrisks based on\nassessments and\nother analytical\noutput from the\nMAP and MEASURE\nfunctions are\nprioritized,\nresponded to, and\nmanaged.\nMANAGE 1.1: A determination is made as to whether the AI\nsystem achieves its intended purposes and stated objectives and\nwhether its development or deployment should proceed.\nMANAGE 1.2: Treatment of documented AI risks is prioritized\nbased on impact, likelihood, and available resources or methods.\nMANAGE 1.3: Responses to the AI risks deemed high priority, as\nidentified by the MAP function, are developed, planned, and documented. Risk response options can include mitigating, transferring, avoiding, or accepting.\nMANAGE 1.4: Negative residual risks (defined as the sum of all\nunmitigated risks) to both downstream acquirers of AI systems\nand end users are documented.\nMANAGE 2:\nStrategies to\nmaximize AI\nbenefits and\nminimize negative\nimpacts are planned,\nprepared,\nimplemented,\ndocumented, and\ninformed by input\nfrom relevant AI\nactors.\nMANAGE 2.1: Resources required to manage AI risks are taken\ninto account \u2013 along with viable non-AI alternative systems, approaches, or methods \u2013 to reduce the magnitude or likelihood of\npotential impacts.\nMANAGE 2.2: Mechanisms are in place and applied to sustain\nthe value of deployed AI systems.\nMANAGE 2.3: Procedures are followed to respond to and recover\nfrom a previously unknown risk when it is identified.\nMANAGE 2.4: Mechanisms are in place and applied, and responsibilities are assigned and understood, to supersede, disengage, or\ndeactivate AI systems that demonstrate performance or outcomes\ninconsistent with intended use.\nMANAGE 3: AI\nrisks and benefits\nfrom third-party\nentities are\nmanaged.\nMANAGE 3.1: AI risks and benefits from third-party resources\nare regularly monitored, and risk controls are applied and\ndocumented.\nMANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and\nmaintenance.\nCategories Subcategories\nContinued on next page\nPage 32\nNIST AI 100-1 AI RMF 1.0\nTable 4: Categories and subcategories for the MANAGE function. (Continued)\nMANAGE 4: Risk\ntreatments,\nincluding response\nand recovery, and\ncommunication\nplans for the\nidentified and\nmeasured AI risks\nare documented and\nmonitored regularly.\nMANAGE 4.1: Post-deployment AI system monitoring plans\nare implemented, including mechanisms for capturing and evaluating input from users and other relevant AI actors, appeal\nand override, decommissioning, incident response, recovery, and\nchange management.\nMANAGE 4.2: Measurable activities for continual improvements\nare integrated into AI system updates and include regular engagement with interested parties, including relevant AI actors.\nMANAGE 4.3: Incidents and errors are communicated to relevant\nAI actors, including affected communities. Processes for tracking, responding to, and recovering from incidents and errors are\nfollowed and documented.\nCategories Subcategories\n6. AI RMF Profiles\nAI RMF use-case profiles are implementations of the AI RMF functions, categories, and\nsubcategories for a specific setting or application based on the requirements, risk tolerance,\nand resources of the Framework user: for example, an AI RMF hiring profile or an AI\nRMF fair housing profile. Profiles may illustrate and offer insights into how risk can be\nmanaged at various stages of the AI lifecycle or in specific sector, technology, or end-use\napplications. AI RMF profiles assist organizations in deciding how they might best manage\nAI risk that is well-aligned with their goals, considers legal/regulatory requirements and\nbest practices, and reflects risk management priorities.\nAI RMF temporal profiles are descriptions of either the current state or the desired, target\nstate of specific AI risk management activities within a given sector, industry, organization,\nor application context. An AI RMF Current Profile indicates how AI is currently being\nmanaged and the related risks in terms of current outcomes. A Target Profile indicates the\noutcomes needed to achieve the desired or target AI risk management goals.\nComparing Current and Target Profiles likely reveals gaps to be addressed to meet AI risk\nmanagement objectives. Action plans can be developed to address these gaps to fulfill\noutcomes in a given category or subcategory. Prioritization of gap mitigation is driven by\nthe user\u2019s needs and risk management processes. This risk-based approach also enables\nFramework users to compare their approaches with other approaches and to gauge the\nresources needed (e.g., staffing, funding) to achieve AI risk management goals in a costeffective, prioritized manner.\nPage 33\nNIST AI 100-1 AI RMF 1.0\nAI RMF cross-sectoral profiles cover risks of models or applications that can be used across\nuse cases or sectors. Cross-sectoral profiles can also cover how to govern, map, measure,\nand manage risks for activities or business processes common across sectors such as the\nuse of large language models, cloud-based services or acquisition.\nThis Framework does not prescribe profile templates, allowing for flexibility in implementation.\nPage 34\nNIST AI 100-1 AI RMF 1.0\nAppendix A:\nDescriptions of AI Actor Tasks from Figures 2 and 3\nAI Design tasks are performed during the Application Context and Data and Input phases\nof the AI lifecycle in Figure 2. AI Design actors create the concept and objectives of AI\nsystems and are responsible for the planning, design, and data collection and processing\ntasks of the AI system so that the AI system is lawful and fit-for-purpose. Tasks include articulating and documenting the system\u2019s concept and objectives, underlying assumptions,\ncontext, and requirements; gathering and cleaning data; and documenting the metadata\nand characteristics of the dataset. AI actors in this category include data scientists, domain experts, socio-cultural analysts, experts in the field of diversity, equity, inclusion,\nand accessibility, members of impacted communities, human factors experts (e.g., UX/UI\ndesign), governance experts, data engineers, data providers, system funders, product managers, third-party entities, evaluators, and legal and privacy governance.\nAI Development tasks are performed during the AI Model phase of the lifecycle in Figure\n2. AI Development actors provide the initial infrastructure of AI systems and are responsible for model building and interpretation tasks, which involve the creation, selection, calibration, training, and/or testing of models or algorithms. AI actors in this category include\nmachine learning experts, data scientists, developers, third-party entities, legal and privacy\ngovernance experts, and experts in the socio-cultural and contextual factors associated with\nthe deployment setting.\nAI Deployment tasks are performed during the Task and Output phase of the lifecycle in\nFigure 2. AI Deployment actors are responsible for contextual decisions relating to how\nthe AI system is used to assure deployment of the system into production. Related tasks\ninclude piloting the system, checking compatibility with legacy systems, ensuring regulatory compliance, managing organizational change, and evaluating user experience. AI\nactors in this category include system integrators, software developers, end users, operators and practitioners, evaluators, and domain experts with expertise in human factors,\nsocio-cultural analysis, and governance.\nOperation and Monitoring tasks are performed in the Application Context/Operate and\nMonitor phase of the lifecycle in Figure 2. These tasks are carried out by AI actors who are\nresponsible for operating the AI system and working with others to regularly assess system\noutput and impacts. AI actors in this category include system operators, domain experts, AI\ndesigners, users who interpret or incorporate the output of AI systems, product developers,\nevaluators and auditors, compliance experts, organizational management, and members of\nthe research community.\nTest, Evaluation, Verification, and Validation (TEVV) tasks are performed throughout\nthe AI lifecycle. They are carried out by AI actors who examine the AI system or its\ncomponents, or detect and remediate problems. Ideally, AI actors carrying out verification\nPage 35\nNIST AI 100-1 AI RMF 1.0\nand validation tasks are distinct from those who perform test and evaluation actions. Tasks\ncan be incorporated into a phase as early as design, where tests are planned in accordance\nwith the design requirement.\n\u2022 TEVV tasks for design, planning, and data may center on internal and external validation of assumptions for system design, data collection, and measurements relative\nto the intended context of deployment or application.\n\u2022 TEVV tasks for development (i.e., model building) include model validation and\nassessment.\n\u2022 TEVV tasks for deployment include system validation and integration in production,\nwith testing, and recalibration for systems and process integration, user experience,\nand compliance with existing legal, regulatory, and ethical specifications.\n\u2022 TEVV tasks for operations involve ongoing monitoring for periodic updates, testing,\nand subject matter expert (SME) recalibration of models, the tracking of incidents\nor errors reported and their management, the detection of emergent properties and\nrelated impacts, and processes for redress and response.\nHuman Factors tasks and activities are found throughout the dimensions of the AI lifecycle. They include human-centered design practices and methodologies, promoting the\nactive involvement of end users and other interested parties and relevant AI actors, incorporating context-specific norms and values in system design, evaluating and adapting end\nuser experiences, and broad integration of humans and human dynamics in all phases of the\nAI lifecycle. Human factors professionals provide multidisciplinary skills and perspectives\nto understand context of use, inform interdisciplinary and demographic diversity, engage\nin consultative processes, design and evaluate user experience, perform human-centered\nevaluation and testing, and inform impact assessments.\nDomain Expert tasks involve input from multidisciplinary practitioners or scholars who\nprovide knowledge or expertise in \u2013 and about \u2013 an industry sector, economic sector, context, or application area where an AI system is being used. AI actors who are domain\nexperts can provide essential guidance for AI system design and development, and interpret outputs in support of work performed by TEVV and AI impact assessment teams.\nAI Impact Assessment tasks include assessing and evaluating requirements for AI system\naccountability, combating harmful bias, examining impacts of AI systems, product safety,\nliability, and security, among others. AI actors such as impact assessors and evaluators\nprovide technical, human factor, socio-cultural, and legal expertise.\nProcurement tasks are conducted by AI actors with financial, legal, or policy management\nauthority for acquisition of AI models, products, or services from a third-party developer,\nvendor, or contractor.\nGovernance and Oversight tasks are assumed by AI actors with management, fiduciary,\nand legal authority and responsibility for the organization in which an AI system is dePage 36\nNIST AI 100-1 AI RMF 1.0\nsigned, developed, and/or deployed. Key AI actors responsible for AI governance include\norganizational management, senior leadership, and the Board of Directors. These actors\nare parties that are concerned with the impact and sustainability of the organization as a\nwhole.\nAdditional AI Actors\nThird-party entities include providers, developers, vendors, and evaluators of data, algorithms, models, and/or systems and related services for another organization or the organization\u2019s customers or clients. Third-party entities are responsible for AI design and\ndevelopment tasks, in whole or in part. By definition, they are external to the design, development, or deployment team of the organization that acquires its technologies or services.\nThe technologies acquired from third-party entities may be complex or opaque, and risk\ntolerances may not align with the deploying or operating organization.\nEnd users of an AI system are the individuals or groups that use the system for specific\npurposes. These individuals or groups interact with an AI system in a specific context. End\nusers can range in competency from AI experts to first-time technology end users.\nAffected individuals/communities encompass all individuals, groups, communities, or\norganizations directly or indirectly affected by AI systems or decisions based on the output\nof AI systems. These individuals do not necessarily interact with the deployed system or\napplication.\nOther AI actors may provide formal or quasi-formal norms or guidance for specifying\nand managing AI risks. They can include trade associations, standards developing organizations, advocacy groups, researchers, environmental groups, and civil society\norganizations.\nThe general public is most likely to directly experience positive and negative impacts of\nAI technologies. They may provide the motivation for actions taken by the AI actors. This\ngroup can include individuals, communities, and consumers associated with the context in\nwhich an AI system is developed or deployed.\nPage 37\nNIST AI 100-1 AI RMF 1.0\nAppendix B:\nHow AI Risks Differ from Traditional Software Risks\nAs with traditional software, risks from AI-based technology can be bigger than an enterprise, span organizations, and lead to societal impacts. AI systems also bring a set of\nrisks that are not comprehensively addressed by current risk frameworks and approaches.\nSome AI system features that present risks also can be beneficial. For example, pre-trained\nmodels and transfer learning can advance research and increase accuracy and resilience\nwhen compared to other models and approaches. Identifying contextual factors in the MAP\nfunction will assist AI actors in determining the level of risk and potential management\nefforts.\nCompared to traditional software, AI-specific risks that are new or increased include the\nfollowing:\n\u2022 The data used for building an AI system may not be a true or appropriate representation of the context or intended use of the AI system, and the ground truth may either\nnot exist or not be available. Additionally, harmful bias and other data quality issues\ncan affect AI system trustworthiness, which could lead to negative impacts.\n\u2022 AI system dependency and reliance on data for training tasks, combined with increased volume and complexity typically associated with such data.\n\u2022 Intentional or unintentional changes during training may fundamentally alter AI system performance.\n\u2022 Datasets used to train AI systems may become detached from their original and intended context or may become stale or outdated relative to deployment context.\n\u2022 AI system scale and complexity (many systems contain billions or even trillions of\ndecision points) housed within more traditional software applications.\n\u2022 Use of pre-trained models that can advance research and improve performance can\nalso increase levels of statistical uncertainty and cause issues with bias management,\nscientific validity, and reproducibility.\n\u2022 Higher degree of difficulty in predicting failure modes for emergent properties of\nlarge-scale pre-trained models.\n\u2022 Privacy risk due to enhanced data aggregation capability for AI systems.\n\u2022 AI systems may require more frequent maintenance and triggers for conducting corrective maintenance due to data, model, or concept drift.\n\u2022 Increased opacity and concerns about reproducibility.\n\u2022 Underdeveloped software testing standards and inability to document AI-based practices to the standard expected of traditionally engineered software for all but the\nsimplest of cases.\n\u2022 Difficulty in performing regular AI-based software testing, or determining what to\ntest, since AI systems are not subject to the same controls as traditional code development.\nPage 38\nNIST AI 100-1 AI RMF 1.0\n\u2022 Computational costs for developing AI systems and their impact on the environment\nand planet.\n\u2022 Inability to predict or detect the side effects of AI-based systems beyond statistical\nmeasures.\nPrivacy and cybersecurity risk management considerations and approaches are applicable\nin the design, development, deployment, evaluation, and use of AI systems. Privacy and\ncybersecurity risks are also considered as part of broader enterprise risk management considerations, which may incorporate AI risks. As part of the effort to address AI trustworthiness characteristics such as \u201cSecure and Resilient\u201d and \u201cPrivacy-Enhanced,\u201d organizations\nmay consider leveraging available standards and guidance that provide broad guidance to\norganizations to reduce security and privacy risks, such as, but not limited to, the NIST Cybersecurity Framework, the NIST Privacy Framework, the NIST Risk Management Framework, and the Secure Software Development Framework. These frameworks have some\nfeatures in common with the AI RMF. Like most risk management approaches, they are\noutcome-based rather than prescriptive and are often structured around a Core set of functions, categories, and subcategories. While there are significant differences between these\nframeworks based on the domain addressed \u2013 and because AI risk management calls for\naddressing many other types of risks \u2013 frameworks like those mentioned above may inform\nsecurity and privacy considerations in the MAP, MEASURE, and MANAGE functions of the\nAI RMF.\nAt the same time, guidance available before publication of this AI RMF does not comprehensively address many AI system risks. For example, existing frameworks and guidance\nare unable to:\n\u2022 adequately manage the problem of harmful bias in AI systems;\n\u2022 confront the challenging risks related to generative AI;\n\u2022 comprehensively address security concerns related to evasion, model extraction, membership inference, availability, or other machine learning attacks;\n\u2022 account for the complex attack surface of AI systems or other security abuses enabled\nby AI systems; and\n\u2022 consider risks associated with third-party AI technologies, transfer learning, and offlabel use where AI systems may be trained for decision-making outside an organization\u2019s security controls or trained in one domain and then \u201cfine-tuned\u201d for another.\nBoth AI and traditional software technologies and systems are subject to rapid innovation.\nTechnology advances should be monitored and deployed to take advantage of those developments and work towards a future of AI that is both trustworthy and responsible.\nPage 39\nNIST AI 100-1 AI RMF 1.0\nAppendix C:\nAI Risk Management and Human-AI Interaction\nOrganizations that design, develop, or deploy AI systems for use in operational settings\nmay enhance their AI risk management by understanding current limitations of humanAI interaction. The AI RMF provides opportunities to clearly define and differentiate the\nvarious human roles and responsibilities when using, interacting with, or managing AI\nsystems.\nMany of the data-driven approaches that AI systems rely on attempt to convert or represent\nindividual and social observational and decision-making practices into measurable quantities. Representing complex human phenomena with mathematical models can come at the\ncost of removing necessary context. This loss of context may in turn make it difficult to\nunderstand individual and societal impacts that are key to AI risk management efforts.\nIssues that merit further consideration and research include:\n1. Human roles and responsibilities in decision making and overseeing AI systems\nneed to be clearly defined and differentiated. Human-AI configurations can span\nfrom fully autonomous to fully manual. AI systems can autonomously make decisions, defer decision making to a human expert, or be used by a human decision\nmaker as an additional opinion. Some AI systems may not require human oversight,\nsuch as models used to improve video compression. Other systems may specifically\nrequire human oversight.\n2. Decisions that go into the design, development, deployment, evaluation, and use\nof AI systems reflect systemic and human cognitive biases. AI actors bring their\ncognitive biases, both individual and group, into the process. Biases can stem from\nend-user decision-making tasks and be introduced across the AI lifecycle via human\nassumptions, expectations, and decisions during design and modeling tasks. These\nbiases, which are not necessarily always harmful, may be exacerbated by AI system\nopacity and the resulting lack of transparency. Systemic biases at the organizational\nlevel can influence how teams are structured and who controls the decision-making\nprocesses throughout the AI lifecycle. These biases can also influence downstream\ndecisions by end users, decision makers, and policy makers and may lead to negative\nimpacts.\n3. Human-AI interaction results vary. Under certain conditions \u2013 for example, in\nperceptual-based judgment tasks \u2013 the AI part of the human-AI interaction can amplify human biases, leading to more biased decisions than the AI or human alone.\nWhen these variations are judiciously taken into account in organizing human-AI\nteams, however, they can result in complementarity and improved overall performance.\nPage 40\nNIST AI 100-1 AI RMF 1.0\n4. Presenting AI system information to humans is complex. Humans perceive and\nderive meaning from AI system output and explanations in different ways, reflecting\ndifferent individual preferences, traits, and skills.\nThe GOVERN function provides organizations with the opportunity to clarify and define\nthe roles and responsibilities for the humans in the Human-AI team configurations and\nthose who are overseeing the AI system performance. The GOVERN function also creates\nmechanisms for organizations to make their decision-making processes more explicit, to\nhelp counter systemic biases.\nThe MAP function suggests opportunities to define and document processes for operator\nand practitioner proficiency with AI system performance and trustworthiness concepts, and\nto define relevant technical standards and certifications. Implementing MAP function categories and subcategories may help organizations improve their internal competency for\nanalyzing context, identifying procedural and system limitations, exploring and examining\nimpacts of AI-based systems in the real world, and evaluating decision-making processes\nthroughout the AI lifecycle.\nThe GOVERN and MAP functions describe the importance of interdisciplinarity and demographically diverse teams and utilizing feedback from potentially impacted individuals and\ncommunities. AI actors called out in the AI RMF who perform human factors tasks and\nactivities can assist technical teams by anchoring in design and development practices to\nuser intentions and representatives of the broader AI community, and societal values. These\nactors further help to incorporate context-specific norms and values in system design and\nevaluate end user experiences \u2013 in conjunction with AI systems.\nAI risk management approaches for human-AI configurations will be augmented by ongoing research and evaluation. For example, the degree to which humans are empowered\nand incentivized to challenge AI system output requires further studies. Data about the frequency and rationale with which humans overrule AI system output in deployed systems\nmay be useful to collect and analyze.\nPage 41\nNIST AI 100-1 AI RMF 1.0\nAppendix D:\nAttributes of the AI RMF\nNIST described several key attributes of the AI RMF when work on the Framework first\nbegan. These attributes have remained intact and were used to guide the AI RMF\u2019s development. They are provided here as a reference.\nThe AI RMF strives to:\n1. Be risk-based, resource-efficient, pro-innovation, and voluntary.\n2. Be consensus-driven and developed and regularly updated through an open, transparent process. All stakeholders should have the opportunity to contribute to the AI\nRMF\u2019s development.\n3. Use clear and plain language that is understandable by a broad audience, including\nsenior executives, government officials, non-governmental organization leadership,\nand those who are not AI professionals \u2013 while still of sufficient technical depth to\nbe useful to practitioners. The AI RMF should allow for communication of AI risks\nacross an organization, between organizations, with customers, and to the public at\nlarge.\n4. Provide common language and understanding to manage AI risks. The AI RMF\nshould offer taxonomy, terminology, definitions, metrics, and characterizations for\nAI risk.\n5. Be easily usable and fit well with other aspects of risk management. Use of the\nFramework should be intuitive and readily adaptable as part of an organization\u2019s\nbroader risk management strategy and processes. It should be consistent or aligned\nwith other approaches to managing AI risks.\n6. Be useful to a wide range of perspectives, sectors, and technology domains. The AI\nRMF should be universally applicable to any AI technology and to context-specific\nuse cases.\n7. Be outcome-focused and non-prescriptive. The Framework should provide a catalog\nof outcomes and approaches rather than prescribe one-size-fits-all requirements.\n8. Take advantage of and foster greater awareness of existing standards, guidelines, best\npractices, methodologies, and tools for managing AI risks \u2013 as well as illustrate the\nneed for additional, improved resources.\n9. Be law- and regulation-agnostic. The Framework should support organizations\u2019\nabilities to operate under applicable domestic and international legal or regulatory\nregimes.\n10. Be a living document. The AI RMF should be readily updated as technology, understanding, and approaches to AI trustworthiness and uses of AI change and as stakeholders learn from implementing AI risk management generally and this framework\nin particular.\nPage 42\nThis publication is available free of charge from:\nhttps://doi.org/10.6028/NIST.AI.100-1\n\n\n\n", "metadata": {"country": "USA", "year": "2023", "legally_binding": "no", "binding_proof": "Page 7:The Framework is intended to be voluntary, rights-preserving, non-sector-specific, and use-case agnostic, providing flexibility to organizations of all sizes and in all sectors and throughout society to implement the approaches in the Framework. ", "date": "01/26/2023 ", "regulator": " ", "type": "Framework", "status": "enacted ", "language": "EN", "use_cases": "[1,2, 3, 4, 5, 6]"}}
{"_id": "686749aca8f60734255f3d24", "title": "Removing Barriers to American Leadership in Artificial Intelligence", "source": "https://www.whitehouse.gov/presidential-actions/2025/01/removing-barriers-to-american-leadership-in-artificial-intelligence/?utm_source=chatgpt.com", "text": "  \nREMOVING BARRIERS TO AMERICAN LEADERSHIP IN ARTIFICIAL INTELLIGENCE\nThe White House\nJanuary 23, 2025\nBy the authority vested in me as President by the Constitution and the laws of the United States of America, it is hereby ordered as follows:\n\n\nSection 1. Purpose. The United States has long been at the forefront of artificial intelligence (AI) innovation, driven by the strength of our free markets, world-class research institutions, and entrepreneurial spirit. To maintain this leadership, we must develop AI systems that are free from ideological bias or engineered social agendas. With the right Government policies, we can solidify our position as the global leader in AI and secure a brighter future for all Americans.\nThis order revokes certain existing AI policies and directives that act as barriers to American AI innovation, clearing a path for the United States to act decisively to retain global leadership in artificial intelligence.\n\n\nSec. 2. Policy. It is the policy of the United States to sustain and enhance America\u2019s global AI dominance in order to promote human flourishing, economic competitiveness, and national security.\n\n\nSec. 3. Definition. For the purposes of this order, \u201cartificial intelligence\u201d or \u201cAI\u201d has the meaning set forth in 15 U.S.C. 9401(3).\n\n\nSec. 4. Developing an Artificial Intelligence Action Plan. (a) Within 180 days of this order, the Assistant to the President for Science and Technology (APST), the Special Advisor for AI and Crypto, and the Assistant to the President for National Security Affairs (APNSA), in coordination with the Assistant to the President for Economic Policy, the Assistant to the President for Domestic Policy, the Director of the Office of Management and Budget (OMB Director), and the heads of such executive departments and agencies (agencies) as the APST and APNSA deem relevant, shall develop and submit to the President an action plan to achieve the policy set forth in section 2 of this order.\n\n\nSec. 5. Implementation of Order Revocation. (a) The APST, the Special Advisor for AI and Crypto, and the APNSA shall immediately review, in coordination with the heads of all agencies as they deem relevant, all policies, directives, regulations, orders, and other actions taken pursuant to the revoked Executive Order 14110 of October 30, 2023 (Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence). The APST, the Special Advisor for AI and Crypto, and the APNSA shall, in coordination with the heads of relevant agencies, identify any actions taken pursuant to Executive Order 14110 that are or may be inconsistent with, or present obstacles to, the policy set forth in section 2 of this order. For any such agency actions identified, the heads of agencies shall, as appropriate and consistent with applicable law, suspend, revise, or rescind such actions, or propose suspending, revising, or rescinding such actions. If in any case such suspension, revision, or rescission cannot be finalized immediately, the APST and the heads of agencies shall promptly take steps to provide all available exemptions authorized by any such orders, rules, regulations, guidelines, or policies, as appropriate and consistent with applicable law, until such action can be finalized.\n(b) Within 60 days of this order, the OMB Director, in coordination with the APST, shall revise OMB Memoranda M-24-10 and M-24-18 as necessary to make them consistent with the policy set forth in section 2 of this order.\n\n\nSec. 6. General Provisions. (a) Nothing in this order shall be construed to impair or otherwise affect:\n(i) the authority granted by law to an executive department or agency, or the head thereof; or\n(ii) the functions of the Director of the Office of Management and Budget relating to budgetary, administrative, or legislative proposals.\n(b) This order shall be implemented consistent with applicable law and subject to the availability of appropriations.\n(c) This order is not intended to, and does not, create any right or benefit, substantive or procedural, enforceable at law or in equity by any party against the United States, its departments, agencies, or entities, its officers, employees, or agents, or any other person.\n\nTHE WHITE HOUSE,\nJanuary 23, 2025.\n\n\n", "metadata": {"country": "USA", "year": "2025", "legally_binding": "yes", "binding_proof": " ", "date": "01/23/2025 ", "regulator": " ", "type": "Executive Order ", "status": "enacted ", "language": "EN", "use_cases": "[1,2, 3, 4, 5, 6]"}}
